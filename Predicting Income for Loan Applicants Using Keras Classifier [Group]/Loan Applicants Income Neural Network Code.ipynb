{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Group Assignment 3_7",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xpr2eRhqGvI4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04ff2dcb-cc2b-4afd-a864-044073646c4b"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "!pip install dmba\n",
        "import dmba\n",
        "from dmba import classificationSummary\n",
        "\n",
        "!pip install eli5\n",
        "import eli5\n",
        "from eli5.sklearn import PermutationImportance\n",
        "\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, KFold\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.datasets import make_moons\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.layers import Dense\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "import joblib"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: dmba in /usr/local/lib/python3.6/dist-packages (0.0.13)\n",
            "Requirement already satisfied: eli5 in /usr/local/lib/python3.6/dist-packages (0.10.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from eli5) (1.4.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from eli5) (1.15.0)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.6/dist-packages (from eli5) (0.22.2.post1)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.6/dist-packages (from eli5) (0.10.1)\n",
            "Requirement already satisfied: attrs>16.0.0 in /usr/local/lib/python3.6/dist-packages (from eli5) (20.3.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.6/dist-packages (from eli5) (2.11.2)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.6/dist-packages (from eli5) (0.8.7)\n",
            "Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from eli5) (1.19.5)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.18->eli5) (1.0.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2->eli5) (1.1.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v2oRAW7WGvI_"
      },
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount('/content/gdrive',force_remount=True)\n",
        "\n",
        "df = pd.read_csv('USCensusTraining.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iy7Qzmk0GnLw"
      },
      "source": [
        "EDA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "gHLs52-6GvJA",
        "outputId": "1685cb76-bd46-448f-9210-790bd63a30d1"
      },
      "source": [
        "# EDA \n",
        "\n",
        "# countplot for age w.r.t. income\n",
        "plt.figure(figsize=(26, 10))\n",
        "sns.countplot(x = \"age\", data = df, hue = \"income\")\n",
        "\n",
        "# countplot for workclass w.r.t. income\n",
        "plt.figure(figsize=(16, 6))\n",
        "sns.countplot(x = \"workclass\", data = df, hue = \"income\")\n",
        "\n",
        "# countplot for education w.r.t. income\n",
        "plt.figure(figsize=(20, 8))\n",
        "sns.countplot(x = \"education\", data = df, hue = \"income\")\n",
        "\n",
        "# countplot for occupation w.r.t. income\n",
        "plt.figure(figsize=(25, 10))\n",
        "sns.countplot(x = \"occupation\", data = df, hue = \"income\")\n",
        "\n",
        "# countplot for marital-status w.r.t. income\n",
        "plt.figure(figsize=(25, 10))\n",
        "sns.countplot(x = \"marital-status\", data = df, hue = \"income\")\n",
        "\n",
        "# countplot for relationship w.r.t. income\n",
        "plt.figure(figsize=(25, 10))\n",
        "sns.countplot(x = \"relationship\", data = df, hue = \"income\")\n",
        "\n",
        "# countplot for hours-per-week w.r.t. income\n",
        "plt.figure(figsize=(25,12))\n",
        "sns.countplot(x = \"hours-per-week\", data = df, hue = \"income\")\n",
        "\n",
        "# cross-Tabulation to show the perfect correlation between education & education-num\n",
        "pd.crosstab(df[\"education\"], df[\"education-num\"])\n",
        "\n",
        "# cross tabulation on workclass and occupation\n",
        "pd.crosstab(df['workclass'], df[\"occupation\"])\n",
        "\n",
        "# cross tabulation on marital-status and relationship\n",
        "pd.crosstab(df['marital-status'], df[\"relationship\"])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>relationship</th>\n",
              "      <th>Husband</th>\n",
              "      <th>Not-in-family</th>\n",
              "      <th>Other-relative</th>\n",
              "      <th>Own-child</th>\n",
              "      <th>Unmarried</th>\n",
              "      <th>Wife</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>marital-status</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Divorced</th>\n",
              "      <td>0</td>\n",
              "      <td>1850</td>\n",
              "      <td>90</td>\n",
              "      <td>250</td>\n",
              "      <td>1245</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Married-AF-spouse</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Married-civ-spouse</th>\n",
              "      <td>10059</td>\n",
              "      <td>12</td>\n",
              "      <td>100</td>\n",
              "      <td>66</td>\n",
              "      <td>0</td>\n",
              "      <td>1204</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Married-spouse-absent</th>\n",
              "      <td>0</td>\n",
              "      <td>172</td>\n",
              "      <td>26</td>\n",
              "      <td>37</td>\n",
              "      <td>93</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Never-married</th>\n",
              "      <td>0</td>\n",
              "      <td>3656</td>\n",
              "      <td>431</td>\n",
              "      <td>3462</td>\n",
              "      <td>676</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Separated</th>\n",
              "      <td>0</td>\n",
              "      <td>327</td>\n",
              "      <td>45</td>\n",
              "      <td>82</td>\n",
              "      <td>332</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Widowed</th>\n",
              "      <td>0</td>\n",
              "      <td>426</td>\n",
              "      <td>36</td>\n",
              "      <td>13</td>\n",
              "      <td>294</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "relationship           Husband  Not-in-family  ...  Unmarried  Wife\n",
              "marital-status                                 ...                 \n",
              "Divorced                     0           1850  ...       1245     0\n",
              "Married-AF-spouse            5              0  ...          0     9\n",
              "Married-civ-spouse       10059             12  ...          0  1204\n",
              "Married-spouse-absent        0            172  ...         93     0\n",
              "Never-married                0           3656  ...        676     0\n",
              "Separated                    0            327  ...        332     0\n",
              "Widowed                      0            426  ...        294     0\n",
              "\n",
              "[7 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1872x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1152x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABa8AAAJNCAYAAAA21omXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzde7CddX3v8c8XglLkKkSMCWnSwuEaCCRQRmWGnlbATAXqIF6wQY5T2gpemA6OtTPYSUeLk6PWSo9UkUsUi2hROB0qcsTLWBVIgHIRSqjcEqNGoErtBAn8zh9ZxA0JsIG99voleb1m1uy1fs9lf9f+i7zn4XmqtRYAAAAAAOjJVqMeAAAAAAAAnkq8BgAAAACgO+I1AAAAAADdEa8BAAAAAOiOeA0AAAAAQHfEawAAAAAAujNl1AMMw2677dZmzZo16jEAAAAAAHgGy5Yt+1lrberGtm2W8XrWrFlZunTpqMcAAAAAAOAZVNW9T7fNbUMAAAAAAOiOeA0AAAAAQHfEawAAAAAAurNZ3vMaAABeiEcffTQrVqzImjVrRj1K17bddtvMmDEj22yzzahHAQBgMyReAwDAU6xYsSI77LBDZs2alaoa9Thdaq3lgQceyIoVKzJ79uxRjwMAwGbIbUMAAOAp1qxZk1133VW4fgZVlV133dXV6QAADI14DQAAGyFcPzt/IwAAhkm8BgCASfDKV75y1CMAAMAmRbwGAIBJ8N3vfnfUIwAAwCZFvAYAgEmw/fbbJ0m++c1v5sgjj8wJJ5yQffbZJyeddFJaa0mS66+/Pq985Stz0EEH5bDDDsvDDz+cNWvW5JRTTsmcOXNy8MEH5xvf+EaS5MILL8zxxx+f17zmNZk1a1bOOeecfPSjH83BBx+cww8/PA8++GCS5D/+4z9yzDHHZN68eTniiCNyxx13jOYPAAAAz9GUUQ8AAABbmhtvvDG33XZbXvGKV+RVr3pV/vVf/zWHHXZY3vjGN+YLX/hCDj300PziF7/Ib/zGb+TjH/94qiq33HJL7rjjjhx11FG58847kyS33nprbrzxxqxZsyZ77rlnPvzhD+fGG2/MGWeckSVLluQ973lPTj311Jx77rnZa6+9cu211+Yd73hHrrnmmhH/BQAA4NmJ1wAAMMkOO+ywzJgxI0kyd+7c3HPPPdlpp50ybdq0HHrooUmSHXfcMUnyne98J+985zuTJPvss09+8zd/c328/t3f/d3ssMMO2WGHHbLTTjvlda97XZJkzpw5ufnmm/Nf//Vf+e53v5s3vOEN63/3I488MmnfEwAAXgjxGgAAJtmLX/zi9e+33nrrrF279gWfZ6uttlr/eauttsratWvz+OOPZ+edd85NN930wgYGAIARcM9rAADowN57751Vq1bl+uuvT5I8/PDDWbt2bY444ohcfPHFSZI777wz9913X/bee+9xnXPHHXfM7Nmz88UvfjFJ0lrLv/3bvw3nCwAAwAQTrwEAoAMvetGL8oUvfCHvfOc7c9BBB+U1r3lN1qxZk3e84x15/PHHM2fOnLzxjW/MhRde+KQrrp/NxRdfnM985jM56KCDsv/+++fyyy8f4rcAAICJU0882XxzMn/+/LZ06dJRjwEAwCbq9ttvz7777jvqMTYJ/lYAALwQVbWstTZ/Y9tceQ0AAAAAQHfEawAAAAAAuiNeAwAAAADQHfEaAAAAAIDuiNcAAAAAAHRHvAYAAAAAoDviNQAAbIa++c1vZqeddsrcuXMzd+7cLFq0aP22r371q9l7772z55575uyzz16/fuSRR2bp0qVJkrvvvjt77bVXrrrqqkmfHQAAkmTKqAcAAIDezTtzyYSeb9nihc/ruF/96ld59NFH85KXvGRc+x9xxBH553/+5yetPfbYYznttNNy9dVXZ8aMGTn00ENz7LHHZr/99lu/z4oVK3LMMcfkIx/5SI4++ujnNSsAALxQW3S8nuh/hEyE5/sPGQAANl+33357zjvvvFx22WW57LLLcvDBBz/vc1133XXZc88981u/9VtJkje96U25/PLL18frVatWZeHChfngBz+YY489dkLmBwCA58NtQwAAoEO//OUvc8EFF+TVr351/viP/zj77bdfbr755vXh+owzzlh/S5Cxr7G3Afne976Xgw46KK997Wtz2223JUlWrlyZPfbYY/0+M2bMyMqVK9d/Pvnkk3P66afnhBNOmKRvCgAAG7dFX3kNAAC9mjZtWg488MCcd9552WeffTbY/rGPfewZjz/kkENy7733Zvvtt8+VV16Z448/PsuXL3/W3/v7v//7+dznPpe3ve1t2W677Z73/AAA8EK58hoAADr0pS99KdOnT8/rX//6LFq0KPfee++Ttj/bldc77rhjtt9++yTJggUL8uijj+ZnP/tZpk+fnvvvv3/9eVasWJHp06ev//ze9743hx56aN7whjdk7dq1k/BNAQBg41x5DQAAHTrqqKNy1FFH5YEHHsjnPve5HHfccdltt91y3nnnZdasWc965fWPf/zj7L777qmqXHfddXn88cez6667Zuedd87y5ctz9913Z/r06bnkkkvy+c9//knH/u3f/m3e8pa35O1vf3suvPDCVNUwvyoAAGyUK68BAKBju+66a9797nfnpptuyoc+9KFsvfXW4zruS1/6Ug444IAcdNBBede73pVLLrkkVZUpU6bknHPOydFHH5199903J554Yvbff/8nHVtVueiii7Jq1aq8973vzY9+9KMsWLBgGF8PAACeVrXWRj3DhJs/f35bunTps+4378wlkzDNc7Ns8cJRjwAAsMW7/fbbs++++456jE2CvxUAAC9EVS1rrc3f2DZXXgMAAAAA0B3xGgAAAACA7ojXAAAAAAB0R7wGAAAAAKA74jUAAAAAAN0RrwEAAAAA6M7Q4nVV7VFV36iqH1TVbVX17sH6X1XVyqq6afBaMOaYv6iqu6rq36vq6DHrxwzW7qqq9w1rZgAA2FS87W1vy+zZszN37tzMnTs3N910U5KktZZ3vetd2XPPPXPggQfmhhtuSJLcc889OeCAA9Yf/+lPfzrz5s3LQw89NJL5AQDg2UwZ4rnXJvnz1toNVbVDkmVVdfVg28daa/977M5VtV+SNyXZP8krkvy/qvofg81/n+Q1SVYkub6qrmit/WCIswMAwHr3LZozoeebedYtz7rPQw89lF122eUZ91m8eHFOOOGEJ639y7/8S5YvX57ly5fn2muvzZ/92Z/l2muvfdI+n/3sZ/OJT3wi11xzzbP+DgAAGJWhXXndWlvVWrth8P7hJLcnmf4MhxyX5JLW2iOttbuT3JXksMHrrtbaD1trv0pyyWBfAADYbM2fPz8nnXRSrrnmmrTWxn3c5ZdfnoULF6aqcvjhh+c///M/s2rVqvXbL7300px99tn52te+lt12220YowMAwISYlHteV9WsJAcneeKSj9Or6uaqOr+qnrjUY3qS+8cctmKw9nTrAACw2brzzjvz5je/Oeecc07222+/fOhDH8qPfvSjJ+3zl3/5lznwwANzxhln5JFHHkmSrFy5Mnvsscf6fWbMmJGVK1cmSe69996cfvrp+drXvpaXv/zlk/dlAADgeRh6vK6q7ZP8U5L3tNZ+keSTSX47ydwkq5J8ZIJ+z6lVtbSqlq5evXoiTgkAACOz9dZb5w/+4A9y2WWX5dvf/nZ++MMfZubMmbnuuuuSJH/zN3+TO+64I9dff30efPDBfPjDH37Wc06dOjUzZ87MpZdeOuzxAQDgBRtqvK6qbbIuXF/cWrssSVprP2mtPdZaezzJp7PutiBJsjLJHmMOnzFYe7r1J2mtfaq1Nr+1Nn/q1KkT/2UAAGCS/fznP88//MM/5Nhjj83y5ctz/vnn58ADD0ySTJs2LVWVF7/4xTnllFPWR+3p06fn/vt//T8urlixItOnr/sfF7fbbrtceeWVOffcc3PxxRdP/hcCAIDnYGjxuqoqyWeS3N5a++iY9WljdvvDJLcO3l+R5E1V9eKqmp1kryTXJbk+yV5VNbuqXpR1D3W8YlhzAwBAD9761rfmkEMOyd13350lS5bkW9/6VhYuXJhtt902Sdbfx7q1lq985Ss54IADkiTHHntslixZktZavv/972ennXbKtGm//k/wl73sZfnqV7+a97///bnqqqsm/4sBAMA4TRniuV+V5I+S3FJVNw3W3p/kzVU1N0lLck+SP0mS1tptVXVpkh8kWZvktNbaY0lSVacnuSrJ1knOb63dNsS5AQBg5E488cRceOGFmTJl4//JftJJJ2X16tVprWXu3Lk599xzkyQLFizIlVdemT333DPbbbddLrjggg2OnT17dq644oosWLAgX/7yl3PDDTckSf70T/90eF8IAACeo3ouTy7fVMyfP78tXbr0Wfebd+aSSZjmuVm2eOGoRwAA2OLdfvvt2XfffUc9xibB3woAgBeiqpa11uZvbNvQH9gIAAAAAADPlXgNAAAAAEB3xGsAAAAAALojXgMAwEZsjs+GmWj+RgAADJN4DQAAT7HtttvmgQceEGefQWstDzzwQLbddttRjwIAwGZqyqgHAACA3syYMSMrVqzI6tWrRz1K17bddtvMmDFj1GMAALCZEq8B2OTNO3PJqEfYwLLFC0c9AvACbLPNNpk9e/aoxwAAgC2a24YAAAAAANAd8RoAAAAAgO6I1wAAAAAAdEe8BgAAAACgOx7YCACwCfBgUgAAYEvjymsAAAAAALojXgMAAAAA0B3xGgAAAACA7ojXAAAAAAB0R7wGAAAAAKA74jUAAAAAAN0RrwEAAAAA6I54DQAAAABAd8RrAAAAAAC6I14DAAAAANAd8RoAAAAAgO6I1wAAAAAAdEe8BgAAAACgO+I1AAAAAADdEa8BAAAAAOiOeA0AAAAAQHfEawAAAAAAuiNeAwAAAADQHfEaAAAAAIDuiNcAAAAAAHRHvAYAAAAAoDviNQAAAAAA3RGvAQAAAADojngNAAAAAEB3xGsAAAAAALojXgMAAAAA0B3xGgAAAACA7ojXAAAAAAB0R7wGAAAAAKA74jUAAAAAAN0RrwEAAAAA6I54DQAAAABAd8RrAAAAAAC6I14DAAAAANAd8RoAAAAAgO6I1wAAAAAAdEe8BgAAAACgO+I1AAAAAADdEa8BAAAAAOiOeA0AAAAAQHfEawAAAAAAuiNeAwAAAADQHfEaAAAAAIDuiNcAAAAAAHRHvAYAAAAAoDviNQAAAAAA3RGvAQAAAADojngNAAAAAEB3xGsAAAAAALojXgMAAAAA0B3xGgAAAACA7ojXAAAAAAB0R7wGAAAAAKA74jUAAAAAAN0RrwEAAAAA6I54DQAAAABAd8RrAAAAAAC6I14DAAAAANAd8RoAAAAAgO6I1wAAAAAAdEe8BgAAAACgO+I1AAAAAADdEa8BAAAAAOiOeA0AAAAAQHfEawAAAAAAuiNeAwAAAADQHfEaAAAAAIDuiNcAAAAAAHRHvAYAAAAAoDviNQAAAAAA3Zky6gEAgE3PvDOXjHqEDSxbvHDUIwAAADCBXHkNAAAAAEB3xGsAAAAAALojXgMAAAAA0B3xGgAAAACA7ojXAAAAAAB0R7wGAAAAAKA74jUAAAAAAN0RrwEAAAAA6M7Q4nVV7VFV36iqH1TVbVX17sH6S6vq6qpaPvi5y2C9qurvququqrq5qg4Zc66TB/svr6qThzUzAAAAAAB9GOaV12uT/Hlrbb8khyc5rar2S/K+JF9vre2V5OuDz0ny2iR7DV6nJvlksi52J/lAkt9JcliSDzwRvAEAAAAA2DwNLV631la11m4YvH84ye1Jpic5LslFg90uSnL84P1xSZa0db6fZOeqmpbk6CRXt9YebK09lOTqJMcMa24AAAAAAEZvUu55XVWzkhyc5Noku7fWVg02/TjJ7oP305PcP+awFYO1p1sHAAAAAGAzNfR4XVXbJ/mnJO9prf1i7LbWWkvSJuj3nFpVS6tq6erVqyfilAAAAAAAjMhQ43VVbZN14fri1tplg+WfDG4HksHPnw7WVybZY8zhMwZrT7f+JK21T7XW5rfW5k+dOnVivwgAAAAAAJNqaPG6qirJZ5Lc3lr76JhNVyQ5efD+5CSXj1lfWOscnuTng9uLXJXkqKraZfCgxqMGawAAAAAAbKamDPHcr0ryR0luqaqbBmvvT3J2kkur6u1J7k1y4mDblUkWJLkryX8nOSVJWmsPVtVfJ7l+sN+i1tqDQ5wbAAAAAIARG1q8bq19J0k9zebf28j+LclpT3Ou85OcP3HTAQAAAADQs6E/sBEAAAAAAJ4r8RoAAAAAgO6I1wAAAAAAdEe8BgAAAACgO+I1AAAAAADdEa8BAAAAAOiOeA0AAAAAQHfEawAAAAAAuiNeAwAAAADQHfEaAAAAAIDuiNcAAAAAAHRHvAYAAAAAoDviNQAAAAAA3RGvAQAAAADojngNAAAAAEB3xGsAAAAAALojXgMAAAAA0B3xGgAAAACA7ojXAAAAAAB0R7wGAAAAAKA74jUAAAAAAN0RrwEAAAAA6I54DQAAAABAd8RrAAAAAAC6I14DAAAAANAd8RoAAAAAgO6I1wAAAAAAdEe8BgAAAACgO+I1AAAAAADdEa8BAAAAAOiOeA0AAAAAQHfEawAAAAAAuiNeAwAAAADQHfEaAAAAAIDuiNcAAAAAAHRHvAYAAAAAoDviNQAAAAAA3RGvAQAAAADojngNAAAAAEB3xGsAAAAAALojXgMAAAAA0B3xGgAAAACA7ojXAAAAAAB0Z8qoBwDY3Mw7c8moR9jAssULRz0CAAAAwHPiymsAAAAAALojXgMAAAAA0B3xGgAAAACA7ojXAAAAAAB0R7wGAAAAAKA74jUAAAAAAN0RrwEAAAAA6I54DQAAAABAd8RrAAAAAAC6I14DAAAAANAd8RoAAAAAgO6I1wAAAAAAdEe8BgAAAACgO+I1AAAAAADdEa8BAAAAAOiOeA0AAAAAQHfEawAAAAAAuiNeAwAAAADQHfEaAAAAAIDuiNcAAAAAAHRHvAYAAAAAoDviNQAAAAAA3RGvAQAAAADojngNAAAAAEB3xGsAAAAAALojXgMAAAAA0B3xGgAAAACA7ojXAAAAAAB0R7wGAAAAAKA74jUAAAAAAN0RrwEAAAAA6I54DQAAAABAd6aMegC2LPPOXDLqETawbPHCUY8AAAAAADyFK68BAAAAAOiOeA0AAAAAQHfEawAAAAAAuiNeAwAAAADQHfEaAAAAAIDuiNcAAAAAAHRHvAYAAAAAoDviNQAAAAAA3RGvAQAAAADojngNAAAAAEB3xGsAAAAAALojXgMAAAAA0B3xGgAAAACA7ojXAAAAAAB0Z2jxuqrOr6qfVtWtY9b+qqpWVtVNg9eCMdv+oqruqqp/r6qjx6wfM1i7q6reN6x5AQAAAADoxzCvvL4wyTEbWf9Ya23u4HVlklTVfknelGT/wTH/p6q2rqqtk/x9ktcm2S/Jmwf7AgAAAACwGZsyrBO31r5dVbPGuftxSS5prT2S5O6quivJYYNtd7XWfpgkVXXJYN8fTPC4AAAAAAB0ZBT3vD69qm4e3FZkl8Ha9CT3j9lnxWDt6dYBAAAAANiMTXa8/mSS304yN8mqJB+ZqBNX1alVtbSqlq5evXqiTgsAAAAAwAhMarxurf2ktfZYa+3xJJ/Or28NsjLJHmN2nTFYe7r1jZ37U621+a21+VOnTp344QEAAAAAmDRDu+f1xlTVtNbaqsHHP0xy6+D9FUk+X1UfTfKKJHsluS5JJdmrqmZnXbR+U5K3TObMbP7uWzRn1CNsYOZZt4x6BAAAAAAYqaHF66r6xyRHJtmtqlYk+UCSI6tqbpKW5J4kf5IkrbXbqurSrHsQ49okp7XWHhuc5/QkVyXZOsn5rbXbhjUzAAAAAAB9GFq8bq29eSPLn3mG/T+Y5IMbWb8yyZUTOBoAAAAAAJ2b7Ac2AgAAAADAsxKvAQAAAADojngNAAAAAEB3xGsAAAAAALojXgMAAAAA0B3xGgAAAACA7ojXAAAAAAB0R7wGAAAAAKA74jUAAAAAAN0RrwEAAAAA6I54DQAAAABAd6aMegAAhu++RXNGPcIGZp51y6hHAAAAADo2riuvq+rr41kDAAAAAICJ8IxXXlfVtkm2S7JbVe2SpAabdkwyfcizAQAAAACwhXq224b8SZL3JHlFkmX5dbz+RZJzhjgXAAAAAABbsGeM1621jyf5eFW9s7X2iUmaCQAAAACALdy4HtjYWvtEVb0yyayxx7TWlgxpLgAAAAAAtmDjitdV9dkkv53kpiSPDZZbEvEaAAAAAIAJN654nWR+kv1aa22YwwAAAAAAQJJsNc79bk3y8mEOAgAAAAAATxjvlde7JflBVV2X5JEnFltrxw5lKgAAAAAAtmjjjdd/NcwhAAAAAABgrHHF69bat4Y9CAAAAAAAPGFc8bqqHk7yxMMaX5RkmyS/bK3tOKzBAAAAAADYco33yusdnnhfVZXkuCSHD2soAAAAAAC2bFs91wPaOl9JcvQQ5gEAAAAAgHHfNuT1Yz5ulWR+kjVDmQgAAIBJMe/MJaMeYQPLFi8c9QgAQCfGFa+TvG7M+7VJ7sm6W4cAAAAAAMCEG+89r08Z9iAAAAAAAPCEcd3zuqpmVNWXq+qng9c/VdWMYQ8HAAAAAMCWabwPbLwgyRVJXjF4/d/BGgAAAAAATLjxxuuprbULWmtrB68Lk0wd4lwAAAAAAGzBxhuvH6iqt1bV1oPXW5M8MMzBAAAAAADYco03Xv+vJCcm+XGSVUlOSPK2Ic0EAAAAAMAWbso491uU5OTW2kNJUlUvTfK/sy5qAwAAAADAhBrvldcHPhGuk6S19mCSg4czEgAAAAAAW7rxxuutqmqXJz4Mrrwe71XbAAAAAADwnIw3QH8kyfeq6ouDz29I8sHhjAQAAAAAwJZuXPG6tbakqpYm+Z+Dpde31n4wvLEAAAAAANiSjfvWH4NYLVgDAAAAADB0473nNQAAAAAATBrxGgAAAACA7ojXAAAAAAB0R7wGAAAAAKA7435gIwAAAMCmZt6ZS0Y9wgaWLV446hEANgmuvAYAAAAAoDviNQAAAAAA3RGvAQAAAADojngNAAAAAEB3xGsAAAAAALojXgMAAAAA0B3xGgAAAACA7ojXAAAAAAB0R7wGAAAAAKA74jUAAAAAAN0RrwEAAAAA6I54DQAAAABAd8RrAAAAAAC6I14DAAAAANAd8RoAAAAAgO6I1wAAAAAAdEe8BgAAAACgO+I1AAAAAADdEa8BAAAAAOiOeA0AAAAAQHfEawAAAAAAuiNeAwAAAADQHfEaAAAAAIDuiNcAAAAAAHRHvAYAAAAAoDviNQAAAAAA3RGvAQAAAADojngNAAAAAEB3xGsAAAAAALojXgMAAAAA0B3xGgAAAACA7ojXAAAAAAB0R7wGAAAAAKA74jUAAAAAAN0RrwEAAAAA6I54DQAAAABAd8RrAAAAAAC6I14DAAAAANAd8RoAAAAAgO6I1wAAAAAAdEe8BgAAAACgO+I1AAAAAADdEa8BAAAAAOiOeA0AAAAAQHfEawAAAAAAuiNeAwAAAADQnaHF66o6v6p+WlW3jll7aVVdXVXLBz93GaxXVf1dVd1VVTdX1SFjjjl5sP/yqjp5WPMCAAAAANCPYV55fWGSY56y9r4kX2+t7ZXk64PPSfLaJHsNXqcm+WSyLnYn+UCS30lyWJIPPBG8AQAAAADYfA0tXrfWvp3kwacsH5fkosH7i5IcP2Z9SVvn+0l2rqppSY5OcnVr7cHW2kNJrs6GQRwAAAAAgM3MZN/zevfW2qrB+x8n2X3wfnqS+8fst2Kw9nTrAAAAAABsxkb2wMbWWkvSJup8VXVqVS2tqqWrV6+eqNMCAAAAADACkx2vfzK4HUgGP386WF+ZZI8x+80YrD3d+gZaa59qrc1vrc2fOnXqhA8OAAAAAMDkmex4fUWSkwfvT05y+Zj1hbXO4Ul+Pri9yFVJjqqqXQYPajxqsAYAAAAAwGZsyrBOXFX/mOTIJLtV1YokH0hydpJLq+rtSe5NcuJg9yuTLEhyV5L/TnJKkrTWHqyqv05y/WC/Ra21pz4EEgAAAACAzczQ4nVr7c1Ps+n3NrJvS3La05zn/CTnT+BoAAAAAAB0bmjxGgAANmXzzlwy6hE2sGzxwlGPAAAAk2ay73kNAAAAAADPSrwGAAAAAKA74jUAAAAAAN0RrwEAAAAA6I54DQAAAABAd8RrAAAAAAC6I14DAAAAANCdKaMeABiueWcuGfUIG1i2eOGoRwAAAACgc668BgAAAACgO+I1AAAAAADdEa8BAAAAAOiOeA0AAAAAQHfEawAAAAAAuiNeAwAAAADQHfEaAAAAAIDuiNcAAAAAAHRHvAYAAAAAoDviNQAAAAAA3RGvAQAAAADojngNAAAAAEB3xGsAAAAAALojXgMAAAAA0B3xGgAAAACA7ojXAAAAAAB0R7wGAAAAAKA74jUAAAAAAN0RrwEAAAAA6I54DQAAAABAd8RrAAAAAAC6I14DAAAAANAd8RoAAAAAgO6I1wAAAAAAdEe8BgAAAACgO+I1AAAAAADdEa8BAAAAAOiOeA0AAAAAQHfEawAAAAAAuiNeAwAAAADQHfEaAAAAAIDuiNcAAAAAAHRHvAYAAAAAoDviNQAAAAAA3RGvAQAAAADojngNAAAAAEB3pox6AACAiXDfojmjHmEDM8+6ZdQjAAAAbLJceQ0AAAAAQHfEawAAAAAAuiNeAwAAAADQHfEaAAAAAIDuiNcAAAAAAHRHvAYAAAAAoDviNQAAAAAA3RGvAQAAAADojngNAAAAAEB3pox6AAAANk33LZoz6hE2MPOsW0Y9AgAAMEFceQ0AAAAAQHfEawAAAAAAuiNeAwAAAADQHfEaAAAAAIDueGAjAADQhXlnLhn1CBtYtnjhqEcAANhiufIaAAAAAIDuiNcAAAAAAHRHvAYAAAAAoDviNQAAAAAA3RGvAQAAAADojngNAAAAAEB3xGsAAAAAALojXgMAAAAA0B3xGgAAAACA7nEILTIAACAASURBVIjXAAAAAAB0R7wGAAAAAKA74jUAAAAAAN0RrwEAAAAA6I54DQAAAABAd8RrAAAAAAC6I14DAAAAANAd8RoAAAAAgO6I1wAAAAAAdEe8BgAAAACgO+I1AAAAAADdEa8BAAAAAOiOeA0AAAAAQHfEawAAAAAAuiNeAwAAAADQHfEaAAAAAIDuiNcAAAAAAHRHvAYAAAAAoDviNQAAAAAA3RGvAQAAAADojngNAAAAAEB3xGsAAAAAALozknhdVfdU1S1VdVNVLR2svbSqrq6q5YOfuwzWq6r+rqruqqqbq+qQUcwMAAAAAMDkGeWV17/bWpvbWps/+Py+JF9vre2V5OuDz0ny2iR7DV6nJvnkpE8KAAAAAMCk6um2IccluWjw/qIkx49ZX9LW+X6Snatq2igGBAAAAABgcowqXrckX6uqZVV16mBt99baqsH7HyfZffB+epL7xxy7YrAGAAAAAMBmasqIfu+rW2srq+plSa6uqjvGbmyttapqz+WEgwh+apLMnDlz4iYFAAAAAGDSjeTK69baysHPnyb5cpLDkvzkiduBDH7+dLD7yiR7jDl8xmDtqef8VGttfmtt/tSpU4c5PgAAAAAAQzbpV15X1UuSbNVae3jw/qgki5JckeTkJGcPfl4+OOSKJKdX1SVJfifJz8fcXgQAAAA2GfPOXDLqETawbPHCUY8AABs1ituG7J7ky1X1xO//fGvtq1V1fZJLq+rtSe5NcuJg/yuTLEhyV5L/TnLK5I8MAAAAAMBkmvR43Vr7YZKDNrL+QJLf28h6S3LaJIwGAAAAAEAnRnLPawAAAAAAeCbiNQAAAAAA3RGvAQAAAADojngNAAAAAEB3xGsAAAAAALojXgMAAAAA0B3xGgAAAACA7ojXAAAAAAB0R7wGAAAAAKA74jUAAAAAAN0RrwEAAAAA6I54DQAAAABAd8RrAAAAAAC6I14DAAAAANAd8RoAAAAAgO6I1wAAAAAAdGfKqAfgye5bNGfUI2xg5lm3jHoEAAAAAGAL48prAAAAAAC6I14DAAAAANAd8RoAAAAAgO6I1wAAAAAAdEe8BgAAAACgO+I1AAAAAADdEa8BAAAAAOiOeA0AAAAAQHfEawAAAAAAujNl1AMAAAAAsPmYd+aSUY+wgWWLF456BOB5cOU1AAAAAADdEa8BAAAAAOiOeA0AAAAAQHfEawAAAAAAuiNeAwAAAADQHfEaAAAAAIDuiNcAAAAAAHRHvAYAAAAAoDviNQAAAAAA3RGvAQAAAADojngNAAAAAEB3xGsAAAAAALojXgMAAAAA0B3xGgAAAACA7ojXAAAAAAB0R7wGAAAAAKA74jUAAAAAAN0RrwEAAAAA6M6UUQ8AAACMz32L5ox6hA3MPOuWUY8AAMBmypXXAAAAAAB0R7wGAAAAAKA74jUAAAAAAN0RrwEAAAAA6I54DQAAAABAd8RrAAAAAAC6M2XUAwAAAACjc9+iOaMeYQMzz7pl1CP8//buPVyOos7/+PtDuBOIy0VEBOMigiwgGkRRLsFFvKKwxo2IYlRE3BUBBcWfilFXQfCyovJDrkFkIdyCiCyQBQJIkJCQewBRRAUVRZEFlft3/6iaTJ+Z7jlzzpkzMyf5vJ7nPGemp7u6urq6qrq6utvMzPqAR16bmZmZmZmZmZmZWd9x57WZmZmZmZmZmZmZ9R13XpuZmZmZmZmZmZlZ33HntZmZmZmZmZmZmZn1Hb+w0czMzMzMzPqGXx5oZmZmNR55bWZmZmZmZmZmZmZ9x53XZmZmZmZmZmZmZtZ33HltZmZmZmZmZmZmZn3HnddmZmZmZmZmZmZm1nfceW1mZmZmZmZmZmZmfWfNXkfAzMzMzMzMzMxsNP36izv1OgpNtj5+aa+jYNb3PPLazMzMzMzMzMzMzPqOR16bmZmZmZmZmXWRRwGbmbXHI6/NzMzMzMzMzMzMrO+489rMzMzMzMzMzMzM+o47r83MzMzMzMzMzMys77jz2szMzMzMzMzMzMz6jjuvzczMzMzMzMzMzKzvrNnrCJiZmZmZmZmZmZmNJZOO/X6vo9BkwcmH9DoKHefOazMzs1Hw6y/u1OsoNNn6+KW9joKZmZmZmZlZ2/zYEDMzMzMzMzMzMzPrO+68NjMzMzMzMzMzM7O+485rMzMzMzMzMzMzM+s77rw2MzMzMzMzMzMzs77jFzaamZmZmZlV8At4zczMzHrHI6/NzMzMzMzMzMzMrO+489rMzMzMzMzMzMzM+o47r83MzMzMzMzMzMys77jz2szMzMzMzMzMzMz6jl/YaGZd5xcfmZmZmZmZmZnZYDzy2szMzMzMzMzMzMz6jjuvzczMzMzMzMzMzKzvuPPazMzMzMzMzMzMzPqOO6/NzMzMzMzMzMzMrO+489rMzMzMzMzMzMzM+o47r83MzMzMzMzMzMys77jz2szMzMzMzMzMzMz6jjuvzczMzMzMzMzMzKzvjJnOa0lvlHS3pJ9LOq7X8TEzMzMzMzMzMzOz0TMmOq8ljQO+C7wJ2AE4SNIOvY2VmZmZmZmZmZmZmY2WNXsdgTbtBvw8Iu4FkHQh8HZgRU9jZWZmZmZmZmZm1mOTjv1+r6PQZMHJh/Q6CrYKGBMjr4Etgd8Uvt+fp5mZmZmZmZmZmZnZKkgR0es4DErSFOCNEXFo/v5e4FUR8dHCPIcBh+Wv2wF3dz2inbEp8FCvI7GacZp3n9O8+5zm3ec07z6nefc5zbvPad59TvPuc5p3n9O8+5zm3ec07z6nefeN1TR/YURsVvbDWHlsyAPAVoXvL8jTVoqI04HTuxmp0SBpfkTs2ut4rE6c5t3nNO8+p3n3Oc27z2nefU7z7nOad5/TvPuc5t3nNO8+p3n3Oc27z2nefatimo+Vx4bcDmwr6UWS1gbeBVzR4ziZmZmZmZmZmZmZ2SgZEyOvI+JpSR8FrgHGAWdHxPIeR8vMzMzMzMzMzMzMRsmY6LwGiIirgKt6HY8uGPOPPhmDnObd5zTvPqd59znNu89p3n1O8+5zmnef07z7nObd5zTvPqd59znNu89p3n2rXJqPiRc2mpmZmZmZmZmZmdnqZaw889rMzMzMzMzMzMzMViPuvG5B0gGSQtL2Fb/PkdTRN3hKmihp2TCWmzvM9U2XdMxwlm0z/GckLSr8HTda6xqL2tlvkh4b6jySpkn6zkjiVghrZR6RNEPSlE6E28Z6h3Us9KPCcbBM0sWS1h/i8hdIWiLp6NGKY8k63zbY8VrMZ7m83KE7sWuPpBdI+qGkeyT9QtK3JK0taRdJby7MN6rlYCe0sz9WRZI+I2l5zv+LJL2qxbxdK5/6naTnSbow5/sFkq6S9JIhLP9OSXdKukHSZEmvGc34VsThcEmHdGldmxTaKb+X9EDh+9rdiEO7GsuvLq1zV0mndGldje3GiR0Ov6NlqaSTcxl18mB5tlVdM9x2fLvy+cwPCt/XlPRHSVcOM7z7JG1aMr1v6qpuxSW3V9/dobBGVBbl8npY+7RXJP2/XsehFyRtL2mupKWSbiw7nlYFIzkHGml9J+mo4vpyW+g5ww1vLNMg/VqjsL6qOmJarntq5dr3uxGf0dRuHh9qPa82+oBWN+68bu0g4Cf5f1+StCZARHT9xLJNf4+IXQp/J/Y6Qv1gDOy3jqht51gzCvGuHQc7Ak8Ch7e7PknPA14ZETtHxDc7HK9KEXHFEI/XA4C+6byWJOAy4PKI2BZ4CTAe+DKwC9Cxzh9J4zoUTmU+GMb+GPMk7Q68FXhFROwM7Av8prex6n85788C5kTENhExCfg0sHlhnsHKuA8CH4qIfYDJQFt1VaeOBYCIOC0imk5qRqNeiYg/1dopwGnANwvtlif7pS7L8eho+dWOiJgfER/r0uoa2433DbaAkrbOaUahLD0M2Dkijq3Ks23Ga7Tbg38FdpS0Xv7+euCBTq+kn+qqLsZlItCRzuvByqJOrKNfFI7b1bLzOntPROwEzKXh3GAVMuxzIEZe3x0FrOxIjIg3R8RfRhDeiAylrhoFlf1aPWjjzCyUa20NUuhx2g2mrTy+qvf7NOrkOUFNv2aAnpM0HtiDdAL3rjxtPaWRTHdKmgWsV5j/scLoi/+RtJvSyOx7Jb2tYh0vzvMulnSHpG0afh+Xw7xdadTZh/P0yZJulnQFsKK2/sJyn8pXcRdLOjFP+1AOZ7GkS4dy1bPTJE2QdLek7fL3CyR9KH8+trC9Xygsc0ietljSeRXhDroPlEZH3JzT+w7l0WQ5TedIukTSXZLOzx0ASDo+x2mZpNML01+p+mjAk5VHCQ9nv0kaL+m6HKelkt7ewfTeX9JtkhbmdNk8T58u6exCGn2ssMxnJP1M0k+A7SrCnaQ0UmCBpGskbZGnz5H0n5LmA0cqjeBblvfdTRVhDfdYKE23vJ/vlHRGzg/XKp+wSdpG0tU53jcrX4FWGrV5mqTbgJMk7a36VeGFkjYc4a6ouRl4cWN+kLSupHPydiyUtE+e/1pgyxyPPRvSpSltla5o/zDvh3skfb4w/3skzcthfU+5UpH0xpyGiyVdVwinNqq6NA8Vwn0N8Dbg5Bz2NpLuKPy+bfF7l7wOeDwizgGIiGeAo4FDgZOAqTmuU/P8O1QcC1Vp9pikr0taDOxeXLGkEyWtyHn1a3naZkpl7+3577V5+nRJ50m6BThP0k8l/VMhrDlKox6L+2NzSbPy/lqsejlWGtcxbAvgoYh4AiAiHoqI36qiTC5Sdfn0scK+ubDL29Mt+wBPRcRptQkRsRgYp+Y66PKcRsslHZanHU9q/5wl6WJSI/zosjIozz/gWBjkmPlmXtd1kjbL00vbJxp418+AemXUUm7gdjXWCbtJujWXg3NVb8NMk3SZUr1yj6ST8vRxOYxlSuX60YVt+Zbqo3R2y9M3zvtjSS4Hdi6kw8oyAvgizeVXMd73SToh/z5f0ivyMfALSYfneaTcbslxm5qnXyjpLQ1pMEWF0Zxq3Xb4nFL77idKbbsR39Gi1vX83UqjtpYBeyq132YotV/Ol7SvpFvyfqmlc7EsnSHplLw/71W+c0PSGpJOzeHNVhqt13RXRz6WxgMLJE1tyLNVZU1VXVNrD7Zqj745T1uQ4z3UEbZXAbX9exBwQWH9Vfl7nKSv5byyRNIRhfCOKOyXWltq0PTNv5W29xvSt7RdpBbtnIbl29nXW0i6SfXjcc/a/lB5eVXWXj2RlP8WaRTukFN1fVbVdh5fln8awqzc7sI8UyTNKKTfaUplys8kvbWQxlVtzo/nsJdJOipPazxuzwLWy/E4v9Np188i4q6IuDd/XQd4vJfx6ZK2z4GU7jQYUN9J2kCp/pmX56vVB03llFL5+nzgBkk35Pnuk7SpUjv932uR0sCyu52yqfQcsWzZkjz/OUknF8JaWU6NFpX3azXug8m5nPlhLiNPlHRwTuultfJF1eczmyidby+XdCbQVO4MEsd2youtVN7PVXVuP2gfxCgozeM5PrV6vrStVRaYpC/n+P9U9T6ciZKuz/nsOklbl4VTWF9Veb+fUr1/h9KI8fEl6x/SsvkY+6rSef+xkuYVwpooaemIUjci/FfyBxwMnJU/zwUmAR8Hzs7TdgaeBnbN3wN4U/48i9ThtBbwMmBRxTpuAw7Mn9clXRmcCCzL0w4DPps/rwPMB15EGgX1V+BFhbAey//flOO7fv6+cf6/SWHe/wCOyJ+nA8eMYjo+Aywq/E3N018P3EoqQK/O0/YjvRVVpAsrVwJ7Af8E/AzYtLhNJesadB/kNF43f94WmJ8/TwYeAV6Q130rsEfj+kgnjvvnz8uA3fPnE0e439YENsqfNwV+DitfqPrYMNL518B38m//UAjrUODrhX0/N8dxU+BPOb0mAUtzWm2U43JMXmYGMCXPNxfYLE+fSv3YmAOcWojbUmDL/Pk5HT4WStMtL/s0sEv+7SLS6AaA64Bt8+dXAdcXtu1KYFz+/iPgtfnzeGDNERwHxf38Q+AjjfkB+EQhDbfP+3DdYjqUhNuUtsA04HfAJqQLbMuAXYGX5m1aK893KnAIsBlpNGstHhsXwhksDxXnmQFMKcTthkL6f4Vc5nTrD/gYacRS4/SF+bfvFKZNp/xYKE2zQnnzryXhbwLcXUiv2n75L+plytbAnYV1LwDWy9+PBr6QP28B3F2S1jOBo/LnccCEVnEdq3+k424Rqfw/Fdi7mEfz52KZPIPBy6ffAusU982q9tci70+muQ6qHe+1smKT/H0O9fbNdFq0E4rHQhvHzMH58/GF/Dxo+4SGemWU0286cAzNdcJG5HqAdBfApfnzNODefByuC/wK2IpUl84uhPucwrackT/vRb2e+zbw+fz5ddTbLdMZWEZMo1B+lcT/PuAj+fM3gSXAhqSy/sE8/R3AbFL5sTmpvtkCOBA4N8+zNqluWC/nnSsL8SkrL19JOl7Xzeu7p1W+aRH/YntmFq3r+WeBV+ffJpLq/Z1I7bgFwNl53reT7sIZkH55H1+c598B+HmePoXU0bsG8DzgYQr1W0N8Hyt8nk49zzaVNVVpVwyHivZoTtdiXX1BbZ+0ma6Pkc5dLslhLWrYr1X5+yN5mdpvtTLjPurH6r8BZw4hfUvb+yVxrmoXTaOknVOyfDtx+QTwmfx5HLDhIOVVWXt1ZTqOQll0LNX1WVVcSs9nStK2bLuL+XkKMKOQflfnMLcF7m+1L6ifS2xAqsuXAy+n4bhtXOfq+Ae8AbiTVbdNMpJzoJXHcP7tK9TP555Dah9uQOtyatPC8veRyt6XAzcWpq8g1dvtlk1N54hVyzbmeVJd/PNCWP9ddox2eB+U9Ws17oPJwF9IbYF1SHfm1M5HjgT+M3+uOp85BTg+f34LqQzdtCQu04A/Uq/n30+b5QXV/VxV5/aD9kF0K483zFfa1ioJN6if45xEvS/kR8D78ucPUG/fzGDguXhtfU3lPek4uAnYIE//VG3/NcRhSMuSjrFPFpZfVMhjn6ptw3D/+uI2yD51EPCt/PnC/P3FpAOTiFgiaUlh/idJlTqkA+WJiHgqX12Y2Bh4vkK3ZUTMyuE9nqcXZ9sP2LlwBWUCqcHwJDAvIn5ZEu99gXMi4m853D/n6TtK+g9SQT8euKaNNOiEv0e69W2AiJgt6Z3Ad0mdy5C2dz9S5xKkeG6bf784Ih7Ky/6Zcu3sg7WA70jahXSCVHwG6LyIuB9A0qK8zE+AfSR9ktQo3BhYLulmUkPv1rzsf5Fub69tx1D3m4CvSNqLVEhvSTqh/H3FtjYakM6SppEaj5AasDOVRmqsDRTX/+NIoxqfkPSHvM49gVm1PJSvGDbaDtgRmJ3z7DhS47VmZuHzLcAMSReRHuMwwAiPhfspTzeAX0bEovx5ATAxXxV8DXBxIfx1Cuu5ONII3Vq8v6E0EuSyWt4YpvVynoJ0RfasHI9iftiD1HlBRNwl6Vek/Pm/LcKtStvZEfEnAEmX5bCfJjUObs/bvh7wB+DVwE21eFQcX63yUJUzgfdL+jjpZGu3NpbppbJj4Z8pTzNI5celJeE8Qho9c5bSqLjayLh9SSPuavNtVLjCfUVE/D1/voh04e3zwL+SGuONXke68EDOr49Iem+LuI5JEfGYpEmkMmkfUh48Dni0sUwmNeRqWpVPS4DzJV0OXN6VDekvjXXQxyQdmD9vRSpX/zTEMIvHQqtj5lnqdcMPqJdZ7bZPZlZMH03FOmECcK6kbUknFGsV5rsuIh4BkLQCeCEpX/6jpG8DPyYd1zUXAETETZI2UnoG5x6kTmUi4vo8immjPH+xjGhHrd5eCoyPiEdJx80ThXVdkLftQUk3kjqf/xv4lqR1gDeS6oa/q3ngZll5+Vrgh7kOf1zSjxoXalNje2Ytquv5X0XETwvL/jIilubllpP2S1S1xbPLI+JZ0sizWrh7kPb9s8DvlUftDVFVWVOWdo3ti7L26GPAvYXj9wLShf225XOXiaRzmqsafq7K3/sCp0XE0zmMYhuhdgwvAP6lYrVl6VvV3m8cGVfVLoLyds78yo2vjsvtwNk5n11eaDc2lVdttlc7bR1K6rNB4lJ1PlNUtd2tXJTT7x5J95I6GaF8XwTpXOKvhel7ksqmxuN2taX0GISzgH2ih4+zGGUjOQdqtB/wNtXv6lmX1IHaqpxqEhELJT1X0vNJnckPR8RvJB1Je2VT0zmipKpy7dcU8nxE/FFpZPOrSRd5t8/hjaayfq0raW4T3h4RvwOQ9Avq7ZalpHY4VJ/P7EWuByLix5IebhGfmRHx0dqXnO7tlBdN/VyDnNu37IPooHbyeFFpW6tkviepn0cuIA3+hHTHb63OPY/Usd1KU3kvaW/ShdxbcrqtTbrY2Ylli+31i0j9ACfm/013DA6FO69LSNqY1Dmwk6QgNRSCemFU5qnIlxRIDZ7abc7PKj/nRtI5pKtIv6W9HSfSqIYBJ3KSJpOu5AzFDOCAiFicOzYnD3H5jsqV9UuBv5FGdd5P2t4TIuJ7DfMeUbL8ONJBDOmk7nja2AekUY0PkjrE12DgLVpPFD4/A6wpaV3SyLFdc6U2nVRRttw8hr7fDiZVnpNyh/t9baynXd8GvhERV+Q4TC/81rTNbYYpYHlE7F7x+8rtjIjDlV6y9hbSrbWTgK/RmWNhGtXp1rht65H2+V/KLqiUxPtEST8mPWvtFklviIi72ohrmaaLOLmwH9JxLOnL5Ft+Iz1bqyxtIZVXRUFKw3Mj4tMNYe7fxqpb5aEql5I6YK8HFtRObLpoBWnU0Eq5I2hrUkd+o7JjoTTNssdrnVqSriF1QMyPiEOVbk//57z+j5LqkzVIIwcG3BbamA8i4gFJf1J6ZMBU2n8GYqu4jlk5jecAc3IH1IdJowdblcmtyqe3kBrY+wOfkbRT7WRnFbKchrxfsDKv5WN5X9IdRH+TNIdB6p2KunflscDQ8mGtnJpBe+2TobZ7OqG4zi8BN0TEgbkDcE7ht6byIyIelvQy0qi6w0kXoz6Q5ykro9uNxwCN5U9DfJ5lYNyepUU9HxGP53zwBlL5U/VoneG2HYajVfuoMV0at7WYDlVxLC7Tshcy17e1NurxEVF2cb+mqawpWV9V2o1m+l5BaoNNJo2WrWmVv6vU4tkqjmXpW9Xe/3fgQ/nrYM+5bTqG2li+KS75AtJepP01Q9I3ovy55YMdo6OltD5T60fZlZ3PNOXdiu0ubmdjfVBVbnWsPFsNPR94JCLu6XVERlFHzoFqiwLviIi7S8IbqotJbaXnUe9sa6tsKjtHbLHsRJq39UJSm+AuUqftqJUvLfq1flwSr3bq0FbnM2XrH0q5XmawfFJ5bl92njxK56NDyuNlba02+rbaaQs8TX4sdO5rWzuvr6meI91RNjsiBjwDvZ26omrZguJ2zyRdWLgsRWVkZZ2feV1uCnBeRLwwIiZGxFakkYYLyC/kkLQj6QS6bRHx/tzh9OZIo2Dul3RADm8dNT+H+hrgI/lKB5JeImmDQVYzmzTasfbMyI3z9A1JV+rXIp0I9NrRpFuk3g2ck+N1DfAB1Z+Zs6Wk55I6v94paZM8feOIeCbqD/o/fgjrnQD8Lo8ceC+pAG+l1nB7KMdrCkC+Ov5oPsAhPz8qG85+mwD8IZ+Y7UMatdUpE6i/lOd9bcx/E3CA0jPeNySdeDW6G9hM6YVqSFpLhef0FknaJiJuy/vpj8BWHTwWhpRuEfG/wC+VRv2j5GVl8+Z4L42Ir5KuOo7225lvJh+bkl5C6mQd0DiLiM9E/UU+pWmbZ3290vNT1yO9SPEW0i1VU/IxRf79hcBPgb0kvag2vSRu7eShR0nlTC2uj5P22/8Hzmk/GTrmOmB9SYfAyk63r5M6yh6kENdBwihLswEi4g15vxyay4kJEXEVqZyr5a9rgZUX4pTu/qgyE/hkDmdJye/XkW5JQ+k5fxPajetYImk7pVGANbtQPyYGlMkNSsun3JDbKiJuIN26NoE0MmZVcz2wjvIzrAHyxZDG51VPII02+pvS8wFfXRHeymO7jbq3VT5cg/r+ejf1kYD91j6pUiwHpw02s6RNgTUi4lLgs8ArCj/XnjG9B6nj4hEG1gGTSc97L7vzprGsXVn+DGFbbiY9R3Sc0rN89wJqzyWcSbqNd0/qd7O14xZgf6Vnl46nfjfaSI1m+6jKLcA7lJ59vTn5gkqub2v5v7LjepTKmrtJI/kn5u/DHb10NulW8MbnTlbl79nAh1UfiFPWRhiq0vZ+RHy3kL6/pXW7qKmdU7L8oHL59GBEnEG6Y6x2nDaVVy3aqwOOyQ57gpL6rM2280qNebfFdj8o6aU5Dx/YEMw78zGxDfCPtNgXpH13gKT1c3v9wDytzFO19v1q6GHSbfmru6pjvfHYuob0rP3aewBenqdXlVOtjs2ZpPP3KaSO7Fr4g5ZNFeeIVf0YZWaRHmd1ENUXiTulql+r6R0mbao6n7mJej/Zm0iDE2mzXG63vGjq52p1bt/iPLkfDGhrDbFvay71vqeDqafVfaS7HyG9i6rWb1JW3v8UeK2kF+d5NpD0kjbritJlyyIaEb8gdbx/jg7cQenO63IHkQqVoktJz9gdL+lO0gsEFjQuOETvJd2yu4SUCZ/X8PuZpNGDdyi9DPB7DHLFJSKuJo2qmK90+0LttprPkZ6NdgvpKl+31F7CUfs7UeklMIcCn4iIm0mF3Wcj4lrS4zduVRphdwnp0RzLgS8DNyq9EOobI4jPqcD7cjjbM8jVvNxJfQbpGW7XkCqomg8CZ+R03oD0uAAYxn4Dzgd2zdt9CJ3dR9NJV7wWAA8NNnNE3EEqXBaTbmu5vWSeJ0mV4VdzWi4i3R5T5mSlFyssI+XzxSXzDPdYGE66HQx8MMd7OanxUOYo5Rd/AE+R0mI0nQqskbdlJjAt8ovqWqhK23mkMmsJ6bmV8yNiBakD5dq8TbOBZjbAPQAABkZJREFULSLij6Rbjy/LaVJWsUxn8Dx0IenFDAtVf2nQ+aSr9ddWLDNq8pXqA0knW/eQnov3OOmt9jeQbnkrfeFZIYzSNBtk1RsCV+b5f0J6VwKk5xDvqvRyjRW0HlF9CalRclHF70eSHme0lFQP7TDMuPa78aTb2FfkbdqBlBerymSgZfk0DvhBTreFwCmxCt6mW8j7+yq9pG85cALNj6G6mjQi707S7XxVt3H/CDhQFS9sbFh3q3z4V2C3XF69jtSOgt61T4bqJOAESQtpbyTslqQ7BhaRHjtQHI3+eA7nNFJbAlLenpTT7USqLxS2VX4NYhapflhMutjxyYio5Y9rgb2B/8nHUlsi4nZS+3MJqb5cSr1dNBKj2T6qcinpjsAVpH13B0Pblo6XNZFuKf434OpcFz86xDjVwrk/Ik4p+akqf59Juu19SS5P3z3kyDfHobS9XzJrq3ZRUztnmNGZDCzO2z2V+q31VeVVWXt1CfCM0ku1Ov3Cxmepbm8P1nZuZTLl230c6Tb1uQx8HCCkfDCPdHwfHvWRl2VtzjtIgwXmkcr3MyOi6g7m00n5a7V6YWM2gXROvLqrOtYb67svkTrkluS2zZfy8lXl1OmkMrPp0U+5f2FD4IHIj8oYQtnUdI44hGWJiIdJg/heGBHzyubpoKp+rapRs4OpOp/5Amkw1HLSIy1+3W6A7ZYXLfq5qs7t2+mD6JVhtbWyI0id+EtI9UDtReZnAHvndNidej/XZBrK+3z+Pw24IIdzK+UD9UaybM1M4D1Un9e2rfZCKTMbIknjI6L2FtfjSB2BRw6ymNmoUn7eeRSeJdbDuBxDGj38uV7Hxcx6S9JjEbEqjnQfEqVbRY8ZQWdb36q1i/KoqJuAw/JJ6ZhT2JZNSCfUry108Pc6TiK9M+aeiPhmL+PUC91o57i8GkjSDNJLKS9pmD6NPmlzmpnZqs3PvDYbvrdI+jTpOPoVbdxGbLa6kDQL2IY0YsnMzFZ9p0vagfTItXPHasd1dqXSyy3XBr7U647r7EOS3keK00Lqz6U0MzMzW6V55LWZmZmZmZmZmZmZ9R0/89rMzMzMzMzMzMzM+o47r83MzMzMzMzMzMys77jz2szMzMzMzMzMzMz6jjuvzczMzMxWEZJ2kfTmwve3STqul3EyMzMzMxsuv7DRzMzMzGwVIWkasGtEfLTXcTEzMzMzGymPvDYzMzMzGyFJH5e0LP8dlacdImmJpMWSzsvTNpc0K09bLOk1kiZKWlYI6xhJ0/PnOZK+JWlRDnu3PH03SbdKWihprqTtJK0NfBGYmuefKmmapO/kZSZKuj7H6TpJW+fpMySdksO5V9KUriaemZmZmVmFNXsdATMzMzOzsUzSJOD9wKsAAbdJuh34LPCaiHhI0sZ59lOAGyPiQEnjgPHAPwyyivUjYhdJewFnAzsCdwF7RsTTkvYFvhIR75B0PIWR13kkds23gXMj4lxJH8hxOSD/tgWwB7A9cAVwybATxMzMzMysQ9x5bWZmZmY2MnsAsyLirwCSLgN2BS6OiIcAIuLPed7XAYfkac8Aj0garPP6gjz/TZI2kvQcYEPgXEnbAgGs1UY8dwf+JX8+Dzip8NvlEfEssELS5m2EZWZmZmY26vzYEDMzMzOz3nqage3ydRt+b3xJTQBfAm6IiB2B/UuWGaonCp81wrDMzMzMzDrCnddmZmZmZiNzM3CApPUlbQAcCMwH3ilpE4DCY0OuAz6Sp42TNAF4EHiupE0krQO8tSH8qXn+PYBHIuIRYALwQP59WmHeR0mjssvMBd6VPx+c421mZmZm1rfceW1mZmZmNgIRcQcwA5gH3AacGRG3AF8GbpS0GPhGnv1IYB9JS4EFwA4R8RTpRYvzgNmk51kXPS5pIXAa8ME87STghDy9+CjAG4Adai9sbAjnCOD9kpYA781xMTMzMzPrW4povAvRzMzMzMz6gaQ5wDERMb/XcTEzMzMz6zaPvDYzMzMzMzMzMzOzvuOR12ZmZmZmZmZmZmbWdzzy2szMzMzMzMzMzMz6jjuvzczMzMzMzMzMzKzvuPPazMzMzMzMzMzMzPqOO6/NzMzMzMzMzMzMrO+489rMzMzMzMzMzMzM+o47r83MzMzMzMzMzMys7/wf/rzUoStoN1sAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 1800x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1800x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1800x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1800x864 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "45ouk3KUGurB",
        "outputId": "2e227684-cdc3-4e2e-c8d9-c95f5238b701"
      },
      "source": [
        "sns.boxplot(x=\"income\", y=\"age\", data=df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fc44af42128>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "TpWsGxeLHQg2",
        "outputId": "31d2403f-5000-4979-e087-6eaef86ee6d9"
      },
      "source": [
        "pd.crosstab(df['income'], df[\"occupation\"])\r\n",
        "pd.crosstab(df['income'], df[\"education\"])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>education</th>\n",
              "      <th>10th</th>\n",
              "      <th>11th</th>\n",
              "      <th>12th</th>\n",
              "      <th>1st-4th</th>\n",
              "      <th>5th-6th</th>\n",
              "      <th>7th-8th</th>\n",
              "      <th>9th</th>\n",
              "      <th>Assoc-acdm</th>\n",
              "      <th>Assoc-voc</th>\n",
              "      <th>Bachelors</th>\n",
              "      <th>Doctorate</th>\n",
              "      <th>HS-grad</th>\n",
              "      <th>Masters</th>\n",
              "      <th>Preschool</th>\n",
              "      <th>Prof-school</th>\n",
              "      <th>Some-college</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>income</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>&lt;=50K.</th>\n",
              "      <td>666</td>\n",
              "      <td>858</td>\n",
              "      <td>299</td>\n",
              "      <td>115</td>\n",
              "      <td>233</td>\n",
              "      <td>460</td>\n",
              "      <td>374</td>\n",
              "      <td>599</td>\n",
              "      <td>786</td>\n",
              "      <td>2428</td>\n",
              "      <td>84</td>\n",
              "      <td>6826</td>\n",
              "      <td>569</td>\n",
              "      <td>36</td>\n",
              "      <td>114</td>\n",
              "      <td>4569</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>&gt;50K.</th>\n",
              "      <td>55</td>\n",
              "      <td>51</td>\n",
              "      <td>24</td>\n",
              "      <td>5</td>\n",
              "      <td>11</td>\n",
              "      <td>31</td>\n",
              "      <td>20</td>\n",
              "      <td>202</td>\n",
              "      <td>273</td>\n",
              "      <td>1712</td>\n",
              "      <td>231</td>\n",
              "      <td>1294</td>\n",
              "      <td>731</td>\n",
              "      <td>0</td>\n",
              "      <td>316</td>\n",
              "      <td>1028</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "education  10th  11th  12th  ...  Preschool  Prof-school  Some-college\n",
              "income                       ...                                      \n",
              "<=50K.      666   858   299  ...         36          114          4569\n",
              ">50K.        55    51    24  ...          0          316          1028\n",
              "\n",
              "[2 rows x 16 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iCQ1ub4CGrix"
      },
      "source": [
        "Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iHGqh7MWGvJA"
      },
      "source": [
        "# data preprocessiong\n",
        "\n",
        "# educatiion/education-num - drop educatiion\n",
        "df = df.drop(columns=['education'])\n",
        "\n",
        "# standadize inputs\n",
        "# continuous variables - MinMax normalization\n",
        "scaler = preprocessing.MinMaxScaler()\n",
        "df['age'] = scaler.fit_transform(df[['age']])\n",
        "df['demogweight'] = scaler.fit_transform(df[['demogweight']])\n",
        "df['education-num'] = scaler.fit_transform(df[['education-num']])\n",
        "df['capital-gain'] = scaler.fit_transform(df[['capital-gain']])\n",
        "df['capital-loss'] = scaler.fit_transform(df[['capital-loss']])\n",
        "df['hours-per-week'] = scaler.fit_transform(df[['hours-per-week']])\n",
        "\n",
        "# categorical variables - Indicator\n",
        "df['sex'].replace({'Male': 1, 'Female': 0}, inplace=True)\n",
        "df['income'].replace({'>50K.': 1, '<=50K.': 0}, inplace=True)\n",
        "df = pd.get_dummies(df, \n",
        "                    prefix=['w', 'o', 'm', 'r', 'race', 'c'], \n",
        "                    columns=['workclass', 'occupation', 'marital-status', 'relationship', 'race', 'native-country'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "saVHv8OzGvJB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 4314
        },
        "outputId": "793ddc25-fc8e-4328-be26-9376e15a06fe"
      },
      "source": [
        "# correlation matrix\n",
        "df.corr()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>demogweight</th>\n",
              "      <th>education-num</th>\n",
              "      <th>sex</th>\n",
              "      <th>capital-gain</th>\n",
              "      <th>capital-loss</th>\n",
              "      <th>hours-per-week</th>\n",
              "      <th>income</th>\n",
              "      <th>w_?</th>\n",
              "      <th>w_Federal-gov</th>\n",
              "      <th>w_Local-gov</th>\n",
              "      <th>w_Never-worked</th>\n",
              "      <th>w_Private</th>\n",
              "      <th>w_Self-emp-inc</th>\n",
              "      <th>w_Self-emp-not-inc</th>\n",
              "      <th>w_State-gov</th>\n",
              "      <th>w_Without-pay</th>\n",
              "      <th>o_?</th>\n",
              "      <th>o_Adm-clerical</th>\n",
              "      <th>o_Armed-Forces</th>\n",
              "      <th>o_Craft-repair</th>\n",
              "      <th>o_Exec-managerial</th>\n",
              "      <th>o_Farming-fishing</th>\n",
              "      <th>o_Handlers-cleaners</th>\n",
              "      <th>o_Machine-op-inspct</th>\n",
              "      <th>o_Other-service</th>\n",
              "      <th>o_Priv-house-serv</th>\n",
              "      <th>o_Prof-specialty</th>\n",
              "      <th>o_Protective-serv</th>\n",
              "      <th>o_Sales</th>\n",
              "      <th>o_Tech-support</th>\n",
              "      <th>o_Transport-moving</th>\n",
              "      <th>m_Divorced</th>\n",
              "      <th>m_Married-AF-spouse</th>\n",
              "      <th>m_Married-civ-spouse</th>\n",
              "      <th>m_Married-spouse-absent</th>\n",
              "      <th>m_Never-married</th>\n",
              "      <th>m_Separated</th>\n",
              "      <th>m_Widowed</th>\n",
              "      <th>r_Husband</th>\n",
              "      <th>...</th>\n",
              "      <th>c_Canada</th>\n",
              "      <th>c_China</th>\n",
              "      <th>c_Columbia</th>\n",
              "      <th>c_Cuba</th>\n",
              "      <th>c_Dominican-Republic</th>\n",
              "      <th>c_Ecuador</th>\n",
              "      <th>c_El-Salvador</th>\n",
              "      <th>c_England</th>\n",
              "      <th>c_France</th>\n",
              "      <th>c_Germany</th>\n",
              "      <th>c_Greece</th>\n",
              "      <th>c_Guatemala</th>\n",
              "      <th>c_Haiti</th>\n",
              "      <th>c_Holand-Netherlands</th>\n",
              "      <th>c_Honduras</th>\n",
              "      <th>c_Hong</th>\n",
              "      <th>c_Hungary</th>\n",
              "      <th>c_India</th>\n",
              "      <th>c_Iran</th>\n",
              "      <th>c_Ireland</th>\n",
              "      <th>c_Italy</th>\n",
              "      <th>c_Jamaica</th>\n",
              "      <th>c_Japan</th>\n",
              "      <th>c_Laos</th>\n",
              "      <th>c_Mexico</th>\n",
              "      <th>c_Nicaragua</th>\n",
              "      <th>c_Outlying-US(Guam-USVI-etc)</th>\n",
              "      <th>c_Peru</th>\n",
              "      <th>c_Philippines</th>\n",
              "      <th>c_Poland</th>\n",
              "      <th>c_Portugal</th>\n",
              "      <th>c_Puerto-Rico</th>\n",
              "      <th>c_Scotland</th>\n",
              "      <th>c_South</th>\n",
              "      <th>c_Taiwan</th>\n",
              "      <th>c_Thailand</th>\n",
              "      <th>c_Trinadad&amp;Tobago</th>\n",
              "      <th>c_United-States</th>\n",
              "      <th>c_Vietnam</th>\n",
              "      <th>c_Yugoslavia</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>age</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.075810</td>\n",
              "      <td>0.032765</td>\n",
              "      <td>0.084250</td>\n",
              "      <td>0.073591</td>\n",
              "      <td>0.056408</td>\n",
              "      <td>0.069045</td>\n",
              "      <td>0.230700</td>\n",
              "      <td>0.036401</td>\n",
              "      <td>0.046560</td>\n",
              "      <td>0.063846</td>\n",
              "      <td>-0.020054</td>\n",
              "      <td>-0.195954</td>\n",
              "      <td>0.105089</td>\n",
              "      <td>0.135998</td>\n",
              "      <td>0.012933</td>\n",
              "      <td>0.003626</td>\n",
              "      <td>0.035108</td>\n",
              "      <td>-0.043545</td>\n",
              "      <td>-0.011746</td>\n",
              "      <td>0.012166</td>\n",
              "      <td>0.097187</td>\n",
              "      <td>0.032172</td>\n",
              "      <td>-1.000663e-01</td>\n",
              "      <td>-0.012148</td>\n",
              "      <td>-0.083478</td>\n",
              "      <td>0.018551</td>\n",
              "      <td>0.048809</td>\n",
              "      <td>0.003741</td>\n",
              "      <td>-0.024984</td>\n",
              "      <td>-0.022003</td>\n",
              "      <td>0.027554</td>\n",
              "      <td>0.129938</td>\n",
              "      <td>-0.010366</td>\n",
              "      <td>0.312885</td>\n",
              "      <td>0.020570</td>\n",
              "      <td>-0.532415</td>\n",
              "      <td>0.006732</td>\n",
              "      <td>0.268079</td>\n",
              "      <td>0.313163</td>\n",
              "      <td>...</td>\n",
              "      <td>0.020935</td>\n",
              "      <td>0.015862</td>\n",
              "      <td>-0.000435</td>\n",
              "      <td>0.030883</td>\n",
              "      <td>-0.003007</td>\n",
              "      <td>0.003761</td>\n",
              "      <td>-0.018907</td>\n",
              "      <td>0.012232</td>\n",
              "      <td>-0.002093</td>\n",
              "      <td>-0.000408</td>\n",
              "      <td>0.019861</td>\n",
              "      <td>-0.021609</td>\n",
              "      <td>-0.000155</td>\n",
              "      <td>-0.003053</td>\n",
              "      <td>-0.002917</td>\n",
              "      <td>-0.003160</td>\n",
              "      <td>0.014166</td>\n",
              "      <td>0.000923</td>\n",
              "      <td>0.000606</td>\n",
              "      <td>-0.002177</td>\n",
              "      <td>0.025300</td>\n",
              "      <td>-0.013133</td>\n",
              "      <td>-0.001477</td>\n",
              "      <td>-0.006675</td>\n",
              "      <td>-0.055328</td>\n",
              "      <td>-0.013977</td>\n",
              "      <td>-0.001447</td>\n",
              "      <td>-0.008189</td>\n",
              "      <td>0.006123</td>\n",
              "      <td>0.008739</td>\n",
              "      <td>-0.001048</td>\n",
              "      <td>0.009957</td>\n",
              "      <td>-0.000379</td>\n",
              "      <td>0.004694</td>\n",
              "      <td>-0.015448</td>\n",
              "      <td>-0.005979</td>\n",
              "      <td>0.007567</td>\n",
              "      <td>0.014750</td>\n",
              "      <td>-1.349745e-02</td>\n",
              "      <td>0.002971</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>demogweight</th>\n",
              "      <td>-0.075810</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.043853</td>\n",
              "      <td>0.029492</td>\n",
              "      <td>0.004366</td>\n",
              "      <td>-0.012152</td>\n",
              "      <td>-0.015179</td>\n",
              "      <td>-0.008029</td>\n",
              "      <td>-0.000828</td>\n",
              "      <td>-0.011089</td>\n",
              "      <td>-0.002865</td>\n",
              "      <td>0.008137</td>\n",
              "      <td>0.037964</td>\n",
              "      <td>-0.024646</td>\n",
              "      <td>-0.030783</td>\n",
              "      <td>-0.010128</td>\n",
              "      <td>-0.001468</td>\n",
              "      <td>-0.000327</td>\n",
              "      <td>0.002274</td>\n",
              "      <td>0.002097</td>\n",
              "      <td>0.010296</td>\n",
              "      <td>-0.017099</td>\n",
              "      <td>-0.030834</td>\n",
              "      <td>2.749919e-02</td>\n",
              "      <td>0.016231</td>\n",
              "      <td>-0.005282</td>\n",
              "      <td>0.011137</td>\n",
              "      <td>-0.018223</td>\n",
              "      <td>0.017104</td>\n",
              "      <td>0.007688</td>\n",
              "      <td>-0.000041</td>\n",
              "      <td>-0.001721</td>\n",
              "      <td>-0.018035</td>\n",
              "      <td>0.002586</td>\n",
              "      <td>-0.023808</td>\n",
              "      <td>0.003888</td>\n",
              "      <td>0.035494</td>\n",
              "      <td>0.029382</td>\n",
              "      <td>-0.024567</td>\n",
              "      <td>-0.019162</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.010107</td>\n",
              "      <td>-0.008856</td>\n",
              "      <td>0.006546</td>\n",
              "      <td>0.030293</td>\n",
              "      <td>0.003193</td>\n",
              "      <td>0.002033</td>\n",
              "      <td>0.034100</td>\n",
              "      <td>-0.000818</td>\n",
              "      <td>0.002485</td>\n",
              "      <td>-0.005904</td>\n",
              "      <td>-0.013729</td>\n",
              "      <td>0.035315</td>\n",
              "      <td>0.008835</td>\n",
              "      <td>-0.009723</td>\n",
              "      <td>0.009367</td>\n",
              "      <td>0.006459</td>\n",
              "      <td>-0.002536</td>\n",
              "      <td>-0.007650</td>\n",
              "      <td>0.000441</td>\n",
              "      <td>-0.014243</td>\n",
              "      <td>-0.000030</td>\n",
              "      <td>0.010710</td>\n",
              "      <td>-0.000894</td>\n",
              "      <td>0.004573</td>\n",
              "      <td>0.135171</td>\n",
              "      <td>0.042862</td>\n",
              "      <td>0.000079</td>\n",
              "      <td>0.024041</td>\n",
              "      <td>-0.018450</td>\n",
              "      <td>0.000162</td>\n",
              "      <td>-0.014834</td>\n",
              "      <td>0.006168</td>\n",
              "      <td>-0.002379</td>\n",
              "      <td>-0.009925</td>\n",
              "      <td>-0.001430</td>\n",
              "      <td>-0.002753</td>\n",
              "      <td>0.004747</td>\n",
              "      <td>-0.075252</td>\n",
              "      <td>-1.083933e-02</td>\n",
              "      <td>-0.003121</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>education-num</th>\n",
              "      <td>0.032765</td>\n",
              "      <td>-0.043853</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.015325</td>\n",
              "      <td>0.120998</td>\n",
              "      <td>0.078483</td>\n",
              "      <td>0.145903</td>\n",
              "      <td>0.333539</td>\n",
              "      <td>-0.076632</td>\n",
              "      <td>0.061801</td>\n",
              "      <td>0.093544</td>\n",
              "      <td>-0.019257</td>\n",
              "      <td>-0.117293</td>\n",
              "      <td>0.074560</td>\n",
              "      <td>0.016396</td>\n",
              "      <td>0.104780</td>\n",
              "      <td>-0.009675</td>\n",
              "      <td>-0.077686</td>\n",
              "      <td>0.001677</td>\n",
              "      <td>-0.002403</td>\n",
              "      <td>-0.144104</td>\n",
              "      <td>0.198788</td>\n",
              "      <td>-0.103183</td>\n",
              "      <td>-1.200995e-01</td>\n",
              "      <td>-0.160261</td>\n",
              "      <td>-0.166606</td>\n",
              "      <td>-0.072322</td>\n",
              "      <td>0.420669</td>\n",
              "      <td>0.007580</td>\n",
              "      <td>0.030819</td>\n",
              "      <td>0.056185</td>\n",
              "      <td>-0.117117</td>\n",
              "      <td>-0.012802</td>\n",
              "      <td>-0.001425</td>\n",
              "      <td>0.085792</td>\n",
              "      <td>-0.028831</td>\n",
              "      <td>-0.026164</td>\n",
              "      <td>-0.056298</td>\n",
              "      <td>-0.074710</td>\n",
              "      <td>0.078546</td>\n",
              "      <td>...</td>\n",
              "      <td>0.010197</td>\n",
              "      <td>0.019219</td>\n",
              "      <td>-0.009472</td>\n",
              "      <td>-0.014264</td>\n",
              "      <td>-0.054384</td>\n",
              "      <td>-0.012232</td>\n",
              "      <td>-0.059220</td>\n",
              "      <td>0.021058</td>\n",
              "      <td>0.028235</td>\n",
              "      <td>0.017840</td>\n",
              "      <td>-0.000967</td>\n",
              "      <td>-0.074257</td>\n",
              "      <td>-0.020116</td>\n",
              "      <td>-0.000201</td>\n",
              "      <td>-0.010191</td>\n",
              "      <td>0.000824</td>\n",
              "      <td>0.007968</td>\n",
              "      <td>0.048578</td>\n",
              "      <td>0.032696</td>\n",
              "      <td>0.000257</td>\n",
              "      <td>-0.013182</td>\n",
              "      <td>-0.010315</td>\n",
              "      <td>0.023618</td>\n",
              "      <td>-0.005818</td>\n",
              "      <td>-0.208710</td>\n",
              "      <td>-0.016846</td>\n",
              "      <td>0.003803</td>\n",
              "      <td>-0.013350</td>\n",
              "      <td>0.023562</td>\n",
              "      <td>0.001418</td>\n",
              "      <td>-0.043159</td>\n",
              "      <td>-0.041182</td>\n",
              "      <td>-0.003078</td>\n",
              "      <td>0.016651</td>\n",
              "      <td>0.055609</td>\n",
              "      <td>0.006886</td>\n",
              "      <td>-0.016410</td>\n",
              "      <td>0.097154</td>\n",
              "      <td>-1.228039e-02</td>\n",
              "      <td>-0.001414</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sex</th>\n",
              "      <td>0.084250</td>\n",
              "      <td>0.029492</td>\n",
              "      <td>0.015325</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.046675</td>\n",
              "      <td>0.047298</td>\n",
              "      <td>0.231300</td>\n",
              "      <td>0.216744</td>\n",
              "      <td>-0.064332</td>\n",
              "      <td>0.001360</td>\n",
              "      <td>-0.037375</td>\n",
              "      <td>0.003955</td>\n",
              "      <td>-0.038663</td>\n",
              "      <td>0.082752</td>\n",
              "      <td>0.108901</td>\n",
              "      <td>-0.015087</td>\n",
              "      <td>-0.000068</td>\n",
              "      <td>-0.063981</td>\n",
              "      <td>-0.261708</td>\n",
              "      <td>0.011789</td>\n",
              "      <td>0.220351</td>\n",
              "      <td>0.041797</td>\n",
              "      <td>0.098223</td>\n",
              "      <td>9.002574e-02</td>\n",
              "      <td>0.028092</td>\n",
              "      <td>-0.152487</td>\n",
              "      <td>-0.092882</td>\n",
              "      <td>-0.029677</td>\n",
              "      <td>0.068263</td>\n",
              "      <td>-0.008180</td>\n",
              "      <td>-0.014317</td>\n",
              "      <td>0.135334</td>\n",
              "      <td>-0.227740</td>\n",
              "      <td>-0.019128</td>\n",
              "      <td>0.428777</td>\n",
              "      <td>-0.036005</td>\n",
              "      <td>-0.168035</td>\n",
              "      <td>-0.105813</td>\n",
              "      <td>-0.192378</td>\n",
              "      <td>0.578051</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.001580</td>\n",
              "      <td>0.005033</td>\n",
              "      <td>-0.004161</td>\n",
              "      <td>-0.016048</td>\n",
              "      <td>-0.011148</td>\n",
              "      <td>0.000928</td>\n",
              "      <td>0.002978</td>\n",
              "      <td>-0.003364</td>\n",
              "      <td>-0.003037</td>\n",
              "      <td>-0.017557</td>\n",
              "      <td>0.012969</td>\n",
              "      <td>-0.000795</td>\n",
              "      <td>-0.007410</td>\n",
              "      <td>-0.008979</td>\n",
              "      <td>-0.011148</td>\n",
              "      <td>-0.001426</td>\n",
              "      <td>-0.007153</td>\n",
              "      <td>0.025012</td>\n",
              "      <td>0.008197</td>\n",
              "      <td>0.000928</td>\n",
              "      <td>0.002249</td>\n",
              "      <td>-0.026074</td>\n",
              "      <td>0.003724</td>\n",
              "      <td>0.003102</td>\n",
              "      <td>0.029994</td>\n",
              "      <td>-0.001906</td>\n",
              "      <td>-0.001648</td>\n",
              "      <td>-0.009450</td>\n",
              "      <td>-0.006494</td>\n",
              "      <td>-0.005282</td>\n",
              "      <td>-0.001814</td>\n",
              "      <td>-0.019455</td>\n",
              "      <td>-0.004547</td>\n",
              "      <td>-0.006347</td>\n",
              "      <td>0.001927</td>\n",
              "      <td>-0.010497</td>\n",
              "      <td>-0.007837</td>\n",
              "      <td>-0.002877</td>\n",
              "      <td>-4.598300e-03</td>\n",
              "      <td>0.002625</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>capital-gain</th>\n",
              "      <td>0.073591</td>\n",
              "      <td>0.004366</td>\n",
              "      <td>0.120998</td>\n",
              "      <td>0.046675</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.031346</td>\n",
              "      <td>0.079760</td>\n",
              "      <td>0.222510</td>\n",
              "      <td>-0.011963</td>\n",
              "      <td>-0.006027</td>\n",
              "      <td>-0.007134</td>\n",
              "      <td>-0.002057</td>\n",
              "      <td>-0.036334</td>\n",
              "      <td>0.088260</td>\n",
              "      <td>0.029712</td>\n",
              "      <td>-0.009090</td>\n",
              "      <td>-0.000836</td>\n",
              "      <td>-0.012069</td>\n",
              "      <td>-0.026552</td>\n",
              "      <td>-0.002433</td>\n",
              "      <td>-0.023552</td>\n",
              "      <td>0.054153</td>\n",
              "      <td>-0.010702</td>\n",
              "      <td>-2.228968e-02</td>\n",
              "      <td>-0.025296</td>\n",
              "      <td>-0.040791</td>\n",
              "      <td>-0.009280</td>\n",
              "      <td>0.087860</td>\n",
              "      <td>-0.006556</td>\n",
              "      <td>0.012519</td>\n",
              "      <td>-0.010222</td>\n",
              "      <td>-0.018225</td>\n",
              "      <td>-0.016525</td>\n",
              "      <td>-0.003119</td>\n",
              "      <td>0.086638</td>\n",
              "      <td>-0.004786</td>\n",
              "      <td>-0.067831</td>\n",
              "      <td>-0.016633</td>\n",
              "      <td>-0.012032</td>\n",
              "      <td>0.080896</td>\n",
              "      <td>...</td>\n",
              "      <td>0.006315</td>\n",
              "      <td>-0.004131</td>\n",
              "      <td>-0.005738</td>\n",
              "      <td>-0.004336</td>\n",
              "      <td>0.005126</td>\n",
              "      <td>-0.001146</td>\n",
              "      <td>-0.003259</td>\n",
              "      <td>-0.002430</td>\n",
              "      <td>-0.002879</td>\n",
              "      <td>-0.004398</td>\n",
              "      <td>0.002149</td>\n",
              "      <td>-0.005590</td>\n",
              "      <td>-0.005673</td>\n",
              "      <td>-0.000920</td>\n",
              "      <td>-0.002602</td>\n",
              "      <td>-0.003051</td>\n",
              "      <td>-0.001803</td>\n",
              "      <td>0.017188</td>\n",
              "      <td>0.007119</td>\n",
              "      <td>-0.002500</td>\n",
              "      <td>-0.002609</td>\n",
              "      <td>-0.007012</td>\n",
              "      <td>0.012574</td>\n",
              "      <td>-0.001740</td>\n",
              "      <td>-0.012803</td>\n",
              "      <td>-0.003452</td>\n",
              "      <td>-0.002602</td>\n",
              "      <td>-0.004090</td>\n",
              "      <td>-0.000619</td>\n",
              "      <td>-0.005214</td>\n",
              "      <td>-0.003519</td>\n",
              "      <td>-0.006005</td>\n",
              "      <td>-0.002759</td>\n",
              "      <td>0.008449</td>\n",
              "      <td>0.008321</td>\n",
              "      <td>-0.003563</td>\n",
              "      <td>-0.003186</td>\n",
              "      <td>0.003183</td>\n",
              "      <td>-3.567427e-03</td>\n",
              "      <td>-0.001635</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>capital-loss</th>\n",
              "      <td>0.056408</td>\n",
              "      <td>-0.012152</td>\n",
              "      <td>0.078483</td>\n",
              "      <td>0.047298</td>\n",
              "      <td>-0.031346</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.055278</td>\n",
              "      <td>0.147657</td>\n",
              "      <td>-0.019842</td>\n",
              "      <td>0.011206</td>\n",
              "      <td>0.016130</td>\n",
              "      <td>-0.003049</td>\n",
              "      <td>-0.029561</td>\n",
              "      <td>0.030359</td>\n",
              "      <td>0.026063</td>\n",
              "      <td>-0.000816</td>\n",
              "      <td>-0.004091</td>\n",
              "      <td>-0.019996</td>\n",
              "      <td>-0.022826</td>\n",
              "      <td>-0.003608</td>\n",
              "      <td>-0.001435</td>\n",
              "      <td>0.048437</td>\n",
              "      <td>-0.009970</td>\n",
              "      <td>-1.900190e-02</td>\n",
              "      <td>-0.013646</td>\n",
              "      <td>-0.041324</td>\n",
              "      <td>-0.010443</td>\n",
              "      <td>0.049235</td>\n",
              "      <td>-0.005645</td>\n",
              "      <td>0.006799</td>\n",
              "      <td>0.007481</td>\n",
              "      <td>-0.002012</td>\n",
              "      <td>-0.020203</td>\n",
              "      <td>-0.005455</td>\n",
              "      <td>0.078373</td>\n",
              "      <td>-0.007371</td>\n",
              "      <td>-0.060309</td>\n",
              "      <td>-0.013159</td>\n",
              "      <td>-0.002788</td>\n",
              "      <td>0.073720</td>\n",
              "      <td>...</td>\n",
              "      <td>0.005144</td>\n",
              "      <td>0.013832</td>\n",
              "      <td>-0.009154</td>\n",
              "      <td>-0.009019</td>\n",
              "      <td>-0.006246</td>\n",
              "      <td>-0.005945</td>\n",
              "      <td>-0.008648</td>\n",
              "      <td>0.002270</td>\n",
              "      <td>-0.006251</td>\n",
              "      <td>-0.003073</td>\n",
              "      <td>0.013072</td>\n",
              "      <td>-0.006094</td>\n",
              "      <td>-0.003959</td>\n",
              "      <td>0.033393</td>\n",
              "      <td>0.006744</td>\n",
              "      <td>-0.004523</td>\n",
              "      <td>0.004003</td>\n",
              "      <td>0.003757</td>\n",
              "      <td>0.001436</td>\n",
              "      <td>0.000881</td>\n",
              "      <td>-0.005916</td>\n",
              "      <td>-0.010396</td>\n",
              "      <td>-0.005834</td>\n",
              "      <td>-0.003857</td>\n",
              "      <td>-0.023695</td>\n",
              "      <td>0.003988</td>\n",
              "      <td>-0.003857</td>\n",
              "      <td>-0.000465</td>\n",
              "      <td>0.005976</td>\n",
              "      <td>-0.009553</td>\n",
              "      <td>-0.007219</td>\n",
              "      <td>-0.003237</td>\n",
              "      <td>-0.004091</td>\n",
              "      <td>0.012681</td>\n",
              "      <td>0.005565</td>\n",
              "      <td>-0.005282</td>\n",
              "      <td>0.014509</td>\n",
              "      <td>0.008887</td>\n",
              "      <td>3.400600e-03</td>\n",
              "      <td>-0.004523</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>hours-per-week</th>\n",
              "      <td>0.069045</td>\n",
              "      <td>-0.015179</td>\n",
              "      <td>0.145903</td>\n",
              "      <td>0.231300</td>\n",
              "      <td>0.079760</td>\n",
              "      <td>0.055278</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.227305</td>\n",
              "      <td>-0.171922</td>\n",
              "      <td>0.018120</td>\n",
              "      <td>0.008648</td>\n",
              "      <td>-0.010818</td>\n",
              "      <td>-0.022269</td>\n",
              "      <td>0.126515</td>\n",
              "      <td>0.098524</td>\n",
              "      <td>-0.023873</td>\n",
              "      <td>-0.013487</td>\n",
              "      <td>-0.172298</td>\n",
              "      <td>-0.086002</td>\n",
              "      <td>0.006832</td>\n",
              "      <td>0.053873</td>\n",
              "      <td>0.140787</td>\n",
              "      <td>0.101812</td>\n",
              "      <td>-3.808032e-02</td>\n",
              "      <td>0.005054</td>\n",
              "      <td>-0.158089</td>\n",
              "      <td>-0.041721</td>\n",
              "      <td>0.058090</td>\n",
              "      <td>0.028399</td>\n",
              "      <td>0.013078</td>\n",
              "      <td>-0.011773</td>\n",
              "      <td>0.079753</td>\n",
              "      <td>0.028222</td>\n",
              "      <td>-0.005211</td>\n",
              "      <td>0.213275</td>\n",
              "      <td>-0.006221</td>\n",
              "      <td>-0.196156</td>\n",
              "      <td>-0.018288</td>\n",
              "      <td>-0.114527</td>\n",
              "      <td>0.247201</td>\n",
              "      <td>...</td>\n",
              "      <td>0.002468</td>\n",
              "      <td>-0.012459</td>\n",
              "      <td>-0.002711</td>\n",
              "      <td>-0.013797</td>\n",
              "      <td>0.006305</td>\n",
              "      <td>-0.005988</td>\n",
              "      <td>-0.015254</td>\n",
              "      <td>0.003318</td>\n",
              "      <td>0.015991</td>\n",
              "      <td>0.000278</td>\n",
              "      <td>0.017124</td>\n",
              "      <td>-0.003958</td>\n",
              "      <td>-0.011978</td>\n",
              "      <td>-0.000210</td>\n",
              "      <td>-0.008412</td>\n",
              "      <td>0.001166</td>\n",
              "      <td>-0.014813</td>\n",
              "      <td>0.005140</td>\n",
              "      <td>0.012764</td>\n",
              "      <td>0.004161</td>\n",
              "      <td>0.006635</td>\n",
              "      <td>-0.004775</td>\n",
              "      <td>0.009617</td>\n",
              "      <td>-0.000593</td>\n",
              "      <td>-0.001360</td>\n",
              "      <td>-0.014425</td>\n",
              "      <td>0.006135</td>\n",
              "      <td>-0.014200</td>\n",
              "      <td>-0.002918</td>\n",
              "      <td>-0.006101</td>\n",
              "      <td>0.002975</td>\n",
              "      <td>-0.010418</td>\n",
              "      <td>-0.004058</td>\n",
              "      <td>0.009392</td>\n",
              "      <td>-0.001518</td>\n",
              "      <td>0.014196</td>\n",
              "      <td>-0.003844</td>\n",
              "      <td>0.003120</td>\n",
              "      <td>-1.014576e-02</td>\n",
              "      <td>0.001631</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>income</th>\n",
              "      <td>0.230700</td>\n",
              "      <td>-0.008029</td>\n",
              "      <td>0.333539</td>\n",
              "      <td>0.216744</td>\n",
              "      <td>0.222510</td>\n",
              "      <td>0.147657</td>\n",
              "      <td>0.227305</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.076215</td>\n",
              "      <td>0.056866</td>\n",
              "      <td>0.030156</td>\n",
              "      <td>-0.007934</td>\n",
              "      <td>-0.081530</td>\n",
              "      <td>0.140589</td>\n",
              "      <td>0.032488</td>\n",
              "      <td>0.019831</td>\n",
              "      <td>-0.010645</td>\n",
              "      <td>-0.076574</td>\n",
              "      <td>-0.092386</td>\n",
              "      <td>-0.009388</td>\n",
              "      <td>-0.012557</td>\n",
              "      <td>0.213747</td>\n",
              "      <td>-0.050876</td>\n",
              "      <td>-8.388988e-02</td>\n",
              "      <td>-0.070135</td>\n",
              "      <td>-0.154604</td>\n",
              "      <td>-0.039121</td>\n",
              "      <td>0.185925</td>\n",
              "      <td>0.026440</td>\n",
              "      <td>0.022895</td>\n",
              "      <td>0.026499</td>\n",
              "      <td>-0.019057</td>\n",
              "      <td>-0.128580</td>\n",
              "      <td>0.011751</td>\n",
              "      <td>0.445289</td>\n",
              "      <td>-0.042436</td>\n",
              "      <td>-0.315986</td>\n",
              "      <td>-0.074208</td>\n",
              "      <td>-0.067359</td>\n",
              "      <td>0.401629</td>\n",
              "      <td>...</td>\n",
              "      <td>0.016872</td>\n",
              "      <td>0.001223</td>\n",
              "      <td>-0.019398</td>\n",
              "      <td>-0.003908</td>\n",
              "      <td>-0.022061</td>\n",
              "      <td>-0.008667</td>\n",
              "      <td>-0.017903</td>\n",
              "      <td>0.015335</td>\n",
              "      <td>0.012857</td>\n",
              "      <td>0.011155</td>\n",
              "      <td>0.004622</td>\n",
              "      <td>-0.023014</td>\n",
              "      <td>-0.014668</td>\n",
              "      <td>-0.003548</td>\n",
              "      <td>-0.004795</td>\n",
              "      <td>0.006111</td>\n",
              "      <td>-0.006533</td>\n",
              "      <td>0.016252</td>\n",
              "      <td>0.011589</td>\n",
              "      <td>0.001538</td>\n",
              "      <td>0.017678</td>\n",
              "      <td>-0.011463</td>\n",
              "      <td>0.018225</td>\n",
              "      <td>-0.004795</td>\n",
              "      <td>-0.062211</td>\n",
              "      <td>-0.011816</td>\n",
              "      <td>-0.010036</td>\n",
              "      <td>-0.013931</td>\n",
              "      <td>0.005876</td>\n",
              "      <td>-0.005783</td>\n",
              "      <td>-0.010376</td>\n",
              "      <td>-0.018156</td>\n",
              "      <td>-0.005704</td>\n",
              "      <td>-0.000592</td>\n",
              "      <td>0.018191</td>\n",
              "      <td>-0.002260</td>\n",
              "      <td>-0.008013</td>\n",
              "      <td>0.034922</td>\n",
              "      <td>-2.091570e-02</td>\n",
              "      <td>0.006111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>w_?</th>\n",
              "      <td>0.036401</td>\n",
              "      <td>-0.000828</td>\n",
              "      <td>-0.076632</td>\n",
              "      <td>-0.064332</td>\n",
              "      <td>-0.011963</td>\n",
              "      <td>-0.019842</td>\n",
              "      <td>-0.171922</td>\n",
              "      <td>-0.076215</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.042817</td>\n",
              "      <td>-0.064173</td>\n",
              "      <td>-0.003444</td>\n",
              "      <td>-0.367871</td>\n",
              "      <td>-0.045871</td>\n",
              "      <td>-0.071365</td>\n",
              "      <td>-0.049516</td>\n",
              "      <td>-0.004620</td>\n",
              "      <td>0.998112</td>\n",
              "      <td>-0.089481</td>\n",
              "      <td>-0.004075</td>\n",
              "      <td>-0.091972</td>\n",
              "      <td>-0.091331</td>\n",
              "      <td>-0.043315</td>\n",
              "      <td>-4.969790e-02</td>\n",
              "      <td>-0.062293</td>\n",
              "      <td>-0.082145</td>\n",
              "      <td>-0.016979</td>\n",
              "      <td>-0.092946</td>\n",
              "      <td>-0.034888</td>\n",
              "      <td>-0.086727</td>\n",
              "      <td>-0.041414</td>\n",
              "      <td>-0.055336</td>\n",
              "      <td>-0.025893</td>\n",
              "      <td>0.007601</td>\n",
              "      <td>-0.054926</td>\n",
              "      <td>0.008634</td>\n",
              "      <td>0.045458</td>\n",
              "      <td>0.005002</td>\n",
              "      <td>0.074551</td>\n",
              "      <td>-0.068908</td>\n",
              "      <td>...</td>\n",
              "      <td>0.009588</td>\n",
              "      <td>0.009398</td>\n",
              "      <td>-0.002128</td>\n",
              "      <td>-0.003342</td>\n",
              "      <td>-0.000082</td>\n",
              "      <td>-0.000399</td>\n",
              "      <td>-0.003342</td>\n",
              "      <td>-0.003342</td>\n",
              "      <td>-0.001052</td>\n",
              "      <td>0.003528</td>\n",
              "      <td>-0.007388</td>\n",
              "      <td>-0.007004</td>\n",
              "      <td>-0.005032</td>\n",
              "      <td>-0.001540</td>\n",
              "      <td>0.005374</td>\n",
              "      <td>0.003190</td>\n",
              "      <td>-0.004870</td>\n",
              "      <td>-0.012621</td>\n",
              "      <td>-0.004462</td>\n",
              "      <td>-0.006715</td>\n",
              "      <td>0.003425</td>\n",
              "      <td>-0.008123</td>\n",
              "      <td>-0.002728</td>\n",
              "      <td>0.005374</td>\n",
              "      <td>-0.000388</td>\n",
              "      <td>-0.002197</td>\n",
              "      <td>-0.004356</td>\n",
              "      <td>-0.001648</td>\n",
              "      <td>-0.001011</td>\n",
              "      <td>0.001015</td>\n",
              "      <td>0.007457</td>\n",
              "      <td>-0.006675</td>\n",
              "      <td>-0.004620</td>\n",
              "      <td>0.015218</td>\n",
              "      <td>0.028258</td>\n",
              "      <td>0.001141</td>\n",
              "      <td>0.002610</td>\n",
              "      <td>0.003616</td>\n",
              "      <td>-7.003826e-03</td>\n",
              "      <td>-0.005108</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>w_Federal-gov</th>\n",
              "      <td>0.046560</td>\n",
              "      <td>-0.011089</td>\n",
              "      <td>0.061801</td>\n",
              "      <td>0.001360</td>\n",
              "      <td>-0.006027</td>\n",
              "      <td>0.011206</td>\n",
              "      <td>0.018120</td>\n",
              "      <td>0.056866</td>\n",
              "      <td>-0.042817</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.046354</td>\n",
              "      <td>-0.002487</td>\n",
              "      <td>-0.265722</td>\n",
              "      <td>-0.033134</td>\n",
              "      <td>-0.051549</td>\n",
              "      <td>-0.035767</td>\n",
              "      <td>-0.003337</td>\n",
              "      <td>-0.042898</td>\n",
              "      <td>0.113517</td>\n",
              "      <td>0.095162</td>\n",
              "      <td>-0.031678</td>\n",
              "      <td>0.028151</td>\n",
              "      <td>-0.023129</td>\n",
              "      <td>-1.316257e-02</td>\n",
              "      <td>-0.035231</td>\n",
              "      <td>-0.036112</td>\n",
              "      <td>-0.012265</td>\n",
              "      <td>0.030683</td>\n",
              "      <td>0.016550</td>\n",
              "      <td>-0.054485</td>\n",
              "      <td>0.049516</td>\n",
              "      <td>-0.018271</td>\n",
              "      <td>0.018356</td>\n",
              "      <td>0.014093</td>\n",
              "      <td>0.010246</td>\n",
              "      <td>-0.001731</td>\n",
              "      <td>-0.025826</td>\n",
              "      <td>-0.002123</td>\n",
              "      <td>0.005337</td>\n",
              "      <td>0.015817</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.003622</td>\n",
              "      <td>-0.008626</td>\n",
              "      <td>0.003596</td>\n",
              "      <td>-0.000700</td>\n",
              "      <td>-0.008182</td>\n",
              "      <td>-0.004850</td>\n",
              "      <td>-0.000700</td>\n",
              "      <td>0.003676</td>\n",
              "      <td>-0.005099</td>\n",
              "      <td>0.003458</td>\n",
              "      <td>-0.005337</td>\n",
              "      <td>-0.002624</td>\n",
              "      <td>-0.006862</td>\n",
              "      <td>-0.001112</td>\n",
              "      <td>-0.003146</td>\n",
              "      <td>-0.003690</td>\n",
              "      <td>-0.003518</td>\n",
              "      <td>-0.004581</td>\n",
              "      <td>0.005958</td>\n",
              "      <td>-0.004850</td>\n",
              "      <td>-0.003253</td>\n",
              "      <td>-0.008481</td>\n",
              "      <td>0.003000</td>\n",
              "      <td>-0.003146</td>\n",
              "      <td>-0.023119</td>\n",
              "      <td>0.001855</td>\n",
              "      <td>-0.003146</td>\n",
              "      <td>-0.005337</td>\n",
              "      <td>0.013528</td>\n",
              "      <td>-0.002492</td>\n",
              "      <td>-0.005889</td>\n",
              "      <td>0.011829</td>\n",
              "      <td>-0.003337</td>\n",
              "      <td>-0.004269</td>\n",
              "      <td>-0.007214</td>\n",
              "      <td>-0.004309</td>\n",
              "      <td>-0.003854</td>\n",
              "      <td>0.017245</td>\n",
              "      <td>-2.624238e-03</td>\n",
              "      <td>-0.003690</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>w_Local-gov</th>\n",
              "      <td>0.063846</td>\n",
              "      <td>-0.002865</td>\n",
              "      <td>0.093544</td>\n",
              "      <td>-0.037375</td>\n",
              "      <td>-0.007134</td>\n",
              "      <td>0.016130</td>\n",
              "      <td>0.008648</td>\n",
              "      <td>0.030156</td>\n",
              "      <td>-0.064173</td>\n",
              "      <td>-0.046354</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.003728</td>\n",
              "      <td>-0.398254</td>\n",
              "      <td>-0.049660</td>\n",
              "      <td>-0.077259</td>\n",
              "      <td>-0.053606</td>\n",
              "      <td>-0.005002</td>\n",
              "      <td>-0.064294</td>\n",
              "      <td>0.013406</td>\n",
              "      <td>-0.004411</td>\n",
              "      <td>-0.040163</td>\n",
              "      <td>-0.013985</td>\n",
              "      <td>-0.025246</td>\n",
              "      <td>-2.729880e-02</td>\n",
              "      <td>-0.062031</td>\n",
              "      <td>-0.004272</td>\n",
              "      <td>-0.018382</td>\n",
              "      <td>0.157055</td>\n",
              "      <td>0.228089</td>\n",
              "      <td>-0.090809</td>\n",
              "      <td>-0.012436</td>\n",
              "      <td>0.009184</td>\n",
              "      <td>0.029164</td>\n",
              "      <td>-0.006670</td>\n",
              "      <td>0.013289</td>\n",
              "      <td>-0.003290</td>\n",
              "      <td>-0.040518</td>\n",
              "      <td>-0.000985</td>\n",
              "      <td>0.017902</td>\n",
              "      <td>0.002728</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.003698</td>\n",
              "      <td>-0.006294</td>\n",
              "      <td>-0.011193</td>\n",
              "      <td>-0.008108</td>\n",
              "      <td>-0.008767</td>\n",
              "      <td>-0.007269</td>\n",
              "      <td>-0.005079</td>\n",
              "      <td>-0.002051</td>\n",
              "      <td>0.009164</td>\n",
              "      <td>-0.001594</td>\n",
              "      <td>-0.002645</td>\n",
              "      <td>-0.004534</td>\n",
              "      <td>0.006380</td>\n",
              "      <td>-0.001667</td>\n",
              "      <td>0.004359</td>\n",
              "      <td>0.002209</td>\n",
              "      <td>-0.005273</td>\n",
              "      <td>-0.010524</td>\n",
              "      <td>-0.001188</td>\n",
              "      <td>-0.007269</td>\n",
              "      <td>-0.008912</td>\n",
              "      <td>-0.005963</td>\n",
              "      <td>-0.007853</td>\n",
              "      <td>0.004359</td>\n",
              "      <td>-0.021939</td>\n",
              "      <td>0.001931</td>\n",
              "      <td>0.004359</td>\n",
              "      <td>-0.002645</td>\n",
              "      <td>-0.003789</td>\n",
              "      <td>-0.000672</td>\n",
              "      <td>-0.003974</td>\n",
              "      <td>-0.003244</td>\n",
              "      <td>-0.005002</td>\n",
              "      <td>-0.013353</td>\n",
              "      <td>-0.002886</td>\n",
              "      <td>-0.006458</td>\n",
              "      <td>-0.005776</td>\n",
              "      <td>0.034434</td>\n",
              "      <td>-9.009347e-04</td>\n",
              "      <td>0.002209</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>w_Never-worked</th>\n",
              "      <td>-0.020054</td>\n",
              "      <td>0.008137</td>\n",
              "      <td>-0.019257</td>\n",
              "      <td>0.003955</td>\n",
              "      <td>-0.002057</td>\n",
              "      <td>-0.003049</td>\n",
              "      <td>-0.010818</td>\n",
              "      <td>-0.007934</td>\n",
              "      <td>-0.003444</td>\n",
              "      <td>-0.002487</td>\n",
              "      <td>-0.003728</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.021370</td>\n",
              "      <td>-0.002665</td>\n",
              "      <td>-0.004146</td>\n",
              "      <td>-0.002876</td>\n",
              "      <td>-0.000268</td>\n",
              "      <td>0.057982</td>\n",
              "      <td>-0.005198</td>\n",
              "      <td>-0.000237</td>\n",
              "      <td>-0.005343</td>\n",
              "      <td>-0.005306</td>\n",
              "      <td>-0.002516</td>\n",
              "      <td>-2.887040e-03</td>\n",
              "      <td>-0.003619</td>\n",
              "      <td>-0.004772</td>\n",
              "      <td>-0.000986</td>\n",
              "      <td>-0.005399</td>\n",
              "      <td>-0.002027</td>\n",
              "      <td>-0.005038</td>\n",
              "      <td>-0.002406</td>\n",
              "      <td>-0.003215</td>\n",
              "      <td>0.002572</td>\n",
              "      <td>-0.000358</td>\n",
              "      <td>-0.012992</td>\n",
              "      <td>-0.001631</td>\n",
              "      <td>0.014178</td>\n",
              "      <td>-0.002548</td>\n",
              "      <td>-0.002520</td>\n",
              "      <td>-0.011610</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.000892</td>\n",
              "      <td>-0.000694</td>\n",
              "      <td>-0.000601</td>\n",
              "      <td>-0.000760</td>\n",
              "      <td>-0.000658</td>\n",
              "      <td>-0.000390</td>\n",
              "      <td>-0.000760</td>\n",
              "      <td>-0.000760</td>\n",
              "      <td>-0.000410</td>\n",
              "      <td>-0.000905</td>\n",
              "      <td>-0.000429</td>\n",
              "      <td>-0.000633</td>\n",
              "      <td>-0.000552</td>\n",
              "      <td>-0.000089</td>\n",
              "      <td>-0.000253</td>\n",
              "      <td>-0.000297</td>\n",
              "      <td>-0.000283</td>\n",
              "      <td>-0.000733</td>\n",
              "      <td>-0.000530</td>\n",
              "      <td>-0.000390</td>\n",
              "      <td>-0.000664</td>\n",
              "      <td>-0.000682</td>\n",
              "      <td>-0.000620</td>\n",
              "      <td>-0.000253</td>\n",
              "      <td>-0.001996</td>\n",
              "      <td>-0.000447</td>\n",
              "      <td>-0.000253</td>\n",
              "      <td>-0.000429</td>\n",
              "      <td>-0.001103</td>\n",
              "      <td>-0.000627</td>\n",
              "      <td>-0.000474</td>\n",
              "      <td>-0.000878</td>\n",
              "      <td>-0.000268</td>\n",
              "      <td>-0.000717</td>\n",
              "      <td>-0.000580</td>\n",
              "      <td>-0.000347</td>\n",
              "      <td>-0.000310</td>\n",
              "      <td>0.004797</td>\n",
              "      <td>-6.331523e-04</td>\n",
              "      <td>-0.000297</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>w_Private</th>\n",
              "      <td>-0.195954</td>\n",
              "      <td>0.037964</td>\n",
              "      <td>-0.117293</td>\n",
              "      <td>-0.038663</td>\n",
              "      <td>-0.036334</td>\n",
              "      <td>-0.029561</td>\n",
              "      <td>-0.022269</td>\n",
              "      <td>-0.081530</td>\n",
              "      <td>-0.367871</td>\n",
              "      <td>-0.265722</td>\n",
              "      <td>-0.398254</td>\n",
              "      <td>-0.021370</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.284674</td>\n",
              "      <td>-0.442888</td>\n",
              "      <td>-0.307297</td>\n",
              "      <td>-0.028674</td>\n",
              "      <td>-0.368567</td>\n",
              "      <td>0.047560</td>\n",
              "      <td>-0.025287</td>\n",
              "      <td>0.065453</td>\n",
              "      <td>-0.028970</td>\n",
              "      <td>-0.089896</td>\n",
              "      <td>1.044930e-01</td>\n",
              "      <td>0.143636</td>\n",
              "      <td>0.097339</td>\n",
              "      <td>0.046156</td>\n",
              "      <td>-0.114867</td>\n",
              "      <td>-0.124902</td>\n",
              "      <td>0.083157</td>\n",
              "      <td>0.028986</td>\n",
              "      <td>0.047875</td>\n",
              "      <td>0.007650</td>\n",
              "      <td>-0.003871</td>\n",
              "      <td>-0.097705</td>\n",
              "      <td>0.003749</td>\n",
              "      <td>0.106609</td>\n",
              "      <td>0.012160</td>\n",
              "      <td>-0.037632</td>\n",
              "      <td>-0.088168</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.002553</td>\n",
              "      <td>-0.006615</td>\n",
              "      <td>0.009651</td>\n",
              "      <td>0.006376</td>\n",
              "      <td>0.017688</td>\n",
              "      <td>0.015099</td>\n",
              "      <td>0.016107</td>\n",
              "      <td>0.004754</td>\n",
              "      <td>-0.004810</td>\n",
              "      <td>0.002821</td>\n",
              "      <td>-0.008584</td>\n",
              "      <td>0.021846</td>\n",
              "      <td>0.007975</td>\n",
              "      <td>0.004186</td>\n",
              "      <td>-0.007596</td>\n",
              "      <td>0.001453</td>\n",
              "      <td>0.000200</td>\n",
              "      <td>-0.002676</td>\n",
              "      <td>-0.007761</td>\n",
              "      <td>0.015099</td>\n",
              "      <td>-0.007878</td>\n",
              "      <td>0.017463</td>\n",
              "      <td>0.003218</td>\n",
              "      <td>0.002123</td>\n",
              "      <td>0.048779</td>\n",
              "      <td>0.004441</td>\n",
              "      <td>0.002123</td>\n",
              "      <td>0.008617</td>\n",
              "      <td>0.014576</td>\n",
              "      <td>0.007714</td>\n",
              "      <td>0.006571</td>\n",
              "      <td>0.010176</td>\n",
              "      <td>0.007978</td>\n",
              "      <td>-0.021509</td>\n",
              "      <td>-0.021661</td>\n",
              "      <td>-0.012177</td>\n",
              "      <td>0.002600</td>\n",
              "      <td>-0.042450</td>\n",
              "      <td>8.228824e-03</td>\n",
              "      <td>0.005597</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>w_Self-emp-inc</th>\n",
              "      <td>0.105089</td>\n",
              "      <td>-0.024646</td>\n",
              "      <td>0.074560</td>\n",
              "      <td>0.082752</td>\n",
              "      <td>0.088260</td>\n",
              "      <td>0.030359</td>\n",
              "      <td>0.126515</td>\n",
              "      <td>0.140589</td>\n",
              "      <td>-0.045871</td>\n",
              "      <td>-0.033134</td>\n",
              "      <td>-0.049660</td>\n",
              "      <td>-0.002665</td>\n",
              "      <td>-0.284674</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.055225</td>\n",
              "      <td>-0.038318</td>\n",
              "      <td>-0.003575</td>\n",
              "      <td>-0.045958</td>\n",
              "      <td>-0.051590</td>\n",
              "      <td>-0.003153</td>\n",
              "      <td>-0.018635</td>\n",
              "      <td>0.137903</td>\n",
              "      <td>0.013650</td>\n",
              "      <td>-3.733633e-02</td>\n",
              "      <td>-0.038134</td>\n",
              "      <td>-0.049777</td>\n",
              "      <td>-0.013139</td>\n",
              "      <td>0.008571</td>\n",
              "      <td>-0.022300</td>\n",
              "      <td>0.089371</td>\n",
              "      <td>-0.029388</td>\n",
              "      <td>-0.022477</td>\n",
              "      <td>-0.022830</td>\n",
              "      <td>-0.004768</td>\n",
              "      <td>0.111996</td>\n",
              "      <td>-0.013995</td>\n",
              "      <td>-0.090283</td>\n",
              "      <td>-0.016307</td>\n",
              "      <td>-0.005553</td>\n",
              "      <td>0.114763</td>\n",
              "      <td>...</td>\n",
              "      <td>0.005623</td>\n",
              "      <td>-0.004748</td>\n",
              "      <td>-0.008001</td>\n",
              "      <td>0.010387</td>\n",
              "      <td>-0.004030</td>\n",
              "      <td>-0.005196</td>\n",
              "      <td>-0.006023</td>\n",
              "      <td>-0.001921</td>\n",
              "      <td>0.002126</td>\n",
              "      <td>0.001736</td>\n",
              "      <td>0.008785</td>\n",
              "      <td>-0.008434</td>\n",
              "      <td>-0.001708</td>\n",
              "      <td>-0.001192</td>\n",
              "      <td>0.008921</td>\n",
              "      <td>-0.003953</td>\n",
              "      <td>-0.003769</td>\n",
              "      <td>0.015747</td>\n",
              "      <td>-0.001175</td>\n",
              "      <td>-0.005196</td>\n",
              "      <td>0.000538</td>\n",
              "      <td>-0.009085</td>\n",
              "      <td>0.001781</td>\n",
              "      <td>-0.003371</td>\n",
              "      <td>-0.013871</td>\n",
              "      <td>-0.005961</td>\n",
              "      <td>-0.003371</td>\n",
              "      <td>-0.005717</td>\n",
              "      <td>-0.009012</td>\n",
              "      <td>-0.003379</td>\n",
              "      <td>-0.006309</td>\n",
              "      <td>-0.011698</td>\n",
              "      <td>-0.003575</td>\n",
              "      <td>0.012208</td>\n",
              "      <td>0.019112</td>\n",
              "      <td>0.022317</td>\n",
              "      <td>0.005908</td>\n",
              "      <td>-0.001873</td>\n",
              "      <td>-3.513435e-03</td>\n",
              "      <td>-0.003953</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>w_Self-emp-not-inc</th>\n",
              "      <td>0.135998</td>\n",
              "      <td>-0.030783</td>\n",
              "      <td>0.016396</td>\n",
              "      <td>0.108901</td>\n",
              "      <td>0.029712</td>\n",
              "      <td>0.026063</td>\n",
              "      <td>0.098524</td>\n",
              "      <td>0.032488</td>\n",
              "      <td>-0.071365</td>\n",
              "      <td>-0.051549</td>\n",
              "      <td>-0.077259</td>\n",
              "      <td>-0.004146</td>\n",
              "      <td>-0.442888</td>\n",
              "      <td>-0.055225</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.059614</td>\n",
              "      <td>-0.005563</td>\n",
              "      <td>-0.071500</td>\n",
              "      <td>-0.089421</td>\n",
              "      <td>-0.004905</td>\n",
              "      <td>0.073958</td>\n",
              "      <td>0.025232</td>\n",
              "      <td>0.232287</td>\n",
              "      <td>-5.227011e-02</td>\n",
              "      <td>-0.056483</td>\n",
              "      <td>-0.032362</td>\n",
              "      <td>-0.020442</td>\n",
              "      <td>0.019746</td>\n",
              "      <td>-0.035670</td>\n",
              "      <td>0.039040</td>\n",
              "      <td>-0.032827</td>\n",
              "      <td>-0.003538</td>\n",
              "      <td>-0.017983</td>\n",
              "      <td>-0.001558</td>\n",
              "      <td>0.118321</td>\n",
              "      <td>-0.001239</td>\n",
              "      <td>-0.103690</td>\n",
              "      <td>-0.016295</td>\n",
              "      <td>-0.005873</td>\n",
              "      <td>0.119882</td>\n",
              "      <td>...</td>\n",
              "      <td>0.002754</td>\n",
              "      <td>0.000766</td>\n",
              "      <td>0.001537</td>\n",
              "      <td>0.000839</td>\n",
              "      <td>-0.007254</td>\n",
              "      <td>-0.008084</td>\n",
              "      <td>-0.007457</td>\n",
              "      <td>-0.004692</td>\n",
              "      <td>0.001731</td>\n",
              "      <td>-0.009462</td>\n",
              "      <td>0.025320</td>\n",
              "      <td>-0.013122</td>\n",
              "      <td>-0.011437</td>\n",
              "      <td>-0.001854</td>\n",
              "      <td>-0.005244</td>\n",
              "      <td>-0.006150</td>\n",
              "      <td>0.016369</td>\n",
              "      <td>-0.003729</td>\n",
              "      <td>0.016768</td>\n",
              "      <td>-0.002706</td>\n",
              "      <td>0.021028</td>\n",
              "      <td>-0.001814</td>\n",
              "      <td>0.000685</td>\n",
              "      <td>-0.005244</td>\n",
              "      <td>-0.019935</td>\n",
              "      <td>-0.004585</td>\n",
              "      <td>0.003041</td>\n",
              "      <td>0.000881</td>\n",
              "      <td>-0.015199</td>\n",
              "      <td>-0.002938</td>\n",
              "      <td>-0.000954</td>\n",
              "      <td>-0.006219</td>\n",
              "      <td>-0.005563</td>\n",
              "      <td>0.037937</td>\n",
              "      <td>-0.008406</td>\n",
              "      <td>0.010973</td>\n",
              "      <td>0.000342</td>\n",
              "      <td>0.011717</td>\n",
              "      <td>1.459445e-04</td>\n",
              "      <td>0.000916</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>w_State-gov</th>\n",
              "      <td>0.012933</td>\n",
              "      <td>-0.010128</td>\n",
              "      <td>0.104780</td>\n",
              "      <td>-0.015087</td>\n",
              "      <td>-0.009090</td>\n",
              "      <td>-0.000816</td>\n",
              "      <td>-0.023873</td>\n",
              "      <td>0.019831</td>\n",
              "      <td>-0.049516</td>\n",
              "      <td>-0.035767</td>\n",
              "      <td>-0.053606</td>\n",
              "      <td>-0.002876</td>\n",
              "      <td>-0.307297</td>\n",
              "      <td>-0.038318</td>\n",
              "      <td>-0.059614</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.003860</td>\n",
              "      <td>-0.049610</td>\n",
              "      <td>0.049233</td>\n",
              "      <td>-0.003404</td>\n",
              "      <td>-0.052046</td>\n",
              "      <td>0.006542</td>\n",
              "      <td>-0.023118</td>\n",
              "      <td>-3.524345e-02</td>\n",
              "      <td>-0.042654</td>\n",
              "      <td>-0.003708</td>\n",
              "      <td>-0.014183</td>\n",
              "      <td>0.120903</td>\n",
              "      <td>0.103596</td>\n",
              "      <td>-0.067911</td>\n",
              "      <td>0.026112</td>\n",
              "      <td>-0.017794</td>\n",
              "      <td>0.006283</td>\n",
              "      <td>0.002952</td>\n",
              "      <td>0.002287</td>\n",
              "      <td>0.001749</td>\n",
              "      <td>-0.005099</td>\n",
              "      <td>0.006784</td>\n",
              "      <td>-0.013694</td>\n",
              "      <td>0.000525</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.006301</td>\n",
              "      <td>0.023510</td>\n",
              "      <td>-0.003805</td>\n",
              "      <td>-0.010930</td>\n",
              "      <td>-0.009462</td>\n",
              "      <td>-0.005609</td>\n",
              "      <td>-0.010930</td>\n",
              "      <td>0.000536</td>\n",
              "      <td>0.001173</td>\n",
              "      <td>-0.000165</td>\n",
              "      <td>-0.006172</td>\n",
              "      <td>-0.009104</td>\n",
              "      <td>0.002579</td>\n",
              "      <td>-0.001286</td>\n",
              "      <td>0.007812</td>\n",
              "      <td>0.005499</td>\n",
              "      <td>-0.004068</td>\n",
              "      <td>0.029073</td>\n",
              "      <td>-0.002137</td>\n",
              "      <td>-0.005609</td>\n",
              "      <td>-0.000807</td>\n",
              "      <td>-0.005550</td>\n",
              "      <td>0.000437</td>\n",
              "      <td>-0.003639</td>\n",
              "      <td>-0.025735</td>\n",
              "      <td>0.000045</td>\n",
              "      <td>-0.003639</td>\n",
              "      <td>-0.006172</td>\n",
              "      <td>-0.010567</td>\n",
              "      <td>-0.009013</td>\n",
              "      <td>-0.006810</td>\n",
              "      <td>-0.002693</td>\n",
              "      <td>0.006937</td>\n",
              "      <td>-0.010303</td>\n",
              "      <td>0.021664</td>\n",
              "      <td>0.003381</td>\n",
              "      <td>-0.004457</td>\n",
              "      <td>0.021842</td>\n",
              "      <td>-4.520152e-03</td>\n",
              "      <td>-0.004267</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>w_Without-pay</th>\n",
              "      <td>0.003626</td>\n",
              "      <td>-0.001468</td>\n",
              "      <td>-0.009675</td>\n",
              "      <td>-0.000068</td>\n",
              "      <td>-0.000836</td>\n",
              "      <td>-0.004091</td>\n",
              "      <td>-0.013487</td>\n",
              "      <td>-0.010645</td>\n",
              "      <td>-0.004620</td>\n",
              "      <td>-0.003337</td>\n",
              "      <td>-0.005002</td>\n",
              "      <td>-0.000268</td>\n",
              "      <td>-0.028674</td>\n",
              "      <td>-0.003575</td>\n",
              "      <td>-0.005563</td>\n",
              "      <td>-0.003860</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.004629</td>\n",
              "      <td>-0.000462</td>\n",
              "      <td>-0.000318</td>\n",
              "      <td>-0.000790</td>\n",
              "      <td>-0.007119</td>\n",
              "      <td>0.045532</td>\n",
              "      <td>6.886543e-03</td>\n",
              "      <td>0.003925</td>\n",
              "      <td>-0.006403</td>\n",
              "      <td>-0.001323</td>\n",
              "      <td>-0.007245</td>\n",
              "      <td>-0.002719</td>\n",
              "      <td>-0.006760</td>\n",
              "      <td>-0.003228</td>\n",
              "      <td>0.005443</td>\n",
              "      <td>-0.007574</td>\n",
              "      <td>-0.000480</td>\n",
              "      <td>-0.000503</td>\n",
              "      <td>-0.002188</td>\n",
              "      <td>0.004663</td>\n",
              "      <td>-0.003419</td>\n",
              "      <td>0.008831</td>\n",
              "      <td>-0.006978</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.001197</td>\n",
              "      <td>-0.000931</td>\n",
              "      <td>-0.000806</td>\n",
              "      <td>-0.001020</td>\n",
              "      <td>-0.000883</td>\n",
              "      <td>-0.000523</td>\n",
              "      <td>-0.001020</td>\n",
              "      <td>-0.001020</td>\n",
              "      <td>-0.000550</td>\n",
              "      <td>-0.001215</td>\n",
              "      <td>-0.000576</td>\n",
              "      <td>-0.000850</td>\n",
              "      <td>-0.000740</td>\n",
              "      <td>-0.000120</td>\n",
              "      <td>-0.000340</td>\n",
              "      <td>-0.000398</td>\n",
              "      <td>-0.000380</td>\n",
              "      <td>-0.000984</td>\n",
              "      <td>-0.000711</td>\n",
              "      <td>-0.000523</td>\n",
              "      <td>-0.000891</td>\n",
              "      <td>-0.000915</td>\n",
              "      <td>-0.000832</td>\n",
              "      <td>-0.000340</td>\n",
              "      <td>-0.002678</td>\n",
              "      <td>-0.000600</td>\n",
              "      <td>-0.000340</td>\n",
              "      <td>-0.000576</td>\n",
              "      <td>-0.001479</td>\n",
              "      <td>-0.000841</td>\n",
              "      <td>-0.000635</td>\n",
              "      <td>-0.001178</td>\n",
              "      <td>-0.000360</td>\n",
              "      <td>-0.000961</td>\n",
              "      <td>-0.000778</td>\n",
              "      <td>-0.000465</td>\n",
              "      <td>-0.000416</td>\n",
              "      <td>0.006436</td>\n",
              "      <td>-8.495309e-04</td>\n",
              "      <td>-0.000398</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>o_?</th>\n",
              "      <td>0.035108</td>\n",
              "      <td>-0.000327</td>\n",
              "      <td>-0.077686</td>\n",
              "      <td>-0.063981</td>\n",
              "      <td>-0.012069</td>\n",
              "      <td>-0.019996</td>\n",
              "      <td>-0.172298</td>\n",
              "      <td>-0.076574</td>\n",
              "      <td>0.998112</td>\n",
              "      <td>-0.042898</td>\n",
              "      <td>-0.064294</td>\n",
              "      <td>0.057982</td>\n",
              "      <td>-0.368567</td>\n",
              "      <td>-0.045958</td>\n",
              "      <td>-0.071500</td>\n",
              "      <td>-0.049610</td>\n",
              "      <td>-0.004629</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.089650</td>\n",
              "      <td>-0.004082</td>\n",
              "      <td>-0.092146</td>\n",
              "      <td>-0.091504</td>\n",
              "      <td>-0.043397</td>\n",
              "      <td>-4.979190e-02</td>\n",
              "      <td>-0.062411</td>\n",
              "      <td>-0.082300</td>\n",
              "      <td>-0.017011</td>\n",
              "      <td>-0.093122</td>\n",
              "      <td>-0.034954</td>\n",
              "      <td>-0.086891</td>\n",
              "      <td>-0.041492</td>\n",
              "      <td>-0.055441</td>\n",
              "      <td>-0.025692</td>\n",
              "      <td>0.007567</td>\n",
              "      <td>-0.055632</td>\n",
              "      <td>0.008519</td>\n",
              "      <td>0.046253</td>\n",
              "      <td>0.004837</td>\n",
              "      <td>0.074271</td>\n",
              "      <td>-0.069506</td>\n",
              "      <td>...</td>\n",
              "      <td>0.009517</td>\n",
              "      <td>0.009340</td>\n",
              "      <td>-0.002161</td>\n",
              "      <td>-0.003383</td>\n",
              "      <td>-0.000122</td>\n",
              "      <td>-0.000423</td>\n",
              "      <td>-0.003383</td>\n",
              "      <td>-0.003383</td>\n",
              "      <td>-0.001076</td>\n",
              "      <td>0.003466</td>\n",
              "      <td>-0.007402</td>\n",
              "      <td>-0.007031</td>\n",
              "      <td>-0.005058</td>\n",
              "      <td>-0.001543</td>\n",
              "      <td>0.005350</td>\n",
              "      <td>0.003167</td>\n",
              "      <td>-0.004880</td>\n",
              "      <td>-0.012645</td>\n",
              "      <td>-0.004487</td>\n",
              "      <td>-0.006727</td>\n",
              "      <td>0.003379</td>\n",
              "      <td>-0.008152</td>\n",
              "      <td>-0.002761</td>\n",
              "      <td>0.005350</td>\n",
              "      <td>-0.000510</td>\n",
              "      <td>-0.002221</td>\n",
              "      <td>-0.004364</td>\n",
              "      <td>-0.001672</td>\n",
              "      <td>-0.001077</td>\n",
              "      <td>0.000975</td>\n",
              "      <td>0.007415</td>\n",
              "      <td>-0.006718</td>\n",
              "      <td>-0.004629</td>\n",
              "      <td>0.015148</td>\n",
              "      <td>0.028175</td>\n",
              "      <td>0.001118</td>\n",
              "      <td>0.002586</td>\n",
              "      <td>0.003905</td>\n",
              "      <td>-7.030973e-03</td>\n",
              "      <td>-0.005118</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>o_Adm-clerical</th>\n",
              "      <td>-0.043545</td>\n",
              "      <td>0.002274</td>\n",
              "      <td>0.001677</td>\n",
              "      <td>-0.261708</td>\n",
              "      <td>-0.026552</td>\n",
              "      <td>-0.022826</td>\n",
              "      <td>-0.086002</td>\n",
              "      <td>-0.092386</td>\n",
              "      <td>-0.089481</td>\n",
              "      <td>0.113517</td>\n",
              "      <td>0.013406</td>\n",
              "      <td>-0.005198</td>\n",
              "      <td>0.047560</td>\n",
              "      <td>-0.051590</td>\n",
              "      <td>-0.089421</td>\n",
              "      <td>0.049233</td>\n",
              "      <td>-0.000462</td>\n",
              "      <td>-0.089650</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.006151</td>\n",
              "      <td>-0.138835</td>\n",
              "      <td>-0.137868</td>\n",
              "      <td>-0.065385</td>\n",
              "      <td>-7.502049e-02</td>\n",
              "      <td>-0.094033</td>\n",
              "      <td>-0.124000</td>\n",
              "      <td>-0.025631</td>\n",
              "      <td>-0.140305</td>\n",
              "      <td>-0.052664</td>\n",
              "      <td>-0.130917</td>\n",
              "      <td>-0.062515</td>\n",
              "      <td>-0.083532</td>\n",
              "      <td>0.079747</td>\n",
              "      <td>0.010239</td>\n",
              "      <td>-0.144683</td>\n",
              "      <td>0.005394</td>\n",
              "      <td>0.076835</td>\n",
              "      <td>0.018028</td>\n",
              "      <td>0.026107</td>\n",
              "      <td>-0.181275</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.001536</td>\n",
              "      <td>-0.015502</td>\n",
              "      <td>0.004794</td>\n",
              "      <td>0.003301</td>\n",
              "      <td>-0.009117</td>\n",
              "      <td>-0.010136</td>\n",
              "      <td>-0.010531</td>\n",
              "      <td>-0.008225</td>\n",
              "      <td>-0.010656</td>\n",
              "      <td>0.007485</td>\n",
              "      <td>-0.007078</td>\n",
              "      <td>-0.010922</td>\n",
              "      <td>0.001516</td>\n",
              "      <td>-0.002324</td>\n",
              "      <td>0.007239</td>\n",
              "      <td>-0.001820</td>\n",
              "      <td>-0.007352</td>\n",
              "      <td>-0.004715</td>\n",
              "      <td>-0.003849</td>\n",
              "      <td>-0.010136</td>\n",
              "      <td>0.001200</td>\n",
              "      <td>0.020794</td>\n",
              "      <td>-0.002009</td>\n",
              "      <td>0.007239</td>\n",
              "      <td>-0.027747</td>\n",
              "      <td>0.007915</td>\n",
              "      <td>-0.006576</td>\n",
              "      <td>-0.011153</td>\n",
              "      <td>0.009616</td>\n",
              "      <td>-0.010701</td>\n",
              "      <td>0.002467</td>\n",
              "      <td>0.005145</td>\n",
              "      <td>-0.000462</td>\n",
              "      <td>-0.011285</td>\n",
              "      <td>-0.009044</td>\n",
              "      <td>-0.003960</td>\n",
              "      <td>0.003226</td>\n",
              "      <td>0.025547</td>\n",
              "      <td>2.502458e-02</td>\n",
              "      <td>-0.001820</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>o_Armed-Forces</th>\n",
              "      <td>-0.011746</td>\n",
              "      <td>0.002097</td>\n",
              "      <td>-0.002403</td>\n",
              "      <td>0.011789</td>\n",
              "      <td>-0.002433</td>\n",
              "      <td>-0.003608</td>\n",
              "      <td>0.006832</td>\n",
              "      <td>-0.009388</td>\n",
              "      <td>-0.004075</td>\n",
              "      <td>0.095162</td>\n",
              "      <td>-0.004411</td>\n",
              "      <td>-0.000237</td>\n",
              "      <td>-0.025287</td>\n",
              "      <td>-0.003153</td>\n",
              "      <td>-0.004905</td>\n",
              "      <td>-0.003404</td>\n",
              "      <td>-0.000318</td>\n",
              "      <td>-0.004082</td>\n",
              "      <td>-0.006151</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.006322</td>\n",
              "      <td>-0.006278</td>\n",
              "      <td>-0.002977</td>\n",
              "      <td>-3.416129e-03</td>\n",
              "      <td>-0.004282</td>\n",
              "      <td>-0.005646</td>\n",
              "      <td>-0.001167</td>\n",
              "      <td>-0.006389</td>\n",
              "      <td>-0.002398</td>\n",
              "      <td>-0.005961</td>\n",
              "      <td>-0.002847</td>\n",
              "      <td>-0.003804</td>\n",
              "      <td>-0.006679</td>\n",
              "      <td>-0.000424</td>\n",
              "      <td>-0.005775</td>\n",
              "      <td>-0.001930</td>\n",
              "      <td>0.013723</td>\n",
              "      <td>-0.003015</td>\n",
              "      <td>-0.002981</td>\n",
              "      <td>-0.008862</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.001055</td>\n",
              "      <td>-0.000821</td>\n",
              "      <td>-0.000711</td>\n",
              "      <td>-0.000899</td>\n",
              "      <td>-0.000779</td>\n",
              "      <td>-0.000462</td>\n",
              "      <td>-0.000899</td>\n",
              "      <td>-0.000899</td>\n",
              "      <td>-0.000485</td>\n",
              "      <td>-0.001071</td>\n",
              "      <td>-0.000508</td>\n",
              "      <td>-0.000749</td>\n",
              "      <td>-0.000653</td>\n",
              "      <td>-0.000106</td>\n",
              "      <td>-0.000299</td>\n",
              "      <td>-0.000351</td>\n",
              "      <td>-0.000335</td>\n",
              "      <td>-0.000868</td>\n",
              "      <td>-0.000627</td>\n",
              "      <td>-0.000462</td>\n",
              "      <td>-0.000786</td>\n",
              "      <td>-0.000807</td>\n",
              "      <td>-0.000734</td>\n",
              "      <td>-0.000299</td>\n",
              "      <td>-0.002361</td>\n",
              "      <td>-0.000529</td>\n",
              "      <td>-0.000299</td>\n",
              "      <td>-0.000508</td>\n",
              "      <td>-0.001305</td>\n",
              "      <td>-0.000742</td>\n",
              "      <td>-0.000560</td>\n",
              "      <td>-0.001039</td>\n",
              "      <td>-0.000318</td>\n",
              "      <td>-0.000848</td>\n",
              "      <td>-0.000687</td>\n",
              "      <td>-0.000410</td>\n",
              "      <td>-0.000367</td>\n",
              "      <td>0.005676</td>\n",
              "      <td>-7.491858e-04</td>\n",
              "      <td>-0.000351</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>o_Craft-repair</th>\n",
              "      <td>0.012166</td>\n",
              "      <td>0.010296</td>\n",
              "      <td>-0.144104</td>\n",
              "      <td>0.220351</td>\n",
              "      <td>-0.023552</td>\n",
              "      <td>-0.001435</td>\n",
              "      <td>0.053873</td>\n",
              "      <td>-0.012557</td>\n",
              "      <td>-0.091972</td>\n",
              "      <td>-0.031678</td>\n",
              "      <td>-0.040163</td>\n",
              "      <td>-0.005343</td>\n",
              "      <td>0.065453</td>\n",
              "      <td>-0.018635</td>\n",
              "      <td>0.073958</td>\n",
              "      <td>-0.052046</td>\n",
              "      <td>-0.000790</td>\n",
              "      <td>-0.092146</td>\n",
              "      <td>-0.138835</td>\n",
              "      <td>-0.006322</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.141706</td>\n",
              "      <td>-0.067206</td>\n",
              "      <td>-7.710935e-02</td>\n",
              "      <td>-0.096651</td>\n",
              "      <td>-0.127452</td>\n",
              "      <td>-0.026344</td>\n",
              "      <td>-0.144211</td>\n",
              "      <td>-0.054130</td>\n",
              "      <td>-0.134562</td>\n",
              "      <td>-0.064256</td>\n",
              "      <td>-0.085858</td>\n",
              "      <td>-0.023887</td>\n",
              "      <td>0.004794</td>\n",
              "      <td>0.123924</td>\n",
              "      <td>-0.004212</td>\n",
              "      <td>-0.091972</td>\n",
              "      <td>-0.012589</td>\n",
              "      <td>-0.044872</td>\n",
              "      <td>0.157463</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.004553</td>\n",
              "      <td>-0.016056</td>\n",
              "      <td>0.003940</td>\n",
              "      <td>-0.009012</td>\n",
              "      <td>-0.004544</td>\n",
              "      <td>0.007145</td>\n",
              "      <td>-0.002238</td>\n",
              "      <td>-0.011270</td>\n",
              "      <td>-0.010953</td>\n",
              "      <td>-0.003299</td>\n",
              "      <td>0.004501</td>\n",
              "      <td>0.007464</td>\n",
              "      <td>-0.005421</td>\n",
              "      <td>-0.002389</td>\n",
              "      <td>-0.006759</td>\n",
              "      <td>-0.002156</td>\n",
              "      <td>0.004546</td>\n",
              "      <td>-0.010221</td>\n",
              "      <td>-0.007672</td>\n",
              "      <td>0.020317</td>\n",
              "      <td>0.005505</td>\n",
              "      <td>-0.005641</td>\n",
              "      <td>-0.005512</td>\n",
              "      <td>0.013537</td>\n",
              "      <td>0.013171</td>\n",
              "      <td>-0.004295</td>\n",
              "      <td>0.000006</td>\n",
              "      <td>-0.003481</td>\n",
              "      <td>-0.010708</td>\n",
              "      <td>0.007881</td>\n",
              "      <td>0.019909</td>\n",
              "      <td>0.001979</td>\n",
              "      <td>-0.007169</td>\n",
              "      <td>-0.002376</td>\n",
              "      <td>-0.015496</td>\n",
              "      <td>-0.004315</td>\n",
              "      <td>-0.002754</td>\n",
              "      <td>0.004800</td>\n",
              "      <td>4.755804e-03</td>\n",
              "      <td>-0.002156</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>o_Exec-managerial</th>\n",
              "      <td>0.097187</td>\n",
              "      <td>-0.017099</td>\n",
              "      <td>0.198788</td>\n",
              "      <td>0.041797</td>\n",
              "      <td>0.054153</td>\n",
              "      <td>0.048437</td>\n",
              "      <td>0.140787</td>\n",
              "      <td>0.213747</td>\n",
              "      <td>-0.091331</td>\n",
              "      <td>0.028151</td>\n",
              "      <td>-0.013985</td>\n",
              "      <td>-0.005306</td>\n",
              "      <td>-0.028970</td>\n",
              "      <td>0.137903</td>\n",
              "      <td>0.025232</td>\n",
              "      <td>0.006542</td>\n",
              "      <td>-0.007119</td>\n",
              "      <td>-0.091504</td>\n",
              "      <td>-0.137868</td>\n",
              "      <td>-0.006278</td>\n",
              "      <td>-0.141706</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.066738</td>\n",
              "      <td>-7.657216e-02</td>\n",
              "      <td>-0.095978</td>\n",
              "      <td>-0.126565</td>\n",
              "      <td>-0.026161</td>\n",
              "      <td>-0.143206</td>\n",
              "      <td>-0.053753</td>\n",
              "      <td>-0.133624</td>\n",
              "      <td>-0.063808</td>\n",
              "      <td>-0.085260</td>\n",
              "      <td>0.012457</td>\n",
              "      <td>-0.004683</td>\n",
              "      <td>0.104408</td>\n",
              "      <td>-0.019735</td>\n",
              "      <td>-0.102682</td>\n",
              "      <td>-0.016005</td>\n",
              "      <td>-0.016811</td>\n",
              "      <td>0.102561</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.000412</td>\n",
              "      <td>-0.000998</td>\n",
              "      <td>-0.007321</td>\n",
              "      <td>0.002538</td>\n",
              "      <td>-0.012213</td>\n",
              "      <td>-0.005932</td>\n",
              "      <td>-0.015621</td>\n",
              "      <td>0.020696</td>\n",
              "      <td>0.018513</td>\n",
              "      <td>0.006521</td>\n",
              "      <td>0.024725</td>\n",
              "      <td>-0.016793</td>\n",
              "      <td>-0.014636</td>\n",
              "      <td>-0.002373</td>\n",
              "      <td>-0.006712</td>\n",
              "      <td>0.003730</td>\n",
              "      <td>0.004662</td>\n",
              "      <td>-0.000624</td>\n",
              "      <td>0.015232</td>\n",
              "      <td>-0.005932</td>\n",
              "      <td>-0.002037</td>\n",
              "      <td>-0.002920</td>\n",
              "      <td>0.022448</td>\n",
              "      <td>-0.006712</td>\n",
              "      <td>-0.043258</td>\n",
              "      <td>-0.011868</td>\n",
              "      <td>0.006890</td>\n",
              "      <td>-0.007371</td>\n",
              "      <td>-0.010404</td>\n",
              "      <td>-0.005623</td>\n",
              "      <td>-0.008925</td>\n",
              "      <td>-0.011490</td>\n",
              "      <td>0.005705</td>\n",
              "      <td>0.007474</td>\n",
              "      <td>0.008372</td>\n",
              "      <td>0.010678</td>\n",
              "      <td>-0.008221</td>\n",
              "      <td>0.024852</td>\n",
              "      <td>-1.134775e-02</td>\n",
              "      <td>0.003730</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>o_Farming-fishing</th>\n",
              "      <td>0.032172</td>\n",
              "      <td>-0.030834</td>\n",
              "      <td>-0.103183</td>\n",
              "      <td>0.098223</td>\n",
              "      <td>-0.010702</td>\n",
              "      <td>-0.009970</td>\n",
              "      <td>0.101812</td>\n",
              "      <td>-0.050876</td>\n",
              "      <td>-0.043315</td>\n",
              "      <td>-0.023129</td>\n",
              "      <td>-0.025246</td>\n",
              "      <td>-0.002516</td>\n",
              "      <td>-0.089896</td>\n",
              "      <td>0.013650</td>\n",
              "      <td>0.232287</td>\n",
              "      <td>-0.023118</td>\n",
              "      <td>0.045532</td>\n",
              "      <td>-0.043397</td>\n",
              "      <td>-0.065385</td>\n",
              "      <td>-0.002977</td>\n",
              "      <td>-0.067206</td>\n",
              "      <td>-0.066738</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-3.631520e-02</td>\n",
              "      <td>-0.045519</td>\n",
              "      <td>-0.060025</td>\n",
              "      <td>-0.012407</td>\n",
              "      <td>-0.067917</td>\n",
              "      <td>-0.025493</td>\n",
              "      <td>-0.063373</td>\n",
              "      <td>-0.030262</td>\n",
              "      <td>-0.040435</td>\n",
              "      <td>-0.039338</td>\n",
              "      <td>0.004669</td>\n",
              "      <td>0.045157</td>\n",
              "      <td>0.020256</td>\n",
              "      <td>-0.014980</td>\n",
              "      <td>-0.017432</td>\n",
              "      <td>-0.007513</td>\n",
              "      <td>0.058288</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.003831</td>\n",
              "      <td>-0.008726</td>\n",
              "      <td>-0.007555</td>\n",
              "      <td>-0.005233</td>\n",
              "      <td>-0.008277</td>\n",
              "      <td>-0.004906</td>\n",
              "      <td>-0.009561</td>\n",
              "      <td>-0.005233</td>\n",
              "      <td>-0.005158</td>\n",
              "      <td>-0.007748</td>\n",
              "      <td>-0.005399</td>\n",
              "      <td>0.012803</td>\n",
              "      <td>-0.006941</td>\n",
              "      <td>-0.001125</td>\n",
              "      <td>-0.003183</td>\n",
              "      <td>-0.003733</td>\n",
              "      <td>-0.003559</td>\n",
              "      <td>-0.009222</td>\n",
              "      <td>-0.006661</td>\n",
              "      <td>-0.004906</td>\n",
              "      <td>-0.003403</td>\n",
              "      <td>-0.008579</td>\n",
              "      <td>-0.002504</td>\n",
              "      <td>-0.003183</td>\n",
              "      <td>0.075496</td>\n",
              "      <td>-0.005629</td>\n",
              "      <td>-0.003183</td>\n",
              "      <td>-0.005399</td>\n",
              "      <td>-0.007881</td>\n",
              "      <td>-0.002640</td>\n",
              "      <td>0.000978</td>\n",
              "      <td>0.000205</td>\n",
              "      <td>-0.003376</td>\n",
              "      <td>-0.009013</td>\n",
              "      <td>-0.007298</td>\n",
              "      <td>-0.004359</td>\n",
              "      <td>-0.003899</td>\n",
              "      <td>-0.005244</td>\n",
              "      <td>2.419382e-03</td>\n",
              "      <td>0.007328</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>o_Handlers-cleaners</th>\n",
              "      <td>-0.100066</td>\n",
              "      <td>0.027499</td>\n",
              "      <td>-0.120100</td>\n",
              "      <td>0.090026</td>\n",
              "      <td>-0.022290</td>\n",
              "      <td>-0.019002</td>\n",
              "      <td>-0.038080</td>\n",
              "      <td>-0.083890</td>\n",
              "      <td>-0.049698</td>\n",
              "      <td>-0.013163</td>\n",
              "      <td>-0.027299</td>\n",
              "      <td>-0.002887</td>\n",
              "      <td>0.104493</td>\n",
              "      <td>-0.037336</td>\n",
              "      <td>-0.052270</td>\n",
              "      <td>-0.035243</td>\n",
              "      <td>0.006887</td>\n",
              "      <td>-0.049792</td>\n",
              "      <td>-0.075020</td>\n",
              "      <td>-0.003416</td>\n",
              "      <td>-0.077109</td>\n",
              "      <td>-0.076572</td>\n",
              "      <td>-0.036315</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>-0.052226</td>\n",
              "      <td>-0.068870</td>\n",
              "      <td>-0.014235</td>\n",
              "      <td>-0.077926</td>\n",
              "      <td>-0.029250</td>\n",
              "      <td>-0.072712</td>\n",
              "      <td>-0.034721</td>\n",
              "      <td>-0.046394</td>\n",
              "      <td>-0.025140</td>\n",
              "      <td>-0.005166</td>\n",
              "      <td>-0.050658</td>\n",
              "      <td>0.006960</td>\n",
              "      <td>0.080807</td>\n",
              "      <td>-0.005194</td>\n",
              "      <td>-0.022178</td>\n",
              "      <td>-0.036445</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.006370</td>\n",
              "      <td>-0.010012</td>\n",
              "      <td>0.005779</td>\n",
              "      <td>0.000457</td>\n",
              "      <td>0.012487</td>\n",
              "      <td>-0.005629</td>\n",
              "      <td>0.008075</td>\n",
              "      <td>-0.003352</td>\n",
              "      <td>-0.005919</td>\n",
              "      <td>-0.003458</td>\n",
              "      <td>0.000539</td>\n",
              "      <td>0.018276</td>\n",
              "      <td>0.007755</td>\n",
              "      <td>-0.001291</td>\n",
              "      <td>0.019173</td>\n",
              "      <td>-0.004283</td>\n",
              "      <td>-0.004083</td>\n",
              "      <td>-0.002685</td>\n",
              "      <td>-0.007643</td>\n",
              "      <td>0.009185</td>\n",
              "      <td>-0.000871</td>\n",
              "      <td>0.002885</td>\n",
              "      <td>-0.004290</td>\n",
              "      <td>-0.003652</td>\n",
              "      <td>0.046448</td>\n",
              "      <td>0.012916</td>\n",
              "      <td>0.007761</td>\n",
              "      <td>0.014004</td>\n",
              "      <td>-0.002740</td>\n",
              "      <td>0.004800</td>\n",
              "      <td>0.011473</td>\n",
              "      <td>0.000528</td>\n",
              "      <td>-0.003874</td>\n",
              "      <td>-0.006302</td>\n",
              "      <td>-0.008374</td>\n",
              "      <td>-0.005002</td>\n",
              "      <td>-0.004473</td>\n",
              "      <td>-0.018683</td>\n",
              "      <td>4.230320e-16</td>\n",
              "      <td>-0.004283</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>o_Machine-op-inspct</th>\n",
              "      <td>-0.012148</td>\n",
              "      <td>0.016231</td>\n",
              "      <td>-0.160261</td>\n",
              "      <td>0.028092</td>\n",
              "      <td>-0.025296</td>\n",
              "      <td>-0.013646</td>\n",
              "      <td>0.005054</td>\n",
              "      <td>-0.070135</td>\n",
              "      <td>-0.062293</td>\n",
              "      <td>-0.035231</td>\n",
              "      <td>-0.062031</td>\n",
              "      <td>-0.003619</td>\n",
              "      <td>0.143636</td>\n",
              "      <td>-0.038134</td>\n",
              "      <td>-0.056483</td>\n",
              "      <td>-0.042654</td>\n",
              "      <td>0.003925</td>\n",
              "      <td>-0.062411</td>\n",
              "      <td>-0.094033</td>\n",
              "      <td>-0.004282</td>\n",
              "      <td>-0.096651</td>\n",
              "      <td>-0.095978</td>\n",
              "      <td>-0.045519</td>\n",
              "      <td>-5.222626e-02</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.086324</td>\n",
              "      <td>-0.017843</td>\n",
              "      <td>-0.097674</td>\n",
              "      <td>-0.036663</td>\n",
              "      <td>-0.091139</td>\n",
              "      <td>-0.043521</td>\n",
              "      <td>-0.058151</td>\n",
              "      <td>0.001913</td>\n",
              "      <td>-0.006475</td>\n",
              "      <td>0.018076</td>\n",
              "      <td>-0.000223</td>\n",
              "      <td>-0.023875</td>\n",
              "      <td>0.012131</td>\n",
              "      <td>-0.002168</td>\n",
              "      <td>0.019248</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.005524</td>\n",
              "      <td>0.014685</td>\n",
              "      <td>0.016643</td>\n",
              "      <td>-0.001317</td>\n",
              "      <td>0.052679</td>\n",
              "      <td>0.023166</td>\n",
              "      <td>0.001791</td>\n",
              "      <td>-0.004425</td>\n",
              "      <td>-0.007419</td>\n",
              "      <td>-0.008537</td>\n",
              "      <td>-0.007764</td>\n",
              "      <td>0.018374</td>\n",
              "      <td>0.007120</td>\n",
              "      <td>0.024720</td>\n",
              "      <td>-0.004578</td>\n",
              "      <td>0.010518</td>\n",
              "      <td>-0.005118</td>\n",
              "      <td>-0.010041</td>\n",
              "      <td>-0.009580</td>\n",
              "      <td>0.005033</td>\n",
              "      <td>0.005762</td>\n",
              "      <td>-0.008876</td>\n",
              "      <td>-0.011222</td>\n",
              "      <td>0.014049</td>\n",
              "      <td>0.046979</td>\n",
              "      <td>0.007715</td>\n",
              "      <td>-0.004578</td>\n",
              "      <td>0.008719</td>\n",
              "      <td>0.001553</td>\n",
              "      <td>0.007493</td>\n",
              "      <td>0.011353</td>\n",
              "      <td>0.024513</td>\n",
              "      <td>0.012706</td>\n",
              "      <td>-0.006369</td>\n",
              "      <td>-0.010496</td>\n",
              "      <td>0.000533</td>\n",
              "      <td>0.017208</td>\n",
              "      <td>-0.045753</td>\n",
              "      <td>7.188365e-03</td>\n",
              "      <td>0.010518</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>o_Other-service</th>\n",
              "      <td>-0.083478</td>\n",
              "      <td>-0.005282</td>\n",
              "      <td>-0.166606</td>\n",
              "      <td>-0.152487</td>\n",
              "      <td>-0.040791</td>\n",
              "      <td>-0.041324</td>\n",
              "      <td>-0.158089</td>\n",
              "      <td>-0.154604</td>\n",
              "      <td>-0.082145</td>\n",
              "      <td>-0.036112</td>\n",
              "      <td>-0.004272</td>\n",
              "      <td>-0.004772</td>\n",
              "      <td>0.097339</td>\n",
              "      <td>-0.049777</td>\n",
              "      <td>-0.032362</td>\n",
              "      <td>-0.003708</td>\n",
              "      <td>-0.006403</td>\n",
              "      <td>-0.082300</td>\n",
              "      <td>-0.124000</td>\n",
              "      <td>-0.005646</td>\n",
              "      <td>-0.127452</td>\n",
              "      <td>-0.126565</td>\n",
              "      <td>-0.060025</td>\n",
              "      <td>-6.886999e-02</td>\n",
              "      <td>-0.086324</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.023529</td>\n",
              "      <td>-0.128802</td>\n",
              "      <td>-0.048346</td>\n",
              "      <td>-0.120184</td>\n",
              "      <td>-0.057390</td>\n",
              "      <td>-0.076684</td>\n",
              "      <td>0.018390</td>\n",
              "      <td>0.001905</td>\n",
              "      <td>-0.160431</td>\n",
              "      <td>0.014481</td>\n",
              "      <td>0.114502</td>\n",
              "      <td>0.052722</td>\n",
              "      <td>0.051552</td>\n",
              "      <td>-0.168168</td>\n",
              "      <td>...</td>\n",
              "      <td>0.001855</td>\n",
              "      <td>0.023932</td>\n",
              "      <td>0.007480</td>\n",
              "      <td>0.008974</td>\n",
              "      <td>-0.001476</td>\n",
              "      <td>-0.004513</td>\n",
              "      <td>0.045937</td>\n",
              "      <td>-0.003347</td>\n",
              "      <td>-0.000666</td>\n",
              "      <td>-0.011237</td>\n",
              "      <td>0.002829</td>\n",
              "      <td>0.002631</td>\n",
              "      <td>0.030901</td>\n",
              "      <td>-0.002134</td>\n",
              "      <td>0.001347</td>\n",
              "      <td>-0.007079</td>\n",
              "      <td>-0.000145</td>\n",
              "      <td>-0.009827</td>\n",
              "      <td>-0.002038</td>\n",
              "      <td>0.009863</td>\n",
              "      <td>0.003887</td>\n",
              "      <td>0.022157</td>\n",
              "      <td>0.012351</td>\n",
              "      <td>-0.006036</td>\n",
              "      <td>0.038301</td>\n",
              "      <td>0.010215</td>\n",
              "      <td>0.008730</td>\n",
              "      <td>0.015895</td>\n",
              "      <td>0.024828</td>\n",
              "      <td>-0.000023</td>\n",
              "      <td>-0.003402</td>\n",
              "      <td>0.008943</td>\n",
              "      <td>0.007519</td>\n",
              "      <td>0.003813</td>\n",
              "      <td>-0.013841</td>\n",
              "      <td>0.013304</td>\n",
              "      <td>0.004664</td>\n",
              "      <td>-0.056623</td>\n",
              "      <td>5.586326e-03</td>\n",
              "      <td>0.018108</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>o_Priv-house-serv</th>\n",
              "      <td>0.018551</td>\n",
              "      <td>0.011137</td>\n",
              "      <td>-0.072322</td>\n",
              "      <td>-0.092882</td>\n",
              "      <td>-0.009280</td>\n",
              "      <td>-0.010443</td>\n",
              "      <td>-0.041721</td>\n",
              "      <td>-0.039121</td>\n",
              "      <td>-0.016979</td>\n",
              "      <td>-0.012265</td>\n",
              "      <td>-0.018382</td>\n",
              "      <td>-0.000986</td>\n",
              "      <td>0.046156</td>\n",
              "      <td>-0.013139</td>\n",
              "      <td>-0.020442</td>\n",
              "      <td>-0.014183</td>\n",
              "      <td>-0.001323</td>\n",
              "      <td>-0.017011</td>\n",
              "      <td>-0.025631</td>\n",
              "      <td>-0.001167</td>\n",
              "      <td>-0.026344</td>\n",
              "      <td>-0.026161</td>\n",
              "      <td>-0.012407</td>\n",
              "      <td>-1.423543e-02</td>\n",
              "      <td>-0.017843</td>\n",
              "      <td>-0.023529</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.026623</td>\n",
              "      <td>-0.009993</td>\n",
              "      <td>-0.024842</td>\n",
              "      <td>-0.011863</td>\n",
              "      <td>-0.015850</td>\n",
              "      <td>0.010672</td>\n",
              "      <td>-0.001765</td>\n",
              "      <td>-0.047865</td>\n",
              "      <td>0.012220</td>\n",
              "      <td>0.017408</td>\n",
              "      <td>0.013858</td>\n",
              "      <td>0.047660</td>\n",
              "      <td>-0.057246</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.004397</td>\n",
              "      <td>-0.003421</td>\n",
              "      <td>0.010636</td>\n",
              "      <td>0.017763</td>\n",
              "      <td>0.009170</td>\n",
              "      <td>0.018991</td>\n",
              "      <td>0.028518</td>\n",
              "      <td>0.028518</td>\n",
              "      <td>0.037767</td>\n",
              "      <td>0.004578</td>\n",
              "      <td>-0.002116</td>\n",
              "      <td>0.112984</td>\n",
              "      <td>0.012073</td>\n",
              "      <td>-0.000441</td>\n",
              "      <td>-0.001248</td>\n",
              "      <td>-0.001463</td>\n",
              "      <td>0.027429</td>\n",
              "      <td>-0.003615</td>\n",
              "      <td>-0.002611</td>\n",
              "      <td>-0.001923</td>\n",
              "      <td>-0.003275</td>\n",
              "      <td>0.008617</td>\n",
              "      <td>-0.003059</td>\n",
              "      <td>-0.001248</td>\n",
              "      <td>0.048486</td>\n",
              "      <td>0.016029</td>\n",
              "      <td>-0.001248</td>\n",
              "      <td>-0.002116</td>\n",
              "      <td>0.009441</td>\n",
              "      <td>0.009941</td>\n",
              "      <td>-0.002335</td>\n",
              "      <td>-0.004330</td>\n",
              "      <td>-0.001323</td>\n",
              "      <td>-0.003533</td>\n",
              "      <td>-0.002861</td>\n",
              "      <td>0.021828</td>\n",
              "      <td>-0.001528</td>\n",
              "      <td>-0.071091</td>\n",
              "      <td>-3.121950e-03</td>\n",
              "      <td>-0.001463</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>o_Prof-specialty</th>\n",
              "      <td>0.048809</td>\n",
              "      <td>-0.018223</td>\n",
              "      <td>0.420669</td>\n",
              "      <td>-0.029677</td>\n",
              "      <td>0.087860</td>\n",
              "      <td>0.049235</td>\n",
              "      <td>0.058090</td>\n",
              "      <td>0.185925</td>\n",
              "      <td>-0.092946</td>\n",
              "      <td>0.030683</td>\n",
              "      <td>0.157055</td>\n",
              "      <td>-0.005399</td>\n",
              "      <td>-0.114867</td>\n",
              "      <td>0.008571</td>\n",
              "      <td>0.019746</td>\n",
              "      <td>0.120903</td>\n",
              "      <td>-0.007245</td>\n",
              "      <td>-0.093122</td>\n",
              "      <td>-0.140305</td>\n",
              "      <td>-0.006389</td>\n",
              "      <td>-0.144211</td>\n",
              "      <td>-0.143206</td>\n",
              "      <td>-0.067917</td>\n",
              "      <td>-7.792567e-02</td>\n",
              "      <td>-0.097674</td>\n",
              "      <td>-0.128802</td>\n",
              "      <td>-0.026623</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.054703</td>\n",
              "      <td>-0.135986</td>\n",
              "      <td>-0.064936</td>\n",
              "      <td>-0.086767</td>\n",
              "      <td>-0.009740</td>\n",
              "      <td>-0.004914</td>\n",
              "      <td>0.038483</td>\n",
              "      <td>0.002404</td>\n",
              "      <td>-0.019219</td>\n",
              "      <td>-0.016496</td>\n",
              "      <td>-0.023512</td>\n",
              "      <td>0.020038</td>\n",
              "      <td>...</td>\n",
              "      <td>0.010336</td>\n",
              "      <td>0.020530</td>\n",
              "      <td>-0.004883</td>\n",
              "      <td>-0.002595</td>\n",
              "      <td>-0.012590</td>\n",
              "      <td>-0.006172</td>\n",
              "      <td>-0.007075</td>\n",
              "      <td>0.017567</td>\n",
              "      <td>0.017938</td>\n",
              "      <td>0.013231</td>\n",
              "      <td>-0.003665</td>\n",
              "      <td>-0.017090</td>\n",
              "      <td>-0.005650</td>\n",
              "      <td>-0.002414</td>\n",
              "      <td>-0.000118</td>\n",
              "      <td>-0.002285</td>\n",
              "      <td>0.010374</td>\n",
              "      <td>0.035940</td>\n",
              "      <td>0.017813</td>\n",
              "      <td>0.002541</td>\n",
              "      <td>0.007697</td>\n",
              "      <td>-0.010923</td>\n",
              "      <td>0.005195</td>\n",
              "      <td>-0.006830</td>\n",
              "      <td>-0.039981</td>\n",
              "      <td>-0.008280</td>\n",
              "      <td>-0.000118</td>\n",
              "      <td>-0.007625</td>\n",
              "      <td>-0.001870</td>\n",
              "      <td>-0.000632</td>\n",
              "      <td>-0.012783</td>\n",
              "      <td>-0.004292</td>\n",
              "      <td>-0.000916</td>\n",
              "      <td>-0.000335</td>\n",
              "      <td>0.042967</td>\n",
              "      <td>-0.004451</td>\n",
              "      <td>-0.002885</td>\n",
              "      <td>-0.003138</td>\n",
              "      <td>-1.171562e-02</td>\n",
              "      <td>-0.008010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>o_Protective-serv</th>\n",
              "      <td>0.003741</td>\n",
              "      <td>0.017104</td>\n",
              "      <td>0.007580</td>\n",
              "      <td>0.068263</td>\n",
              "      <td>-0.006556</td>\n",
              "      <td>-0.005645</td>\n",
              "      <td>0.028399</td>\n",
              "      <td>0.026440</td>\n",
              "      <td>-0.034888</td>\n",
              "      <td>0.016550</td>\n",
              "      <td>0.228089</td>\n",
              "      <td>-0.002027</td>\n",
              "      <td>-0.124902</td>\n",
              "      <td>-0.022300</td>\n",
              "      <td>-0.035670</td>\n",
              "      <td>0.103596</td>\n",
              "      <td>-0.002719</td>\n",
              "      <td>-0.034954</td>\n",
              "      <td>-0.052664</td>\n",
              "      <td>-0.002398</td>\n",
              "      <td>-0.054130</td>\n",
              "      <td>-0.053753</td>\n",
              "      <td>-0.025493</td>\n",
              "      <td>-2.924973e-02</td>\n",
              "      <td>-0.036663</td>\n",
              "      <td>-0.048346</td>\n",
              "      <td>-0.009993</td>\n",
              "      <td>-0.054703</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.051043</td>\n",
              "      <td>-0.024374</td>\n",
              "      <td>-0.032568</td>\n",
              "      <td>-0.004230</td>\n",
              "      <td>0.007638</td>\n",
              "      <td>0.039345</td>\n",
              "      <td>-0.006508</td>\n",
              "      <td>-0.028792</td>\n",
              "      <td>-0.006227</td>\n",
              "      <td>-0.017278</td>\n",
              "      <td>0.050835</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000037</td>\n",
              "      <td>-0.007028</td>\n",
              "      <td>-0.006085</td>\n",
              "      <td>0.002931</td>\n",
              "      <td>-0.000531</td>\n",
              "      <td>-0.003952</td>\n",
              "      <td>-0.007701</td>\n",
              "      <td>0.002931</td>\n",
              "      <td>0.005679</td>\n",
              "      <td>0.008705</td>\n",
              "      <td>-0.004348</td>\n",
              "      <td>-0.006415</td>\n",
              "      <td>0.001722</td>\n",
              "      <td>-0.000906</td>\n",
              "      <td>-0.002564</td>\n",
              "      <td>0.010578</td>\n",
              "      <td>-0.002866</td>\n",
              "      <td>0.009103</td>\n",
              "      <td>-0.005365</td>\n",
              "      <td>-0.003952</td>\n",
              "      <td>-0.006728</td>\n",
              "      <td>-0.006910</td>\n",
              "      <td>0.000223</td>\n",
              "      <td>-0.002564</td>\n",
              "      <td>-0.011982</td>\n",
              "      <td>-0.004534</td>\n",
              "      <td>-0.002564</td>\n",
              "      <td>0.014445</td>\n",
              "      <td>-0.003817</td>\n",
              "      <td>-0.006350</td>\n",
              "      <td>0.003719</td>\n",
              "      <td>0.000315</td>\n",
              "      <td>0.012298</td>\n",
              "      <td>-0.007259</td>\n",
              "      <td>-0.005878</td>\n",
              "      <td>0.008123</td>\n",
              "      <td>-0.003140</td>\n",
              "      <td>0.014882</td>\n",
              "      <td>-6.414714e-03</td>\n",
              "      <td>-0.003006</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>o_Sales</th>\n",
              "      <td>-0.024984</td>\n",
              "      <td>0.007688</td>\n",
              "      <td>0.030819</td>\n",
              "      <td>-0.008180</td>\n",
              "      <td>0.012519</td>\n",
              "      <td>0.006799</td>\n",
              "      <td>0.013078</td>\n",
              "      <td>0.022895</td>\n",
              "      <td>-0.086727</td>\n",
              "      <td>-0.054485</td>\n",
              "      <td>-0.090809</td>\n",
              "      <td>-0.005038</td>\n",
              "      <td>0.083157</td>\n",
              "      <td>0.089371</td>\n",
              "      <td>0.039040</td>\n",
              "      <td>-0.067911</td>\n",
              "      <td>-0.006760</td>\n",
              "      <td>-0.086891</td>\n",
              "      <td>-0.130917</td>\n",
              "      <td>-0.005961</td>\n",
              "      <td>-0.134562</td>\n",
              "      <td>-0.133624</td>\n",
              "      <td>-0.063373</td>\n",
              "      <td>-7.271163e-02</td>\n",
              "      <td>-0.091139</td>\n",
              "      <td>-0.120184</td>\n",
              "      <td>-0.024842</td>\n",
              "      <td>-0.135986</td>\n",
              "      <td>-0.051043</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.060591</td>\n",
              "      <td>-0.080961</td>\n",
              "      <td>-0.014622</td>\n",
              "      <td>-0.004011</td>\n",
              "      <td>-0.000573</td>\n",
              "      <td>-0.011046</td>\n",
              "      <td>0.019893</td>\n",
              "      <td>-0.012693</td>\n",
              "      <td>-0.002631</td>\n",
              "      <td>0.008204</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.006342</td>\n",
              "      <td>-0.007127</td>\n",
              "      <td>-0.012141</td>\n",
              "      <td>-0.000253</td>\n",
              "      <td>-0.000219</td>\n",
              "      <td>0.003952</td>\n",
              "      <td>-0.004976</td>\n",
              "      <td>-0.007337</td>\n",
              "      <td>-0.005960</td>\n",
              "      <td>-0.000963</td>\n",
              "      <td>0.001712</td>\n",
              "      <td>-0.007449</td>\n",
              "      <td>-0.010650</td>\n",
              "      <td>-0.002253</td>\n",
              "      <td>0.000702</td>\n",
              "      <td>-0.001440</td>\n",
              "      <td>-0.007126</td>\n",
              "      <td>0.008459</td>\n",
              "      <td>0.006968</td>\n",
              "      <td>-0.009824</td>\n",
              "      <td>-0.008624</td>\n",
              "      <td>-0.001396</td>\n",
              "      <td>-0.006951</td>\n",
              "      <td>-0.006373</td>\n",
              "      <td>-0.025564</td>\n",
              "      <td>-0.007266</td>\n",
              "      <td>0.000702</td>\n",
              "      <td>-0.002462</td>\n",
              "      <td>-0.001637</td>\n",
              "      <td>-0.001480</td>\n",
              "      <td>-0.011928</td>\n",
              "      <td>-0.003702</td>\n",
              "      <td>-0.006760</td>\n",
              "      <td>0.019517</td>\n",
              "      <td>-0.005343</td>\n",
              "      <td>-0.008728</td>\n",
              "      <td>-0.007806</td>\n",
              "      <td>0.026790</td>\n",
              "      <td>-7.449147e-03</td>\n",
              "      <td>-0.007474</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>o_Tech-support</th>\n",
              "      <td>-0.022003</td>\n",
              "      <td>-0.000041</td>\n",
              "      <td>0.056185</td>\n",
              "      <td>-0.014317</td>\n",
              "      <td>-0.010222</td>\n",
              "      <td>0.007481</td>\n",
              "      <td>-0.011773</td>\n",
              "      <td>0.026499</td>\n",
              "      <td>-0.041414</td>\n",
              "      <td>0.049516</td>\n",
              "      <td>-0.012436</td>\n",
              "      <td>-0.002406</td>\n",
              "      <td>0.028986</td>\n",
              "      <td>-0.029388</td>\n",
              "      <td>-0.032827</td>\n",
              "      <td>0.026112</td>\n",
              "      <td>-0.003228</td>\n",
              "      <td>-0.041492</td>\n",
              "      <td>-0.062515</td>\n",
              "      <td>-0.002847</td>\n",
              "      <td>-0.064256</td>\n",
              "      <td>-0.063808</td>\n",
              "      <td>-0.030262</td>\n",
              "      <td>-3.472128e-02</td>\n",
              "      <td>-0.043521</td>\n",
              "      <td>-0.057390</td>\n",
              "      <td>-0.011863</td>\n",
              "      <td>-0.064936</td>\n",
              "      <td>-0.024374</td>\n",
              "      <td>-0.060591</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.038661</td>\n",
              "      <td>0.003098</td>\n",
              "      <td>-0.004305</td>\n",
              "      <td>-0.002293</td>\n",
              "      <td>-0.008981</td>\n",
              "      <td>0.008092</td>\n",
              "      <td>-0.002915</td>\n",
              "      <td>-0.012085</td>\n",
              "      <td>-0.003454</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000833</td>\n",
              "      <td>0.001547</td>\n",
              "      <td>0.004193</td>\n",
              "      <td>-0.009142</td>\n",
              "      <td>-0.007914</td>\n",
              "      <td>0.004089</td>\n",
              "      <td>-0.009142</td>\n",
              "      <td>0.004404</td>\n",
              "      <td>-0.004932</td>\n",
              "      <td>-0.003296</td>\n",
              "      <td>-0.005162</td>\n",
              "      <td>-0.002199</td>\n",
              "      <td>-0.006637</td>\n",
              "      <td>-0.001076</td>\n",
              "      <td>-0.003043</td>\n",
              "      <td>0.007969</td>\n",
              "      <td>0.008698</td>\n",
              "      <td>0.005223</td>\n",
              "      <td>-0.006369</td>\n",
              "      <td>-0.004691</td>\n",
              "      <td>-0.007987</td>\n",
              "      <td>0.001856</td>\n",
              "      <td>-0.007461</td>\n",
              "      <td>-0.003043</td>\n",
              "      <td>-0.020503</td>\n",
              "      <td>0.002274</td>\n",
              "      <td>-0.003043</td>\n",
              "      <td>-0.005162</td>\n",
              "      <td>0.014845</td>\n",
              "      <td>0.003403</td>\n",
              "      <td>-0.005696</td>\n",
              "      <td>-0.010561</td>\n",
              "      <td>-0.003228</td>\n",
              "      <td>-0.008617</td>\n",
              "      <td>-0.006978</td>\n",
              "      <td>-0.004168</td>\n",
              "      <td>0.018366</td>\n",
              "      <td>0.015529</td>\n",
              "      <td>3.217008e-03</td>\n",
              "      <td>-0.003569</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>o_Transport-moving</th>\n",
              "      <td>0.027554</td>\n",
              "      <td>-0.001721</td>\n",
              "      <td>-0.117117</td>\n",
              "      <td>0.135334</td>\n",
              "      <td>-0.018225</td>\n",
              "      <td>-0.002012</td>\n",
              "      <td>0.079753</td>\n",
              "      <td>-0.019057</td>\n",
              "      <td>-0.055336</td>\n",
              "      <td>-0.018271</td>\n",
              "      <td>0.009184</td>\n",
              "      <td>-0.003215</td>\n",
              "      <td>0.047875</td>\n",
              "      <td>-0.022477</td>\n",
              "      <td>-0.003538</td>\n",
              "      <td>-0.017794</td>\n",
              "      <td>0.005443</td>\n",
              "      <td>-0.055441</td>\n",
              "      <td>-0.083532</td>\n",
              "      <td>-0.003804</td>\n",
              "      <td>-0.085858</td>\n",
              "      <td>-0.085260</td>\n",
              "      <td>-0.040435</td>\n",
              "      <td>-4.639388e-02</td>\n",
              "      <td>-0.058151</td>\n",
              "      <td>-0.076684</td>\n",
              "      <td>-0.015850</td>\n",
              "      <td>-0.086767</td>\n",
              "      <td>-0.032568</td>\n",
              "      <td>-0.080961</td>\n",
              "      <td>-0.038661</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.014369</td>\n",
              "      <td>-0.005752</td>\n",
              "      <td>0.075793</td>\n",
              "      <td>-0.003434</td>\n",
              "      <td>-0.056335</td>\n",
              "      <td>-0.011251</td>\n",
              "      <td>-0.022267</td>\n",
              "      <td>0.095353</td>\n",
              "      <td>...</td>\n",
              "      <td>0.006298</td>\n",
              "      <td>-0.011148</td>\n",
              "      <td>-0.005285</td>\n",
              "      <td>0.005054</td>\n",
              "      <td>0.001385</td>\n",
              "      <td>0.000448</td>\n",
              "      <td>0.001600</td>\n",
              "      <td>-0.012215</td>\n",
              "      <td>-0.006590</td>\n",
              "      <td>-0.008740</td>\n",
              "      <td>-0.006897</td>\n",
              "      <td>-0.006032</td>\n",
              "      <td>0.005385</td>\n",
              "      <td>-0.001437</td>\n",
              "      <td>-0.004066</td>\n",
              "      <td>-0.004769</td>\n",
              "      <td>-0.004547</td>\n",
              "      <td>-0.004622</td>\n",
              "      <td>-0.003560</td>\n",
              "      <td>-0.006268</td>\n",
              "      <td>-0.006722</td>\n",
              "      <td>-0.007113</td>\n",
              "      <td>-0.009969</td>\n",
              "      <td>-0.004066</td>\n",
              "      <td>-0.013339</td>\n",
              "      <td>0.004521</td>\n",
              "      <td>-0.004066</td>\n",
              "      <td>0.005313</td>\n",
              "      <td>-0.015329</td>\n",
              "      <td>0.002482</td>\n",
              "      <td>-0.007611</td>\n",
              "      <td>-0.005134</td>\n",
              "      <td>-0.004313</td>\n",
              "      <td>-0.007852</td>\n",
              "      <td>-0.009324</td>\n",
              "      <td>-0.005569</td>\n",
              "      <td>-0.004981</td>\n",
              "      <td>0.030230</td>\n",
              "      <td>-6.031830e-03</td>\n",
              "      <td>-0.004769</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>m_Divorced</th>\n",
              "      <td>0.129938</td>\n",
              "      <td>-0.018035</td>\n",
              "      <td>-0.012802</td>\n",
              "      <td>-0.227740</td>\n",
              "      <td>-0.016525</td>\n",
              "      <td>-0.020203</td>\n",
              "      <td>0.028222</td>\n",
              "      <td>-0.128580</td>\n",
              "      <td>-0.025893</td>\n",
              "      <td>0.018356</td>\n",
              "      <td>0.029164</td>\n",
              "      <td>0.002572</td>\n",
              "      <td>0.007650</td>\n",
              "      <td>-0.022830</td>\n",
              "      <td>-0.017983</td>\n",
              "      <td>0.006283</td>\n",
              "      <td>-0.007574</td>\n",
              "      <td>-0.025692</td>\n",
              "      <td>0.079747</td>\n",
              "      <td>-0.006679</td>\n",
              "      <td>-0.023887</td>\n",
              "      <td>0.012457</td>\n",
              "      <td>-0.039338</td>\n",
              "      <td>-2.513982e-02</td>\n",
              "      <td>0.001913</td>\n",
              "      <td>0.018390</td>\n",
              "      <td>0.010672</td>\n",
              "      <td>-0.009740</td>\n",
              "      <td>-0.004230</td>\n",
              "      <td>-0.014622</td>\n",
              "      <td>0.003098</td>\n",
              "      <td>-0.014369</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.010100</td>\n",
              "      <td>-0.366612</td>\n",
              "      <td>-0.046018</td>\n",
              "      <td>-0.279464</td>\n",
              "      <td>-0.071906</td>\n",
              "      <td>-0.071099</td>\n",
              "      <td>-0.327610</td>\n",
              "      <td>...</td>\n",
              "      <td>0.002585</td>\n",
              "      <td>-0.010078</td>\n",
              "      <td>-0.003243</td>\n",
              "      <td>0.006737</td>\n",
              "      <td>-0.011061</td>\n",
              "      <td>-0.002574</td>\n",
              "      <td>-0.012777</td>\n",
              "      <td>0.011073</td>\n",
              "      <td>0.012491</td>\n",
              "      <td>0.010909</td>\n",
              "      <td>-0.008279</td>\n",
              "      <td>-0.010065</td>\n",
              "      <td>-0.003642</td>\n",
              "      <td>-0.002524</td>\n",
              "      <td>0.005852</td>\n",
              "      <td>-0.008374</td>\n",
              "      <td>-0.002173</td>\n",
              "      <td>-0.018442</td>\n",
              "      <td>0.003701</td>\n",
              "      <td>0.001642</td>\n",
              "      <td>-0.013781</td>\n",
              "      <td>-0.009586</td>\n",
              "      <td>0.001074</td>\n",
              "      <td>-0.007141</td>\n",
              "      <td>-0.039516</td>\n",
              "      <td>-0.005275</td>\n",
              "      <td>0.005852</td>\n",
              "      <td>-0.000614</td>\n",
              "      <td>-0.016116</td>\n",
              "      <td>-0.007179</td>\n",
              "      <td>0.000531</td>\n",
              "      <td>-0.000358</td>\n",
              "      <td>0.004676</td>\n",
              "      <td>-0.006423</td>\n",
              "      <td>-0.016372</td>\n",
              "      <td>-0.005034</td>\n",
              "      <td>-0.003442</td>\n",
              "      <td>0.047502</td>\n",
              "      <td>-7.463861e-03</td>\n",
              "      <td>-0.002833</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>m_Married-AF-spouse</th>\n",
              "      <td>-0.010366</td>\n",
              "      <td>0.002586</td>\n",
              "      <td>-0.001425</td>\n",
              "      <td>-0.019128</td>\n",
              "      <td>-0.003119</td>\n",
              "      <td>-0.005455</td>\n",
              "      <td>-0.005211</td>\n",
              "      <td>0.011751</td>\n",
              "      <td>0.007601</td>\n",
              "      <td>0.014093</td>\n",
              "      <td>-0.006670</td>\n",
              "      <td>-0.000358</td>\n",
              "      <td>-0.003871</td>\n",
              "      <td>-0.004768</td>\n",
              "      <td>-0.001558</td>\n",
              "      <td>0.002952</td>\n",
              "      <td>-0.000480</td>\n",
              "      <td>0.007567</td>\n",
              "      <td>0.010239</td>\n",
              "      <td>-0.000424</td>\n",
              "      <td>0.004794</td>\n",
              "      <td>-0.004683</td>\n",
              "      <td>0.004669</td>\n",
              "      <td>-5.165631e-03</td>\n",
              "      <td>-0.006475</td>\n",
              "      <td>0.001905</td>\n",
              "      <td>-0.001765</td>\n",
              "      <td>-0.004914</td>\n",
              "      <td>0.007638</td>\n",
              "      <td>-0.004011</td>\n",
              "      <td>-0.004305</td>\n",
              "      <td>-0.005752</td>\n",
              "      <td>-0.010100</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.023246</td>\n",
              "      <td>-0.002918</td>\n",
              "      <td>-0.017720</td>\n",
              "      <td>-0.004559</td>\n",
              "      <td>-0.004508</td>\n",
              "      <td>-0.004647</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.001596</td>\n",
              "      <td>-0.001241</td>\n",
              "      <td>-0.001075</td>\n",
              "      <td>-0.001360</td>\n",
              "      <td>-0.001177</td>\n",
              "      <td>-0.000698</td>\n",
              "      <td>-0.001360</td>\n",
              "      <td>-0.001360</td>\n",
              "      <td>-0.000734</td>\n",
              "      <td>-0.001620</td>\n",
              "      <td>-0.000768</td>\n",
              "      <td>-0.001133</td>\n",
              "      <td>-0.000987</td>\n",
              "      <td>-0.000160</td>\n",
              "      <td>-0.000453</td>\n",
              "      <td>-0.000531</td>\n",
              "      <td>-0.000506</td>\n",
              "      <td>-0.001312</td>\n",
              "      <td>-0.000948</td>\n",
              "      <td>-0.000698</td>\n",
              "      <td>-0.001188</td>\n",
              "      <td>-0.001220</td>\n",
              "      <td>-0.001110</td>\n",
              "      <td>-0.000453</td>\n",
              "      <td>-0.003571</td>\n",
              "      <td>-0.000801</td>\n",
              "      <td>-0.000453</td>\n",
              "      <td>-0.000768</td>\n",
              "      <td>-0.001973</td>\n",
              "      <td>-0.001121</td>\n",
              "      <td>-0.000847</td>\n",
              "      <td>-0.001571</td>\n",
              "      <td>-0.000480</td>\n",
              "      <td>-0.001282</td>\n",
              "      <td>-0.001038</td>\n",
              "      <td>-0.000620</td>\n",
              "      <td>-0.000555</td>\n",
              "      <td>0.008583</td>\n",
              "      <td>-1.132866e-03</td>\n",
              "      <td>-0.000531</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>m_Married-civ-spouse</th>\n",
              "      <td>0.312885</td>\n",
              "      <td>-0.023808</td>\n",
              "      <td>0.085792</td>\n",
              "      <td>0.428777</td>\n",
              "      <td>0.086638</td>\n",
              "      <td>0.078373</td>\n",
              "      <td>0.213275</td>\n",
              "      <td>0.445289</td>\n",
              "      <td>-0.054926</td>\n",
              "      <td>0.010246</td>\n",
              "      <td>0.013289</td>\n",
              "      <td>-0.012992</td>\n",
              "      <td>-0.097705</td>\n",
              "      <td>0.111996</td>\n",
              "      <td>0.118321</td>\n",
              "      <td>0.002287</td>\n",
              "      <td>-0.000503</td>\n",
              "      <td>-0.055632</td>\n",
              "      <td>-0.144683</td>\n",
              "      <td>-0.005775</td>\n",
              "      <td>0.123924</td>\n",
              "      <td>0.104408</td>\n",
              "      <td>0.045157</td>\n",
              "      <td>-5.065794e-02</td>\n",
              "      <td>0.018076</td>\n",
              "      <td>-0.160431</td>\n",
              "      <td>-0.047865</td>\n",
              "      <td>0.038483</td>\n",
              "      <td>0.039345</td>\n",
              "      <td>-0.000573</td>\n",
              "      <td>-0.002293</td>\n",
              "      <td>0.075793</td>\n",
              "      <td>-0.366612</td>\n",
              "      <td>-0.023246</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.105914</td>\n",
              "      <td>-0.643213</td>\n",
              "      <td>-0.165499</td>\n",
              "      <td>-0.163642</td>\n",
              "      <td>0.892795</td>\n",
              "      <td>...</td>\n",
              "      <td>0.008557</td>\n",
              "      <td>0.020579</td>\n",
              "      <td>-0.012489</td>\n",
              "      <td>0.000075</td>\n",
              "      <td>-0.013338</td>\n",
              "      <td>0.003802</td>\n",
              "      <td>-0.013409</td>\n",
              "      <td>-0.002922</td>\n",
              "      <td>-0.001692</td>\n",
              "      <td>-0.000856</td>\n",
              "      <td>0.017146</td>\n",
              "      <td>-0.021353</td>\n",
              "      <td>-0.009048</td>\n",
              "      <td>-0.005810</td>\n",
              "      <td>-0.007457</td>\n",
              "      <td>0.019012</td>\n",
              "      <td>-0.006330</td>\n",
              "      <td>0.016055</td>\n",
              "      <td>0.002110</td>\n",
              "      <td>-0.004939</td>\n",
              "      <td>0.018558</td>\n",
              "      <td>-0.015926</td>\n",
              "      <td>0.003729</td>\n",
              "      <td>0.014988</td>\n",
              "      <td>0.009676</td>\n",
              "      <td>-0.001120</td>\n",
              "      <td>-0.011946</td>\n",
              "      <td>-0.009337</td>\n",
              "      <td>0.005074</td>\n",
              "      <td>0.001045</td>\n",
              "      <td>0.005248</td>\n",
              "      <td>-0.011597</td>\n",
              "      <td>-0.000503</td>\n",
              "      <td>0.004308</td>\n",
              "      <td>0.009369</td>\n",
              "      <td>-0.002835</td>\n",
              "      <td>0.001863</td>\n",
              "      <td>-0.007324</td>\n",
              "      <td>-6.976369e-03</td>\n",
              "      <td>0.011355</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>m_Married-spouse-absent</th>\n",
              "      <td>0.020570</td>\n",
              "      <td>0.003888</td>\n",
              "      <td>-0.028831</td>\n",
              "      <td>-0.036005</td>\n",
              "      <td>-0.004786</td>\n",
              "      <td>-0.007371</td>\n",
              "      <td>-0.006221</td>\n",
              "      <td>-0.042436</td>\n",
              "      <td>0.008634</td>\n",
              "      <td>-0.001731</td>\n",
              "      <td>-0.003290</td>\n",
              "      <td>-0.001631</td>\n",
              "      <td>0.003749</td>\n",
              "      <td>-0.013995</td>\n",
              "      <td>-0.001239</td>\n",
              "      <td>0.001749</td>\n",
              "      <td>-0.002188</td>\n",
              "      <td>0.008519</td>\n",
              "      <td>0.005394</td>\n",
              "      <td>-0.001930</td>\n",
              "      <td>-0.004212</td>\n",
              "      <td>-0.019735</td>\n",
              "      <td>0.020256</td>\n",
              "      <td>6.960285e-03</td>\n",
              "      <td>-0.000223</td>\n",
              "      <td>0.014481</td>\n",
              "      <td>0.012220</td>\n",
              "      <td>0.002404</td>\n",
              "      <td>-0.006508</td>\n",
              "      <td>-0.011046</td>\n",
              "      <td>-0.008981</td>\n",
              "      <td>-0.003434</td>\n",
              "      <td>-0.046018</td>\n",
              "      <td>-0.002918</td>\n",
              "      <td>-0.105914</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.080737</td>\n",
              "      <td>-0.020774</td>\n",
              "      <td>-0.020541</td>\n",
              "      <td>-0.094646</td>\n",
              "      <td>...</td>\n",
              "      <td>0.009522</td>\n",
              "      <td>0.030266</td>\n",
              "      <td>0.019983</td>\n",
              "      <td>0.013483</td>\n",
              "      <td>0.055210</td>\n",
              "      <td>0.009576</td>\n",
              "      <td>0.020043</td>\n",
              "      <td>-0.006197</td>\n",
              "      <td>0.008791</td>\n",
              "      <td>0.003649</td>\n",
              "      <td>-0.003499</td>\n",
              "      <td>0.049916</td>\n",
              "      <td>0.031595</td>\n",
              "      <td>-0.000729</td>\n",
              "      <td>0.017591</td>\n",
              "      <td>-0.002419</td>\n",
              "      <td>-0.002306</td>\n",
              "      <td>0.041619</td>\n",
              "      <td>0.005084</td>\n",
              "      <td>0.009576</td>\n",
              "      <td>0.009592</td>\n",
              "      <td>0.038280</td>\n",
              "      <td>0.002973</td>\n",
              "      <td>-0.002063</td>\n",
              "      <td>0.047256</td>\n",
              "      <td>-0.003648</td>\n",
              "      <td>-0.002063</td>\n",
              "      <td>0.008096</td>\n",
              "      <td>0.036381</td>\n",
              "      <td>0.042578</td>\n",
              "      <td>-0.003861</td>\n",
              "      <td>0.038311</td>\n",
              "      <td>-0.002188</td>\n",
              "      <td>0.008072</td>\n",
              "      <td>0.003854</td>\n",
              "      <td>0.025886</td>\n",
              "      <td>-0.002527</td>\n",
              "      <td>-0.118071</td>\n",
              "      <td>1.057499e-02</td>\n",
              "      <td>-0.002419</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>m_Never-married</th>\n",
              "      <td>-0.532415</td>\n",
              "      <td>0.035494</td>\n",
              "      <td>-0.026164</td>\n",
              "      <td>-0.168035</td>\n",
              "      <td>-0.067831</td>\n",
              "      <td>-0.060309</td>\n",
              "      <td>-0.196156</td>\n",
              "      <td>-0.315986</td>\n",
              "      <td>0.045458</td>\n",
              "      <td>-0.025826</td>\n",
              "      <td>-0.040518</td>\n",
              "      <td>0.014178</td>\n",
              "      <td>0.106609</td>\n",
              "      <td>-0.090283</td>\n",
              "      <td>-0.103690</td>\n",
              "      <td>-0.005099</td>\n",
              "      <td>0.004663</td>\n",
              "      <td>0.046253</td>\n",
              "      <td>0.076835</td>\n",
              "      <td>0.013723</td>\n",
              "      <td>-0.091972</td>\n",
              "      <td>-0.102682</td>\n",
              "      <td>-0.014980</td>\n",
              "      <td>8.080684e-02</td>\n",
              "      <td>-0.023875</td>\n",
              "      <td>0.114502</td>\n",
              "      <td>0.017408</td>\n",
              "      <td>-0.019219</td>\n",
              "      <td>-0.028792</td>\n",
              "      <td>0.019893</td>\n",
              "      <td>0.008092</td>\n",
              "      <td>-0.056335</td>\n",
              "      <td>-0.279464</td>\n",
              "      <td>-0.017720</td>\n",
              "      <td>-0.643213</td>\n",
              "      <td>-0.080737</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.126158</td>\n",
              "      <td>-0.124742</td>\n",
              "      <td>-0.574784</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.010263</td>\n",
              "      <td>-0.020426</td>\n",
              "      <td>0.004408</td>\n",
              "      <td>-0.013802</td>\n",
              "      <td>0.011432</td>\n",
              "      <td>-0.003865</td>\n",
              "      <td>0.016382</td>\n",
              "      <td>-0.002682</td>\n",
              "      <td>-0.005610</td>\n",
              "      <td>-0.010094</td>\n",
              "      <td>-0.010016</td>\n",
              "      <td>0.012481</td>\n",
              "      <td>0.003274</td>\n",
              "      <td>0.009032</td>\n",
              "      <td>-0.007768</td>\n",
              "      <td>-0.010632</td>\n",
              "      <td>0.003023</td>\n",
              "      <td>-0.011598</td>\n",
              "      <td>-0.008003</td>\n",
              "      <td>0.005403</td>\n",
              "      <td>-0.014709</td>\n",
              "      <td>0.015781</td>\n",
              "      <td>-0.003485</td>\n",
              "      <td>-0.007768</td>\n",
              "      <td>0.005199</td>\n",
              "      <td>0.007474</td>\n",
              "      <td>0.011271</td>\n",
              "      <td>0.001216</td>\n",
              "      <td>-0.002944</td>\n",
              "      <td>-0.007932</td>\n",
              "      <td>-0.008175</td>\n",
              "      <td>-0.006310</td>\n",
              "      <td>-0.004313</td>\n",
              "      <td>-0.001779</td>\n",
              "      <td>0.006615</td>\n",
              "      <td>-0.003251</td>\n",
              "      <td>0.000202</td>\n",
              "      <td>0.005735</td>\n",
              "      <td>1.629246e-02</td>\n",
              "      <td>-0.006572</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>m_Separated</th>\n",
              "      <td>0.006732</td>\n",
              "      <td>0.029382</td>\n",
              "      <td>-0.056298</td>\n",
              "      <td>-0.105813</td>\n",
              "      <td>-0.016633</td>\n",
              "      <td>-0.013159</td>\n",
              "      <td>-0.018288</td>\n",
              "      <td>-0.074208</td>\n",
              "      <td>0.005002</td>\n",
              "      <td>-0.002123</td>\n",
              "      <td>-0.000985</td>\n",
              "      <td>-0.002548</td>\n",
              "      <td>0.012160</td>\n",
              "      <td>-0.016307</td>\n",
              "      <td>-0.016295</td>\n",
              "      <td>0.006784</td>\n",
              "      <td>-0.003419</td>\n",
              "      <td>0.004837</td>\n",
              "      <td>0.018028</td>\n",
              "      <td>-0.003015</td>\n",
              "      <td>-0.012589</td>\n",
              "      <td>-0.016005</td>\n",
              "      <td>-0.017432</td>\n",
              "      <td>-5.193652e-03</td>\n",
              "      <td>0.012131</td>\n",
              "      <td>0.052722</td>\n",
              "      <td>0.013858</td>\n",
              "      <td>-0.016496</td>\n",
              "      <td>-0.006227</td>\n",
              "      <td>-0.012693</td>\n",
              "      <td>-0.002915</td>\n",
              "      <td>-0.011251</td>\n",
              "      <td>-0.071906</td>\n",
              "      <td>-0.004559</td>\n",
              "      <td>-0.165499</td>\n",
              "      <td>-0.020774</td>\n",
              "      <td>-0.126158</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.032096</td>\n",
              "      <td>-0.147893</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.004061</td>\n",
              "      <td>0.000532</td>\n",
              "      <td>0.013980</td>\n",
              "      <td>0.011704</td>\n",
              "      <td>-0.003445</td>\n",
              "      <td>-0.004969</td>\n",
              "      <td>-0.001128</td>\n",
              "      <td>-0.001128</td>\n",
              "      <td>-0.005224</td>\n",
              "      <td>0.002852</td>\n",
              "      <td>-0.005467</td>\n",
              "      <td>0.017588</td>\n",
              "      <td>0.004738</td>\n",
              "      <td>-0.001140</td>\n",
              "      <td>0.022408</td>\n",
              "      <td>-0.003780</td>\n",
              "      <td>-0.003604</td>\n",
              "      <td>-0.004906</td>\n",
              "      <td>-0.000616</td>\n",
              "      <td>-0.004969</td>\n",
              "      <td>0.001325</td>\n",
              "      <td>0.005605</td>\n",
              "      <td>-0.002666</td>\n",
              "      <td>-0.003223</td>\n",
              "      <td>0.017658</td>\n",
              "      <td>-0.005700</td>\n",
              "      <td>-0.003223</td>\n",
              "      <td>0.024775</td>\n",
              "      <td>0.003706</td>\n",
              "      <td>-0.007984</td>\n",
              "      <td>0.007673</td>\n",
              "      <td>0.022169</td>\n",
              "      <td>0.008664</td>\n",
              "      <td>-0.009128</td>\n",
              "      <td>-0.007391</td>\n",
              "      <td>-0.004415</td>\n",
              "      <td>0.006517</td>\n",
              "      <td>-0.018023</td>\n",
              "      <td>-8.065434e-03</td>\n",
              "      <td>-0.003780</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>m_Widowed</th>\n",
              "      <td>0.268079</td>\n",
              "      <td>-0.024567</td>\n",
              "      <td>-0.074710</td>\n",
              "      <td>-0.192378</td>\n",
              "      <td>-0.012032</td>\n",
              "      <td>-0.002788</td>\n",
              "      <td>-0.114527</td>\n",
              "      <td>-0.067359</td>\n",
              "      <td>0.074551</td>\n",
              "      <td>0.005337</td>\n",
              "      <td>0.017902</td>\n",
              "      <td>-0.002520</td>\n",
              "      <td>-0.037632</td>\n",
              "      <td>-0.005553</td>\n",
              "      <td>-0.005873</td>\n",
              "      <td>-0.013694</td>\n",
              "      <td>0.008831</td>\n",
              "      <td>0.074271</td>\n",
              "      <td>0.026107</td>\n",
              "      <td>-0.002981</td>\n",
              "      <td>-0.044872</td>\n",
              "      <td>-0.016811</td>\n",
              "      <td>-0.007513</td>\n",
              "      <td>-2.217780e-02</td>\n",
              "      <td>-0.002168</td>\n",
              "      <td>0.051552</td>\n",
              "      <td>0.047660</td>\n",
              "      <td>-0.023512</td>\n",
              "      <td>-0.017278</td>\n",
              "      <td>-0.002631</td>\n",
              "      <td>-0.012085</td>\n",
              "      <td>-0.022267</td>\n",
              "      <td>-0.071099</td>\n",
              "      <td>-0.004508</td>\n",
              "      <td>-0.163642</td>\n",
              "      <td>-0.020541</td>\n",
              "      <td>-0.124742</td>\n",
              "      <td>-0.032096</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.146233</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.003856</td>\n",
              "      <td>-0.004003</td>\n",
              "      <td>0.003365</td>\n",
              "      <td>0.003395</td>\n",
              "      <td>-0.003299</td>\n",
              "      <td>0.003493</td>\n",
              "      <td>0.007718</td>\n",
              "      <td>-0.000928</td>\n",
              "      <td>-0.005165</td>\n",
              "      <td>0.003134</td>\n",
              "      <td>0.002235</td>\n",
              "      <td>-0.002790</td>\n",
              "      <td>-0.001004</td>\n",
              "      <td>-0.001127</td>\n",
              "      <td>-0.003187</td>\n",
              "      <td>-0.003738</td>\n",
              "      <td>0.019607</td>\n",
              "      <td>-0.000273</td>\n",
              "      <td>0.005721</td>\n",
              "      <td>-0.004913</td>\n",
              "      <td>0.006468</td>\n",
              "      <td>-0.008591</td>\n",
              "      <td>-0.002522</td>\n",
              "      <td>-0.003187</td>\n",
              "      <td>-0.011740</td>\n",
              "      <td>0.001693</td>\n",
              "      <td>-0.003187</td>\n",
              "      <td>-0.005406</td>\n",
              "      <td>-0.001928</td>\n",
              "      <td>0.013057</td>\n",
              "      <td>0.000961</td>\n",
              "      <td>0.003922</td>\n",
              "      <td>-0.003381</td>\n",
              "      <td>0.009313</td>\n",
              "      <td>-0.007308</td>\n",
              "      <td>0.014556</td>\n",
              "      <td>-0.003904</td>\n",
              "      <td>0.005583</td>\n",
              "      <td>-7.974936e-03</td>\n",
              "      <td>-0.003738</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>r_Husband</th>\n",
              "      <td>0.313163</td>\n",
              "      <td>-0.019162</td>\n",
              "      <td>0.078546</td>\n",
              "      <td>0.578051</td>\n",
              "      <td>0.080896</td>\n",
              "      <td>0.073720</td>\n",
              "      <td>0.247201</td>\n",
              "      <td>0.401629</td>\n",
              "      <td>-0.068908</td>\n",
              "      <td>0.015817</td>\n",
              "      <td>0.002728</td>\n",
              "      <td>-0.011610</td>\n",
              "      <td>-0.088168</td>\n",
              "      <td>0.114763</td>\n",
              "      <td>0.119882</td>\n",
              "      <td>0.000525</td>\n",
              "      <td>-0.006978</td>\n",
              "      <td>-0.069506</td>\n",
              "      <td>-0.181275</td>\n",
              "      <td>-0.008862</td>\n",
              "      <td>0.157463</td>\n",
              "      <td>0.102561</td>\n",
              "      <td>0.058288</td>\n",
              "      <td>-3.644498e-02</td>\n",
              "      <td>0.019248</td>\n",
              "      <td>-0.168168</td>\n",
              "      <td>-0.057246</td>\n",
              "      <td>0.020038</td>\n",
              "      <td>0.050835</td>\n",
              "      <td>0.008204</td>\n",
              "      <td>-0.003454</td>\n",
              "      <td>0.095353</td>\n",
              "      <td>-0.327610</td>\n",
              "      <td>-0.004647</td>\n",
              "      <td>0.892795</td>\n",
              "      <td>-0.094646</td>\n",
              "      <td>-0.574784</td>\n",
              "      <td>-0.147893</td>\n",
              "      <td>-0.146233</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.002788</td>\n",
              "      <td>0.008079</td>\n",
              "      <td>-0.011767</td>\n",
              "      <td>-0.004542</td>\n",
              "      <td>-0.017109</td>\n",
              "      <td>0.004000</td>\n",
              "      <td>-0.016719</td>\n",
              "      <td>-0.004542</td>\n",
              "      <td>-0.001278</td>\n",
              "      <td>-0.002637</td>\n",
              "      <td>0.015445</td>\n",
              "      <td>-0.018490</td>\n",
              "      <td>-0.015278</td>\n",
              "      <td>-0.005192</td>\n",
              "      <td>-0.014686</td>\n",
              "      <td>0.010003</td>\n",
              "      <td>-0.004183</td>\n",
              "      <td>0.015822</td>\n",
              "      <td>-0.000195</td>\n",
              "      <td>-0.004880</td>\n",
              "      <td>0.015423</td>\n",
              "      <td>-0.015849</td>\n",
              "      <td>0.003125</td>\n",
              "      <td>0.008115</td>\n",
              "      <td>0.004452</td>\n",
              "      <td>-0.002746</td>\n",
              "      <td>-0.010126</td>\n",
              "      <td>-0.011458</td>\n",
              "      <td>-0.006091</td>\n",
              "      <td>-0.003182</td>\n",
              "      <td>-0.000663</td>\n",
              "      <td>-0.017996</td>\n",
              "      <td>-0.006978</td>\n",
              "      <td>-0.002847</td>\n",
              "      <td>0.006159</td>\n",
              "      <td>-0.006790</td>\n",
              "      <td>0.000630</td>\n",
              "      <td>0.013462</td>\n",
              "      <td>-7.536279e-03</td>\n",
              "      <td>0.010003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>r_Not-in-family</th>\n",
              "      <td>-0.010713</td>\n",
              "      <td>0.003392</td>\n",
              "      <td>0.054017</td>\n",
              "      <td>-0.164772</td>\n",
              "      <td>-0.026559</td>\n",
              "      <td>-0.016947</td>\n",
              "      <td>0.006401</td>\n",
              "      <td>-0.189083</td>\n",
              "      <td>-0.011758</td>\n",
              "      <td>0.013247</td>\n",
              "      <td>-0.003168</td>\n",
              "      <td>-0.001866</td>\n",
              "      <td>0.036670</td>\n",
              "      <td>-0.045673</td>\n",
              "      <td>-0.035497</td>\n",
              "      <td>0.012683</td>\n",
              "      <td>-0.011182</td>\n",
              "      <td>-0.011853</td>\n",
              "      <td>0.045837</td>\n",
              "      <td>0.006537</td>\n",
              "      <td>-0.047196</td>\n",
              "      <td>-0.009402</td>\n",
              "      <td>-0.033766</td>\n",
              "      <td>-1.947066e-02</td>\n",
              "      <td>-0.013656</td>\n",
              "      <td>0.030350</td>\n",
              "      <td>0.027430</td>\n",
              "      <td>0.049529</td>\n",
              "      <td>-0.012788</td>\n",
              "      <td>-0.006794</td>\n",
              "      <td>0.014285</td>\n",
              "      <td>-0.030671</td>\n",
              "      <td>0.256278</td>\n",
              "      <td>-0.014911</td>\n",
              "      <td>-0.539060</td>\n",
              "      <td>0.070299</td>\n",
              "      <td>0.299024</td>\n",
              "      <td>0.065212</td>\n",
              "      <td>0.120663</td>\n",
              "      <td>-0.483680</td>\n",
              "      <td>...</td>\n",
              "      <td>0.006532</td>\n",
              "      <td>-0.002735</td>\n",
              "      <td>0.013814</td>\n",
              "      <td>-0.002655</td>\n",
              "      <td>0.002134</td>\n",
              "      <td>-0.006294</td>\n",
              "      <td>-0.002655</td>\n",
              "      <td>0.012704</td>\n",
              "      <td>0.008169</td>\n",
              "      <td>0.005326</td>\n",
              "      <td>-0.008831</td>\n",
              "      <td>0.008421</td>\n",
              "      <td>-0.013600</td>\n",
              "      <td>-0.003727</td>\n",
              "      <td>-0.010542</td>\n",
              "      <td>-0.012363</td>\n",
              "      <td>0.015655</td>\n",
              "      <td>-0.009318</td>\n",
              "      <td>-0.002495</td>\n",
              "      <td>0.013617</td>\n",
              "      <td>-0.004245</td>\n",
              "      <td>0.005802</td>\n",
              "      <td>0.005493</td>\n",
              "      <td>-0.005429</td>\n",
              "      <td>-0.021000</td>\n",
              "      <td>-0.012856</td>\n",
              "      <td>0.020137</td>\n",
              "      <td>-0.008831</td>\n",
              "      <td>-0.015245</td>\n",
              "      <td>0.004904</td>\n",
              "      <td>-0.006060</td>\n",
              "      <td>-0.008489</td>\n",
              "      <td>-0.001540</td>\n",
              "      <td>-0.017183</td>\n",
              "      <td>-0.008540</td>\n",
              "      <td>0.007971</td>\n",
              "      <td>-0.000387</td>\n",
              "      <td>0.016134</td>\n",
              "      <td>-7.954714e-03</td>\n",
              "      <td>-0.008002</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>r_Other-relative</th>\n",
              "      <td>-0.060138</td>\n",
              "      <td>0.025574</td>\n",
              "      <td>-0.089569</td>\n",
              "      <td>-0.042030</td>\n",
              "      <td>-0.018309</td>\n",
              "      <td>-0.013064</td>\n",
              "      <td>-0.051591</td>\n",
              "      <td>-0.081620</td>\n",
              "      <td>0.013658</td>\n",
              "      <td>-0.008181</td>\n",
              "      <td>-0.014812</td>\n",
              "      <td>-0.002451</td>\n",
              "      <td>0.033603</td>\n",
              "      <td>-0.027426</td>\n",
              "      <td>-0.019093</td>\n",
              "      <td>-0.016988</td>\n",
              "      <td>-0.003289</td>\n",
              "      <td>0.013485</td>\n",
              "      <td>0.008994</td>\n",
              "      <td>0.025518</td>\n",
              "      <td>-0.010095</td>\n",
              "      <td>-0.036095</td>\n",
              "      <td>-0.003261</td>\n",
              "      <td>3.984097e-02</td>\n",
              "      <td>0.015058</td>\n",
              "      <td>0.052188</td>\n",
              "      <td>0.032445</td>\n",
              "      <td>-0.035481</td>\n",
              "      <td>-0.006210</td>\n",
              "      <td>-0.009841</td>\n",
              "      <td>-0.005032</td>\n",
              "      <td>-0.016290</td>\n",
              "      <td>-0.007019</td>\n",
              "      <td>0.005014</td>\n",
              "      <td>-0.111480</td>\n",
              "      <td>0.034338</td>\n",
              "      <td>0.096723</td>\n",
              "      <td>0.030081</td>\n",
              "      <td>0.018692</td>\n",
              "      <td>-0.142262</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.007142</td>\n",
              "      <td>0.015792</td>\n",
              "      <td>-0.001751</td>\n",
              "      <td>0.003995</td>\n",
              "      <td>0.017540</td>\n",
              "      <td>0.029728</td>\n",
              "      <td>0.039485</td>\n",
              "      <td>-0.009314</td>\n",
              "      <td>-0.005025</td>\n",
              "      <td>-0.003634</td>\n",
              "      <td>0.002582</td>\n",
              "      <td>0.045454</td>\n",
              "      <td>0.042057</td>\n",
              "      <td>0.036494</td>\n",
              "      <td>0.010191</td>\n",
              "      <td>0.007700</td>\n",
              "      <td>0.008422</td>\n",
              "      <td>0.009410</td>\n",
              "      <td>-0.000131</td>\n",
              "      <td>0.003847</td>\n",
              "      <td>0.002010</td>\n",
              "      <td>0.026233</td>\n",
              "      <td>-0.002171</td>\n",
              "      <td>-0.003101</td>\n",
              "      <td>0.087245</td>\n",
              "      <td>0.032125</td>\n",
              "      <td>-0.003101</td>\n",
              "      <td>0.002582</td>\n",
              "      <td>0.032514</td>\n",
              "      <td>0.013820</td>\n",
              "      <td>-0.005803</td>\n",
              "      <td>0.016146</td>\n",
              "      <td>-0.003289</td>\n",
              "      <td>0.028857</td>\n",
              "      <td>-0.001305</td>\n",
              "      <td>-0.004246</td>\n",
              "      <td>0.007056</td>\n",
              "      <td>-0.100666</td>\n",
              "      <td>2.416903e-02</td>\n",
              "      <td>-0.003636</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>r_Own-child</th>\n",
              "      <td>-0.432241</td>\n",
              "      <td>0.013083</td>\n",
              "      <td>-0.094243</td>\n",
              "      <td>-0.101727</td>\n",
              "      <td>-0.054354</td>\n",
              "      <td>-0.050220</td>\n",
              "      <td>-0.245686</td>\n",
              "      <td>-0.227382</td>\n",
              "      <td>0.090131</td>\n",
              "      <td>-0.045396</td>\n",
              "      <td>-0.037109</td>\n",
              "      <td>0.025056</td>\n",
              "      <td>0.061795</td>\n",
              "      <td>-0.056928</td>\n",
              "      <td>-0.071974</td>\n",
              "      <td>-0.015981</td>\n",
              "      <td>0.015045</td>\n",
              "      <td>0.091519</td>\n",
              "      <td>0.050191</td>\n",
              "      <td>-0.000626</td>\n",
              "      <td>-0.062421</td>\n",
              "      <td>-0.098596</td>\n",
              "      <td>-0.001270</td>\n",
              "      <td>9.134319e-02</td>\n",
              "      <td>-0.019392</td>\n",
              "      <td>0.102253</td>\n",
              "      <td>-0.004647</td>\n",
              "      <td>-0.081453</td>\n",
              "      <td>-0.015440</td>\n",
              "      <td>0.031915</td>\n",
              "      <td>-0.010642</td>\n",
              "      <td>-0.032153</td>\n",
              "      <td>-0.091912</td>\n",
              "      <td>-0.006544</td>\n",
              "      <td>-0.380993</td>\n",
              "      <td>-0.013850</td>\n",
              "      <td>0.509782</td>\n",
              "      <td>-0.025847</td>\n",
              "      <td>-0.068427</td>\n",
              "      <td>-0.353496</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.011374</td>\n",
              "      <td>-0.012121</td>\n",
              "      <td>-0.007896</td>\n",
              "      <td>-0.006706</td>\n",
              "      <td>0.001310</td>\n",
              "      <td>-0.007881</td>\n",
              "      <td>0.003568</td>\n",
              "      <td>-0.008761</td>\n",
              "      <td>-0.008686</td>\n",
              "      <td>-0.012017</td>\n",
              "      <td>-0.005804</td>\n",
              "      <td>-0.011884</td>\n",
              "      <td>0.000156</td>\n",
              "      <td>-0.002724</td>\n",
              "      <td>-0.007705</td>\n",
              "      <td>-0.009035</td>\n",
              "      <td>-0.008615</td>\n",
              "      <td>-0.007415</td>\n",
              "      <td>-0.001400</td>\n",
              "      <td>-0.007881</td>\n",
              "      <td>-0.013171</td>\n",
              "      <td>-0.002457</td>\n",
              "      <td>-0.008827</td>\n",
              "      <td>-0.007705</td>\n",
              "      <td>-0.026538</td>\n",
              "      <td>0.000310</td>\n",
              "      <td>-0.001548</td>\n",
              "      <td>0.008723</td>\n",
              "      <td>0.007642</td>\n",
              "      <td>-0.009126</td>\n",
              "      <td>-0.001252</td>\n",
              "      <td>-0.007154</td>\n",
              "      <td>-0.002368</td>\n",
              "      <td>-0.000026</td>\n",
              "      <td>0.003844</td>\n",
              "      <td>-0.006055</td>\n",
              "      <td>-0.004410</td>\n",
              "      <td>0.043245</td>\n",
              "      <td>4.387002e-04</td>\n",
              "      <td>0.001466</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>r_Unmarried</th>\n",
              "      <td>0.044975</td>\n",
              "      <td>0.006629</td>\n",
              "      <td>-0.065155</td>\n",
              "      <td>-0.320817</td>\n",
              "      <td>-0.029451</td>\n",
              "      <td>-0.038438</td>\n",
              "      <td>-0.037797</td>\n",
              "      <td>-0.144253</td>\n",
              "      <td>-0.006079</td>\n",
              "      <td>0.019685</td>\n",
              "      <td>0.033010</td>\n",
              "      <td>-0.004860</td>\n",
              "      <td>0.017009</td>\n",
              "      <td>-0.036124</td>\n",
              "      <td>-0.046713</td>\n",
              "      <td>0.006757</td>\n",
              "      <td>0.000340</td>\n",
              "      <td>-0.006367</td>\n",
              "      <td>0.104048</td>\n",
              "      <td>-0.005751</td>\n",
              "      <td>-0.053814</td>\n",
              "      <td>-0.022034</td>\n",
              "      <td>-0.023394</td>\n",
              "      <td>-1.766762e-02</td>\n",
              "      <td>0.005853</td>\n",
              "      <td>0.067543</td>\n",
              "      <td>0.036050</td>\n",
              "      <td>-0.019456</td>\n",
              "      <td>-0.023282</td>\n",
              "      <td>-0.021108</td>\n",
              "      <td>-0.001761</td>\n",
              "      <td>-0.033531</td>\n",
              "      <td>0.333551</td>\n",
              "      <td>-0.008696</td>\n",
              "      <td>-0.315634</td>\n",
              "      <td>0.066758</td>\n",
              "      <td>-0.053342</td>\n",
              "      <td>0.185718</td>\n",
              "      <td>0.160403</td>\n",
              "      <td>-0.282055</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.005087</td>\n",
              "      <td>-0.011534</td>\n",
              "      <td>0.013044</td>\n",
              "      <td>0.010679</td>\n",
              "      <td>0.006441</td>\n",
              "      <td>-0.000030</td>\n",
              "      <td>0.003393</td>\n",
              "      <td>0.000964</td>\n",
              "      <td>0.003515</td>\n",
              "      <td>0.008634</td>\n",
              "      <td>-0.006134</td>\n",
              "      <td>0.010837</td>\n",
              "      <td>0.013321</td>\n",
              "      <td>-0.002173</td>\n",
              "      <td>0.030238</td>\n",
              "      <td>-0.007209</td>\n",
              "      <td>-0.006874</td>\n",
              "      <td>-0.002707</td>\n",
              "      <td>0.001058</td>\n",
              "      <td>-0.000030</td>\n",
              "      <td>-0.007801</td>\n",
              "      <td>0.005073</td>\n",
              "      <td>-0.003178</td>\n",
              "      <td>-0.006148</td>\n",
              "      <td>0.010788</td>\n",
              "      <td>0.001482</td>\n",
              "      <td>-0.006148</td>\n",
              "      <td>0.015331</td>\n",
              "      <td>-0.001588</td>\n",
              "      <td>-0.000513</td>\n",
              "      <td>0.004059</td>\n",
              "      <td>0.029172</td>\n",
              "      <td>0.007201</td>\n",
              "      <td>0.003198</td>\n",
              "      <td>-0.007739</td>\n",
              "      <td>0.002211</td>\n",
              "      <td>-0.001588</td>\n",
              "      <td>-0.020821</td>\n",
              "      <td>1.083739e-02</td>\n",
              "      <td>-0.007209</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>r_Wife</th>\n",
              "      <td>0.020590</td>\n",
              "      <td>-0.014796</td>\n",
              "      <td>0.033434</td>\n",
              "      <td>-0.320182</td>\n",
              "      <td>0.017783</td>\n",
              "      <td>0.016352</td>\n",
              "      <td>-0.067407</td>\n",
              "      <td>0.122886</td>\n",
              "      <td>0.026826</td>\n",
              "      <td>-0.008065</td>\n",
              "      <td>0.027347</td>\n",
              "      <td>-0.003194</td>\n",
              "      <td>-0.028525</td>\n",
              "      <td>0.000428</td>\n",
              "      <td>0.002088</td>\n",
              "      <td>0.003641</td>\n",
              "      <td>0.015342</td>\n",
              "      <td>0.026585</td>\n",
              "      <td>0.079720</td>\n",
              "      <td>-0.003779</td>\n",
              "      <td>-0.072916</td>\n",
              "      <td>0.011528</td>\n",
              "      <td>-0.026141</td>\n",
              "      <td>-3.754491e-02</td>\n",
              "      <td>-0.003509</td>\n",
              "      <td>0.011696</td>\n",
              "      <td>0.005711</td>\n",
              "      <td>0.046769</td>\n",
              "      <td>-0.025729</td>\n",
              "      <td>-0.020957</td>\n",
              "      <td>0.003255</td>\n",
              "      <td>-0.040126</td>\n",
              "      <td>-0.090126</td>\n",
              "      <td>0.060536</td>\n",
              "      <td>0.242471</td>\n",
              "      <td>-0.026037</td>\n",
              "      <td>-0.158124</td>\n",
              "      <td>-0.040685</td>\n",
              "      <td>-0.040229</td>\n",
              "      <td>-0.185365</td>\n",
              "      <td>...</td>\n",
              "      <td>0.012440</td>\n",
              "      <td>0.011752</td>\n",
              "      <td>-0.005197</td>\n",
              "      <td>0.008708</td>\n",
              "      <td>0.009543</td>\n",
              "      <td>-0.006228</td>\n",
              "      <td>0.001760</td>\n",
              "      <td>0.005234</td>\n",
              "      <td>-0.000122</td>\n",
              "      <td>0.005990</td>\n",
              "      <td>-0.000712</td>\n",
              "      <td>-0.005942</td>\n",
              "      <td>0.010304</td>\n",
              "      <td>-0.001428</td>\n",
              "      <td>0.016777</td>\n",
              "      <td>0.021893</td>\n",
              "      <td>-0.004517</td>\n",
              "      <td>-0.008105</td>\n",
              "      <td>0.006482</td>\n",
              "      <td>-0.006228</td>\n",
              "      <td>0.005290</td>\n",
              "      <td>0.000719</td>\n",
              "      <td>0.002854</td>\n",
              "      <td>0.016777</td>\n",
              "      <td>-0.006295</td>\n",
              "      <td>0.004635</td>\n",
              "      <td>-0.004040</td>\n",
              "      <td>0.005428</td>\n",
              "      <td>0.008826</td>\n",
              "      <td>0.002620</td>\n",
              "      <td>0.014702</td>\n",
              "      <td>0.016080</td>\n",
              "      <td>0.015342</td>\n",
              "      <td>0.014349</td>\n",
              "      <td>0.008920</td>\n",
              "      <td>0.009672</td>\n",
              "      <td>0.003551</td>\n",
              "      <td>-0.028073</td>\n",
              "      <td>-1.775126e-03</td>\n",
              "      <td>0.004139</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>race_Amer-Indian-Eskimo</th>\n",
              "      <td>-0.011074</td>\n",
              "      <td>-0.070516</td>\n",
              "      <td>-0.029399</td>\n",
              "      <td>-0.013108</td>\n",
              "      <td>-0.005776</td>\n",
              "      <td>-0.012180</td>\n",
              "      <td>-0.000572</td>\n",
              "      <td>-0.029441</td>\n",
              "      <td>0.013383</td>\n",
              "      <td>0.013847</td>\n",
              "      <td>0.025488</td>\n",
              "      <td>-0.001395</td>\n",
              "      <td>-0.018316</td>\n",
              "      <td>-0.016338</td>\n",
              "      <td>-0.001620</td>\n",
              "      <td>0.000896</td>\n",
              "      <td>-0.001872</td>\n",
              "      <td>0.013274</td>\n",
              "      <td>-0.002123</td>\n",
              "      <td>0.022817</td>\n",
              "      <td>0.006073</td>\n",
              "      <td>-0.009623</td>\n",
              "      <td>-0.003309</td>\n",
              "      <td>9.108478e-03</td>\n",
              "      <td>-0.003081</td>\n",
              "      <td>0.003203</td>\n",
              "      <td>-0.006880</td>\n",
              "      <td>-0.008177</td>\n",
              "      <td>0.006272</td>\n",
              "      <td>-0.009242</td>\n",
              "      <td>-0.006877</td>\n",
              "      <td>0.015461</td>\n",
              "      <td>0.016513</td>\n",
              "      <td>-0.002497</td>\n",
              "      <td>-0.022426</td>\n",
              "      <td>0.013808</td>\n",
              "      <td>0.005847</td>\n",
              "      <td>0.000992</td>\n",
              "      <td>0.006133</td>\n",
              "      <td>-0.026727</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.006221</td>\n",
              "      <td>-0.004839</td>\n",
              "      <td>0.005468</td>\n",
              "      <td>-0.005302</td>\n",
              "      <td>-0.004590</td>\n",
              "      <td>-0.002721</td>\n",
              "      <td>-0.005302</td>\n",
              "      <td>-0.005302</td>\n",
              "      <td>-0.002861</td>\n",
              "      <td>0.000107</td>\n",
              "      <td>-0.002994</td>\n",
              "      <td>-0.004417</td>\n",
              "      <td>-0.003849</td>\n",
              "      <td>-0.000624</td>\n",
              "      <td>-0.001765</td>\n",
              "      <td>-0.002070</td>\n",
              "      <td>-0.001974</td>\n",
              "      <td>-0.005114</td>\n",
              "      <td>-0.003694</td>\n",
              "      <td>-0.002721</td>\n",
              "      <td>-0.004633</td>\n",
              "      <td>-0.004758</td>\n",
              "      <td>-0.004327</td>\n",
              "      <td>-0.001765</td>\n",
              "      <td>0.003834</td>\n",
              "      <td>-0.003121</td>\n",
              "      <td>-0.001765</td>\n",
              "      <td>-0.002994</td>\n",
              "      <td>-0.002407</td>\n",
              "      <td>-0.004372</td>\n",
              "      <td>-0.003304</td>\n",
              "      <td>0.000494</td>\n",
              "      <td>-0.001872</td>\n",
              "      <td>0.011205</td>\n",
              "      <td>-0.004047</td>\n",
              "      <td>-0.002417</td>\n",
              "      <td>-0.002162</td>\n",
              "      <td>0.017310</td>\n",
              "      <td>-4.416637e-03</td>\n",
              "      <td>-0.002070</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>race_Asian-Pac-Islander</th>\n",
              "      <td>-0.005739</td>\n",
              "      <td>-0.051432</td>\n",
              "      <td>0.062088</td>\n",
              "      <td>0.000010</td>\n",
              "      <td>0.014440</td>\n",
              "      <td>0.008460</td>\n",
              "      <td>-0.003223</td>\n",
              "      <td>0.007841</td>\n",
              "      <td>0.006658</td>\n",
              "      <td>0.018603</td>\n",
              "      <td>-0.021860</td>\n",
              "      <td>-0.002530</td>\n",
              "      <td>-0.011501</td>\n",
              "      <td>0.011965</td>\n",
              "      <td>-0.001127</td>\n",
              "      <td>0.021527</td>\n",
              "      <td>-0.003394</td>\n",
              "      <td>0.006492</td>\n",
              "      <td>0.009106</td>\n",
              "      <td>-0.002993</td>\n",
              "      <td>-0.023584</td>\n",
              "      <td>0.004489</td>\n",
              "      <td>-0.015761</td>\n",
              "      <td>-1.648844e-02</td>\n",
              "      <td>-0.002514</td>\n",
              "      <td>0.013558</td>\n",
              "      <td>-0.002497</td>\n",
              "      <td>0.025226</td>\n",
              "      <td>-0.009193</td>\n",
              "      <td>-0.003114</td>\n",
              "      <td>0.012854</td>\n",
              "      <td>-0.017159</td>\n",
              "      <td>-0.029151</td>\n",
              "      <td>-0.004526</td>\n",
              "      <td>0.012197</td>\n",
              "      <td>0.048337</td>\n",
              "      <td>0.005907</td>\n",
              "      <td>-0.017677</td>\n",
              "      <td>-0.006468</td>\n",
              "      <td>-0.003287</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.007603</td>\n",
              "      <td>0.264793</td>\n",
              "      <td>-0.007595</td>\n",
              "      <td>-0.009613</td>\n",
              "      <td>-0.008322</td>\n",
              "      <td>-0.004933</td>\n",
              "      <td>-0.009613</td>\n",
              "      <td>-0.005306</td>\n",
              "      <td>-0.005186</td>\n",
              "      <td>-0.004207</td>\n",
              "      <td>0.002185</td>\n",
              "      <td>-0.008007</td>\n",
              "      <td>-0.001054</td>\n",
              "      <td>-0.001131</td>\n",
              "      <td>-0.003200</td>\n",
              "      <td>0.106296</td>\n",
              "      <td>-0.003578</td>\n",
              "      <td>0.245181</td>\n",
              "      <td>0.017993</td>\n",
              "      <td>-0.004933</td>\n",
              "      <td>-0.008399</td>\n",
              "      <td>-0.008625</td>\n",
              "      <td>0.150318</td>\n",
              "      <td>0.100029</td>\n",
              "      <td>-0.023569</td>\n",
              "      <td>-0.005659</td>\n",
              "      <td>-0.003200</td>\n",
              "      <td>-0.005428</td>\n",
              "      <td>0.414978</td>\n",
              "      <td>-0.002708</td>\n",
              "      <td>0.000911</td>\n",
              "      <td>-0.007374</td>\n",
              "      <td>-0.003394</td>\n",
              "      <td>0.269540</td>\n",
              "      <td>0.212445</td>\n",
              "      <td>0.118140</td>\n",
              "      <td>0.006617</td>\n",
              "      <td>-0.366520</td>\n",
              "      <td>2.451169e-01</td>\n",
              "      <td>-0.003753</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>race_Black</th>\n",
              "      <td>-0.020923</td>\n",
              "      <td>0.120882</td>\n",
              "      <td>-0.073343</td>\n",
              "      <td>-0.113508</td>\n",
              "      <td>-0.023755</td>\n",
              "      <td>-0.021971</td>\n",
              "      <td>-0.054357</td>\n",
              "      <td>-0.086716</td>\n",
              "      <td>0.010599</td>\n",
              "      <td>0.050847</td>\n",
              "      <td>0.037866</td>\n",
              "      <td>0.005053</td>\n",
              "      <td>-0.000106</td>\n",
              "      <td>-0.047614</td>\n",
              "      <td>-0.057686</td>\n",
              "      <td>0.019199</td>\n",
              "      <td>0.001032</td>\n",
              "      <td>0.010892</td>\n",
              "      <td>0.045426</td>\n",
              "      <td>0.002720</td>\n",
              "      <td>-0.046633</td>\n",
              "      <td>-0.042892</td>\n",
              "      <td>-0.029238</td>\n",
              "      <td>2.284465e-02</td>\n",
              "      <td>0.040210</td>\n",
              "      <td>0.086344</td>\n",
              "      <td>0.020596</td>\n",
              "      <td>-0.050979</td>\n",
              "      <td>0.024402</td>\n",
              "      <td>-0.029702</td>\n",
              "      <td>-0.022179</td>\n",
              "      <td>0.010182</td>\n",
              "      <td>0.012324</td>\n",
              "      <td>-0.002817</td>\n",
              "      <td>-0.124420</td>\n",
              "      <td>0.018913</td>\n",
              "      <td>0.075523</td>\n",
              "      <td>0.097024</td>\n",
              "      <td>0.018807</td>\n",
              "      <td>-0.124163</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.020448</td>\n",
              "      <td>-0.015906</td>\n",
              "      <td>-0.013771</td>\n",
              "      <td>-0.012341</td>\n",
              "      <td>0.005465</td>\n",
              "      <td>-0.008944</td>\n",
              "      <td>-0.014885</td>\n",
              "      <td>-0.002166</td>\n",
              "      <td>-0.009403</td>\n",
              "      <td>-0.005787</td>\n",
              "      <td>-0.009841</td>\n",
              "      <td>-0.014517</td>\n",
              "      <td>0.116813</td>\n",
              "      <td>-0.002051</td>\n",
              "      <td>0.001819</td>\n",
              "      <td>-0.006804</td>\n",
              "      <td>-0.006487</td>\n",
              "      <td>-0.014174</td>\n",
              "      <td>-0.012143</td>\n",
              "      <td>-0.008944</td>\n",
              "      <td>-0.015228</td>\n",
              "      <td>0.131698</td>\n",
              "      <td>-0.007996</td>\n",
              "      <td>-0.005802</td>\n",
              "      <td>-0.042801</td>\n",
              "      <td>-0.001635</td>\n",
              "      <td>0.032305</td>\n",
              "      <td>-0.009841</td>\n",
              "      <td>-0.025280</td>\n",
              "      <td>-0.014371</td>\n",
              "      <td>-0.010859</td>\n",
              "      <td>-0.004706</td>\n",
              "      <td>-0.006154</td>\n",
              "      <td>-0.016429</td>\n",
              "      <td>-0.013303</td>\n",
              "      <td>-0.007946</td>\n",
              "      <td>0.055128</td>\n",
              "      <td>0.012736</td>\n",
              "      <td>-1.451747e-02</td>\n",
              "      <td>-0.006804</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>race_Other</th>\n",
              "      <td>-0.035494</td>\n",
              "      <td>0.009401</td>\n",
              "      <td>-0.047280</td>\n",
              "      <td>-0.017550</td>\n",
              "      <td>-0.005521</td>\n",
              "      <td>-0.007606</td>\n",
              "      <td>-0.006926</td>\n",
              "      <td>-0.036860</td>\n",
              "      <td>0.011381</td>\n",
              "      <td>-0.001069</td>\n",
              "      <td>-0.010397</td>\n",
              "      <td>-0.001314</td>\n",
              "      <td>0.019042</td>\n",
              "      <td>-0.007961</td>\n",
              "      <td>-0.019193</td>\n",
              "      <td>-0.010005</td>\n",
              "      <td>-0.001763</td>\n",
              "      <td>0.011281</td>\n",
              "      <td>-0.010012</td>\n",
              "      <td>-0.001555</td>\n",
              "      <td>-0.004892</td>\n",
              "      <td>-0.024293</td>\n",
              "      <td>0.006130</td>\n",
              "      <td>9.749379e-04</td>\n",
              "      <td>0.034087</td>\n",
              "      <td>0.011653</td>\n",
              "      <td>0.012289</td>\n",
              "      <td>-0.001591</td>\n",
              "      <td>0.002147</td>\n",
              "      <td>-0.005627</td>\n",
              "      <td>-0.007926</td>\n",
              "      <td>-0.001028</td>\n",
              "      <td>-0.010599</td>\n",
              "      <td>-0.002351</td>\n",
              "      <td>-0.018246</td>\n",
              "      <td>0.035076</td>\n",
              "      <td>0.015335</td>\n",
              "      <td>0.010629</td>\n",
              "      <td>-0.001465</td>\n",
              "      <td>-0.027578</td>\n",
              "      <td>...</td>\n",
              "      <td>0.001055</td>\n",
              "      <td>-0.004558</td>\n",
              "      <td>0.047271</td>\n",
              "      <td>0.003109</td>\n",
              "      <td>0.126613</td>\n",
              "      <td>0.076218</td>\n",
              "      <td>0.011211</td>\n",
              "      <td>-0.004994</td>\n",
              "      <td>-0.002694</td>\n",
              "      <td>0.000864</td>\n",
              "      <td>-0.002820</td>\n",
              "      <td>0.034715</td>\n",
              "      <td>-0.003625</td>\n",
              "      <td>-0.000588</td>\n",
              "      <td>-0.001662</td>\n",
              "      <td>-0.001950</td>\n",
              "      <td>-0.001859</td>\n",
              "      <td>0.020379</td>\n",
              "      <td>-0.003479</td>\n",
              "      <td>-0.002563</td>\n",
              "      <td>-0.004363</td>\n",
              "      <td>0.004544</td>\n",
              "      <td>-0.004075</td>\n",
              "      <td>-0.001662</td>\n",
              "      <td>0.084185</td>\n",
              "      <td>0.024535</td>\n",
              "      <td>-0.001662</td>\n",
              "      <td>0.011502</td>\n",
              "      <td>-0.007243</td>\n",
              "      <td>-0.004118</td>\n",
              "      <td>-0.003111</td>\n",
              "      <td>0.127618</td>\n",
              "      <td>-0.001763</td>\n",
              "      <td>-0.004707</td>\n",
              "      <td>0.006791</td>\n",
              "      <td>-0.002277</td>\n",
              "      <td>0.017787</td>\n",
              "      <td>-0.119801</td>\n",
              "      <td>-4.159617e-03</td>\n",
              "      <td>-0.001950</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>race_White</th>\n",
              "      <td>0.032681</td>\n",
              "      <td>-0.058423</td>\n",
              "      <td>0.051183</td>\n",
              "      <td>0.103009</td>\n",
              "      <td>0.015766</td>\n",
              "      <td>0.019553</td>\n",
              "      <td>0.048948</td>\n",
              "      <td>0.086381</td>\n",
              "      <td>-0.018837</td>\n",
              "      <td>-0.055196</td>\n",
              "      <td>-0.025195</td>\n",
              "      <td>-0.002239</td>\n",
              "      <td>0.005860</td>\n",
              "      <td>0.040482</td>\n",
              "      <td>0.054200</td>\n",
              "      <td>-0.024272</td>\n",
              "      <td>0.001795</td>\n",
              "      <td>-0.018943</td>\n",
              "      <td>-0.039203</td>\n",
              "      <td>-0.006731</td>\n",
              "      <td>0.050159</td>\n",
              "      <td>0.042641</td>\n",
              "      <td>0.031497</td>\n",
              "      <td>-1.373007e-02</td>\n",
              "      <td>-0.040411</td>\n",
              "      <td>-0.082721</td>\n",
              "      <td>-0.017272</td>\n",
              "      <td>0.032814</td>\n",
              "      <td>-0.018146</td>\n",
              "      <td>0.030379</td>\n",
              "      <td>0.016168</td>\n",
              "      <td>-0.004069</td>\n",
              "      <td>0.002273</td>\n",
              "      <td>0.005894</td>\n",
              "      <td>0.108883</td>\n",
              "      <td>-0.052661</td>\n",
              "      <td>-0.071613</td>\n",
              "      <td>-0.075352</td>\n",
              "      <td>-0.013834</td>\n",
              "      <td>0.119945</td>\n",
              "      <td>...</td>\n",
              "      <td>0.022275</td>\n",
              "      <td>-0.114760</td>\n",
              "      <td>0.001332</td>\n",
              "      <td>0.015703</td>\n",
              "      <td>-0.032371</td>\n",
              "      <td>-0.009322</td>\n",
              "      <td>0.015703</td>\n",
              "      <td>0.007208</td>\n",
              "      <td>0.011910</td>\n",
              "      <td>0.006650</td>\n",
              "      <td>0.008710</td>\n",
              "      <td>0.008198</td>\n",
              "      <td>-0.094989</td>\n",
              "      <td>0.002598</td>\n",
              "      <td>0.000986</td>\n",
              "      <td>-0.045652</td>\n",
              "      <td>0.008217</td>\n",
              "      <td>-0.112995</td>\n",
              "      <td>0.003204</td>\n",
              "      <td>0.011328</td>\n",
              "      <td>0.019287</td>\n",
              "      <td>-0.105572</td>\n",
              "      <td>-0.065182</td>\n",
              "      <td>-0.043558</td>\n",
              "      <td>0.024226</td>\n",
              "      <td>-0.001408</td>\n",
              "      <td>-0.024468</td>\n",
              "      <td>0.008710</td>\n",
              "      <td>-0.180969</td>\n",
              "      <td>0.015629</td>\n",
              "      <td>0.010351</td>\n",
              "      <td>-0.026023</td>\n",
              "      <td>0.007795</td>\n",
              "      <td>-0.121086</td>\n",
              "      <td>-0.094313</td>\n",
              "      <td>-0.050357</td>\n",
              "      <td>-0.053352</td>\n",
              "      <td>0.196704</td>\n",
              "      <td>-1.064388e-01</td>\n",
              "      <td>0.008618</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>c_?</th>\n",
              "      <td>0.000683</td>\n",
              "      <td>0.005641</td>\n",
              "      <td>0.026118</td>\n",
              "      <td>0.015794</td>\n",
              "      <td>0.012328</td>\n",
              "      <td>0.009639</td>\n",
              "      <td>0.010446</td>\n",
              "      <td>0.001053</td>\n",
              "      <td>-0.006452</td>\n",
              "      <td>-0.002394</td>\n",
              "      <td>-0.010933</td>\n",
              "      <td>-0.001904</td>\n",
              "      <td>0.004303</td>\n",
              "      <td>0.024517</td>\n",
              "      <td>-0.002475</td>\n",
              "      <td>-0.005693</td>\n",
              "      <td>-0.002555</td>\n",
              "      <td>-0.006558</td>\n",
              "      <td>-0.014907</td>\n",
              "      <td>-0.002253</td>\n",
              "      <td>-0.000523</td>\n",
              "      <td>-0.000824</td>\n",
              "      <td>-0.016933</td>\n",
              "      <td>-1.204146e-02</td>\n",
              "      <td>0.005870</td>\n",
              "      <td>0.013503</td>\n",
              "      <td>0.012406</td>\n",
              "      <td>0.021242</td>\n",
              "      <td>-0.008518</td>\n",
              "      <td>0.001812</td>\n",
              "      <td>0.002720</td>\n",
              "      <td>-0.005401</td>\n",
              "      <td>-0.022094</td>\n",
              "      <td>-0.003407</td>\n",
              "      <td>0.006285</td>\n",
              "      <td>0.032333</td>\n",
              "      <td>0.001671</td>\n",
              "      <td>0.005217</td>\n",
              "      <td>-0.004710</td>\n",
              "      <td>0.002382</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.008488</td>\n",
              "      <td>-0.006603</td>\n",
              "      <td>-0.005717</td>\n",
              "      <td>-0.007235</td>\n",
              "      <td>-0.006263</td>\n",
              "      <td>-0.003713</td>\n",
              "      <td>-0.007235</td>\n",
              "      <td>-0.007235</td>\n",
              "      <td>-0.003903</td>\n",
              "      <td>-0.008616</td>\n",
              "      <td>-0.004085</td>\n",
              "      <td>-0.006026</td>\n",
              "      <td>-0.005252</td>\n",
              "      <td>-0.000851</td>\n",
              "      <td>-0.002409</td>\n",
              "      <td>-0.002824</td>\n",
              "      <td>-0.002693</td>\n",
              "      <td>-0.006978</td>\n",
              "      <td>-0.005041</td>\n",
              "      <td>-0.003713</td>\n",
              "      <td>-0.006321</td>\n",
              "      <td>-0.006492</td>\n",
              "      <td>-0.005904</td>\n",
              "      <td>-0.002409</td>\n",
              "      <td>-0.018995</td>\n",
              "      <td>-0.004259</td>\n",
              "      <td>-0.002409</td>\n",
              "      <td>-0.004085</td>\n",
              "      <td>-0.010494</td>\n",
              "      <td>-0.005966</td>\n",
              "      <td>-0.004508</td>\n",
              "      <td>-0.008358</td>\n",
              "      <td>-0.002555</td>\n",
              "      <td>-0.006820</td>\n",
              "      <td>-0.005522</td>\n",
              "      <td>-0.003298</td>\n",
              "      <td>-0.002950</td>\n",
              "      <td>-0.396928</td>\n",
              "      <td>-6.026425e-03</td>\n",
              "      <td>-0.002824</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>c_Cambodia</th>\n",
              "      <td>-0.005051</td>\n",
              "      <td>0.000635</td>\n",
              "      <td>-0.013177</td>\n",
              "      <td>0.007748</td>\n",
              "      <td>0.000446</td>\n",
              "      <td>0.008254</td>\n",
              "      <td>0.001348</td>\n",
              "      <td>0.000631</td>\n",
              "      <td>0.000720</td>\n",
              "      <td>0.004821</td>\n",
              "      <td>-0.006670</td>\n",
              "      <td>-0.000358</td>\n",
              "      <td>0.006439</td>\n",
              "      <td>-0.004768</td>\n",
              "      <td>-0.001558</td>\n",
              "      <td>-0.005147</td>\n",
              "      <td>-0.000480</td>\n",
              "      <td>0.000697</td>\n",
              "      <td>-0.009301</td>\n",
              "      <td>-0.000424</td>\n",
              "      <td>0.014362</td>\n",
              "      <td>-0.004683</td>\n",
              "      <td>0.004669</td>\n",
              "      <td>-5.165631e-03</td>\n",
              "      <td>0.013285</td>\n",
              "      <td>-0.003317</td>\n",
              "      <td>-0.001765</td>\n",
              "      <td>0.004580</td>\n",
              "      <td>-0.003626</td>\n",
              "      <td>-0.004011</td>\n",
              "      <td>-0.004305</td>\n",
              "      <td>-0.005752</td>\n",
              "      <td>-0.010100</td>\n",
              "      <td>-0.000640</td>\n",
              "      <td>0.002152</td>\n",
              "      <td>0.010982</td>\n",
              "      <td>0.005844</td>\n",
              "      <td>-0.004559</td>\n",
              "      <td>-0.004508</td>\n",
              "      <td>0.001803</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.001596</td>\n",
              "      <td>-0.001241</td>\n",
              "      <td>-0.001075</td>\n",
              "      <td>-0.001360</td>\n",
              "      <td>-0.001177</td>\n",
              "      <td>-0.000698</td>\n",
              "      <td>-0.001360</td>\n",
              "      <td>-0.001360</td>\n",
              "      <td>-0.000734</td>\n",
              "      <td>-0.001620</td>\n",
              "      <td>-0.000768</td>\n",
              "      <td>-0.001133</td>\n",
              "      <td>-0.000987</td>\n",
              "      <td>-0.000160</td>\n",
              "      <td>-0.000453</td>\n",
              "      <td>-0.000531</td>\n",
              "      <td>-0.000506</td>\n",
              "      <td>-0.001312</td>\n",
              "      <td>-0.000948</td>\n",
              "      <td>-0.000698</td>\n",
              "      <td>-0.001188</td>\n",
              "      <td>-0.001220</td>\n",
              "      <td>-0.001110</td>\n",
              "      <td>-0.000453</td>\n",
              "      <td>-0.003571</td>\n",
              "      <td>-0.000801</td>\n",
              "      <td>-0.000453</td>\n",
              "      <td>-0.000768</td>\n",
              "      <td>-0.001973</td>\n",
              "      <td>-0.001121</td>\n",
              "      <td>-0.000847</td>\n",
              "      <td>-0.001571</td>\n",
              "      <td>-0.000480</td>\n",
              "      <td>-0.001282</td>\n",
              "      <td>-0.001038</td>\n",
              "      <td>-0.000620</td>\n",
              "      <td>-0.000555</td>\n",
              "      <td>-0.074616</td>\n",
              "      <td>-1.132866e-03</td>\n",
              "      <td>-0.000531</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>c_Canada</th>\n",
              "      <td>0.020935</td>\n",
              "      <td>-0.010107</td>\n",
              "      <td>0.010197</td>\n",
              "      <td>-0.001580</td>\n",
              "      <td>0.006315</td>\n",
              "      <td>0.005144</td>\n",
              "      <td>0.002468</td>\n",
              "      <td>0.016872</td>\n",
              "      <td>0.009588</td>\n",
              "      <td>-0.003622</td>\n",
              "      <td>-0.003698</td>\n",
              "      <td>-0.000892</td>\n",
              "      <td>-0.002553</td>\n",
              "      <td>0.005623</td>\n",
              "      <td>0.002754</td>\n",
              "      <td>-0.006301</td>\n",
              "      <td>-0.001197</td>\n",
              "      <td>0.009517</td>\n",
              "      <td>-0.001536</td>\n",
              "      <td>-0.001055</td>\n",
              "      <td>-0.004553</td>\n",
              "      <td>-0.000412</td>\n",
              "      <td>-0.003831</td>\n",
              "      <td>-6.370367e-03</td>\n",
              "      <td>-0.005524</td>\n",
              "      <td>0.001855</td>\n",
              "      <td>-0.004397</td>\n",
              "      <td>0.010336</td>\n",
              "      <td>0.000037</td>\n",
              "      <td>-0.006342</td>\n",
              "      <td>0.000833</td>\n",
              "      <td>0.006298</td>\n",
              "      <td>0.002585</td>\n",
              "      <td>-0.001596</td>\n",
              "      <td>0.008557</td>\n",
              "      <td>0.009522</td>\n",
              "      <td>-0.010263</td>\n",
              "      <td>-0.004061</td>\n",
              "      <td>-0.003856</td>\n",
              "      <td>0.002788</td>\n",
              "      <td>...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.003093</td>\n",
              "      <td>-0.002678</td>\n",
              "      <td>-0.003389</td>\n",
              "      <td>-0.002934</td>\n",
              "      <td>-0.001739</td>\n",
              "      <td>-0.003389</td>\n",
              "      <td>-0.003389</td>\n",
              "      <td>-0.001828</td>\n",
              "      <td>-0.004036</td>\n",
              "      <td>-0.001913</td>\n",
              "      <td>-0.002823</td>\n",
              "      <td>-0.002460</td>\n",
              "      <td>-0.000399</td>\n",
              "      <td>-0.001128</td>\n",
              "      <td>-0.001323</td>\n",
              "      <td>-0.001261</td>\n",
              "      <td>-0.003269</td>\n",
              "      <td>-0.002361</td>\n",
              "      <td>-0.001739</td>\n",
              "      <td>-0.002961</td>\n",
              "      <td>-0.003041</td>\n",
              "      <td>-0.002766</td>\n",
              "      <td>-0.001128</td>\n",
              "      <td>-0.008897</td>\n",
              "      <td>-0.001995</td>\n",
              "      <td>-0.001128</td>\n",
              "      <td>-0.001913</td>\n",
              "      <td>-0.004915</td>\n",
              "      <td>-0.002794</td>\n",
              "      <td>-0.002111</td>\n",
              "      <td>-0.003915</td>\n",
              "      <td>-0.001197</td>\n",
              "      <td>-0.003194</td>\n",
              "      <td>-0.002587</td>\n",
              "      <td>-0.001545</td>\n",
              "      <td>-0.001382</td>\n",
              "      <td>-0.185914</td>\n",
              "      <td>-2.822662e-03</td>\n",
              "      <td>-0.001323</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>c_China</th>\n",
              "      <td>0.015862</td>\n",
              "      <td>-0.008856</td>\n",
              "      <td>0.019219</td>\n",
              "      <td>0.005033</td>\n",
              "      <td>-0.004131</td>\n",
              "      <td>0.013832</td>\n",
              "      <td>-0.012459</td>\n",
              "      <td>0.001223</td>\n",
              "      <td>0.009398</td>\n",
              "      <td>-0.008626</td>\n",
              "      <td>-0.006294</td>\n",
              "      <td>-0.000694</td>\n",
              "      <td>-0.006615</td>\n",
              "      <td>-0.004748</td>\n",
              "      <td>0.000766</td>\n",
              "      <td>0.023510</td>\n",
              "      <td>-0.000931</td>\n",
              "      <td>0.009340</td>\n",
              "      <td>-0.015502</td>\n",
              "      <td>-0.000821</td>\n",
              "      <td>-0.016056</td>\n",
              "      <td>-0.000998</td>\n",
              "      <td>-0.008726</td>\n",
              "      <td>-1.001202e-02</td>\n",
              "      <td>0.014685</td>\n",
              "      <td>0.023932</td>\n",
              "      <td>-0.003421</td>\n",
              "      <td>0.020530</td>\n",
              "      <td>-0.007028</td>\n",
              "      <td>-0.007127</td>\n",
              "      <td>0.001547</td>\n",
              "      <td>-0.011148</td>\n",
              "      <td>-0.010078</td>\n",
              "      <td>-0.001241</td>\n",
              "      <td>0.020579</td>\n",
              "      <td>0.030266</td>\n",
              "      <td>-0.020426</td>\n",
              "      <td>0.000532</td>\n",
              "      <td>-0.004003</td>\n",
              "      <td>0.008079</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.003093</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.002083</td>\n",
              "      <td>-0.002636</td>\n",
              "      <td>-0.002282</td>\n",
              "      <td>-0.001353</td>\n",
              "      <td>-0.002636</td>\n",
              "      <td>-0.002636</td>\n",
              "      <td>-0.001422</td>\n",
              "      <td>-0.003139</td>\n",
              "      <td>-0.001488</td>\n",
              "      <td>-0.002196</td>\n",
              "      <td>-0.001914</td>\n",
              "      <td>-0.000310</td>\n",
              "      <td>-0.000878</td>\n",
              "      <td>-0.001029</td>\n",
              "      <td>-0.000981</td>\n",
              "      <td>-0.002543</td>\n",
              "      <td>-0.001837</td>\n",
              "      <td>-0.001353</td>\n",
              "      <td>-0.002303</td>\n",
              "      <td>-0.002365</td>\n",
              "      <td>-0.002151</td>\n",
              "      <td>-0.000878</td>\n",
              "      <td>-0.006921</td>\n",
              "      <td>-0.001552</td>\n",
              "      <td>-0.000878</td>\n",
              "      <td>-0.001488</td>\n",
              "      <td>-0.003824</td>\n",
              "      <td>-0.002174</td>\n",
              "      <td>-0.001642</td>\n",
              "      <td>-0.003045</td>\n",
              "      <td>-0.000931</td>\n",
              "      <td>-0.002485</td>\n",
              "      <td>-0.002012</td>\n",
              "      <td>-0.001202</td>\n",
              "      <td>-0.001075</td>\n",
              "      <td>-0.144620</td>\n",
              "      <td>-2.195721e-03</td>\n",
              "      <td>-0.001029</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>c_Columbia</th>\n",
              "      <td>-0.000435</td>\n",
              "      <td>0.006546</td>\n",
              "      <td>-0.009472</td>\n",
              "      <td>-0.004161</td>\n",
              "      <td>-0.005738</td>\n",
              "      <td>-0.009154</td>\n",
              "      <td>-0.002711</td>\n",
              "      <td>-0.019398</td>\n",
              "      <td>-0.002128</td>\n",
              "      <td>0.003596</td>\n",
              "      <td>-0.011193</td>\n",
              "      <td>-0.000601</td>\n",
              "      <td>0.009651</td>\n",
              "      <td>-0.008001</td>\n",
              "      <td>0.001537</td>\n",
              "      <td>-0.003805</td>\n",
              "      <td>-0.000806</td>\n",
              "      <td>-0.002161</td>\n",
              "      <td>0.004794</td>\n",
              "      <td>-0.000711</td>\n",
              "      <td>0.003940</td>\n",
              "      <td>-0.007321</td>\n",
              "      <td>-0.007555</td>\n",
              "      <td>5.778706e-03</td>\n",
              "      <td>0.016643</td>\n",
              "      <td>0.007480</td>\n",
              "      <td>0.010636</td>\n",
              "      <td>-0.004883</td>\n",
              "      <td>-0.006085</td>\n",
              "      <td>-0.012141</td>\n",
              "      <td>0.004193</td>\n",
              "      <td>-0.005285</td>\n",
              "      <td>-0.003243</td>\n",
              "      <td>-0.001075</td>\n",
              "      <td>-0.012489</td>\n",
              "      <td>0.019983</td>\n",
              "      <td>0.004408</td>\n",
              "      <td>0.013980</td>\n",
              "      <td>0.003365</td>\n",
              "      <td>-0.011767</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.002678</td>\n",
              "      <td>-0.002083</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.002282</td>\n",
              "      <td>-0.001976</td>\n",
              "      <td>-0.001171</td>\n",
              "      <td>-0.002282</td>\n",
              "      <td>-0.002282</td>\n",
              "      <td>-0.001231</td>\n",
              "      <td>-0.002718</td>\n",
              "      <td>-0.001289</td>\n",
              "      <td>-0.001901</td>\n",
              "      <td>-0.001657</td>\n",
              "      <td>-0.000269</td>\n",
              "      <td>-0.000760</td>\n",
              "      <td>-0.000891</td>\n",
              "      <td>-0.000849</td>\n",
              "      <td>-0.002201</td>\n",
              "      <td>-0.001590</td>\n",
              "      <td>-0.001171</td>\n",
              "      <td>-0.001994</td>\n",
              "      <td>-0.002048</td>\n",
              "      <td>-0.001862</td>\n",
              "      <td>-0.000760</td>\n",
              "      <td>-0.005992</td>\n",
              "      <td>-0.001344</td>\n",
              "      <td>-0.000760</td>\n",
              "      <td>-0.001289</td>\n",
              "      <td>-0.003310</td>\n",
              "      <td>-0.001882</td>\n",
              "      <td>-0.001422</td>\n",
              "      <td>-0.002637</td>\n",
              "      <td>-0.000806</td>\n",
              "      <td>-0.002151</td>\n",
              "      <td>-0.001742</td>\n",
              "      <td>-0.001040</td>\n",
              "      <td>-0.000931</td>\n",
              "      <td>-0.125207</td>\n",
              "      <td>-1.900978e-03</td>\n",
              "      <td>-0.000891</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>c_Cuba</th>\n",
              "      <td>0.030883</td>\n",
              "      <td>0.030293</td>\n",
              "      <td>-0.014264</td>\n",
              "      <td>-0.016048</td>\n",
              "      <td>-0.004336</td>\n",
              "      <td>-0.009019</td>\n",
              "      <td>-0.013797</td>\n",
              "      <td>-0.003908</td>\n",
              "      <td>-0.003342</td>\n",
              "      <td>-0.000700</td>\n",
              "      <td>-0.008108</td>\n",
              "      <td>-0.000760</td>\n",
              "      <td>0.006376</td>\n",
              "      <td>0.010387</td>\n",
              "      <td>0.000839</td>\n",
              "      <td>-0.010930</td>\n",
              "      <td>-0.001020</td>\n",
              "      <td>-0.003383</td>\n",
              "      <td>0.003301</td>\n",
              "      <td>-0.000899</td>\n",
              "      <td>-0.009012</td>\n",
              "      <td>0.002538</td>\n",
              "      <td>-0.005233</td>\n",
              "      <td>4.570942e-04</td>\n",
              "      <td>-0.001317</td>\n",
              "      <td>0.008974</td>\n",
              "      <td>0.017763</td>\n",
              "      <td>-0.002595</td>\n",
              "      <td>0.002931</td>\n",
              "      <td>-0.000253</td>\n",
              "      <td>-0.009142</td>\n",
              "      <td>0.005054</td>\n",
              "      <td>0.006737</td>\n",
              "      <td>-0.001360</td>\n",
              "      <td>0.000075</td>\n",
              "      <td>0.013483</td>\n",
              "      <td>-0.013802</td>\n",
              "      <td>0.011704</td>\n",
              "      <td>0.003395</td>\n",
              "      <td>-0.004542</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.003389</td>\n",
              "      <td>-0.002636</td>\n",
              "      <td>-0.002282</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.002500</td>\n",
              "      <td>-0.001482</td>\n",
              "      <td>-0.002888</td>\n",
              "      <td>-0.002888</td>\n",
              "      <td>-0.001558</td>\n",
              "      <td>-0.003440</td>\n",
              "      <td>-0.001631</td>\n",
              "      <td>-0.002406</td>\n",
              "      <td>-0.002097</td>\n",
              "      <td>-0.000340</td>\n",
              "      <td>-0.000962</td>\n",
              "      <td>-0.001128</td>\n",
              "      <td>-0.001075</td>\n",
              "      <td>-0.002786</td>\n",
              "      <td>-0.002012</td>\n",
              "      <td>-0.001482</td>\n",
              "      <td>-0.002524</td>\n",
              "      <td>-0.002592</td>\n",
              "      <td>-0.002357</td>\n",
              "      <td>-0.000962</td>\n",
              "      <td>-0.007583</td>\n",
              "      <td>-0.001700</td>\n",
              "      <td>-0.000962</td>\n",
              "      <td>-0.001631</td>\n",
              "      <td>-0.004189</td>\n",
              "      <td>-0.002382</td>\n",
              "      <td>-0.001800</td>\n",
              "      <td>-0.003337</td>\n",
              "      <td>-0.001020</td>\n",
              "      <td>-0.002723</td>\n",
              "      <td>-0.002205</td>\n",
              "      <td>-0.001317</td>\n",
              "      <td>-0.001178</td>\n",
              "      <td>-0.158462</td>\n",
              "      <td>-2.405871e-03</td>\n",
              "      <td>-0.001128</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>c_Dominican-Republic</th>\n",
              "      <td>-0.003007</td>\n",
              "      <td>0.003193</td>\n",
              "      <td>-0.054384</td>\n",
              "      <td>-0.011148</td>\n",
              "      <td>0.005126</td>\n",
              "      <td>-0.006246</td>\n",
              "      <td>0.006305</td>\n",
              "      <td>-0.022061</td>\n",
              "      <td>-0.000082</td>\n",
              "      <td>-0.008182</td>\n",
              "      <td>-0.008767</td>\n",
              "      <td>-0.000658</td>\n",
              "      <td>0.017688</td>\n",
              "      <td>-0.004030</td>\n",
              "      <td>-0.007254</td>\n",
              "      <td>-0.009462</td>\n",
              "      <td>-0.000883</td>\n",
              "      <td>-0.000122</td>\n",
              "      <td>-0.009117</td>\n",
              "      <td>-0.000779</td>\n",
              "      <td>-0.004544</td>\n",
              "      <td>-0.012213</td>\n",
              "      <td>-0.008277</td>\n",
              "      <td>1.248692e-02</td>\n",
              "      <td>0.052679</td>\n",
              "      <td>-0.001476</td>\n",
              "      <td>0.009170</td>\n",
              "      <td>-0.012590</td>\n",
              "      <td>-0.000531</td>\n",
              "      <td>-0.000219</td>\n",
              "      <td>-0.007914</td>\n",
              "      <td>0.001385</td>\n",
              "      <td>-0.011061</td>\n",
              "      <td>-0.001177</td>\n",
              "      <td>-0.013338</td>\n",
              "      <td>0.055210</td>\n",
              "      <td>0.011432</td>\n",
              "      <td>-0.003445</td>\n",
              "      <td>-0.003299</td>\n",
              "      <td>-0.017109</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.002934</td>\n",
              "      <td>-0.002282</td>\n",
              "      <td>-0.001976</td>\n",
              "      <td>-0.002500</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.001283</td>\n",
              "      <td>-0.002500</td>\n",
              "      <td>-0.002500</td>\n",
              "      <td>-0.001349</td>\n",
              "      <td>-0.002978</td>\n",
              "      <td>-0.001412</td>\n",
              "      <td>-0.002083</td>\n",
              "      <td>-0.001815</td>\n",
              "      <td>-0.000294</td>\n",
              "      <td>-0.000832</td>\n",
              "      <td>-0.000976</td>\n",
              "      <td>-0.000931</td>\n",
              "      <td>-0.002412</td>\n",
              "      <td>-0.001742</td>\n",
              "      <td>-0.001283</td>\n",
              "      <td>-0.002185</td>\n",
              "      <td>-0.002244</td>\n",
              "      <td>-0.002041</td>\n",
              "      <td>-0.000832</td>\n",
              "      <td>-0.006565</td>\n",
              "      <td>-0.001472</td>\n",
              "      <td>-0.000832</td>\n",
              "      <td>-0.001412</td>\n",
              "      <td>-0.003627</td>\n",
              "      <td>-0.002062</td>\n",
              "      <td>-0.001558</td>\n",
              "      <td>-0.002889</td>\n",
              "      <td>-0.000883</td>\n",
              "      <td>-0.002357</td>\n",
              "      <td>-0.001909</td>\n",
              "      <td>-0.001140</td>\n",
              "      <td>-0.001020</td>\n",
              "      <td>-0.137182</td>\n",
              "      <td>-2.082793e-03</td>\n",
              "      <td>-0.000976</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>c_Ecuador</th>\n",
              "      <td>0.003761</td>\n",
              "      <td>0.002033</td>\n",
              "      <td>-0.012232</td>\n",
              "      <td>0.000928</td>\n",
              "      <td>-0.001146</td>\n",
              "      <td>-0.005945</td>\n",
              "      <td>-0.005988</td>\n",
              "      <td>-0.008667</td>\n",
              "      <td>-0.000399</td>\n",
              "      <td>-0.004850</td>\n",
              "      <td>-0.007269</td>\n",
              "      <td>-0.000390</td>\n",
              "      <td>0.015099</td>\n",
              "      <td>-0.005196</td>\n",
              "      <td>-0.008084</td>\n",
              "      <td>-0.005609</td>\n",
              "      <td>-0.000523</td>\n",
              "      <td>-0.000423</td>\n",
              "      <td>-0.010136</td>\n",
              "      <td>-0.000462</td>\n",
              "      <td>0.007145</td>\n",
              "      <td>-0.005932</td>\n",
              "      <td>-0.004906</td>\n",
              "      <td>-5.629454e-03</td>\n",
              "      <td>0.023166</td>\n",
              "      <td>-0.004513</td>\n",
              "      <td>0.018991</td>\n",
              "      <td>-0.006172</td>\n",
              "      <td>-0.003952</td>\n",
              "      <td>0.003952</td>\n",
              "      <td>0.004089</td>\n",
              "      <td>0.000448</td>\n",
              "      <td>-0.002574</td>\n",
              "      <td>-0.000698</td>\n",
              "      <td>0.003802</td>\n",
              "      <td>0.009576</td>\n",
              "      <td>-0.003865</td>\n",
              "      <td>-0.004969</td>\n",
              "      <td>0.003493</td>\n",
              "      <td>0.004000</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.001739</td>\n",
              "      <td>-0.001353</td>\n",
              "      <td>-0.001171</td>\n",
              "      <td>-0.001482</td>\n",
              "      <td>-0.001283</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.001482</td>\n",
              "      <td>-0.001482</td>\n",
              "      <td>-0.000800</td>\n",
              "      <td>-0.001765</td>\n",
              "      <td>-0.000837</td>\n",
              "      <td>-0.001235</td>\n",
              "      <td>-0.001076</td>\n",
              "      <td>-0.000174</td>\n",
              "      <td>-0.000493</td>\n",
              "      <td>-0.000579</td>\n",
              "      <td>-0.000552</td>\n",
              "      <td>-0.001430</td>\n",
              "      <td>-0.001033</td>\n",
              "      <td>-0.000761</td>\n",
              "      <td>-0.001295</td>\n",
              "      <td>-0.001330</td>\n",
              "      <td>-0.001210</td>\n",
              "      <td>-0.000493</td>\n",
              "      <td>-0.003891</td>\n",
              "      <td>-0.000873</td>\n",
              "      <td>-0.000493</td>\n",
              "      <td>-0.000837</td>\n",
              "      <td>-0.002150</td>\n",
              "      <td>-0.001222</td>\n",
              "      <td>-0.000923</td>\n",
              "      <td>-0.001712</td>\n",
              "      <td>-0.000523</td>\n",
              "      <td>-0.001397</td>\n",
              "      <td>-0.001131</td>\n",
              "      <td>-0.000676</td>\n",
              "      <td>-0.000604</td>\n",
              "      <td>-0.081316</td>\n",
              "      <td>-1.234587e-03</td>\n",
              "      <td>-0.000579</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>c_El-Salvador</th>\n",
              "      <td>-0.018907</td>\n",
              "      <td>0.034100</td>\n",
              "      <td>-0.059220</td>\n",
              "      <td>0.002978</td>\n",
              "      <td>-0.003259</td>\n",
              "      <td>-0.008648</td>\n",
              "      <td>-0.015254</td>\n",
              "      <td>-0.017903</td>\n",
              "      <td>-0.003342</td>\n",
              "      <td>-0.000700</td>\n",
              "      <td>-0.005079</td>\n",
              "      <td>-0.000760</td>\n",
              "      <td>0.016107</td>\n",
              "      <td>-0.006023</td>\n",
              "      <td>-0.007457</td>\n",
              "      <td>-0.010930</td>\n",
              "      <td>-0.001020</td>\n",
              "      <td>-0.003383</td>\n",
              "      <td>-0.010531</td>\n",
              "      <td>-0.000899</td>\n",
              "      <td>-0.002238</td>\n",
              "      <td>-0.015621</td>\n",
              "      <td>-0.009561</td>\n",
              "      <td>8.075330e-03</td>\n",
              "      <td>0.001791</td>\n",
              "      <td>0.045937</td>\n",
              "      <td>0.028518</td>\n",
              "      <td>-0.007075</td>\n",
              "      <td>-0.007701</td>\n",
              "      <td>-0.004976</td>\n",
              "      <td>-0.009142</td>\n",
              "      <td>0.001600</td>\n",
              "      <td>-0.012777</td>\n",
              "      <td>-0.001360</td>\n",
              "      <td>-0.013409</td>\n",
              "      <td>0.020043</td>\n",
              "      <td>0.016382</td>\n",
              "      <td>-0.001128</td>\n",
              "      <td>0.007718</td>\n",
              "      <td>-0.016719</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.003389</td>\n",
              "      <td>-0.002636</td>\n",
              "      <td>-0.002282</td>\n",
              "      <td>-0.002888</td>\n",
              "      <td>-0.002500</td>\n",
              "      <td>-0.001482</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.002888</td>\n",
              "      <td>-0.001558</td>\n",
              "      <td>-0.003440</td>\n",
              "      <td>-0.001631</td>\n",
              "      <td>-0.002406</td>\n",
              "      <td>-0.002097</td>\n",
              "      <td>-0.000340</td>\n",
              "      <td>-0.000962</td>\n",
              "      <td>-0.001128</td>\n",
              "      <td>-0.001075</td>\n",
              "      <td>-0.002786</td>\n",
              "      <td>-0.002012</td>\n",
              "      <td>-0.001482</td>\n",
              "      <td>-0.002524</td>\n",
              "      <td>-0.002592</td>\n",
              "      <td>-0.002357</td>\n",
              "      <td>-0.000962</td>\n",
              "      <td>-0.007583</td>\n",
              "      <td>-0.001700</td>\n",
              "      <td>-0.000962</td>\n",
              "      <td>-0.001631</td>\n",
              "      <td>-0.004189</td>\n",
              "      <td>-0.002382</td>\n",
              "      <td>-0.001800</td>\n",
              "      <td>-0.003337</td>\n",
              "      <td>-0.001020</td>\n",
              "      <td>-0.002723</td>\n",
              "      <td>-0.002205</td>\n",
              "      <td>-0.001317</td>\n",
              "      <td>-0.001178</td>\n",
              "      <td>-0.158462</td>\n",
              "      <td>-2.405871e-03</td>\n",
              "      <td>-0.001128</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>c_England</th>\n",
              "      <td>0.012232</td>\n",
              "      <td>-0.000818</td>\n",
              "      <td>0.021058</td>\n",
              "      <td>-0.003364</td>\n",
              "      <td>-0.002430</td>\n",
              "      <td>0.002270</td>\n",
              "      <td>0.003318</td>\n",
              "      <td>0.015335</td>\n",
              "      <td>-0.003342</td>\n",
              "      <td>0.003676</td>\n",
              "      <td>-0.002051</td>\n",
              "      <td>-0.000760</td>\n",
              "      <td>0.004754</td>\n",
              "      <td>-0.001921</td>\n",
              "      <td>-0.004692</td>\n",
              "      <td>0.000536</td>\n",
              "      <td>-0.001020</td>\n",
              "      <td>-0.003383</td>\n",
              "      <td>-0.008225</td>\n",
              "      <td>-0.000899</td>\n",
              "      <td>-0.011270</td>\n",
              "      <td>0.020696</td>\n",
              "      <td>-0.005233</td>\n",
              "      <td>-3.352024e-03</td>\n",
              "      <td>-0.004425</td>\n",
              "      <td>-0.003347</td>\n",
              "      <td>0.028518</td>\n",
              "      <td>0.017567</td>\n",
              "      <td>0.002931</td>\n",
              "      <td>-0.007337</td>\n",
              "      <td>0.004404</td>\n",
              "      <td>-0.012215</td>\n",
              "      <td>0.011073</td>\n",
              "      <td>-0.001360</td>\n",
              "      <td>-0.002922</td>\n",
              "      <td>-0.006197</td>\n",
              "      <td>-0.002682</td>\n",
              "      <td>-0.001128</td>\n",
              "      <td>-0.000928</td>\n",
              "      <td>-0.004542</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.003389</td>\n",
              "      <td>-0.002636</td>\n",
              "      <td>-0.002282</td>\n",
              "      <td>-0.002888</td>\n",
              "      <td>-0.002500</td>\n",
              "      <td>-0.001482</td>\n",
              "      <td>-0.002888</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.001558</td>\n",
              "      <td>-0.003440</td>\n",
              "      <td>-0.001631</td>\n",
              "      <td>-0.002406</td>\n",
              "      <td>-0.002097</td>\n",
              "      <td>-0.000340</td>\n",
              "      <td>-0.000962</td>\n",
              "      <td>-0.001128</td>\n",
              "      <td>-0.001075</td>\n",
              "      <td>-0.002786</td>\n",
              "      <td>-0.002012</td>\n",
              "      <td>-0.001482</td>\n",
              "      <td>-0.002524</td>\n",
              "      <td>-0.002592</td>\n",
              "      <td>-0.002357</td>\n",
              "      <td>-0.000962</td>\n",
              "      <td>-0.007583</td>\n",
              "      <td>-0.001700</td>\n",
              "      <td>-0.000962</td>\n",
              "      <td>-0.001631</td>\n",
              "      <td>-0.004189</td>\n",
              "      <td>-0.002382</td>\n",
              "      <td>-0.001800</td>\n",
              "      <td>-0.003337</td>\n",
              "      <td>-0.001020</td>\n",
              "      <td>-0.002723</td>\n",
              "      <td>-0.002205</td>\n",
              "      <td>-0.001317</td>\n",
              "      <td>-0.001178</td>\n",
              "      <td>-0.158462</td>\n",
              "      <td>-2.405871e-03</td>\n",
              "      <td>-0.001128</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>c_France</th>\n",
              "      <td>-0.002093</td>\n",
              "      <td>0.002485</td>\n",
              "      <td>0.028235</td>\n",
              "      <td>-0.003037</td>\n",
              "      <td>-0.002879</td>\n",
              "      <td>-0.006251</td>\n",
              "      <td>0.015991</td>\n",
              "      <td>0.012857</td>\n",
              "      <td>-0.001052</td>\n",
              "      <td>-0.005099</td>\n",
              "      <td>0.009164</td>\n",
              "      <td>-0.000410</td>\n",
              "      <td>-0.004810</td>\n",
              "      <td>0.002126</td>\n",
              "      <td>0.001731</td>\n",
              "      <td>0.001173</td>\n",
              "      <td>-0.000550</td>\n",
              "      <td>-0.001076</td>\n",
              "      <td>-0.010656</td>\n",
              "      <td>-0.000485</td>\n",
              "      <td>-0.010953</td>\n",
              "      <td>0.018513</td>\n",
              "      <td>-0.005158</td>\n",
              "      <td>-5.918566e-03</td>\n",
              "      <td>-0.007419</td>\n",
              "      <td>-0.000666</td>\n",
              "      <td>0.037767</td>\n",
              "      <td>0.017938</td>\n",
              "      <td>0.005679</td>\n",
              "      <td>-0.005960</td>\n",
              "      <td>-0.004932</td>\n",
              "      <td>-0.006590</td>\n",
              "      <td>0.012491</td>\n",
              "      <td>-0.000734</td>\n",
              "      <td>-0.001692</td>\n",
              "      <td>0.008791</td>\n",
              "      <td>-0.005610</td>\n",
              "      <td>-0.005224</td>\n",
              "      <td>-0.005165</td>\n",
              "      <td>-0.001278</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.001828</td>\n",
              "      <td>-0.001422</td>\n",
              "      <td>-0.001231</td>\n",
              "      <td>-0.001558</td>\n",
              "      <td>-0.001349</td>\n",
              "      <td>-0.000800</td>\n",
              "      <td>-0.001558</td>\n",
              "      <td>-0.001558</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.001856</td>\n",
              "      <td>-0.000880</td>\n",
              "      <td>-0.001298</td>\n",
              "      <td>-0.001131</td>\n",
              "      <td>-0.000183</td>\n",
              "      <td>-0.000519</td>\n",
              "      <td>-0.000608</td>\n",
              "      <td>-0.000580</td>\n",
              "      <td>-0.001503</td>\n",
              "      <td>-0.001086</td>\n",
              "      <td>-0.000800</td>\n",
              "      <td>-0.001361</td>\n",
              "      <td>-0.001398</td>\n",
              "      <td>-0.001272</td>\n",
              "      <td>-0.000519</td>\n",
              "      <td>-0.004091</td>\n",
              "      <td>-0.000917</td>\n",
              "      <td>-0.000519</td>\n",
              "      <td>-0.000880</td>\n",
              "      <td>-0.002260</td>\n",
              "      <td>-0.001285</td>\n",
              "      <td>-0.000971</td>\n",
              "      <td>-0.001800</td>\n",
              "      <td>-0.000550</td>\n",
              "      <td>-0.001469</td>\n",
              "      <td>-0.001189</td>\n",
              "      <td>-0.000710</td>\n",
              "      <td>-0.000635</td>\n",
              "      <td>-0.085492</td>\n",
              "      <td>-1.297992e-03</td>\n",
              "      <td>-0.000608</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>c_Germany</th>\n",
              "      <td>-0.000408</td>\n",
              "      <td>-0.005904</td>\n",
              "      <td>0.017840</td>\n",
              "      <td>-0.017557</td>\n",
              "      <td>-0.004398</td>\n",
              "      <td>-0.003073</td>\n",
              "      <td>0.000278</td>\n",
              "      <td>0.011155</td>\n",
              "      <td>0.003528</td>\n",
              "      <td>0.003458</td>\n",
              "      <td>-0.001594</td>\n",
              "      <td>-0.000905</td>\n",
              "      <td>0.002821</td>\n",
              "      <td>0.001736</td>\n",
              "      <td>-0.009462</td>\n",
              "      <td>-0.000165</td>\n",
              "      <td>-0.001215</td>\n",
              "      <td>0.003466</td>\n",
              "      <td>0.007485</td>\n",
              "      <td>-0.001071</td>\n",
              "      <td>-0.003299</td>\n",
              "      <td>0.006521</td>\n",
              "      <td>-0.007748</td>\n",
              "      <td>-3.458405e-03</td>\n",
              "      <td>-0.008537</td>\n",
              "      <td>-0.011237</td>\n",
              "      <td>0.004578</td>\n",
              "      <td>0.013231</td>\n",
              "      <td>0.008705</td>\n",
              "      <td>-0.000963</td>\n",
              "      <td>-0.003296</td>\n",
              "      <td>-0.008740</td>\n",
              "      <td>0.010909</td>\n",
              "      <td>-0.001620</td>\n",
              "      <td>-0.000856</td>\n",
              "      <td>0.003649</td>\n",
              "      <td>-0.010094</td>\n",
              "      <td>0.002852</td>\n",
              "      <td>0.003134</td>\n",
              "      <td>-0.002637</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.004036</td>\n",
              "      <td>-0.003139</td>\n",
              "      <td>-0.002718</td>\n",
              "      <td>-0.003440</td>\n",
              "      <td>-0.002978</td>\n",
              "      <td>-0.001765</td>\n",
              "      <td>-0.003440</td>\n",
              "      <td>-0.003440</td>\n",
              "      <td>-0.001856</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.001942</td>\n",
              "      <td>-0.002865</td>\n",
              "      <td>-0.002497</td>\n",
              "      <td>-0.000405</td>\n",
              "      <td>-0.001145</td>\n",
              "      <td>-0.001343</td>\n",
              "      <td>-0.001280</td>\n",
              "      <td>-0.003318</td>\n",
              "      <td>-0.002397</td>\n",
              "      <td>-0.001765</td>\n",
              "      <td>-0.003005</td>\n",
              "      <td>-0.003086</td>\n",
              "      <td>-0.002807</td>\n",
              "      <td>-0.001145</td>\n",
              "      <td>-0.009031</td>\n",
              "      <td>-0.002025</td>\n",
              "      <td>-0.001145</td>\n",
              "      <td>-0.001942</td>\n",
              "      <td>-0.004989</td>\n",
              "      <td>-0.002836</td>\n",
              "      <td>-0.002143</td>\n",
              "      <td>-0.003974</td>\n",
              "      <td>-0.001215</td>\n",
              "      <td>-0.003243</td>\n",
              "      <td>-0.002626</td>\n",
              "      <td>-0.001568</td>\n",
              "      <td>-0.001403</td>\n",
              "      <td>-0.188721</td>\n",
              "      <td>-2.865283e-03</td>\n",
              "      <td>-0.001343</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>c_Greece</th>\n",
              "      <td>0.019861</td>\n",
              "      <td>-0.013729</td>\n",
              "      <td>-0.000967</td>\n",
              "      <td>0.012969</td>\n",
              "      <td>0.002149</td>\n",
              "      <td>0.013072</td>\n",
              "      <td>0.017124</td>\n",
              "      <td>0.004622</td>\n",
              "      <td>-0.007388</td>\n",
              "      <td>-0.005337</td>\n",
              "      <td>-0.002645</td>\n",
              "      <td>-0.000429</td>\n",
              "      <td>-0.008584</td>\n",
              "      <td>0.008785</td>\n",
              "      <td>0.025320</td>\n",
              "      <td>-0.006172</td>\n",
              "      <td>-0.000576</td>\n",
              "      <td>-0.007402</td>\n",
              "      <td>-0.007078</td>\n",
              "      <td>-0.000508</td>\n",
              "      <td>0.004501</td>\n",
              "      <td>0.024725</td>\n",
              "      <td>-0.005399</td>\n",
              "      <td>5.386297e-04</td>\n",
              "      <td>-0.007764</td>\n",
              "      <td>0.002829</td>\n",
              "      <td>-0.002116</td>\n",
              "      <td>-0.003665</td>\n",
              "      <td>-0.004348</td>\n",
              "      <td>0.001712</td>\n",
              "      <td>-0.005162</td>\n",
              "      <td>-0.006897</td>\n",
              "      <td>-0.008279</td>\n",
              "      <td>-0.000768</td>\n",
              "      <td>0.017146</td>\n",
              "      <td>-0.003499</td>\n",
              "      <td>-0.010016</td>\n",
              "      <td>-0.005467</td>\n",
              "      <td>0.002235</td>\n",
              "      <td>0.015445</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.001913</td>\n",
              "      <td>-0.001488</td>\n",
              "      <td>-0.001289</td>\n",
              "      <td>-0.001631</td>\n",
              "      <td>-0.001412</td>\n",
              "      <td>-0.000837</td>\n",
              "      <td>-0.001631</td>\n",
              "      <td>-0.001631</td>\n",
              "      <td>-0.000880</td>\n",
              "      <td>-0.001942</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.001358</td>\n",
              "      <td>-0.001184</td>\n",
              "      <td>-0.000192</td>\n",
              "      <td>-0.000543</td>\n",
              "      <td>-0.000637</td>\n",
              "      <td>-0.000607</td>\n",
              "      <td>-0.001573</td>\n",
              "      <td>-0.001136</td>\n",
              "      <td>-0.000837</td>\n",
              "      <td>-0.001425</td>\n",
              "      <td>-0.001463</td>\n",
              "      <td>-0.001331</td>\n",
              "      <td>-0.000543</td>\n",
              "      <td>-0.004282</td>\n",
              "      <td>-0.000960</td>\n",
              "      <td>-0.000543</td>\n",
              "      <td>-0.000921</td>\n",
              "      <td>-0.002366</td>\n",
              "      <td>-0.001345</td>\n",
              "      <td>-0.001016</td>\n",
              "      <td>-0.001884</td>\n",
              "      <td>-0.000576</td>\n",
              "      <td>-0.001537</td>\n",
              "      <td>-0.001245</td>\n",
              "      <td>-0.000744</td>\n",
              "      <td>-0.000665</td>\n",
              "      <td>-0.089474</td>\n",
              "      <td>-1.358450e-03</td>\n",
              "      <td>-0.000637</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>c_Guatemala</th>\n",
              "      <td>-0.021609</td>\n",
              "      <td>0.035315</td>\n",
              "      <td>-0.074257</td>\n",
              "      <td>-0.000795</td>\n",
              "      <td>-0.005590</td>\n",
              "      <td>-0.006094</td>\n",
              "      <td>-0.003958</td>\n",
              "      <td>-0.023014</td>\n",
              "      <td>-0.007004</td>\n",
              "      <td>-0.002624</td>\n",
              "      <td>-0.004534</td>\n",
              "      <td>-0.000633</td>\n",
              "      <td>0.021846</td>\n",
              "      <td>-0.008434</td>\n",
              "      <td>-0.013122</td>\n",
              "      <td>-0.009104</td>\n",
              "      <td>-0.000850</td>\n",
              "      <td>-0.007031</td>\n",
              "      <td>-0.010922</td>\n",
              "      <td>-0.000749</td>\n",
              "      <td>0.007464</td>\n",
              "      <td>-0.016793</td>\n",
              "      <td>0.012803</td>\n",
              "      <td>1.827570e-02</td>\n",
              "      <td>0.018374</td>\n",
              "      <td>0.002631</td>\n",
              "      <td>0.112984</td>\n",
              "      <td>-0.017090</td>\n",
              "      <td>-0.006415</td>\n",
              "      <td>-0.007449</td>\n",
              "      <td>-0.002199</td>\n",
              "      <td>-0.006032</td>\n",
              "      <td>-0.010065</td>\n",
              "      <td>-0.001133</td>\n",
              "      <td>-0.021353</td>\n",
              "      <td>0.049916</td>\n",
              "      <td>0.012481</td>\n",
              "      <td>0.017588</td>\n",
              "      <td>-0.002790</td>\n",
              "      <td>-0.018490</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.002823</td>\n",
              "      <td>-0.002196</td>\n",
              "      <td>-0.001901</td>\n",
              "      <td>-0.002406</td>\n",
              "      <td>-0.002083</td>\n",
              "      <td>-0.001235</td>\n",
              "      <td>-0.002406</td>\n",
              "      <td>-0.002406</td>\n",
              "      <td>-0.001298</td>\n",
              "      <td>-0.002865</td>\n",
              "      <td>-0.001358</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.001747</td>\n",
              "      <td>-0.000283</td>\n",
              "      <td>-0.000801</td>\n",
              "      <td>-0.000939</td>\n",
              "      <td>-0.000896</td>\n",
              "      <td>-0.002321</td>\n",
              "      <td>-0.001676</td>\n",
              "      <td>-0.001235</td>\n",
              "      <td>-0.002102</td>\n",
              "      <td>-0.002159</td>\n",
              "      <td>-0.001963</td>\n",
              "      <td>-0.000801</td>\n",
              "      <td>-0.006316</td>\n",
              "      <td>-0.001416</td>\n",
              "      <td>-0.000801</td>\n",
              "      <td>-0.001358</td>\n",
              "      <td>-0.003490</td>\n",
              "      <td>-0.001984</td>\n",
              "      <td>-0.001499</td>\n",
              "      <td>-0.002779</td>\n",
              "      <td>-0.000850</td>\n",
              "      <td>-0.002268</td>\n",
              "      <td>-0.001836</td>\n",
              "      <td>-0.001097</td>\n",
              "      <td>-0.000981</td>\n",
              "      <td>-0.131993</td>\n",
              "      <td>-2.004008e-03</td>\n",
              "      <td>-0.000939</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>c_Haiti</th>\n",
              "      <td>-0.000155</td>\n",
              "      <td>0.008835</td>\n",
              "      <td>-0.020116</td>\n",
              "      <td>-0.007410</td>\n",
              "      <td>-0.005673</td>\n",
              "      <td>-0.003959</td>\n",
              "      <td>-0.011978</td>\n",
              "      <td>-0.014668</td>\n",
              "      <td>-0.005032</td>\n",
              "      <td>-0.006862</td>\n",
              "      <td>0.006380</td>\n",
              "      <td>-0.000552</td>\n",
              "      <td>0.007975</td>\n",
              "      <td>-0.001708</td>\n",
              "      <td>-0.011437</td>\n",
              "      <td>0.002579</td>\n",
              "      <td>-0.000740</td>\n",
              "      <td>-0.005058</td>\n",
              "      <td>0.001516</td>\n",
              "      <td>-0.000653</td>\n",
              "      <td>-0.005421</td>\n",
              "      <td>-0.014636</td>\n",
              "      <td>-0.006941</td>\n",
              "      <td>7.754693e-03</td>\n",
              "      <td>0.007120</td>\n",
              "      <td>0.030901</td>\n",
              "      <td>0.012073</td>\n",
              "      <td>-0.005650</td>\n",
              "      <td>0.001722</td>\n",
              "      <td>-0.010650</td>\n",
              "      <td>-0.006637</td>\n",
              "      <td>0.005385</td>\n",
              "      <td>-0.003642</td>\n",
              "      <td>-0.000987</td>\n",
              "      <td>-0.009048</td>\n",
              "      <td>0.031595</td>\n",
              "      <td>0.003274</td>\n",
              "      <td>0.004738</td>\n",
              "      <td>-0.001004</td>\n",
              "      <td>-0.015278</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.002460</td>\n",
              "      <td>-0.001914</td>\n",
              "      <td>-0.001657</td>\n",
              "      <td>-0.002097</td>\n",
              "      <td>-0.001815</td>\n",
              "      <td>-0.001076</td>\n",
              "      <td>-0.002097</td>\n",
              "      <td>-0.002097</td>\n",
              "      <td>-0.001131</td>\n",
              "      <td>-0.002497</td>\n",
              "      <td>-0.001184</td>\n",
              "      <td>-0.001747</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.000247</td>\n",
              "      <td>-0.000698</td>\n",
              "      <td>-0.000819</td>\n",
              "      <td>-0.000780</td>\n",
              "      <td>-0.002023</td>\n",
              "      <td>-0.001461</td>\n",
              "      <td>-0.001076</td>\n",
              "      <td>-0.001832</td>\n",
              "      <td>-0.001881</td>\n",
              "      <td>-0.001711</td>\n",
              "      <td>-0.000698</td>\n",
              "      <td>-0.005505</td>\n",
              "      <td>-0.001234</td>\n",
              "      <td>-0.000698</td>\n",
              "      <td>-0.001184</td>\n",
              "      <td>-0.003041</td>\n",
              "      <td>-0.001729</td>\n",
              "      <td>-0.001306</td>\n",
              "      <td>-0.002422</td>\n",
              "      <td>-0.000740</td>\n",
              "      <td>-0.001977</td>\n",
              "      <td>-0.001601</td>\n",
              "      <td>-0.000956</td>\n",
              "      <td>-0.000855</td>\n",
              "      <td>-0.115041</td>\n",
              "      <td>-1.746634e-03</td>\n",
              "      <td>-0.000819</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>c_Holand-Netherlands</th>\n",
              "      <td>-0.003053</td>\n",
              "      <td>-0.009723</td>\n",
              "      <td>-0.000201</td>\n",
              "      <td>-0.008979</td>\n",
              "      <td>-0.000920</td>\n",
              "      <td>0.033393</td>\n",
              "      <td>-0.000210</td>\n",
              "      <td>-0.003548</td>\n",
              "      <td>-0.001540</td>\n",
              "      <td>-0.001112</td>\n",
              "      <td>-0.001667</td>\n",
              "      <td>-0.000089</td>\n",
              "      <td>0.004186</td>\n",
              "      <td>-0.001192</td>\n",
              "      <td>-0.001854</td>\n",
              "      <td>-0.001286</td>\n",
              "      <td>-0.000120</td>\n",
              "      <td>-0.001543</td>\n",
              "      <td>-0.002324</td>\n",
              "      <td>-0.000106</td>\n",
              "      <td>-0.002389</td>\n",
              "      <td>-0.002373</td>\n",
              "      <td>-0.001125</td>\n",
              "      <td>-1.291020e-03</td>\n",
              "      <td>0.024720</td>\n",
              "      <td>-0.002134</td>\n",
              "      <td>-0.000441</td>\n",
              "      <td>-0.002414</td>\n",
              "      <td>-0.000906</td>\n",
              "      <td>-0.002253</td>\n",
              "      <td>-0.001076</td>\n",
              "      <td>-0.001437</td>\n",
              "      <td>-0.002524</td>\n",
              "      <td>-0.000160</td>\n",
              "      <td>-0.005810</td>\n",
              "      <td>-0.000729</td>\n",
              "      <td>0.009032</td>\n",
              "      <td>-0.001140</td>\n",
              "      <td>-0.001127</td>\n",
              "      <td>-0.005192</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.000399</td>\n",
              "      <td>-0.000310</td>\n",
              "      <td>-0.000269</td>\n",
              "      <td>-0.000340</td>\n",
              "      <td>-0.000294</td>\n",
              "      <td>-0.000174</td>\n",
              "      <td>-0.000340</td>\n",
              "      <td>-0.000340</td>\n",
              "      <td>-0.000183</td>\n",
              "      <td>-0.000405</td>\n",
              "      <td>-0.000192</td>\n",
              "      <td>-0.000283</td>\n",
              "      <td>-0.000247</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.000113</td>\n",
              "      <td>-0.000133</td>\n",
              "      <td>-0.000127</td>\n",
              "      <td>-0.000328</td>\n",
              "      <td>-0.000237</td>\n",
              "      <td>-0.000174</td>\n",
              "      <td>-0.000297</td>\n",
              "      <td>-0.000305</td>\n",
              "      <td>-0.000277</td>\n",
              "      <td>-0.000113</td>\n",
              "      <td>-0.000892</td>\n",
              "      <td>-0.000200</td>\n",
              "      <td>-0.000113</td>\n",
              "      <td>-0.000192</td>\n",
              "      <td>-0.000493</td>\n",
              "      <td>-0.000280</td>\n",
              "      <td>-0.000212</td>\n",
              "      <td>-0.000393</td>\n",
              "      <td>-0.000120</td>\n",
              "      <td>-0.000320</td>\n",
              "      <td>-0.000259</td>\n",
              "      <td>-0.000155</td>\n",
              "      <td>-0.000139</td>\n",
              "      <td>-0.018648</td>\n",
              "      <td>-2.831316e-04</td>\n",
              "      <td>-0.000133</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>c_Honduras</th>\n",
              "      <td>-0.002917</td>\n",
              "      <td>0.009367</td>\n",
              "      <td>-0.010191</td>\n",
              "      <td>-0.011148</td>\n",
              "      <td>-0.002602</td>\n",
              "      <td>0.006744</td>\n",
              "      <td>-0.008412</td>\n",
              "      <td>-0.004795</td>\n",
              "      <td>0.005374</td>\n",
              "      <td>-0.003146</td>\n",
              "      <td>0.004359</td>\n",
              "      <td>-0.000253</td>\n",
              "      <td>-0.007596</td>\n",
              "      <td>0.008921</td>\n",
              "      <td>-0.005244</td>\n",
              "      <td>0.007812</td>\n",
              "      <td>-0.000340</td>\n",
              "      <td>0.005350</td>\n",
              "      <td>0.007239</td>\n",
              "      <td>-0.000299</td>\n",
              "      <td>-0.006759</td>\n",
              "      <td>-0.006712</td>\n",
              "      <td>-0.003183</td>\n",
              "      <td>1.917336e-02</td>\n",
              "      <td>-0.004578</td>\n",
              "      <td>0.001347</td>\n",
              "      <td>-0.001248</td>\n",
              "      <td>-0.000118</td>\n",
              "      <td>-0.002564</td>\n",
              "      <td>0.000702</td>\n",
              "      <td>-0.003043</td>\n",
              "      <td>-0.004066</td>\n",
              "      <td>0.005852</td>\n",
              "      <td>-0.000453</td>\n",
              "      <td>-0.007457</td>\n",
              "      <td>0.017591</td>\n",
              "      <td>-0.007768</td>\n",
              "      <td>0.022408</td>\n",
              "      <td>-0.003187</td>\n",
              "      <td>-0.014686</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.001128</td>\n",
              "      <td>-0.000878</td>\n",
              "      <td>-0.000760</td>\n",
              "      <td>-0.000962</td>\n",
              "      <td>-0.000832</td>\n",
              "      <td>-0.000493</td>\n",
              "      <td>-0.000962</td>\n",
              "      <td>-0.000962</td>\n",
              "      <td>-0.000519</td>\n",
              "      <td>-0.001145</td>\n",
              "      <td>-0.000543</td>\n",
              "      <td>-0.000801</td>\n",
              "      <td>-0.000698</td>\n",
              "      <td>-0.000113</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.000375</td>\n",
              "      <td>-0.000358</td>\n",
              "      <td>-0.000927</td>\n",
              "      <td>-0.000670</td>\n",
              "      <td>-0.000493</td>\n",
              "      <td>-0.000840</td>\n",
              "      <td>-0.000863</td>\n",
              "      <td>-0.000785</td>\n",
              "      <td>-0.000320</td>\n",
              "      <td>-0.002524</td>\n",
              "      <td>-0.000566</td>\n",
              "      <td>-0.000320</td>\n",
              "      <td>-0.000543</td>\n",
              "      <td>-0.001395</td>\n",
              "      <td>-0.000793</td>\n",
              "      <td>-0.000599</td>\n",
              "      <td>-0.001111</td>\n",
              "      <td>-0.000340</td>\n",
              "      <td>-0.000906</td>\n",
              "      <td>-0.000734</td>\n",
              "      <td>-0.000438</td>\n",
              "      <td>-0.000392</td>\n",
              "      <td>-0.052753</td>\n",
              "      <td>-8.009294e-04</td>\n",
              "      <td>-0.000375</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>c_Hong</th>\n",
              "      <td>-0.003160</td>\n",
              "      <td>0.006459</td>\n",
              "      <td>0.000824</td>\n",
              "      <td>-0.001426</td>\n",
              "      <td>-0.003051</td>\n",
              "      <td>-0.004523</td>\n",
              "      <td>0.001166</td>\n",
              "      <td>0.006111</td>\n",
              "      <td>0.003190</td>\n",
              "      <td>-0.003690</td>\n",
              "      <td>0.002209</td>\n",
              "      <td>-0.000297</td>\n",
              "      <td>0.001453</td>\n",
              "      <td>-0.003953</td>\n",
              "      <td>-0.006150</td>\n",
              "      <td>0.005499</td>\n",
              "      <td>-0.000398</td>\n",
              "      <td>0.003167</td>\n",
              "      <td>-0.001820</td>\n",
              "      <td>-0.000351</td>\n",
              "      <td>-0.002156</td>\n",
              "      <td>0.003730</td>\n",
              "      <td>-0.003733</td>\n",
              "      <td>-4.282686e-03</td>\n",
              "      <td>0.010518</td>\n",
              "      <td>-0.007079</td>\n",
              "      <td>-0.001463</td>\n",
              "      <td>-0.002285</td>\n",
              "      <td>0.010578</td>\n",
              "      <td>-0.001440</td>\n",
              "      <td>0.007969</td>\n",
              "      <td>-0.004769</td>\n",
              "      <td>-0.008374</td>\n",
              "      <td>-0.000531</td>\n",
              "      <td>0.019012</td>\n",
              "      <td>-0.002419</td>\n",
              "      <td>-0.010632</td>\n",
              "      <td>-0.003780</td>\n",
              "      <td>-0.003738</td>\n",
              "      <td>0.010003</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.001323</td>\n",
              "      <td>-0.001029</td>\n",
              "      <td>-0.000891</td>\n",
              "      <td>-0.001128</td>\n",
              "      <td>-0.000976</td>\n",
              "      <td>-0.000579</td>\n",
              "      <td>-0.001128</td>\n",
              "      <td>-0.001128</td>\n",
              "      <td>-0.000608</td>\n",
              "      <td>-0.001343</td>\n",
              "      <td>-0.000637</td>\n",
              "      <td>-0.000939</td>\n",
              "      <td>-0.000819</td>\n",
              "      <td>-0.000133</td>\n",
              "      <td>-0.000375</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.000420</td>\n",
              "      <td>-0.001088</td>\n",
              "      <td>-0.000786</td>\n",
              "      <td>-0.000579</td>\n",
              "      <td>-0.000985</td>\n",
              "      <td>-0.001012</td>\n",
              "      <td>-0.000920</td>\n",
              "      <td>-0.000375</td>\n",
              "      <td>-0.002960</td>\n",
              "      <td>-0.000664</td>\n",
              "      <td>-0.000375</td>\n",
              "      <td>-0.000637</td>\n",
              "      <td>-0.001636</td>\n",
              "      <td>-0.000930</td>\n",
              "      <td>-0.000703</td>\n",
              "      <td>-0.001303</td>\n",
              "      <td>-0.000398</td>\n",
              "      <td>-0.001063</td>\n",
              "      <td>-0.000861</td>\n",
              "      <td>-0.000514</td>\n",
              "      <td>-0.000460</td>\n",
              "      <td>-0.061862</td>\n",
              "      <td>-9.392293e-04</td>\n",
              "      <td>-0.000440</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>c_Hungary</th>\n",
              "      <td>0.014166</td>\n",
              "      <td>-0.002536</td>\n",
              "      <td>0.007968</td>\n",
              "      <td>-0.007153</td>\n",
              "      <td>-0.001803</td>\n",
              "      <td>0.004003</td>\n",
              "      <td>-0.014813</td>\n",
              "      <td>-0.006533</td>\n",
              "      <td>-0.004870</td>\n",
              "      <td>-0.003518</td>\n",
              "      <td>-0.005273</td>\n",
              "      <td>-0.000283</td>\n",
              "      <td>0.000200</td>\n",
              "      <td>-0.003769</td>\n",
              "      <td>0.016369</td>\n",
              "      <td>-0.004068</td>\n",
              "      <td>-0.000380</td>\n",
              "      <td>-0.004880</td>\n",
              "      <td>-0.007352</td>\n",
              "      <td>-0.000335</td>\n",
              "      <td>0.004546</td>\n",
              "      <td>0.004662</td>\n",
              "      <td>-0.003559</td>\n",
              "      <td>-4.083300e-03</td>\n",
              "      <td>-0.005118</td>\n",
              "      <td>-0.000145</td>\n",
              "      <td>0.027429</td>\n",
              "      <td>0.010374</td>\n",
              "      <td>-0.002866</td>\n",
              "      <td>-0.007126</td>\n",
              "      <td>0.008698</td>\n",
              "      <td>-0.004547</td>\n",
              "      <td>-0.002173</td>\n",
              "      <td>-0.000506</td>\n",
              "      <td>-0.006330</td>\n",
              "      <td>-0.002306</td>\n",
              "      <td>0.003023</td>\n",
              "      <td>-0.003604</td>\n",
              "      <td>0.019607</td>\n",
              "      <td>-0.004183</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.001261</td>\n",
              "      <td>-0.000981</td>\n",
              "      <td>-0.000849</td>\n",
              "      <td>-0.001075</td>\n",
              "      <td>-0.000931</td>\n",
              "      <td>-0.000552</td>\n",
              "      <td>-0.001075</td>\n",
              "      <td>-0.001075</td>\n",
              "      <td>-0.000580</td>\n",
              "      <td>-0.001280</td>\n",
              "      <td>-0.000607</td>\n",
              "      <td>-0.000896</td>\n",
              "      <td>-0.000780</td>\n",
              "      <td>-0.000127</td>\n",
              "      <td>-0.000358</td>\n",
              "      <td>-0.000420</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.001037</td>\n",
              "      <td>-0.000749</td>\n",
              "      <td>-0.000552</td>\n",
              "      <td>-0.000939</td>\n",
              "      <td>-0.000965</td>\n",
              "      <td>-0.000877</td>\n",
              "      <td>-0.000358</td>\n",
              "      <td>-0.002823</td>\n",
              "      <td>-0.000633</td>\n",
              "      <td>-0.000358</td>\n",
              "      <td>-0.000607</td>\n",
              "      <td>-0.001559</td>\n",
              "      <td>-0.000886</td>\n",
              "      <td>-0.000670</td>\n",
              "      <td>-0.001242</td>\n",
              "      <td>-0.000380</td>\n",
              "      <td>-0.001013</td>\n",
              "      <td>-0.000821</td>\n",
              "      <td>-0.000490</td>\n",
              "      <td>-0.000438</td>\n",
              "      <td>-0.058982</td>\n",
              "      <td>-8.955021e-04</td>\n",
              "      <td>-0.000420</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>c_India</th>\n",
              "      <td>0.000923</td>\n",
              "      <td>-0.007650</td>\n",
              "      <td>0.048578</td>\n",
              "      <td>0.025012</td>\n",
              "      <td>0.017188</td>\n",
              "      <td>0.003757</td>\n",
              "      <td>0.005140</td>\n",
              "      <td>0.016252</td>\n",
              "      <td>-0.012621</td>\n",
              "      <td>-0.004581</td>\n",
              "      <td>-0.010524</td>\n",
              "      <td>-0.000733</td>\n",
              "      <td>-0.002676</td>\n",
              "      <td>0.015747</td>\n",
              "      <td>-0.003729</td>\n",
              "      <td>0.029073</td>\n",
              "      <td>-0.000984</td>\n",
              "      <td>-0.012645</td>\n",
              "      <td>-0.004715</td>\n",
              "      <td>-0.000868</td>\n",
              "      <td>-0.010221</td>\n",
              "      <td>-0.000624</td>\n",
              "      <td>-0.009222</td>\n",
              "      <td>-2.684841e-03</td>\n",
              "      <td>-0.010041</td>\n",
              "      <td>-0.009827</td>\n",
              "      <td>-0.003615</td>\n",
              "      <td>0.035940</td>\n",
              "      <td>0.009103</td>\n",
              "      <td>0.008459</td>\n",
              "      <td>0.005223</td>\n",
              "      <td>-0.004622</td>\n",
              "      <td>-0.018442</td>\n",
              "      <td>-0.001312</td>\n",
              "      <td>0.016055</td>\n",
              "      <td>0.041619</td>\n",
              "      <td>-0.011598</td>\n",
              "      <td>-0.004906</td>\n",
              "      <td>-0.000273</td>\n",
              "      <td>0.015822</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.003269</td>\n",
              "      <td>-0.002543</td>\n",
              "      <td>-0.002201</td>\n",
              "      <td>-0.002786</td>\n",
              "      <td>-0.002412</td>\n",
              "      <td>-0.001430</td>\n",
              "      <td>-0.002786</td>\n",
              "      <td>-0.002786</td>\n",
              "      <td>-0.001503</td>\n",
              "      <td>-0.003318</td>\n",
              "      <td>-0.001573</td>\n",
              "      <td>-0.002321</td>\n",
              "      <td>-0.002023</td>\n",
              "      <td>-0.000328</td>\n",
              "      <td>-0.000927</td>\n",
              "      <td>-0.001088</td>\n",
              "      <td>-0.001037</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.001941</td>\n",
              "      <td>-0.001430</td>\n",
              "      <td>-0.002434</td>\n",
              "      <td>-0.002500</td>\n",
              "      <td>-0.002274</td>\n",
              "      <td>-0.000927</td>\n",
              "      <td>-0.007314</td>\n",
              "      <td>-0.001640</td>\n",
              "      <td>-0.000927</td>\n",
              "      <td>-0.001573</td>\n",
              "      <td>-0.004041</td>\n",
              "      <td>-0.002297</td>\n",
              "      <td>-0.001736</td>\n",
              "      <td>-0.003218</td>\n",
              "      <td>-0.000984</td>\n",
              "      <td>-0.002626</td>\n",
              "      <td>-0.002127</td>\n",
              "      <td>-0.001270</td>\n",
              "      <td>-0.001136</td>\n",
              "      <td>-0.152845</td>\n",
              "      <td>-2.320598e-03</td>\n",
              "      <td>-0.001088</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>c_Iran</th>\n",
              "      <td>0.000606</td>\n",
              "      <td>0.000441</td>\n",
              "      <td>0.032696</td>\n",
              "      <td>0.008197</td>\n",
              "      <td>0.007119</td>\n",
              "      <td>0.001436</td>\n",
              "      <td>0.012764</td>\n",
              "      <td>0.011589</td>\n",
              "      <td>-0.004462</td>\n",
              "      <td>0.005958</td>\n",
              "      <td>-0.001188</td>\n",
              "      <td>-0.000530</td>\n",
              "      <td>-0.007761</td>\n",
              "      <td>-0.001175</td>\n",
              "      <td>0.016768</td>\n",
              "      <td>-0.002137</td>\n",
              "      <td>-0.000711</td>\n",
              "      <td>-0.004487</td>\n",
              "      <td>-0.003849</td>\n",
              "      <td>-0.000627</td>\n",
              "      <td>-0.007672</td>\n",
              "      <td>0.015232</td>\n",
              "      <td>-0.006661</td>\n",
              "      <td>-7.642978e-03</td>\n",
              "      <td>-0.009580</td>\n",
              "      <td>-0.002038</td>\n",
              "      <td>-0.002611</td>\n",
              "      <td>0.017813</td>\n",
              "      <td>-0.005365</td>\n",
              "      <td>0.006968</td>\n",
              "      <td>-0.006369</td>\n",
              "      <td>-0.003560</td>\n",
              "      <td>0.003701</td>\n",
              "      <td>-0.000948</td>\n",
              "      <td>0.002110</td>\n",
              "      <td>0.005084</td>\n",
              "      <td>-0.008003</td>\n",
              "      <td>-0.000616</td>\n",
              "      <td>0.005721</td>\n",
              "      <td>-0.000195</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.002361</td>\n",
              "      <td>-0.001837</td>\n",
              "      <td>-0.001590</td>\n",
              "      <td>-0.002012</td>\n",
              "      <td>-0.001742</td>\n",
              "      <td>-0.001033</td>\n",
              "      <td>-0.002012</td>\n",
              "      <td>-0.002012</td>\n",
              "      <td>-0.001086</td>\n",
              "      <td>-0.002397</td>\n",
              "      <td>-0.001136</td>\n",
              "      <td>-0.001676</td>\n",
              "      <td>-0.001461</td>\n",
              "      <td>-0.000237</td>\n",
              "      <td>-0.000670</td>\n",
              "      <td>-0.000786</td>\n",
              "      <td>-0.000749</td>\n",
              "      <td>-0.001941</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.001033</td>\n",
              "      <td>-0.001758</td>\n",
              "      <td>-0.001806</td>\n",
              "      <td>-0.001642</td>\n",
              "      <td>-0.000670</td>\n",
              "      <td>-0.005283</td>\n",
              "      <td>-0.001185</td>\n",
              "      <td>-0.000670</td>\n",
              "      <td>-0.001136</td>\n",
              "      <td>-0.002919</td>\n",
              "      <td>-0.001659</td>\n",
              "      <td>-0.001254</td>\n",
              "      <td>-0.002325</td>\n",
              "      <td>-0.000711</td>\n",
              "      <td>-0.001897</td>\n",
              "      <td>-0.001536</td>\n",
              "      <td>-0.000917</td>\n",
              "      <td>-0.000821</td>\n",
              "      <td>-0.110400</td>\n",
              "      <td>-1.676170e-03</td>\n",
              "      <td>-0.000786</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>c_Ireland</th>\n",
              "      <td>-0.002177</td>\n",
              "      <td>-0.014243</td>\n",
              "      <td>0.000257</td>\n",
              "      <td>0.000928</td>\n",
              "      <td>-0.002500</td>\n",
              "      <td>0.000881</td>\n",
              "      <td>0.004161</td>\n",
              "      <td>0.001538</td>\n",
              "      <td>-0.006715</td>\n",
              "      <td>-0.004850</td>\n",
              "      <td>-0.007269</td>\n",
              "      <td>-0.000390</td>\n",
              "      <td>0.015099</td>\n",
              "      <td>-0.005196</td>\n",
              "      <td>-0.002706</td>\n",
              "      <td>-0.005609</td>\n",
              "      <td>-0.000523</td>\n",
              "      <td>-0.006727</td>\n",
              "      <td>-0.010136</td>\n",
              "      <td>-0.000462</td>\n",
              "      <td>0.020317</td>\n",
              "      <td>-0.005932</td>\n",
              "      <td>-0.004906</td>\n",
              "      <td>9.184899e-03</td>\n",
              "      <td>0.005033</td>\n",
              "      <td>0.009863</td>\n",
              "      <td>-0.001923</td>\n",
              "      <td>0.002541</td>\n",
              "      <td>-0.003952</td>\n",
              "      <td>-0.009824</td>\n",
              "      <td>-0.004691</td>\n",
              "      <td>-0.006268</td>\n",
              "      <td>0.001642</td>\n",
              "      <td>-0.000698</td>\n",
              "      <td>-0.004939</td>\n",
              "      <td>0.009576</td>\n",
              "      <td>0.005403</td>\n",
              "      <td>-0.004969</td>\n",
              "      <td>-0.004913</td>\n",
              "      <td>-0.004880</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.001739</td>\n",
              "      <td>-0.001353</td>\n",
              "      <td>-0.001171</td>\n",
              "      <td>-0.001482</td>\n",
              "      <td>-0.001283</td>\n",
              "      <td>-0.000761</td>\n",
              "      <td>-0.001482</td>\n",
              "      <td>-0.001482</td>\n",
              "      <td>-0.000800</td>\n",
              "      <td>-0.001765</td>\n",
              "      <td>-0.000837</td>\n",
              "      <td>-0.001235</td>\n",
              "      <td>-0.001076</td>\n",
              "      <td>-0.000174</td>\n",
              "      <td>-0.000493</td>\n",
              "      <td>-0.000579</td>\n",
              "      <td>-0.000552</td>\n",
              "      <td>-0.001430</td>\n",
              "      <td>-0.001033</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.001295</td>\n",
              "      <td>-0.001330</td>\n",
              "      <td>-0.001210</td>\n",
              "      <td>-0.000493</td>\n",
              "      <td>-0.003891</td>\n",
              "      <td>-0.000873</td>\n",
              "      <td>-0.000493</td>\n",
              "      <td>-0.000837</td>\n",
              "      <td>-0.002150</td>\n",
              "      <td>-0.001222</td>\n",
              "      <td>-0.000923</td>\n",
              "      <td>-0.001712</td>\n",
              "      <td>-0.000523</td>\n",
              "      <td>-0.001397</td>\n",
              "      <td>-0.001131</td>\n",
              "      <td>-0.000676</td>\n",
              "      <td>-0.000604</td>\n",
              "      <td>-0.081316</td>\n",
              "      <td>-1.234587e-03</td>\n",
              "      <td>-0.000579</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>c_Italy</th>\n",
              "      <td>0.025300</td>\n",
              "      <td>-0.000030</td>\n",
              "      <td>-0.013182</td>\n",
              "      <td>0.002249</td>\n",
              "      <td>-0.002609</td>\n",
              "      <td>-0.005916</td>\n",
              "      <td>0.006635</td>\n",
              "      <td>0.017678</td>\n",
              "      <td>0.003425</td>\n",
              "      <td>-0.003253</td>\n",
              "      <td>-0.008912</td>\n",
              "      <td>-0.000664</td>\n",
              "      <td>-0.007878</td>\n",
              "      <td>0.000538</td>\n",
              "      <td>0.021028</td>\n",
              "      <td>-0.000807</td>\n",
              "      <td>-0.000891</td>\n",
              "      <td>0.003379</td>\n",
              "      <td>0.001200</td>\n",
              "      <td>-0.000786</td>\n",
              "      <td>0.005505</td>\n",
              "      <td>-0.002037</td>\n",
              "      <td>-0.003403</td>\n",
              "      <td>-8.713473e-04</td>\n",
              "      <td>0.005762</td>\n",
              "      <td>0.003887</td>\n",
              "      <td>-0.003275</td>\n",
              "      <td>0.007697</td>\n",
              "      <td>-0.006728</td>\n",
              "      <td>-0.008624</td>\n",
              "      <td>-0.007987</td>\n",
              "      <td>-0.006722</td>\n",
              "      <td>-0.013781</td>\n",
              "      <td>-0.001188</td>\n",
              "      <td>0.018558</td>\n",
              "      <td>0.009592</td>\n",
              "      <td>-0.014709</td>\n",
              "      <td>0.001325</td>\n",
              "      <td>0.006468</td>\n",
              "      <td>0.015423</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.002961</td>\n",
              "      <td>-0.002303</td>\n",
              "      <td>-0.001994</td>\n",
              "      <td>-0.002524</td>\n",
              "      <td>-0.002185</td>\n",
              "      <td>-0.001295</td>\n",
              "      <td>-0.002524</td>\n",
              "      <td>-0.002524</td>\n",
              "      <td>-0.001361</td>\n",
              "      <td>-0.003005</td>\n",
              "      <td>-0.001425</td>\n",
              "      <td>-0.002102</td>\n",
              "      <td>-0.001832</td>\n",
              "      <td>-0.000297</td>\n",
              "      <td>-0.000840</td>\n",
              "      <td>-0.000985</td>\n",
              "      <td>-0.000939</td>\n",
              "      <td>-0.002434</td>\n",
              "      <td>-0.001758</td>\n",
              "      <td>-0.001295</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.002264</td>\n",
              "      <td>-0.002059</td>\n",
              "      <td>-0.000840</td>\n",
              "      <td>-0.006625</td>\n",
              "      <td>-0.001486</td>\n",
              "      <td>-0.000840</td>\n",
              "      <td>-0.001425</td>\n",
              "      <td>-0.003660</td>\n",
              "      <td>-0.002081</td>\n",
              "      <td>-0.001572</td>\n",
              "      <td>-0.002915</td>\n",
              "      <td>-0.000891</td>\n",
              "      <td>-0.002379</td>\n",
              "      <td>-0.001926</td>\n",
              "      <td>-0.001151</td>\n",
              "      <td>-0.001029</td>\n",
              "      <td>-0.138450</td>\n",
              "      <td>-2.102032e-03</td>\n",
              "      <td>-0.000985</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>c_Jamaica</th>\n",
              "      <td>-0.013133</td>\n",
              "      <td>0.010710</td>\n",
              "      <td>-0.010315</td>\n",
              "      <td>-0.026074</td>\n",
              "      <td>-0.007012</td>\n",
              "      <td>-0.010396</td>\n",
              "      <td>-0.004775</td>\n",
              "      <td>-0.011463</td>\n",
              "      <td>-0.008123</td>\n",
              "      <td>-0.008481</td>\n",
              "      <td>-0.005963</td>\n",
              "      <td>-0.000682</td>\n",
              "      <td>0.017463</td>\n",
              "      <td>-0.009085</td>\n",
              "      <td>-0.001814</td>\n",
              "      <td>-0.005550</td>\n",
              "      <td>-0.000915</td>\n",
              "      <td>-0.008152</td>\n",
              "      <td>0.020794</td>\n",
              "      <td>-0.000807</td>\n",
              "      <td>-0.005641</td>\n",
              "      <td>-0.002920</td>\n",
              "      <td>-0.008579</td>\n",
              "      <td>2.885119e-03</td>\n",
              "      <td>-0.008876</td>\n",
              "      <td>0.022157</td>\n",
              "      <td>0.008617</td>\n",
              "      <td>-0.010923</td>\n",
              "      <td>-0.006910</td>\n",
              "      <td>-0.001396</td>\n",
              "      <td>0.001856</td>\n",
              "      <td>-0.007113</td>\n",
              "      <td>-0.009586</td>\n",
              "      <td>-0.001220</td>\n",
              "      <td>-0.015926</td>\n",
              "      <td>0.038280</td>\n",
              "      <td>0.015781</td>\n",
              "      <td>0.005605</td>\n",
              "      <td>-0.008591</td>\n",
              "      <td>-0.015849</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.003041</td>\n",
              "      <td>-0.002365</td>\n",
              "      <td>-0.002048</td>\n",
              "      <td>-0.002592</td>\n",
              "      <td>-0.002244</td>\n",
              "      <td>-0.001330</td>\n",
              "      <td>-0.002592</td>\n",
              "      <td>-0.002592</td>\n",
              "      <td>-0.001398</td>\n",
              "      <td>-0.003086</td>\n",
              "      <td>-0.001463</td>\n",
              "      <td>-0.002159</td>\n",
              "      <td>-0.001881</td>\n",
              "      <td>-0.000305</td>\n",
              "      <td>-0.000863</td>\n",
              "      <td>-0.001012</td>\n",
              "      <td>-0.000965</td>\n",
              "      <td>-0.002500</td>\n",
              "      <td>-0.001806</td>\n",
              "      <td>-0.001330</td>\n",
              "      <td>-0.002264</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.002115</td>\n",
              "      <td>-0.000863</td>\n",
              "      <td>-0.006804</td>\n",
              "      <td>-0.001526</td>\n",
              "      <td>-0.000863</td>\n",
              "      <td>-0.001463</td>\n",
              "      <td>-0.003759</td>\n",
              "      <td>-0.002137</td>\n",
              "      <td>-0.001615</td>\n",
              "      <td>-0.002994</td>\n",
              "      <td>-0.000915</td>\n",
              "      <td>-0.002443</td>\n",
              "      <td>-0.001978</td>\n",
              "      <td>-0.001182</td>\n",
              "      <td>-0.001057</td>\n",
              "      <td>-0.142184</td>\n",
              "      <td>-2.158729e-03</td>\n",
              "      <td>-0.001012</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>c_Japan</th>\n",
              "      <td>-0.001477</td>\n",
              "      <td>-0.000894</td>\n",
              "      <td>0.023618</td>\n",
              "      <td>0.003724</td>\n",
              "      <td>0.012574</td>\n",
              "      <td>-0.005834</td>\n",
              "      <td>0.009617</td>\n",
              "      <td>0.018225</td>\n",
              "      <td>-0.002728</td>\n",
              "      <td>0.003000</td>\n",
              "      <td>-0.007853</td>\n",
              "      <td>-0.000620</td>\n",
              "      <td>0.003218</td>\n",
              "      <td>0.001781</td>\n",
              "      <td>0.000685</td>\n",
              "      <td>0.000437</td>\n",
              "      <td>-0.000832</td>\n",
              "      <td>-0.002761</td>\n",
              "      <td>-0.002009</td>\n",
              "      <td>-0.000734</td>\n",
              "      <td>-0.005512</td>\n",
              "      <td>0.022448</td>\n",
              "      <td>-0.002504</td>\n",
              "      <td>-4.289917e-03</td>\n",
              "      <td>-0.011222</td>\n",
              "      <td>0.012351</td>\n",
              "      <td>-0.003059</td>\n",
              "      <td>0.005195</td>\n",
              "      <td>0.000223</td>\n",
              "      <td>-0.006951</td>\n",
              "      <td>-0.007461</td>\n",
              "      <td>-0.009969</td>\n",
              "      <td>0.001074</td>\n",
              "      <td>-0.001110</td>\n",
              "      <td>0.003729</td>\n",
              "      <td>0.002973</td>\n",
              "      <td>-0.003485</td>\n",
              "      <td>-0.002666</td>\n",
              "      <td>-0.002522</td>\n",
              "      <td>0.003125</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.002766</td>\n",
              "      <td>-0.002151</td>\n",
              "      <td>-0.001862</td>\n",
              "      <td>-0.002357</td>\n",
              "      <td>-0.002041</td>\n",
              "      <td>-0.001210</td>\n",
              "      <td>-0.002357</td>\n",
              "      <td>-0.002357</td>\n",
              "      <td>-0.001272</td>\n",
              "      <td>-0.002807</td>\n",
              "      <td>-0.001331</td>\n",
              "      <td>-0.001963</td>\n",
              "      <td>-0.001711</td>\n",
              "      <td>-0.000277</td>\n",
              "      <td>-0.000785</td>\n",
              "      <td>-0.000920</td>\n",
              "      <td>-0.000877</td>\n",
              "      <td>-0.002274</td>\n",
              "      <td>-0.001642</td>\n",
              "      <td>-0.001210</td>\n",
              "      <td>-0.002059</td>\n",
              "      <td>-0.002115</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.000785</td>\n",
              "      <td>-0.006189</td>\n",
              "      <td>-0.001388</td>\n",
              "      <td>-0.000785</td>\n",
              "      <td>-0.001331</td>\n",
              "      <td>-0.003419</td>\n",
              "      <td>-0.001944</td>\n",
              "      <td>-0.001469</td>\n",
              "      <td>-0.002723</td>\n",
              "      <td>-0.000832</td>\n",
              "      <td>-0.002222</td>\n",
              "      <td>-0.001799</td>\n",
              "      <td>-0.001075</td>\n",
              "      <td>-0.000961</td>\n",
              "      <td>-0.129321</td>\n",
              "      <td>-1.963440e-03</td>\n",
              "      <td>-0.000920</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>c_Laos</th>\n",
              "      <td>-0.006675</td>\n",
              "      <td>0.004573</td>\n",
              "      <td>-0.005818</td>\n",
              "      <td>0.003102</td>\n",
              "      <td>-0.001740</td>\n",
              "      <td>-0.003857</td>\n",
              "      <td>-0.000593</td>\n",
              "      <td>-0.004795</td>\n",
              "      <td>0.005374</td>\n",
              "      <td>-0.003146</td>\n",
              "      <td>0.004359</td>\n",
              "      <td>-0.000253</td>\n",
              "      <td>0.002123</td>\n",
              "      <td>-0.003371</td>\n",
              "      <td>-0.005244</td>\n",
              "      <td>-0.003639</td>\n",
              "      <td>-0.000340</td>\n",
              "      <td>0.005350</td>\n",
              "      <td>0.007239</td>\n",
              "      <td>-0.000299</td>\n",
              "      <td>0.013537</td>\n",
              "      <td>-0.006712</td>\n",
              "      <td>-0.003183</td>\n",
              "      <td>-3.652068e-03</td>\n",
              "      <td>0.014049</td>\n",
              "      <td>-0.006036</td>\n",
              "      <td>-0.001248</td>\n",
              "      <td>-0.006830</td>\n",
              "      <td>-0.002564</td>\n",
              "      <td>-0.006373</td>\n",
              "      <td>-0.003043</td>\n",
              "      <td>-0.004066</td>\n",
              "      <td>-0.007141</td>\n",
              "      <td>-0.000453</td>\n",
              "      <td>0.014988</td>\n",
              "      <td>-0.002063</td>\n",
              "      <td>-0.007768</td>\n",
              "      <td>-0.003223</td>\n",
              "      <td>-0.003187</td>\n",
              "      <td>0.008115</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.001128</td>\n",
              "      <td>-0.000878</td>\n",
              "      <td>-0.000760</td>\n",
              "      <td>-0.000962</td>\n",
              "      <td>-0.000832</td>\n",
              "      <td>-0.000493</td>\n",
              "      <td>-0.000962</td>\n",
              "      <td>-0.000962</td>\n",
              "      <td>-0.000519</td>\n",
              "      <td>-0.001145</td>\n",
              "      <td>-0.000543</td>\n",
              "      <td>-0.000801</td>\n",
              "      <td>-0.000698</td>\n",
              "      <td>-0.000113</td>\n",
              "      <td>-0.000320</td>\n",
              "      <td>-0.000375</td>\n",
              "      <td>-0.000358</td>\n",
              "      <td>-0.000927</td>\n",
              "      <td>-0.000670</td>\n",
              "      <td>-0.000493</td>\n",
              "      <td>-0.000840</td>\n",
              "      <td>-0.000863</td>\n",
              "      <td>-0.000785</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.002524</td>\n",
              "      <td>-0.000566</td>\n",
              "      <td>-0.000320</td>\n",
              "      <td>-0.000543</td>\n",
              "      <td>-0.001395</td>\n",
              "      <td>-0.000793</td>\n",
              "      <td>-0.000599</td>\n",
              "      <td>-0.001111</td>\n",
              "      <td>-0.000340</td>\n",
              "      <td>-0.000906</td>\n",
              "      <td>-0.000734</td>\n",
              "      <td>-0.000438</td>\n",
              "      <td>-0.000392</td>\n",
              "      <td>-0.052753</td>\n",
              "      <td>-8.009294e-04</td>\n",
              "      <td>-0.000375</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>c_Mexico</th>\n",
              "      <td>-0.055328</td>\n",
              "      <td>0.135171</td>\n",
              "      <td>-0.208710</td>\n",
              "      <td>0.029994</td>\n",
              "      <td>-0.012803</td>\n",
              "      <td>-0.023695</td>\n",
              "      <td>-0.001360</td>\n",
              "      <td>-0.062211</td>\n",
              "      <td>-0.000388</td>\n",
              "      <td>-0.023119</td>\n",
              "      <td>-0.021939</td>\n",
              "      <td>-0.001996</td>\n",
              "      <td>0.048779</td>\n",
              "      <td>-0.013871</td>\n",
              "      <td>-0.019935</td>\n",
              "      <td>-0.025735</td>\n",
              "      <td>-0.002678</td>\n",
              "      <td>-0.000510</td>\n",
              "      <td>-0.027747</td>\n",
              "      <td>-0.002361</td>\n",
              "      <td>0.013171</td>\n",
              "      <td>-0.043258</td>\n",
              "      <td>0.075496</td>\n",
              "      <td>4.644830e-02</td>\n",
              "      <td>0.046979</td>\n",
              "      <td>0.038301</td>\n",
              "      <td>0.048486</td>\n",
              "      <td>-0.039981</td>\n",
              "      <td>-0.011982</td>\n",
              "      <td>-0.025564</td>\n",
              "      <td>-0.020503</td>\n",
              "      <td>-0.013339</td>\n",
              "      <td>-0.039516</td>\n",
              "      <td>-0.003571</td>\n",
              "      <td>0.009676</td>\n",
              "      <td>0.047256</td>\n",
              "      <td>0.005199</td>\n",
              "      <td>0.017658</td>\n",
              "      <td>-0.011740</td>\n",
              "      <td>0.004452</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.008897</td>\n",
              "      <td>-0.006921</td>\n",
              "      <td>-0.005992</td>\n",
              "      <td>-0.007583</td>\n",
              "      <td>-0.006565</td>\n",
              "      <td>-0.003891</td>\n",
              "      <td>-0.007583</td>\n",
              "      <td>-0.007583</td>\n",
              "      <td>-0.004091</td>\n",
              "      <td>-0.009031</td>\n",
              "      <td>-0.004282</td>\n",
              "      <td>-0.006316</td>\n",
              "      <td>-0.005505</td>\n",
              "      <td>-0.000892</td>\n",
              "      <td>-0.002524</td>\n",
              "      <td>-0.002960</td>\n",
              "      <td>-0.002823</td>\n",
              "      <td>-0.007314</td>\n",
              "      <td>-0.005283</td>\n",
              "      <td>-0.003891</td>\n",
              "      <td>-0.006625</td>\n",
              "      <td>-0.006804</td>\n",
              "      <td>-0.006189</td>\n",
              "      <td>-0.002524</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.004464</td>\n",
              "      <td>-0.002524</td>\n",
              "      <td>-0.004282</td>\n",
              "      <td>-0.010999</td>\n",
              "      <td>-0.006253</td>\n",
              "      <td>-0.004725</td>\n",
              "      <td>-0.008760</td>\n",
              "      <td>-0.002678</td>\n",
              "      <td>-0.007148</td>\n",
              "      <td>-0.005788</td>\n",
              "      <td>-0.003457</td>\n",
              "      <td>-0.003092</td>\n",
              "      <td>-0.416028</td>\n",
              "      <td>-6.316409e-03</td>\n",
              "      <td>-0.002960</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>c_Nicaragua</th>\n",
              "      <td>-0.013977</td>\n",
              "      <td>0.042862</td>\n",
              "      <td>-0.016846</td>\n",
              "      <td>-0.001906</td>\n",
              "      <td>-0.003452</td>\n",
              "      <td>0.003988</td>\n",
              "      <td>-0.014425</td>\n",
              "      <td>-0.011816</td>\n",
              "      <td>-0.002197</td>\n",
              "      <td>0.001855</td>\n",
              "      <td>0.001931</td>\n",
              "      <td>-0.000447</td>\n",
              "      <td>0.004441</td>\n",
              "      <td>-0.005961</td>\n",
              "      <td>-0.004585</td>\n",
              "      <td>0.000045</td>\n",
              "      <td>-0.000600</td>\n",
              "      <td>-0.002221</td>\n",
              "      <td>0.007915</td>\n",
              "      <td>-0.000529</td>\n",
              "      <td>-0.004295</td>\n",
              "      <td>-0.011868</td>\n",
              "      <td>-0.005629</td>\n",
              "      <td>1.291640e-02</td>\n",
              "      <td>0.007715</td>\n",
              "      <td>0.010215</td>\n",
              "      <td>0.016029</td>\n",
              "      <td>-0.008280</td>\n",
              "      <td>-0.004534</td>\n",
              "      <td>-0.007266</td>\n",
              "      <td>0.002274</td>\n",
              "      <td>0.004521</td>\n",
              "      <td>-0.005275</td>\n",
              "      <td>-0.000801</td>\n",
              "      <td>-0.001120</td>\n",
              "      <td>-0.003648</td>\n",
              "      <td>0.007474</td>\n",
              "      <td>-0.005700</td>\n",
              "      <td>0.001693</td>\n",
              "      <td>-0.002746</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.001995</td>\n",
              "      <td>-0.001552</td>\n",
              "      <td>-0.001344</td>\n",
              "      <td>-0.001700</td>\n",
              "      <td>-0.001472</td>\n",
              "      <td>-0.000873</td>\n",
              "      <td>-0.001700</td>\n",
              "      <td>-0.001700</td>\n",
              "      <td>-0.000917</td>\n",
              "      <td>-0.002025</td>\n",
              "      <td>-0.000960</td>\n",
              "      <td>-0.001416</td>\n",
              "      <td>-0.001234</td>\n",
              "      <td>-0.000200</td>\n",
              "      <td>-0.000566</td>\n",
              "      <td>-0.000664</td>\n",
              "      <td>-0.000633</td>\n",
              "      <td>-0.001640</td>\n",
              "      <td>-0.001185</td>\n",
              "      <td>-0.000873</td>\n",
              "      <td>-0.001486</td>\n",
              "      <td>-0.001526</td>\n",
              "      <td>-0.001388</td>\n",
              "      <td>-0.000566</td>\n",
              "      <td>-0.004464</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.000566</td>\n",
              "      <td>-0.000960</td>\n",
              "      <td>-0.002466</td>\n",
              "      <td>-0.001402</td>\n",
              "      <td>-0.001059</td>\n",
              "      <td>-0.001964</td>\n",
              "      <td>-0.000600</td>\n",
              "      <td>-0.001603</td>\n",
              "      <td>-0.001298</td>\n",
              "      <td>-0.000775</td>\n",
              "      <td>-0.000693</td>\n",
              "      <td>-0.093287</td>\n",
              "      <td>-1.416338e-03</td>\n",
              "      <td>-0.000664</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>c_Outlying-US(Guam-USVI-etc)</th>\n",
              "      <td>-0.001447</td>\n",
              "      <td>0.000079</td>\n",
              "      <td>0.003803</td>\n",
              "      <td>-0.001648</td>\n",
              "      <td>-0.002602</td>\n",
              "      <td>-0.003857</td>\n",
              "      <td>0.006135</td>\n",
              "      <td>-0.010036</td>\n",
              "      <td>-0.004356</td>\n",
              "      <td>-0.003146</td>\n",
              "      <td>0.004359</td>\n",
              "      <td>-0.000253</td>\n",
              "      <td>0.002123</td>\n",
              "      <td>-0.003371</td>\n",
              "      <td>0.003041</td>\n",
              "      <td>-0.003639</td>\n",
              "      <td>-0.000340</td>\n",
              "      <td>-0.004364</td>\n",
              "      <td>-0.006576</td>\n",
              "      <td>-0.000299</td>\n",
              "      <td>0.000006</td>\n",
              "      <td>0.006890</td>\n",
              "      <td>-0.003183</td>\n",
              "      <td>7.760645e-03</td>\n",
              "      <td>-0.004578</td>\n",
              "      <td>0.008730</td>\n",
              "      <td>-0.001248</td>\n",
              "      <td>-0.000118</td>\n",
              "      <td>-0.002564</td>\n",
              "      <td>0.000702</td>\n",
              "      <td>-0.003043</td>\n",
              "      <td>-0.004066</td>\n",
              "      <td>0.005852</td>\n",
              "      <td>-0.000453</td>\n",
              "      <td>-0.011946</td>\n",
              "      <td>-0.002063</td>\n",
              "      <td>0.011271</td>\n",
              "      <td>-0.003223</td>\n",
              "      <td>-0.003187</td>\n",
              "      <td>-0.010126</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.001128</td>\n",
              "      <td>-0.000878</td>\n",
              "      <td>-0.000760</td>\n",
              "      <td>-0.000962</td>\n",
              "      <td>-0.000832</td>\n",
              "      <td>-0.000493</td>\n",
              "      <td>-0.000962</td>\n",
              "      <td>-0.000962</td>\n",
              "      <td>-0.000519</td>\n",
              "      <td>-0.001145</td>\n",
              "      <td>-0.000543</td>\n",
              "      <td>-0.000801</td>\n",
              "      <td>-0.000698</td>\n",
              "      <td>-0.000113</td>\n",
              "      <td>-0.000320</td>\n",
              "      <td>-0.000375</td>\n",
              "      <td>-0.000358</td>\n",
              "      <td>-0.000927</td>\n",
              "      <td>-0.000670</td>\n",
              "      <td>-0.000493</td>\n",
              "      <td>-0.000840</td>\n",
              "      <td>-0.000863</td>\n",
              "      <td>-0.000785</td>\n",
              "      <td>-0.000320</td>\n",
              "      <td>-0.002524</td>\n",
              "      <td>-0.000566</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.000543</td>\n",
              "      <td>-0.001395</td>\n",
              "      <td>-0.000793</td>\n",
              "      <td>-0.000599</td>\n",
              "      <td>-0.001111</td>\n",
              "      <td>-0.000340</td>\n",
              "      <td>-0.000906</td>\n",
              "      <td>-0.000734</td>\n",
              "      <td>-0.000438</td>\n",
              "      <td>-0.000392</td>\n",
              "      <td>-0.052753</td>\n",
              "      <td>-8.009294e-04</td>\n",
              "      <td>-0.000375</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>c_Peru</th>\n",
              "      <td>-0.008189</td>\n",
              "      <td>0.024041</td>\n",
              "      <td>-0.013350</td>\n",
              "      <td>-0.009450</td>\n",
              "      <td>-0.004090</td>\n",
              "      <td>-0.000465</td>\n",
              "      <td>-0.014200</td>\n",
              "      <td>-0.013931</td>\n",
              "      <td>-0.001648</td>\n",
              "      <td>-0.005337</td>\n",
              "      <td>-0.002645</td>\n",
              "      <td>-0.000429</td>\n",
              "      <td>0.008617</td>\n",
              "      <td>-0.005717</td>\n",
              "      <td>0.000881</td>\n",
              "      <td>-0.006172</td>\n",
              "      <td>-0.000576</td>\n",
              "      <td>-0.001672</td>\n",
              "      <td>-0.011153</td>\n",
              "      <td>-0.000508</td>\n",
              "      <td>-0.003481</td>\n",
              "      <td>-0.007371</td>\n",
              "      <td>-0.005399</td>\n",
              "      <td>1.400437e-02</td>\n",
              "      <td>0.008719</td>\n",
              "      <td>0.015895</td>\n",
              "      <td>-0.002116</td>\n",
              "      <td>-0.007625</td>\n",
              "      <td>0.014445</td>\n",
              "      <td>-0.002462</td>\n",
              "      <td>-0.005162</td>\n",
              "      <td>0.005313</td>\n",
              "      <td>-0.000614</td>\n",
              "      <td>-0.000768</td>\n",
              "      <td>-0.009337</td>\n",
              "      <td>0.008096</td>\n",
              "      <td>0.001216</td>\n",
              "      <td>0.024775</td>\n",
              "      <td>-0.005406</td>\n",
              "      <td>-0.011458</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.001913</td>\n",
              "      <td>-0.001488</td>\n",
              "      <td>-0.001289</td>\n",
              "      <td>-0.001631</td>\n",
              "      <td>-0.001412</td>\n",
              "      <td>-0.000837</td>\n",
              "      <td>-0.001631</td>\n",
              "      <td>-0.001631</td>\n",
              "      <td>-0.000880</td>\n",
              "      <td>-0.001942</td>\n",
              "      <td>-0.000921</td>\n",
              "      <td>-0.001358</td>\n",
              "      <td>-0.001184</td>\n",
              "      <td>-0.000192</td>\n",
              "      <td>-0.000543</td>\n",
              "      <td>-0.000637</td>\n",
              "      <td>-0.000607</td>\n",
              "      <td>-0.001573</td>\n",
              "      <td>-0.001136</td>\n",
              "      <td>-0.000837</td>\n",
              "      <td>-0.001425</td>\n",
              "      <td>-0.001463</td>\n",
              "      <td>-0.001331</td>\n",
              "      <td>-0.000543</td>\n",
              "      <td>-0.004282</td>\n",
              "      <td>-0.000960</td>\n",
              "      <td>-0.000543</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.002366</td>\n",
              "      <td>-0.001345</td>\n",
              "      <td>-0.001016</td>\n",
              "      <td>-0.001884</td>\n",
              "      <td>-0.000576</td>\n",
              "      <td>-0.001537</td>\n",
              "      <td>-0.001245</td>\n",
              "      <td>-0.000744</td>\n",
              "      <td>-0.000665</td>\n",
              "      <td>-0.089474</td>\n",
              "      <td>-1.358450e-03</td>\n",
              "      <td>-0.000637</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>c_Philippines</th>\n",
              "      <td>0.006123</td>\n",
              "      <td>-0.018450</td>\n",
              "      <td>0.023562</td>\n",
              "      <td>-0.006494</td>\n",
              "      <td>-0.000619</td>\n",
              "      <td>0.005976</td>\n",
              "      <td>-0.002918</td>\n",
              "      <td>0.005876</td>\n",
              "      <td>-0.001011</td>\n",
              "      <td>0.013528</td>\n",
              "      <td>-0.003789</td>\n",
              "      <td>-0.001103</td>\n",
              "      <td>0.014576</td>\n",
              "      <td>-0.009012</td>\n",
              "      <td>-0.015199</td>\n",
              "      <td>-0.010567</td>\n",
              "      <td>-0.001479</td>\n",
              "      <td>-0.001077</td>\n",
              "      <td>0.009616</td>\n",
              "      <td>-0.001305</td>\n",
              "      <td>-0.010708</td>\n",
              "      <td>-0.010404</td>\n",
              "      <td>-0.007881</td>\n",
              "      <td>-2.739837e-03</td>\n",
              "      <td>0.001553</td>\n",
              "      <td>0.024828</td>\n",
              "      <td>0.009441</td>\n",
              "      <td>-0.001870</td>\n",
              "      <td>-0.003817</td>\n",
              "      <td>-0.001637</td>\n",
              "      <td>0.014845</td>\n",
              "      <td>-0.015329</td>\n",
              "      <td>-0.016116</td>\n",
              "      <td>-0.001973</td>\n",
              "      <td>0.005074</td>\n",
              "      <td>0.036381</td>\n",
              "      <td>-0.002944</td>\n",
              "      <td>0.003706</td>\n",
              "      <td>-0.001928</td>\n",
              "      <td>-0.006091</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.004915</td>\n",
              "      <td>-0.003824</td>\n",
              "      <td>-0.003310</td>\n",
              "      <td>-0.004189</td>\n",
              "      <td>-0.003627</td>\n",
              "      <td>-0.002150</td>\n",
              "      <td>-0.004189</td>\n",
              "      <td>-0.004189</td>\n",
              "      <td>-0.002260</td>\n",
              "      <td>-0.004989</td>\n",
              "      <td>-0.002366</td>\n",
              "      <td>-0.003490</td>\n",
              "      <td>-0.003041</td>\n",
              "      <td>-0.000493</td>\n",
              "      <td>-0.001395</td>\n",
              "      <td>-0.001636</td>\n",
              "      <td>-0.001559</td>\n",
              "      <td>-0.004041</td>\n",
              "      <td>-0.002919</td>\n",
              "      <td>-0.002150</td>\n",
              "      <td>-0.003660</td>\n",
              "      <td>-0.003759</td>\n",
              "      <td>-0.003419</td>\n",
              "      <td>-0.001395</td>\n",
              "      <td>-0.010999</td>\n",
              "      <td>-0.002466</td>\n",
              "      <td>-0.001395</td>\n",
              "      <td>-0.002366</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.003455</td>\n",
              "      <td>-0.002610</td>\n",
              "      <td>-0.004840</td>\n",
              "      <td>-0.001479</td>\n",
              "      <td>-0.003949</td>\n",
              "      <td>-0.003198</td>\n",
              "      <td>-0.001910</td>\n",
              "      <td>-0.001708</td>\n",
              "      <td>-0.229845</td>\n",
              "      <td>-3.489665e-03</td>\n",
              "      <td>-0.001636</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>c_Poland</th>\n",
              "      <td>0.008739</td>\n",
              "      <td>0.000162</td>\n",
              "      <td>0.001418</td>\n",
              "      <td>-0.005282</td>\n",
              "      <td>-0.005214</td>\n",
              "      <td>-0.009553</td>\n",
              "      <td>-0.006101</td>\n",
              "      <td>-0.005783</td>\n",
              "      <td>0.001015</td>\n",
              "      <td>-0.002492</td>\n",
              "      <td>-0.000672</td>\n",
              "      <td>-0.000627</td>\n",
              "      <td>0.007714</td>\n",
              "      <td>-0.003379</td>\n",
              "      <td>-0.002938</td>\n",
              "      <td>-0.009013</td>\n",
              "      <td>-0.000841</td>\n",
              "      <td>0.000975</td>\n",
              "      <td>-0.010701</td>\n",
              "      <td>-0.000742</td>\n",
              "      <td>0.007881</td>\n",
              "      <td>-0.005623</td>\n",
              "      <td>-0.002640</td>\n",
              "      <td>4.799828e-03</td>\n",
              "      <td>0.007493</td>\n",
              "      <td>-0.000023</td>\n",
              "      <td>0.009941</td>\n",
              "      <td>-0.000632</td>\n",
              "      <td>-0.006350</td>\n",
              "      <td>-0.001480</td>\n",
              "      <td>0.003403</td>\n",
              "      <td>0.002482</td>\n",
              "      <td>-0.007179</td>\n",
              "      <td>-0.001121</td>\n",
              "      <td>0.001045</td>\n",
              "      <td>0.042578</td>\n",
              "      <td>-0.007932</td>\n",
              "      <td>-0.007984</td>\n",
              "      <td>0.013057</td>\n",
              "      <td>-0.003182</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.002794</td>\n",
              "      <td>-0.002174</td>\n",
              "      <td>-0.001882</td>\n",
              "      <td>-0.002382</td>\n",
              "      <td>-0.002062</td>\n",
              "      <td>-0.001222</td>\n",
              "      <td>-0.002382</td>\n",
              "      <td>-0.002382</td>\n",
              "      <td>-0.001285</td>\n",
              "      <td>-0.002836</td>\n",
              "      <td>-0.001345</td>\n",
              "      <td>-0.001984</td>\n",
              "      <td>-0.001729</td>\n",
              "      <td>-0.000280</td>\n",
              "      <td>-0.000793</td>\n",
              "      <td>-0.000930</td>\n",
              "      <td>-0.000886</td>\n",
              "      <td>-0.002297</td>\n",
              "      <td>-0.001659</td>\n",
              "      <td>-0.001222</td>\n",
              "      <td>-0.002081</td>\n",
              "      <td>-0.002137</td>\n",
              "      <td>-0.001944</td>\n",
              "      <td>-0.000793</td>\n",
              "      <td>-0.006253</td>\n",
              "      <td>-0.001402</td>\n",
              "      <td>-0.000793</td>\n",
              "      <td>-0.001345</td>\n",
              "      <td>-0.003455</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.001484</td>\n",
              "      <td>-0.002751</td>\n",
              "      <td>-0.000841</td>\n",
              "      <td>-0.002245</td>\n",
              "      <td>-0.001818</td>\n",
              "      <td>-0.001086</td>\n",
              "      <td>-0.000971</td>\n",
              "      <td>-0.130664</td>\n",
              "      <td>-1.983827e-03</td>\n",
              "      <td>-0.000930</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>c_Portugal</th>\n",
              "      <td>-0.001048</td>\n",
              "      <td>-0.014834</td>\n",
              "      <td>-0.043159</td>\n",
              "      <td>-0.001814</td>\n",
              "      <td>-0.003519</td>\n",
              "      <td>-0.007219</td>\n",
              "      <td>0.002975</td>\n",
              "      <td>-0.010376</td>\n",
              "      <td>0.007457</td>\n",
              "      <td>-0.005889</td>\n",
              "      <td>-0.003974</td>\n",
              "      <td>-0.000474</td>\n",
              "      <td>0.006571</td>\n",
              "      <td>-0.006309</td>\n",
              "      <td>-0.000954</td>\n",
              "      <td>-0.006810</td>\n",
              "      <td>-0.000635</td>\n",
              "      <td>0.007415</td>\n",
              "      <td>0.002467</td>\n",
              "      <td>-0.000560</td>\n",
              "      <td>0.019909</td>\n",
              "      <td>-0.008925</td>\n",
              "      <td>0.000978</td>\n",
              "      <td>1.147325e-02</td>\n",
              "      <td>0.011353</td>\n",
              "      <td>-0.003402</td>\n",
              "      <td>-0.002335</td>\n",
              "      <td>-0.012783</td>\n",
              "      <td>0.003719</td>\n",
              "      <td>-0.011928</td>\n",
              "      <td>-0.005696</td>\n",
              "      <td>-0.007611</td>\n",
              "      <td>0.000531</td>\n",
              "      <td>-0.000847</td>\n",
              "      <td>0.005248</td>\n",
              "      <td>-0.003861</td>\n",
              "      <td>-0.008175</td>\n",
              "      <td>0.007673</td>\n",
              "      <td>0.000961</td>\n",
              "      <td>-0.000663</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.002111</td>\n",
              "      <td>-0.001642</td>\n",
              "      <td>-0.001422</td>\n",
              "      <td>-0.001800</td>\n",
              "      <td>-0.001558</td>\n",
              "      <td>-0.000923</td>\n",
              "      <td>-0.001800</td>\n",
              "      <td>-0.001800</td>\n",
              "      <td>-0.000971</td>\n",
              "      <td>-0.002143</td>\n",
              "      <td>-0.001016</td>\n",
              "      <td>-0.001499</td>\n",
              "      <td>-0.001306</td>\n",
              "      <td>-0.000212</td>\n",
              "      <td>-0.000599</td>\n",
              "      <td>-0.000703</td>\n",
              "      <td>-0.000670</td>\n",
              "      <td>-0.001736</td>\n",
              "      <td>-0.001254</td>\n",
              "      <td>-0.000923</td>\n",
              "      <td>-0.001572</td>\n",
              "      <td>-0.001615</td>\n",
              "      <td>-0.001469</td>\n",
              "      <td>-0.000599</td>\n",
              "      <td>-0.004725</td>\n",
              "      <td>-0.001059</td>\n",
              "      <td>-0.000599</td>\n",
              "      <td>-0.001016</td>\n",
              "      <td>-0.002610</td>\n",
              "      <td>-0.001484</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.002079</td>\n",
              "      <td>-0.000635</td>\n",
              "      <td>-0.001696</td>\n",
              "      <td>-0.001374</td>\n",
              "      <td>-0.000820</td>\n",
              "      <td>-0.000734</td>\n",
              "      <td>-0.098731</td>\n",
              "      <td>-1.499002e-03</td>\n",
              "      <td>-0.000703</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>c_Puerto-Rico</th>\n",
              "      <td>0.009957</td>\n",
              "      <td>0.006168</td>\n",
              "      <td>-0.041182</td>\n",
              "      <td>-0.019455</td>\n",
              "      <td>-0.006005</td>\n",
              "      <td>-0.003237</td>\n",
              "      <td>-0.010418</td>\n",
              "      <td>-0.018156</td>\n",
              "      <td>-0.006675</td>\n",
              "      <td>0.011829</td>\n",
              "      <td>-0.003244</td>\n",
              "      <td>-0.000878</td>\n",
              "      <td>0.010176</td>\n",
              "      <td>-0.011698</td>\n",
              "      <td>-0.006219</td>\n",
              "      <td>-0.002693</td>\n",
              "      <td>-0.001178</td>\n",
              "      <td>-0.006718</td>\n",
              "      <td>0.005145</td>\n",
              "      <td>-0.001039</td>\n",
              "      <td>0.001979</td>\n",
              "      <td>-0.011490</td>\n",
              "      <td>0.000205</td>\n",
              "      <td>5.280611e-04</td>\n",
              "      <td>0.024513</td>\n",
              "      <td>0.008943</td>\n",
              "      <td>-0.004330</td>\n",
              "      <td>-0.004292</td>\n",
              "      <td>0.000315</td>\n",
              "      <td>-0.003702</td>\n",
              "      <td>-0.010561</td>\n",
              "      <td>-0.005134</td>\n",
              "      <td>-0.000358</td>\n",
              "      <td>-0.001571</td>\n",
              "      <td>-0.011597</td>\n",
              "      <td>0.038311</td>\n",
              "      <td>-0.006310</td>\n",
              "      <td>0.022169</td>\n",
              "      <td>0.003922</td>\n",
              "      <td>-0.017996</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.003915</td>\n",
              "      <td>-0.003045</td>\n",
              "      <td>-0.002637</td>\n",
              "      <td>-0.003337</td>\n",
              "      <td>-0.002889</td>\n",
              "      <td>-0.001712</td>\n",
              "      <td>-0.003337</td>\n",
              "      <td>-0.003337</td>\n",
              "      <td>-0.001800</td>\n",
              "      <td>-0.003974</td>\n",
              "      <td>-0.001884</td>\n",
              "      <td>-0.002779</td>\n",
              "      <td>-0.002422</td>\n",
              "      <td>-0.000393</td>\n",
              "      <td>-0.001111</td>\n",
              "      <td>-0.001303</td>\n",
              "      <td>-0.001242</td>\n",
              "      <td>-0.003218</td>\n",
              "      <td>-0.002325</td>\n",
              "      <td>-0.001712</td>\n",
              "      <td>-0.002915</td>\n",
              "      <td>-0.002994</td>\n",
              "      <td>-0.002723</td>\n",
              "      <td>-0.001111</td>\n",
              "      <td>-0.008760</td>\n",
              "      <td>-0.001964</td>\n",
              "      <td>-0.001111</td>\n",
              "      <td>-0.001884</td>\n",
              "      <td>-0.004840</td>\n",
              "      <td>-0.002751</td>\n",
              "      <td>-0.002079</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.001178</td>\n",
              "      <td>-0.003145</td>\n",
              "      <td>-0.002547</td>\n",
              "      <td>-0.001521</td>\n",
              "      <td>-0.001361</td>\n",
              "      <td>-0.183064</td>\n",
              "      <td>-2.779398e-03</td>\n",
              "      <td>-0.001303</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>c_Scotland</th>\n",
              "      <td>-0.000379</td>\n",
              "      <td>-0.002379</td>\n",
              "      <td>-0.003078</td>\n",
              "      <td>-0.004547</td>\n",
              "      <td>-0.002759</td>\n",
              "      <td>-0.004091</td>\n",
              "      <td>-0.004058</td>\n",
              "      <td>-0.005704</td>\n",
              "      <td>-0.004620</td>\n",
              "      <td>-0.003337</td>\n",
              "      <td>-0.005002</td>\n",
              "      <td>-0.000268</td>\n",
              "      <td>0.007978</td>\n",
              "      <td>-0.003575</td>\n",
              "      <td>-0.005563</td>\n",
              "      <td>0.006937</td>\n",
              "      <td>-0.000360</td>\n",
              "      <td>-0.004629</td>\n",
              "      <td>-0.000462</td>\n",
              "      <td>-0.000318</td>\n",
              "      <td>-0.007169</td>\n",
              "      <td>0.005705</td>\n",
              "      <td>-0.003376</td>\n",
              "      <td>-3.873681e-03</td>\n",
              "      <td>0.012706</td>\n",
              "      <td>0.007519</td>\n",
              "      <td>-0.001323</td>\n",
              "      <td>-0.000916</td>\n",
              "      <td>0.012298</td>\n",
              "      <td>-0.006760</td>\n",
              "      <td>-0.003228</td>\n",
              "      <td>-0.004313</td>\n",
              "      <td>0.004676</td>\n",
              "      <td>-0.000480</td>\n",
              "      <td>-0.000503</td>\n",
              "      <td>-0.002188</td>\n",
              "      <td>-0.004313</td>\n",
              "      <td>0.008664</td>\n",
              "      <td>-0.003381</td>\n",
              "      <td>-0.006978</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.001197</td>\n",
              "      <td>-0.000931</td>\n",
              "      <td>-0.000806</td>\n",
              "      <td>-0.001020</td>\n",
              "      <td>-0.000883</td>\n",
              "      <td>-0.000523</td>\n",
              "      <td>-0.001020</td>\n",
              "      <td>-0.001020</td>\n",
              "      <td>-0.000550</td>\n",
              "      <td>-0.001215</td>\n",
              "      <td>-0.000576</td>\n",
              "      <td>-0.000850</td>\n",
              "      <td>-0.000740</td>\n",
              "      <td>-0.000120</td>\n",
              "      <td>-0.000340</td>\n",
              "      <td>-0.000398</td>\n",
              "      <td>-0.000380</td>\n",
              "      <td>-0.000984</td>\n",
              "      <td>-0.000711</td>\n",
              "      <td>-0.000523</td>\n",
              "      <td>-0.000891</td>\n",
              "      <td>-0.000915</td>\n",
              "      <td>-0.000832</td>\n",
              "      <td>-0.000340</td>\n",
              "      <td>-0.002678</td>\n",
              "      <td>-0.000600</td>\n",
              "      <td>-0.000340</td>\n",
              "      <td>-0.000576</td>\n",
              "      <td>-0.001479</td>\n",
              "      <td>-0.000841</td>\n",
              "      <td>-0.000635</td>\n",
              "      <td>-0.001178</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.000961</td>\n",
              "      <td>-0.000778</td>\n",
              "      <td>-0.000465</td>\n",
              "      <td>-0.000416</td>\n",
              "      <td>-0.055954</td>\n",
              "      <td>-8.495309e-04</td>\n",
              "      <td>-0.000398</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>c_South</th>\n",
              "      <td>0.004694</td>\n",
              "      <td>-0.009925</td>\n",
              "      <td>0.016651</td>\n",
              "      <td>-0.006347</td>\n",
              "      <td>0.008449</td>\n",
              "      <td>0.012681</td>\n",
              "      <td>0.009392</td>\n",
              "      <td>-0.000592</td>\n",
              "      <td>0.015218</td>\n",
              "      <td>-0.004269</td>\n",
              "      <td>-0.013353</td>\n",
              "      <td>-0.000717</td>\n",
              "      <td>-0.021509</td>\n",
              "      <td>0.012208</td>\n",
              "      <td>0.037937</td>\n",
              "      <td>-0.010303</td>\n",
              "      <td>-0.000961</td>\n",
              "      <td>0.015148</td>\n",
              "      <td>-0.011285</td>\n",
              "      <td>-0.000848</td>\n",
              "      <td>-0.002376</td>\n",
              "      <td>0.007474</td>\n",
              "      <td>-0.009013</td>\n",
              "      <td>-6.301669e-03</td>\n",
              "      <td>-0.006369</td>\n",
              "      <td>0.003813</td>\n",
              "      <td>-0.003533</td>\n",
              "      <td>-0.000335</td>\n",
              "      <td>-0.007259</td>\n",
              "      <td>0.019517</td>\n",
              "      <td>-0.008617</td>\n",
              "      <td>-0.007852</td>\n",
              "      <td>-0.006423</td>\n",
              "      <td>-0.001282</td>\n",
              "      <td>0.004308</td>\n",
              "      <td>0.008072</td>\n",
              "      <td>-0.001779</td>\n",
              "      <td>-0.009128</td>\n",
              "      <td>0.009313</td>\n",
              "      <td>-0.002847</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.003194</td>\n",
              "      <td>-0.002485</td>\n",
              "      <td>-0.002151</td>\n",
              "      <td>-0.002723</td>\n",
              "      <td>-0.002357</td>\n",
              "      <td>-0.001397</td>\n",
              "      <td>-0.002723</td>\n",
              "      <td>-0.002723</td>\n",
              "      <td>-0.001469</td>\n",
              "      <td>-0.003243</td>\n",
              "      <td>-0.001537</td>\n",
              "      <td>-0.002268</td>\n",
              "      <td>-0.001977</td>\n",
              "      <td>-0.000320</td>\n",
              "      <td>-0.000906</td>\n",
              "      <td>-0.001063</td>\n",
              "      <td>-0.001013</td>\n",
              "      <td>-0.002626</td>\n",
              "      <td>-0.001897</td>\n",
              "      <td>-0.001397</td>\n",
              "      <td>-0.002379</td>\n",
              "      <td>-0.002443</td>\n",
              "      <td>-0.002222</td>\n",
              "      <td>-0.000906</td>\n",
              "      <td>-0.007148</td>\n",
              "      <td>-0.001603</td>\n",
              "      <td>-0.000906</td>\n",
              "      <td>-0.001537</td>\n",
              "      <td>-0.003949</td>\n",
              "      <td>-0.002245</td>\n",
              "      <td>-0.001696</td>\n",
              "      <td>-0.003145</td>\n",
              "      <td>-0.000961</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.002078</td>\n",
              "      <td>-0.001241</td>\n",
              "      <td>-0.001110</td>\n",
              "      <td>-0.149375</td>\n",
              "      <td>-2.267913e-03</td>\n",
              "      <td>-0.001063</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>c_Taiwan</th>\n",
              "      <td>-0.015448</td>\n",
              "      <td>-0.001430</td>\n",
              "      <td>0.055609</td>\n",
              "      <td>0.001927</td>\n",
              "      <td>0.008321</td>\n",
              "      <td>0.005565</td>\n",
              "      <td>-0.001518</td>\n",
              "      <td>0.018191</td>\n",
              "      <td>0.028258</td>\n",
              "      <td>-0.007214</td>\n",
              "      <td>-0.002886</td>\n",
              "      <td>-0.000580</td>\n",
              "      <td>-0.021661</td>\n",
              "      <td>0.019112</td>\n",
              "      <td>-0.008406</td>\n",
              "      <td>0.021664</td>\n",
              "      <td>-0.000778</td>\n",
              "      <td>0.028175</td>\n",
              "      <td>-0.009044</td>\n",
              "      <td>-0.000687</td>\n",
              "      <td>-0.015496</td>\n",
              "      <td>0.008372</td>\n",
              "      <td>-0.007298</td>\n",
              "      <td>-8.373637e-03</td>\n",
              "      <td>-0.010496</td>\n",
              "      <td>-0.013841</td>\n",
              "      <td>-0.002861</td>\n",
              "      <td>0.042967</td>\n",
              "      <td>-0.005878</td>\n",
              "      <td>-0.005343</td>\n",
              "      <td>-0.006978</td>\n",
              "      <td>-0.009324</td>\n",
              "      <td>-0.016372</td>\n",
              "      <td>-0.001038</td>\n",
              "      <td>0.009369</td>\n",
              "      <td>0.003854</td>\n",
              "      <td>0.006615</td>\n",
              "      <td>-0.007391</td>\n",
              "      <td>-0.007308</td>\n",
              "      <td>0.006159</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.002587</td>\n",
              "      <td>-0.002012</td>\n",
              "      <td>-0.001742</td>\n",
              "      <td>-0.002205</td>\n",
              "      <td>-0.001909</td>\n",
              "      <td>-0.001131</td>\n",
              "      <td>-0.002205</td>\n",
              "      <td>-0.002205</td>\n",
              "      <td>-0.001189</td>\n",
              "      <td>-0.002626</td>\n",
              "      <td>-0.001245</td>\n",
              "      <td>-0.001836</td>\n",
              "      <td>-0.001601</td>\n",
              "      <td>-0.000259</td>\n",
              "      <td>-0.000734</td>\n",
              "      <td>-0.000861</td>\n",
              "      <td>-0.000821</td>\n",
              "      <td>-0.002127</td>\n",
              "      <td>-0.001536</td>\n",
              "      <td>-0.001131</td>\n",
              "      <td>-0.001926</td>\n",
              "      <td>-0.001978</td>\n",
              "      <td>-0.001799</td>\n",
              "      <td>-0.000734</td>\n",
              "      <td>-0.005788</td>\n",
              "      <td>-0.001298</td>\n",
              "      <td>-0.000734</td>\n",
              "      <td>-0.001245</td>\n",
              "      <td>-0.003198</td>\n",
              "      <td>-0.001818</td>\n",
              "      <td>-0.001374</td>\n",
              "      <td>-0.002547</td>\n",
              "      <td>-0.000778</td>\n",
              "      <td>-0.002078</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.001005</td>\n",
              "      <td>-0.000899</td>\n",
              "      <td>-0.120954</td>\n",
              "      <td>-1.836409e-03</td>\n",
              "      <td>-0.000861</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>c_Thailand</th>\n",
              "      <td>-0.005979</td>\n",
              "      <td>-0.002753</td>\n",
              "      <td>0.006886</td>\n",
              "      <td>-0.010497</td>\n",
              "      <td>-0.003563</td>\n",
              "      <td>-0.005282</td>\n",
              "      <td>0.014196</td>\n",
              "      <td>-0.002260</td>\n",
              "      <td>0.001141</td>\n",
              "      <td>-0.004309</td>\n",
              "      <td>-0.006458</td>\n",
              "      <td>-0.000347</td>\n",
              "      <td>-0.012177</td>\n",
              "      <td>0.022317</td>\n",
              "      <td>0.010973</td>\n",
              "      <td>0.003381</td>\n",
              "      <td>-0.000465</td>\n",
              "      <td>0.001118</td>\n",
              "      <td>-0.003960</td>\n",
              "      <td>-0.000410</td>\n",
              "      <td>-0.004315</td>\n",
              "      <td>0.010678</td>\n",
              "      <td>-0.004359</td>\n",
              "      <td>-5.001501e-03</td>\n",
              "      <td>0.000533</td>\n",
              "      <td>0.013304</td>\n",
              "      <td>0.021828</td>\n",
              "      <td>-0.004451</td>\n",
              "      <td>0.008123</td>\n",
              "      <td>-0.008728</td>\n",
              "      <td>-0.004168</td>\n",
              "      <td>-0.005569</td>\n",
              "      <td>-0.005034</td>\n",
              "      <td>-0.000620</td>\n",
              "      <td>-0.002835</td>\n",
              "      <td>0.025886</td>\n",
              "      <td>-0.003251</td>\n",
              "      <td>-0.004415</td>\n",
              "      <td>0.014556</td>\n",
              "      <td>-0.006790</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.001545</td>\n",
              "      <td>-0.001202</td>\n",
              "      <td>-0.001040</td>\n",
              "      <td>-0.001317</td>\n",
              "      <td>-0.001140</td>\n",
              "      <td>-0.000676</td>\n",
              "      <td>-0.001317</td>\n",
              "      <td>-0.001317</td>\n",
              "      <td>-0.000710</td>\n",
              "      <td>-0.001568</td>\n",
              "      <td>-0.000744</td>\n",
              "      <td>-0.001097</td>\n",
              "      <td>-0.000956</td>\n",
              "      <td>-0.000155</td>\n",
              "      <td>-0.000438</td>\n",
              "      <td>-0.000514</td>\n",
              "      <td>-0.000490</td>\n",
              "      <td>-0.001270</td>\n",
              "      <td>-0.000917</td>\n",
              "      <td>-0.000676</td>\n",
              "      <td>-0.001151</td>\n",
              "      <td>-0.001182</td>\n",
              "      <td>-0.001075</td>\n",
              "      <td>-0.000438</td>\n",
              "      <td>-0.003457</td>\n",
              "      <td>-0.000775</td>\n",
              "      <td>-0.000438</td>\n",
              "      <td>-0.000744</td>\n",
              "      <td>-0.001910</td>\n",
              "      <td>-0.001086</td>\n",
              "      <td>-0.000820</td>\n",
              "      <td>-0.001521</td>\n",
              "      <td>-0.000465</td>\n",
              "      <td>-0.001241</td>\n",
              "      <td>-0.001005</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.000537</td>\n",
              "      <td>-0.072245</td>\n",
              "      <td>-1.096871e-03</td>\n",
              "      <td>-0.000514</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>c_Trinadad&amp;Tobago</th>\n",
              "      <td>0.007567</td>\n",
              "      <td>0.004747</td>\n",
              "      <td>-0.016410</td>\n",
              "      <td>-0.007837</td>\n",
              "      <td>-0.003186</td>\n",
              "      <td>0.014509</td>\n",
              "      <td>-0.003844</td>\n",
              "      <td>-0.008013</td>\n",
              "      <td>0.002610</td>\n",
              "      <td>-0.003854</td>\n",
              "      <td>-0.005776</td>\n",
              "      <td>-0.000310</td>\n",
              "      <td>0.002600</td>\n",
              "      <td>0.005908</td>\n",
              "      <td>0.000342</td>\n",
              "      <td>-0.004457</td>\n",
              "      <td>-0.000416</td>\n",
              "      <td>0.002586</td>\n",
              "      <td>0.003226</td>\n",
              "      <td>-0.000367</td>\n",
              "      <td>-0.002754</td>\n",
              "      <td>-0.008221</td>\n",
              "      <td>-0.003899</td>\n",
              "      <td>-4.473210e-03</td>\n",
              "      <td>0.017208</td>\n",
              "      <td>0.004664</td>\n",
              "      <td>-0.001528</td>\n",
              "      <td>-0.002885</td>\n",
              "      <td>-0.003140</td>\n",
              "      <td>-0.007806</td>\n",
              "      <td>0.018366</td>\n",
              "      <td>-0.004981</td>\n",
              "      <td>-0.003442</td>\n",
              "      <td>-0.000555</td>\n",
              "      <td>0.001863</td>\n",
              "      <td>-0.002527</td>\n",
              "      <td>0.000202</td>\n",
              "      <td>0.006517</td>\n",
              "      <td>-0.003904</td>\n",
              "      <td>0.000630</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.001382</td>\n",
              "      <td>-0.001075</td>\n",
              "      <td>-0.000931</td>\n",
              "      <td>-0.001178</td>\n",
              "      <td>-0.001020</td>\n",
              "      <td>-0.000604</td>\n",
              "      <td>-0.001178</td>\n",
              "      <td>-0.001178</td>\n",
              "      <td>-0.000635</td>\n",
              "      <td>-0.001403</td>\n",
              "      <td>-0.000665</td>\n",
              "      <td>-0.000981</td>\n",
              "      <td>-0.000855</td>\n",
              "      <td>-0.000139</td>\n",
              "      <td>-0.000392</td>\n",
              "      <td>-0.000460</td>\n",
              "      <td>-0.000438</td>\n",
              "      <td>-0.001136</td>\n",
              "      <td>-0.000821</td>\n",
              "      <td>-0.000604</td>\n",
              "      <td>-0.001029</td>\n",
              "      <td>-0.001057</td>\n",
              "      <td>-0.000961</td>\n",
              "      <td>-0.000392</td>\n",
              "      <td>-0.003092</td>\n",
              "      <td>-0.000693</td>\n",
              "      <td>-0.000392</td>\n",
              "      <td>-0.000665</td>\n",
              "      <td>-0.001708</td>\n",
              "      <td>-0.000971</td>\n",
              "      <td>-0.000734</td>\n",
              "      <td>-0.001361</td>\n",
              "      <td>-0.000416</td>\n",
              "      <td>-0.001110</td>\n",
              "      <td>-0.000899</td>\n",
              "      <td>-0.000537</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.064614</td>\n",
              "      <td>-9.810126e-04</td>\n",
              "      <td>-0.000460</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>c_United-States</th>\n",
              "      <td>0.014750</td>\n",
              "      <td>-0.075252</td>\n",
              "      <td>0.097154</td>\n",
              "      <td>-0.002877</td>\n",
              "      <td>0.003183</td>\n",
              "      <td>0.008887</td>\n",
              "      <td>0.003120</td>\n",
              "      <td>0.034922</td>\n",
              "      <td>0.003616</td>\n",
              "      <td>0.017245</td>\n",
              "      <td>0.034434</td>\n",
              "      <td>0.004797</td>\n",
              "      <td>-0.042450</td>\n",
              "      <td>-0.001873</td>\n",
              "      <td>0.011717</td>\n",
              "      <td>0.021842</td>\n",
              "      <td>0.006436</td>\n",
              "      <td>0.003905</td>\n",
              "      <td>0.025547</td>\n",
              "      <td>0.005676</td>\n",
              "      <td>0.004800</td>\n",
              "      <td>0.024852</td>\n",
              "      <td>-0.005244</td>\n",
              "      <td>-1.868317e-02</td>\n",
              "      <td>-0.045753</td>\n",
              "      <td>-0.056623</td>\n",
              "      <td>-0.071091</td>\n",
              "      <td>-0.003138</td>\n",
              "      <td>0.014882</td>\n",
              "      <td>0.026790</td>\n",
              "      <td>0.015529</td>\n",
              "      <td>0.030230</td>\n",
              "      <td>0.047502</td>\n",
              "      <td>0.008583</td>\n",
              "      <td>-0.007324</td>\n",
              "      <td>-0.118071</td>\n",
              "      <td>0.005735</td>\n",
              "      <td>-0.018023</td>\n",
              "      <td>0.005583</td>\n",
              "      <td>0.013462</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.185914</td>\n",
              "      <td>-0.144620</td>\n",
              "      <td>-0.125207</td>\n",
              "      <td>-0.158462</td>\n",
              "      <td>-0.137182</td>\n",
              "      <td>-0.081316</td>\n",
              "      <td>-0.158462</td>\n",
              "      <td>-0.158462</td>\n",
              "      <td>-0.085492</td>\n",
              "      <td>-0.188721</td>\n",
              "      <td>-0.089474</td>\n",
              "      <td>-0.131993</td>\n",
              "      <td>-0.115041</td>\n",
              "      <td>-0.018648</td>\n",
              "      <td>-0.052753</td>\n",
              "      <td>-0.061862</td>\n",
              "      <td>-0.058982</td>\n",
              "      <td>-0.152845</td>\n",
              "      <td>-0.110400</td>\n",
              "      <td>-0.081316</td>\n",
              "      <td>-0.138450</td>\n",
              "      <td>-0.142184</td>\n",
              "      <td>-0.129321</td>\n",
              "      <td>-0.052753</td>\n",
              "      <td>-0.416028</td>\n",
              "      <td>-0.093287</td>\n",
              "      <td>-0.052753</td>\n",
              "      <td>-0.089474</td>\n",
              "      <td>-0.229845</td>\n",
              "      <td>-0.130664</td>\n",
              "      <td>-0.098731</td>\n",
              "      <td>-0.183064</td>\n",
              "      <td>-0.055954</td>\n",
              "      <td>-0.149375</td>\n",
              "      <td>-0.120954</td>\n",
              "      <td>-0.072245</td>\n",
              "      <td>-0.064614</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-1.319932e-01</td>\n",
              "      <td>-0.061862</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>c_Vietnam</th>\n",
              "      <td>-0.013497</td>\n",
              "      <td>-0.010839</td>\n",
              "      <td>-0.012280</td>\n",
              "      <td>-0.004598</td>\n",
              "      <td>-0.003567</td>\n",
              "      <td>0.003401</td>\n",
              "      <td>-0.010146</td>\n",
              "      <td>-0.020916</td>\n",
              "      <td>-0.007004</td>\n",
              "      <td>-0.002624</td>\n",
              "      <td>-0.000901</td>\n",
              "      <td>-0.000633</td>\n",
              "      <td>0.008229</td>\n",
              "      <td>-0.003513</td>\n",
              "      <td>0.000146</td>\n",
              "      <td>-0.004520</td>\n",
              "      <td>-0.000850</td>\n",
              "      <td>-0.007031</td>\n",
              "      <td>0.025025</td>\n",
              "      <td>-0.000749</td>\n",
              "      <td>0.004756</td>\n",
              "      <td>-0.011348</td>\n",
              "      <td>0.002419</td>\n",
              "      <td>4.230320e-16</td>\n",
              "      <td>0.007188</td>\n",
              "      <td>0.005586</td>\n",
              "      <td>-0.003122</td>\n",
              "      <td>-0.011716</td>\n",
              "      <td>-0.006415</td>\n",
              "      <td>-0.007449</td>\n",
              "      <td>0.003217</td>\n",
              "      <td>-0.006032</td>\n",
              "      <td>-0.007464</td>\n",
              "      <td>-0.001133</td>\n",
              "      <td>-0.006976</td>\n",
              "      <td>0.010575</td>\n",
              "      <td>0.016292</td>\n",
              "      <td>-0.008065</td>\n",
              "      <td>-0.007975</td>\n",
              "      <td>-0.007536</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.002823</td>\n",
              "      <td>-0.002196</td>\n",
              "      <td>-0.001901</td>\n",
              "      <td>-0.002406</td>\n",
              "      <td>-0.002083</td>\n",
              "      <td>-0.001235</td>\n",
              "      <td>-0.002406</td>\n",
              "      <td>-0.002406</td>\n",
              "      <td>-0.001298</td>\n",
              "      <td>-0.002865</td>\n",
              "      <td>-0.001358</td>\n",
              "      <td>-0.002004</td>\n",
              "      <td>-0.001747</td>\n",
              "      <td>-0.000283</td>\n",
              "      <td>-0.000801</td>\n",
              "      <td>-0.000939</td>\n",
              "      <td>-0.000896</td>\n",
              "      <td>-0.002321</td>\n",
              "      <td>-0.001676</td>\n",
              "      <td>-0.001235</td>\n",
              "      <td>-0.002102</td>\n",
              "      <td>-0.002159</td>\n",
              "      <td>-0.001963</td>\n",
              "      <td>-0.000801</td>\n",
              "      <td>-0.006316</td>\n",
              "      <td>-0.001416</td>\n",
              "      <td>-0.000801</td>\n",
              "      <td>-0.001358</td>\n",
              "      <td>-0.003490</td>\n",
              "      <td>-0.001984</td>\n",
              "      <td>-0.001499</td>\n",
              "      <td>-0.002779</td>\n",
              "      <td>-0.000850</td>\n",
              "      <td>-0.002268</td>\n",
              "      <td>-0.001836</td>\n",
              "      <td>-0.001097</td>\n",
              "      <td>-0.000981</td>\n",
              "      <td>-0.131993</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>-0.000939</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>c_Yugoslavia</th>\n",
              "      <td>0.002971</td>\n",
              "      <td>-0.003121</td>\n",
              "      <td>-0.001414</td>\n",
              "      <td>0.002625</td>\n",
              "      <td>-0.001635</td>\n",
              "      <td>-0.004523</td>\n",
              "      <td>0.001631</td>\n",
              "      <td>0.006111</td>\n",
              "      <td>-0.005108</td>\n",
              "      <td>-0.003690</td>\n",
              "      <td>0.002209</td>\n",
              "      <td>-0.000297</td>\n",
              "      <td>0.005597</td>\n",
              "      <td>-0.003953</td>\n",
              "      <td>0.000916</td>\n",
              "      <td>-0.004267</td>\n",
              "      <td>-0.000398</td>\n",
              "      <td>-0.005118</td>\n",
              "      <td>-0.001820</td>\n",
              "      <td>-0.000351</td>\n",
              "      <td>-0.002156</td>\n",
              "      <td>0.003730</td>\n",
              "      <td>0.007328</td>\n",
              "      <td>-4.282686e-03</td>\n",
              "      <td>0.010518</td>\n",
              "      <td>0.018108</td>\n",
              "      <td>-0.001463</td>\n",
              "      <td>-0.008010</td>\n",
              "      <td>-0.003006</td>\n",
              "      <td>-0.007474</td>\n",
              "      <td>-0.003569</td>\n",
              "      <td>-0.004769</td>\n",
              "      <td>-0.002833</td>\n",
              "      <td>-0.000531</td>\n",
              "      <td>0.011355</td>\n",
              "      <td>-0.002419</td>\n",
              "      <td>-0.006572</td>\n",
              "      <td>-0.003780</td>\n",
              "      <td>-0.003738</td>\n",
              "      <td>0.010003</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.001323</td>\n",
              "      <td>-0.001029</td>\n",
              "      <td>-0.000891</td>\n",
              "      <td>-0.001128</td>\n",
              "      <td>-0.000976</td>\n",
              "      <td>-0.000579</td>\n",
              "      <td>-0.001128</td>\n",
              "      <td>-0.001128</td>\n",
              "      <td>-0.000608</td>\n",
              "      <td>-0.001343</td>\n",
              "      <td>-0.000637</td>\n",
              "      <td>-0.000939</td>\n",
              "      <td>-0.000819</td>\n",
              "      <td>-0.000133</td>\n",
              "      <td>-0.000375</td>\n",
              "      <td>-0.000440</td>\n",
              "      <td>-0.000420</td>\n",
              "      <td>-0.001088</td>\n",
              "      <td>-0.000786</td>\n",
              "      <td>-0.000579</td>\n",
              "      <td>-0.000985</td>\n",
              "      <td>-0.001012</td>\n",
              "      <td>-0.000920</td>\n",
              "      <td>-0.000375</td>\n",
              "      <td>-0.002960</td>\n",
              "      <td>-0.000664</td>\n",
              "      <td>-0.000375</td>\n",
              "      <td>-0.000637</td>\n",
              "      <td>-0.001636</td>\n",
              "      <td>-0.000930</td>\n",
              "      <td>-0.000703</td>\n",
              "      <td>-0.001303</td>\n",
              "      <td>-0.000398</td>\n",
              "      <td>-0.001063</td>\n",
              "      <td>-0.000861</td>\n",
              "      <td>-0.000514</td>\n",
              "      <td>-0.000460</td>\n",
              "      <td>-0.061862</td>\n",
              "      <td>-9.392293e-04</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>92 rows × 92 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                   age  demogweight  ...     c_Vietnam  c_Yugoslavia\n",
              "age                           1.000000    -0.075810  ... -1.349745e-02      0.002971\n",
              "demogweight                  -0.075810     1.000000  ... -1.083933e-02     -0.003121\n",
              "education-num                 0.032765    -0.043853  ... -1.228039e-02     -0.001414\n",
              "sex                           0.084250     0.029492  ... -4.598300e-03      0.002625\n",
              "capital-gain                  0.073591     0.004366  ... -3.567427e-03     -0.001635\n",
              "capital-loss                  0.056408    -0.012152  ...  3.400600e-03     -0.004523\n",
              "hours-per-week                0.069045    -0.015179  ... -1.014576e-02      0.001631\n",
              "income                        0.230700    -0.008029  ... -2.091570e-02      0.006111\n",
              "w_?                           0.036401    -0.000828  ... -7.003826e-03     -0.005108\n",
              "w_Federal-gov                 0.046560    -0.011089  ... -2.624238e-03     -0.003690\n",
              "w_Local-gov                   0.063846    -0.002865  ... -9.009347e-04      0.002209\n",
              "w_Never-worked               -0.020054     0.008137  ... -6.331523e-04     -0.000297\n",
              "w_Private                    -0.195954     0.037964  ...  8.228824e-03      0.005597\n",
              "w_Self-emp-inc                0.105089    -0.024646  ... -3.513435e-03     -0.003953\n",
              "w_Self-emp-not-inc            0.135998    -0.030783  ...  1.459445e-04      0.000916\n",
              "w_State-gov                   0.012933    -0.010128  ... -4.520152e-03     -0.004267\n",
              "w_Without-pay                 0.003626    -0.001468  ... -8.495309e-04     -0.000398\n",
              "o_?                           0.035108    -0.000327  ... -7.030973e-03     -0.005118\n",
              "o_Adm-clerical               -0.043545     0.002274  ...  2.502458e-02     -0.001820\n",
              "o_Armed-Forces               -0.011746     0.002097  ... -7.491858e-04     -0.000351\n",
              "o_Craft-repair                0.012166     0.010296  ...  4.755804e-03     -0.002156\n",
              "o_Exec-managerial             0.097187    -0.017099  ... -1.134775e-02      0.003730\n",
              "o_Farming-fishing             0.032172    -0.030834  ...  2.419382e-03      0.007328\n",
              "o_Handlers-cleaners          -0.100066     0.027499  ...  4.230320e-16     -0.004283\n",
              "o_Machine-op-inspct          -0.012148     0.016231  ...  7.188365e-03      0.010518\n",
              "o_Other-service              -0.083478    -0.005282  ...  5.586326e-03      0.018108\n",
              "o_Priv-house-serv             0.018551     0.011137  ... -3.121950e-03     -0.001463\n",
              "o_Prof-specialty              0.048809    -0.018223  ... -1.171562e-02     -0.008010\n",
              "o_Protective-serv             0.003741     0.017104  ... -6.414714e-03     -0.003006\n",
              "o_Sales                      -0.024984     0.007688  ... -7.449147e-03     -0.007474\n",
              "o_Tech-support               -0.022003    -0.000041  ...  3.217008e-03     -0.003569\n",
              "o_Transport-moving            0.027554    -0.001721  ... -6.031830e-03     -0.004769\n",
              "m_Divorced                    0.129938    -0.018035  ... -7.463861e-03     -0.002833\n",
              "m_Married-AF-spouse          -0.010366     0.002586  ... -1.132866e-03     -0.000531\n",
              "m_Married-civ-spouse          0.312885    -0.023808  ... -6.976369e-03      0.011355\n",
              "m_Married-spouse-absent       0.020570     0.003888  ...  1.057499e-02     -0.002419\n",
              "m_Never-married              -0.532415     0.035494  ...  1.629246e-02     -0.006572\n",
              "m_Separated                   0.006732     0.029382  ... -8.065434e-03     -0.003780\n",
              "m_Widowed                     0.268079    -0.024567  ... -7.974936e-03     -0.003738\n",
              "r_Husband                     0.313163    -0.019162  ... -7.536279e-03      0.010003\n",
              "r_Not-in-family              -0.010713     0.003392  ... -7.954714e-03     -0.008002\n",
              "r_Other-relative             -0.060138     0.025574  ...  2.416903e-02     -0.003636\n",
              "r_Own-child                  -0.432241     0.013083  ...  4.387002e-04      0.001466\n",
              "r_Unmarried                   0.044975     0.006629  ...  1.083739e-02     -0.007209\n",
              "r_Wife                        0.020590    -0.014796  ... -1.775126e-03      0.004139\n",
              "race_Amer-Indian-Eskimo      -0.011074    -0.070516  ... -4.416637e-03     -0.002070\n",
              "race_Asian-Pac-Islander      -0.005739    -0.051432  ...  2.451169e-01     -0.003753\n",
              "race_Black                   -0.020923     0.120882  ... -1.451747e-02     -0.006804\n",
              "race_Other                   -0.035494     0.009401  ... -4.159617e-03     -0.001950\n",
              "race_White                    0.032681    -0.058423  ... -1.064388e-01      0.008618\n",
              "c_?                           0.000683     0.005641  ... -6.026425e-03     -0.002824\n",
              "c_Cambodia                   -0.005051     0.000635  ... -1.132866e-03     -0.000531\n",
              "c_Canada                      0.020935    -0.010107  ... -2.822662e-03     -0.001323\n",
              "c_China                       0.015862    -0.008856  ... -2.195721e-03     -0.001029\n",
              "c_Columbia                   -0.000435     0.006546  ... -1.900978e-03     -0.000891\n",
              "c_Cuba                        0.030883     0.030293  ... -2.405871e-03     -0.001128\n",
              "c_Dominican-Republic         -0.003007     0.003193  ... -2.082793e-03     -0.000976\n",
              "c_Ecuador                     0.003761     0.002033  ... -1.234587e-03     -0.000579\n",
              "c_El-Salvador                -0.018907     0.034100  ... -2.405871e-03     -0.001128\n",
              "c_England                     0.012232    -0.000818  ... -2.405871e-03     -0.001128\n",
              "c_France                     -0.002093     0.002485  ... -1.297992e-03     -0.000608\n",
              "c_Germany                    -0.000408    -0.005904  ... -2.865283e-03     -0.001343\n",
              "c_Greece                      0.019861    -0.013729  ... -1.358450e-03     -0.000637\n",
              "c_Guatemala                  -0.021609     0.035315  ... -2.004008e-03     -0.000939\n",
              "c_Haiti                      -0.000155     0.008835  ... -1.746634e-03     -0.000819\n",
              "c_Holand-Netherlands         -0.003053    -0.009723  ... -2.831316e-04     -0.000133\n",
              "c_Honduras                   -0.002917     0.009367  ... -8.009294e-04     -0.000375\n",
              "c_Hong                       -0.003160     0.006459  ... -9.392293e-04     -0.000440\n",
              "c_Hungary                     0.014166    -0.002536  ... -8.955021e-04     -0.000420\n",
              "c_India                       0.000923    -0.007650  ... -2.320598e-03     -0.001088\n",
              "c_Iran                        0.000606     0.000441  ... -1.676170e-03     -0.000786\n",
              "c_Ireland                    -0.002177    -0.014243  ... -1.234587e-03     -0.000579\n",
              "c_Italy                       0.025300    -0.000030  ... -2.102032e-03     -0.000985\n",
              "c_Jamaica                    -0.013133     0.010710  ... -2.158729e-03     -0.001012\n",
              "c_Japan                      -0.001477    -0.000894  ... -1.963440e-03     -0.000920\n",
              "c_Laos                       -0.006675     0.004573  ... -8.009294e-04     -0.000375\n",
              "c_Mexico                     -0.055328     0.135171  ... -6.316409e-03     -0.002960\n",
              "c_Nicaragua                  -0.013977     0.042862  ... -1.416338e-03     -0.000664\n",
              "c_Outlying-US(Guam-USVI-etc) -0.001447     0.000079  ... -8.009294e-04     -0.000375\n",
              "c_Peru                       -0.008189     0.024041  ... -1.358450e-03     -0.000637\n",
              "c_Philippines                 0.006123    -0.018450  ... -3.489665e-03     -0.001636\n",
              "c_Poland                      0.008739     0.000162  ... -1.983827e-03     -0.000930\n",
              "c_Portugal                   -0.001048    -0.014834  ... -1.499002e-03     -0.000703\n",
              "c_Puerto-Rico                 0.009957     0.006168  ... -2.779398e-03     -0.001303\n",
              "c_Scotland                   -0.000379    -0.002379  ... -8.495309e-04     -0.000398\n",
              "c_South                       0.004694    -0.009925  ... -2.267913e-03     -0.001063\n",
              "c_Taiwan                     -0.015448    -0.001430  ... -1.836409e-03     -0.000861\n",
              "c_Thailand                   -0.005979    -0.002753  ... -1.096871e-03     -0.000514\n",
              "c_Trinadad&Tobago             0.007567     0.004747  ... -9.810126e-04     -0.000460\n",
              "c_United-States               0.014750    -0.075252  ... -1.319932e-01     -0.061862\n",
              "c_Vietnam                    -0.013497    -0.010839  ...  1.000000e+00     -0.000939\n",
              "c_Yugoslavia                  0.002971    -0.003121  ... -9.392293e-04      1.000000\n",
              "\n",
              "[92 rows x 92 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bn2fq7iYGvJB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b48f8b73-1157-4d87-a8a7-d603a8fbc59a"
      },
      "source": [
        "df.columns"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['age', 'demogweight', 'education-num', 'sex', 'capital-gain',\n",
              "       'capital-loss', 'hours-per-week', 'income', 'w_?', 'w_Federal-gov',\n",
              "       'w_Local-gov', 'w_Never-worked', 'w_Private', 'w_Self-emp-inc',\n",
              "       'w_Self-emp-not-inc', 'w_State-gov', 'w_Without-pay', 'o_?',\n",
              "       'o_Adm-clerical', 'o_Armed-Forces', 'o_Craft-repair',\n",
              "       'o_Exec-managerial', 'o_Farming-fishing', 'o_Handlers-cleaners',\n",
              "       'o_Machine-op-inspct', 'o_Other-service', 'o_Priv-house-serv',\n",
              "       'o_Prof-specialty', 'o_Protective-serv', 'o_Sales', 'o_Tech-support',\n",
              "       'o_Transport-moving', 'm_Divorced', 'm_Married-AF-spouse',\n",
              "       'm_Married-civ-spouse', 'm_Married-spouse-absent', 'm_Never-married',\n",
              "       'm_Separated', 'm_Widowed', 'r_Husband', 'r_Not-in-family',\n",
              "       'r_Other-relative', 'r_Own-child', 'r_Unmarried', 'r_Wife',\n",
              "       'race_Amer-Indian-Eskimo', 'race_Asian-Pac-Islander', 'race_Black',\n",
              "       'race_Other', 'race_White', 'c_?', 'c_Cambodia', 'c_Canada', 'c_China',\n",
              "       'c_Columbia', 'c_Cuba', 'c_Dominican-Republic', 'c_Ecuador',\n",
              "       'c_El-Salvador', 'c_England', 'c_France', 'c_Germany', 'c_Greece',\n",
              "       'c_Guatemala', 'c_Haiti', 'c_Holand-Netherlands', 'c_Honduras',\n",
              "       'c_Hong', 'c_Hungary', 'c_India', 'c_Iran', 'c_Ireland', 'c_Italy',\n",
              "       'c_Jamaica', 'c_Japan', 'c_Laos', 'c_Mexico', 'c_Nicaragua',\n",
              "       'c_Outlying-US(Guam-USVI-etc)', 'c_Peru', 'c_Philippines', 'c_Poland',\n",
              "       'c_Portugal', 'c_Puerto-Rico', 'c_Scotland', 'c_South', 'c_Taiwan',\n",
              "       'c_Thailand', 'c_Trinadad&Tobago', 'c_United-States', 'c_Vietnam',\n",
              "       'c_Yugoslavia'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lvzOp_mXbYB4"
      },
      "source": [
        "Parameter Tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9l9QsruJGvJC"
      },
      "source": [
        "# setting\n",
        "seed = 7\n",
        "num_folds = 10\n",
        "kfold = KFold(n_splits=num_folds, shuffle=True, random_state=seed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jQg0eJRRGvJC"
      },
      "source": [
        "# create model\n",
        "def create_model(neurons,learning_rate):\n",
        "    model = Sequential()\n",
        "    \n",
        "    # hidden layers\n",
        "    model.add(Dense(neurons, input_dim=91, kernel_initializer='uniform', activation='relu'))\n",
        "    model.add(Dense(20, kernel_initializer='uniform', activation='relu'))\n",
        "    \n",
        "    # output layer\n",
        "    model.add(Dense(1, kernel_initializer='uniform', activation='sigmoid'))\n",
        "    \n",
        "    adam = keras.optimizers.Adam(lr = learning_rate)\n",
        "    model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
        "    \n",
        "    return model\n",
        "\n",
        "model = KerasClassifier(build_fn=create_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9smKBmL4GvJC"
      },
      "source": [
        "# full model\n",
        "X = df.drop(columns=['income'])\n",
        "y = df['income']\n",
        "\n",
        "# split the data into training and test datasets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=seed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GpCMk0OwOerI"
      },
      "source": [
        "# simple early stopping\r\n",
        "import keras\r\n",
        "es = EarlyStopping(monitor='val_loss', mode='min', patience=5)\r\n",
        "mc = ModelCheckpoint('best_model.h5', monitor='val_accuracy', mode='max', save_best_only=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hCAPmir9GvJD",
        "scrolled": true,
        "outputId": "a423e29a-2692-4910-c751-3abd5d277dc0"
      },
      "source": [
        "# grid search neurons, epochs, and batch size\n",
        "param_grid = {\n",
        "    'neurons': [60,80,100], \n",
        "    'epochs': [50, 100], \n",
        "    'batch_size': [5,10],\n",
        "    'learning_rate': [0.001,0.01]\n",
        "}\n",
        "\n",
        "grid = GridSearchCV(estimator=model, param_grid=param_grid, cv=kfold)\n",
        "grid_result = grid.fit(X_train, y_train, validation_data=(X_test, y_test), callbacks=[es, mc], verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Epoch 1/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.4296 - accuracy: 0.7994 - val_loss: 0.3638 - val_accuracy: 0.8322\n",
            "Epoch 2/50\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3548 - accuracy: 0.8303 - val_loss: 0.3356 - val_accuracy: 0.8465\n",
            "Epoch 3/50\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3330 - accuracy: 0.8451 - val_loss: 0.3259 - val_accuracy: 0.8529\n",
            "Epoch 4/50\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3221 - accuracy: 0.8487 - val_loss: 0.3264 - val_accuracy: 0.8491\n",
            "Epoch 5/50\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3225 - accuracy: 0.8460 - val_loss: 0.3242 - val_accuracy: 0.8516\n",
            "Epoch 6/50\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3039 - accuracy: 0.8577 - val_loss: 0.3234 - val_accuracy: 0.8528\n",
            "Epoch 7/50\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3016 - accuracy: 0.8598 - val_loss: 0.3223 - val_accuracy: 0.8532\n",
            "Epoch 8/50\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3104 - accuracy: 0.8552 - val_loss: 0.3264 - val_accuracy: 0.8503\n",
            "Epoch 9/50\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.2965 - accuracy: 0.8617 - val_loss: 0.3256 - val_accuracy: 0.8539\n",
            "Epoch 10/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3026 - accuracy: 0.8591 - val_loss: 0.3307 - val_accuracy: 0.8478\n",
            "Epoch 11/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.2971 - accuracy: 0.8601 - val_loss: 0.3297 - val_accuracy: 0.8526\n",
            "Epoch 12/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.2924 - accuracy: 0.8635 - val_loss: 0.3316 - val_accuracy: 0.8518\n",
            "300/300 [==============================] - 0s 1ms/step - loss: 0.3283 - accuracy: 0.8593\n",
            "Epoch 1/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.4293 - accuracy: 0.7988 - val_loss: 0.3488 - val_accuracy: 0.8411\n",
            "Epoch 2/50\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3411 - accuracy: 0.8420 - val_loss: 0.3303 - val_accuracy: 0.8471\n",
            "Epoch 3/50\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3236 - accuracy: 0.8435 - val_loss: 0.3260 - val_accuracy: 0.8501\n",
            "Epoch 4/50\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3212 - accuracy: 0.8472 - val_loss: 0.3290 - val_accuracy: 0.8440\n",
            "Epoch 5/50\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3110 - accuracy: 0.8547 - val_loss: 0.3245 - val_accuracy: 0.8531\n",
            "Epoch 6/50\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3156 - accuracy: 0.8507 - val_loss: 0.3388 - val_accuracy: 0.8450\n",
            "Epoch 7/50\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3131 - accuracy: 0.8528 - val_loss: 0.3275 - val_accuracy: 0.8524\n",
            "Epoch 8/50\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3047 - accuracy: 0.8587 - val_loss: 0.3246 - val_accuracy: 0.8505\n",
            "Epoch 9/50\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3002 - accuracy: 0.8580 - val_loss: 0.3351 - val_accuracy: 0.8480\n",
            "Epoch 10/50\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3042 - accuracy: 0.8556 - val_loss: 0.3243 - val_accuracy: 0.8528\n",
            "Epoch 11/50\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.2993 - accuracy: 0.8563 - val_loss: 0.3251 - val_accuracy: 0.8506\n",
            "Epoch 12/50\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.2914 - accuracy: 0.8631 - val_loss: 0.3302 - val_accuracy: 0.8519\n",
            "Epoch 13/50\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.2919 - accuracy: 0.8653 - val_loss: 0.3273 - val_accuracy: 0.8507\n",
            "Epoch 14/50\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.2913 - accuracy: 0.8623 - val_loss: 0.3401 - val_accuracy: 0.8450\n",
            "Epoch 15/50\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.2964 - accuracy: 0.8600 - val_loss: 0.3408 - val_accuracy: 0.8527\n",
            "300/300 [==============================] - 0s 1ms/step - loss: 0.3216 - accuracy: 0.8540\n",
            "Epoch 1/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.4268 - accuracy: 0.7972 - val_loss: 0.3427 - val_accuracy: 0.8437\n",
            "Epoch 2/50\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3365 - accuracy: 0.8429 - val_loss: 0.3380 - val_accuracy: 0.8413\n",
            "Epoch 3/50\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3328 - accuracy: 0.8432 - val_loss: 0.3257 - val_accuracy: 0.8502\n",
            "Epoch 4/50\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3179 - accuracy: 0.8557 - val_loss: 0.3217 - val_accuracy: 0.8548\n",
            "Epoch 5/50\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3158 - accuracy: 0.8511 - val_loss: 0.3382 - val_accuracy: 0.8434\n",
            "Epoch 6/50\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3150 - accuracy: 0.8492 - val_loss: 0.3213 - val_accuracy: 0.8535\n",
            "Epoch 7/50\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3064 - accuracy: 0.8568 - val_loss: 0.3226 - val_accuracy: 0.8523\n",
            "Epoch 8/50\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3071 - accuracy: 0.8583 - val_loss: 0.3244 - val_accuracy: 0.8519\n",
            "Epoch 9/50\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3053 - accuracy: 0.8582 - val_loss: 0.3352 - val_accuracy: 0.8444\n",
            "Epoch 10/50\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3063 - accuracy: 0.8549 - val_loss: 0.3308 - val_accuracy: 0.8469\n",
            "Epoch 11/50\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3044 - accuracy: 0.8566 - val_loss: 0.3271 - val_accuracy: 0.8548\n",
            "300/300 [==============================] - 0s 957us/step - loss: 0.3244 - accuracy: 0.8467\n",
            "Epoch 1/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.4277 - accuracy: 0.8008 - val_loss: 0.3393 - val_accuracy: 0.8440\n",
            "Epoch 2/50\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3298 - accuracy: 0.8444 - val_loss: 0.3284 - val_accuracy: 0.8502\n",
            "Epoch 3/50\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3185 - accuracy: 0.8481 - val_loss: 0.3380 - val_accuracy: 0.8449\n",
            "Epoch 4/50\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3186 - accuracy: 0.8537 - val_loss: 0.3225 - val_accuracy: 0.8544\n",
            "Epoch 5/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3069 - accuracy: 0.8542 - val_loss: 0.3256 - val_accuracy: 0.8513\n",
            "Epoch 6/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3140 - accuracy: 0.8509 - val_loss: 0.3265 - val_accuracy: 0.8497\n",
            "Epoch 7/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3116 - accuracy: 0.8495 - val_loss: 0.3336 - val_accuracy: 0.8506\n",
            "Epoch 8/50\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3045 - accuracy: 0.8533 - val_loss: 0.3268 - val_accuracy: 0.8538\n",
            "Epoch 9/50\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3024 - accuracy: 0.8562 - val_loss: 0.3247 - val_accuracy: 0.8524\n",
            "300/300 [==============================] - 0s 904us/step - loss: 0.3309 - accuracy: 0.8553\n",
            "Epoch 1/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.4213 - accuracy: 0.8015 - val_loss: 0.3412 - val_accuracy: 0.8417\n",
            "Epoch 2/50\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3393 - accuracy: 0.8443 - val_loss: 0.3267 - val_accuracy: 0.8474\n",
            "Epoch 3/50\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3311 - accuracy: 0.8421 - val_loss: 0.3329 - val_accuracy: 0.8422\n",
            "Epoch 4/50\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3252 - accuracy: 0.8445 - val_loss: 0.3296 - val_accuracy: 0.8479\n",
            "Epoch 5/50\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3188 - accuracy: 0.8471 - val_loss: 0.3393 - val_accuracy: 0.8374\n",
            "Epoch 6/50\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3113 - accuracy: 0.8507 - val_loss: 0.3222 - val_accuracy: 0.8516\n",
            "Epoch 7/50\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3125 - accuracy: 0.8537 - val_loss: 0.3223 - val_accuracy: 0.8520\n",
            "Epoch 8/50\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3030 - accuracy: 0.8597 - val_loss: 0.3268 - val_accuracy: 0.8497\n",
            "Epoch 9/50\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.2959 - accuracy: 0.8596 - val_loss: 0.3228 - val_accuracy: 0.8541\n",
            "Epoch 10/50\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.2984 - accuracy: 0.8587 - val_loss: 0.3368 - val_accuracy: 0.8414\n",
            "Epoch 11/50\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.2975 - accuracy: 0.8604 - val_loss: 0.3295 - val_accuracy: 0.8516\n",
            "300/300 [==============================] - 0s 966us/step - loss: 0.3441 - accuracy: 0.8453\n",
            "Epoch 1/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.4305 - accuracy: 0.8027 - val_loss: 0.3423 - val_accuracy: 0.8385\n",
            "Epoch 2/50\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3411 - accuracy: 0.8370 - val_loss: 0.3319 - val_accuracy: 0.8464\n",
            "Epoch 3/50\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3264 - accuracy: 0.8449 - val_loss: 0.3240 - val_accuracy: 0.8528\n",
            "Epoch 4/50\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3218 - accuracy: 0.8478 - val_loss: 0.3276 - val_accuracy: 0.8492\n",
            "Epoch 5/50\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3175 - accuracy: 0.8512 - val_loss: 0.3239 - val_accuracy: 0.8518\n",
            "Epoch 6/50\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3093 - accuracy: 0.8557 - val_loss: 0.3250 - val_accuracy: 0.8503\n",
            "Epoch 7/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3043 - accuracy: 0.8563 - val_loss: 0.3242 - val_accuracy: 0.8526\n",
            "Epoch 8/50\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3085 - accuracy: 0.8538 - val_loss: 0.3290 - val_accuracy: 0.8528\n",
            "Epoch 9/50\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3039 - accuracy: 0.8626 - val_loss: 0.3339 - val_accuracy: 0.8468\n",
            "Epoch 10/50\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.2923 - accuracy: 0.8633 - val_loss: 0.3279 - val_accuracy: 0.8503\n",
            "300/300 [==============================] - 0s 945us/step - loss: 0.3243 - accuracy: 0.8500\n",
            "Epoch 1/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.4256 - accuracy: 0.8021 - val_loss: 0.3572 - val_accuracy: 0.8390\n",
            "Epoch 2/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3480 - accuracy: 0.8317 - val_loss: 0.3293 - val_accuracy: 0.8502\n",
            "Epoch 3/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3262 - accuracy: 0.8446 - val_loss: 0.3204 - val_accuracy: 0.8552\n",
            "Epoch 4/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3221 - accuracy: 0.8495 - val_loss: 0.3310 - val_accuracy: 0.8489\n",
            "Epoch 5/50\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3200 - accuracy: 0.8478 - val_loss: 0.3230 - val_accuracy: 0.8536\n",
            "Epoch 6/50\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3217 - accuracy: 0.8455 - val_loss: 0.3272 - val_accuracy: 0.8499\n",
            "Epoch 7/50\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3171 - accuracy: 0.8488 - val_loss: 0.3236 - val_accuracy: 0.8548\n",
            "Epoch 8/50\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3089 - accuracy: 0.8524 - val_loss: 0.3312 - val_accuracy: 0.8443\n",
            "300/300 [==============================] - 0s 975us/step - loss: 0.3273 - accuracy: 0.8420\n",
            "Epoch 1/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.4272 - accuracy: 0.7970 - val_loss: 0.3402 - val_accuracy: 0.8446\n",
            "Epoch 2/50\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3369 - accuracy: 0.8436 - val_loss: 0.3288 - val_accuracy: 0.8485\n",
            "Epoch 3/50\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3223 - accuracy: 0.8418 - val_loss: 0.3270 - val_accuracy: 0.8496\n",
            "Epoch 4/50\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3208 - accuracy: 0.8470 - val_loss: 0.3203 - val_accuracy: 0.8535\n",
            "Epoch 5/50\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3155 - accuracy: 0.8553 - val_loss: 0.3282 - val_accuracy: 0.8465\n",
            "Epoch 6/50\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3115 - accuracy: 0.8519 - val_loss: 0.3217 - val_accuracy: 0.8527\n",
            "Epoch 7/50\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3088 - accuracy: 0.8580 - val_loss: 0.3328 - val_accuracy: 0.8464\n",
            "Epoch 8/50\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3077 - accuracy: 0.8558 - val_loss: 0.3248 - val_accuracy: 0.8531\n",
            "Epoch 9/50\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3057 - accuracy: 0.8575 - val_loss: 0.3254 - val_accuracy: 0.8490\n",
            "300/300 [==============================] - 0s 978us/step - loss: 0.3236 - accuracy: 0.8467\n",
            "Epoch 1/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.4288 - accuracy: 0.8007 - val_loss: 0.3418 - val_accuracy: 0.8408\n",
            "Epoch 2/50\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3363 - accuracy: 0.8417 - val_loss: 0.3255 - val_accuracy: 0.8490\n",
            "Epoch 3/50\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3212 - accuracy: 0.8509 - val_loss: 0.3615 - val_accuracy: 0.8316\n",
            "Epoch 4/50\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3152 - accuracy: 0.8487 - val_loss: 0.3241 - val_accuracy: 0.8499\n",
            "Epoch 5/50\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3114 - accuracy: 0.8531 - val_loss: 0.3242 - val_accuracy: 0.8527\n",
            "Epoch 6/50\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3107 - accuracy: 0.8544 - val_loss: 0.3318 - val_accuracy: 0.8487\n",
            "Epoch 7/50\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3139 - accuracy: 0.8558 - val_loss: 0.3281 - val_accuracy: 0.8453\n",
            "Epoch 8/50\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3055 - accuracy: 0.8546 - val_loss: 0.3410 - val_accuracy: 0.8452\n",
            "Epoch 9/50\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3037 - accuracy: 0.8561 - val_loss: 0.3241 - val_accuracy: 0.8527\n",
            "300/300 [==============================] - 0s 1ms/step - loss: 0.3086 - accuracy: 0.8567\n",
            "Epoch 1/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.4197 - accuracy: 0.8062 - val_loss: 0.3466 - val_accuracy: 0.8374\n",
            "Epoch 2/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3306 - accuracy: 0.8434 - val_loss: 0.3266 - val_accuracy: 0.8508\n",
            "Epoch 3/50\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3239 - accuracy: 0.8454 - val_loss: 0.3362 - val_accuracy: 0.8387\n",
            "Epoch 4/50\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3148 - accuracy: 0.8455 - val_loss: 0.3240 - val_accuracy: 0.8516\n",
            "Epoch 5/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3213 - accuracy: 0.8446 - val_loss: 0.3221 - val_accuracy: 0.8521\n",
            "Epoch 6/50\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3163 - accuracy: 0.8484 - val_loss: 0.3216 - val_accuracy: 0.8531\n",
            "Epoch 7/50\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3089 - accuracy: 0.8556 - val_loss: 0.3342 - val_accuracy: 0.8498\n",
            "Epoch 8/50\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.2949 - accuracy: 0.8651 - val_loss: 0.3234 - val_accuracy: 0.8541\n",
            "Epoch 9/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3005 - accuracy: 0.8594 - val_loss: 0.3271 - val_accuracy: 0.8530\n",
            "Epoch 10/50\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3027 - accuracy: 0.8546 - val_loss: 0.3282 - val_accuracy: 0.8501\n",
            "Epoch 11/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3038 - accuracy: 0.8578 - val_loss: 0.3279 - val_accuracy: 0.8506\n",
            "300/300 [==============================] - 0s 982us/step - loss: 0.3288 - accuracy: 0.8480\n",
            "Epoch 1/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.4237 - accuracy: 0.8005 - val_loss: 0.3409 - val_accuracy: 0.8436\n",
            "Epoch 2/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3353 - accuracy: 0.8402 - val_loss: 0.3338 - val_accuracy: 0.8427\n",
            "Epoch 3/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3317 - accuracy: 0.8435 - val_loss: 0.3234 - val_accuracy: 0.8521\n",
            "Epoch 4/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3151 - accuracy: 0.8501 - val_loss: 0.3218 - val_accuracy: 0.8538\n",
            "Epoch 5/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3143 - accuracy: 0.8473 - val_loss: 0.3333 - val_accuracy: 0.8415\n",
            "Epoch 6/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3077 - accuracy: 0.8548 - val_loss: 0.3226 - val_accuracy: 0.8512\n",
            "Epoch 7/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3019 - accuracy: 0.8633 - val_loss: 0.3280 - val_accuracy: 0.8489\n",
            "Epoch 8/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3031 - accuracy: 0.8572 - val_loss: 0.3277 - val_accuracy: 0.8510\n",
            "Epoch 9/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3057 - accuracy: 0.8555 - val_loss: 0.3304 - val_accuracy: 0.8472\n",
            "300/300 [==============================] - 0s 996us/step - loss: 0.3171 - accuracy: 0.8580\n",
            "Epoch 1/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.4243 - accuracy: 0.8014 - val_loss: 0.3447 - val_accuracy: 0.8425\n",
            "Epoch 2/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3377 - accuracy: 0.8392 - val_loss: 0.3431 - val_accuracy: 0.8359\n",
            "Epoch 3/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3196 - accuracy: 0.8501 - val_loss: 0.3301 - val_accuracy: 0.8427\n",
            "Epoch 4/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3246 - accuracy: 0.8463 - val_loss: 0.3310 - val_accuracy: 0.8548\n",
            "Epoch 5/50\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3101 - accuracy: 0.8542 - val_loss: 0.3211 - val_accuracy: 0.8503\n",
            "Epoch 6/50\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3093 - accuracy: 0.8521 - val_loss: 0.3224 - val_accuracy: 0.8516\n",
            "Epoch 7/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3145 - accuracy: 0.8479 - val_loss: 0.3237 - val_accuracy: 0.8498\n",
            "Epoch 8/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3048 - accuracy: 0.8558 - val_loss: 0.3234 - val_accuracy: 0.8523\n",
            "Epoch 9/50\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3110 - accuracy: 0.8532 - val_loss: 0.3281 - val_accuracy: 0.8481\n",
            "Epoch 10/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3030 - accuracy: 0.8596 - val_loss: 0.3330 - val_accuracy: 0.8507\n",
            "300/300 [==============================] - 0s 1ms/step - loss: 0.3206 - accuracy: 0.8560\n",
            "Epoch 1/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.4231 - accuracy: 0.8002 - val_loss: 0.3363 - val_accuracy: 0.8445\n",
            "Epoch 2/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3413 - accuracy: 0.8404 - val_loss: 0.3251 - val_accuracy: 0.8527\n",
            "Epoch 3/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3211 - accuracy: 0.8492 - val_loss: 0.3301 - val_accuracy: 0.8466\n",
            "Epoch 4/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3226 - accuracy: 0.8498 - val_loss: 0.3234 - val_accuracy: 0.8514\n",
            "Epoch 5/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3183 - accuracy: 0.8491 - val_loss: 0.3322 - val_accuracy: 0.8467\n",
            "Epoch 6/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3118 - accuracy: 0.8538 - val_loss: 0.3226 - val_accuracy: 0.8522\n",
            "Epoch 7/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3159 - accuracy: 0.8502 - val_loss: 0.3260 - val_accuracy: 0.8529\n",
            "Epoch 8/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.2974 - accuracy: 0.8610 - val_loss: 0.3256 - val_accuracy: 0.8506\n",
            "Epoch 9/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3096 - accuracy: 0.8526 - val_loss: 0.3238 - val_accuracy: 0.8526\n",
            "Epoch 10/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3049 - accuracy: 0.8547 - val_loss: 0.3275 - val_accuracy: 0.8523\n",
            "Epoch 11/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.2923 - accuracy: 0.8631 - val_loss: 0.3325 - val_accuracy: 0.8475\n",
            "300/300 [==============================] - 0s 966us/step - loss: 0.3264 - accuracy: 0.8393\n",
            "Epoch 1/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.4250 - accuracy: 0.7983 - val_loss: 0.3440 - val_accuracy: 0.8416\n",
            "Epoch 2/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3405 - accuracy: 0.8391 - val_loss: 0.3270 - val_accuracy: 0.8500\n",
            "Epoch 3/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3142 - accuracy: 0.8510 - val_loss: 0.3260 - val_accuracy: 0.8507\n",
            "Epoch 4/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3184 - accuracy: 0.8469 - val_loss: 0.3226 - val_accuracy: 0.8534\n",
            "Epoch 5/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3142 - accuracy: 0.8488 - val_loss: 0.3226 - val_accuracy: 0.8530\n",
            "Epoch 6/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3116 - accuracy: 0.8571 - val_loss: 0.3236 - val_accuracy: 0.8506\n",
            "Epoch 7/50\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3113 - accuracy: 0.8536 - val_loss: 0.3258 - val_accuracy: 0.8540\n",
            "Epoch 8/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3091 - accuracy: 0.8548 - val_loss: 0.3227 - val_accuracy: 0.8518\n",
            "Epoch 9/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.2931 - accuracy: 0.8641 - val_loss: 0.3299 - val_accuracy: 0.8516\n",
            "Epoch 10/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3022 - accuracy: 0.8576 - val_loss: 0.3279 - val_accuracy: 0.8518\n",
            "300/300 [==============================] - 0s 958us/step - loss: 0.3309 - accuracy: 0.8513\n",
            "Epoch 1/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.4227 - accuracy: 0.7987 - val_loss: 0.3501 - val_accuracy: 0.8347\n",
            "Epoch 2/50\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3415 - accuracy: 0.8390 - val_loss: 0.3374 - val_accuracy: 0.8366\n",
            "Epoch 3/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3301 - accuracy: 0.8434 - val_loss: 0.3220 - val_accuracy: 0.8535\n",
            "Epoch 4/50\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3165 - accuracy: 0.8501 - val_loss: 0.3462 - val_accuracy: 0.8415\n",
            "Epoch 5/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3139 - accuracy: 0.8497 - val_loss: 0.3318 - val_accuracy: 0.8490\n",
            "Epoch 6/50\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3117 - accuracy: 0.8500 - val_loss: 0.3223 - val_accuracy: 0.8529\n",
            "Epoch 7/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3112 - accuracy: 0.8554 - val_loss: 0.3364 - val_accuracy: 0.8468\n",
            "Epoch 8/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3094 - accuracy: 0.8557 - val_loss: 0.3326 - val_accuracy: 0.8536\n",
            "300/300 [==============================] - 0s 976us/step - loss: 0.3460 - accuracy: 0.8420\n",
            "Epoch 1/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.4202 - accuracy: 0.8009 - val_loss: 0.3385 - val_accuracy: 0.8446\n",
            "Epoch 2/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3432 - accuracy: 0.8397 - val_loss: 0.3261 - val_accuracy: 0.8521\n",
            "Epoch 3/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3252 - accuracy: 0.8448 - val_loss: 0.3235 - val_accuracy: 0.8510\n",
            "Epoch 4/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3294 - accuracy: 0.8432 - val_loss: 0.3265 - val_accuracy: 0.8524\n",
            "Epoch 5/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3189 - accuracy: 0.8511 - val_loss: 0.3331 - val_accuracy: 0.8416\n",
            "Epoch 6/50\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3150 - accuracy: 0.8523 - val_loss: 0.3228 - val_accuracy: 0.8506\n",
            "Epoch 7/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3117 - accuracy: 0.8578 - val_loss: 0.3330 - val_accuracy: 0.8488\n",
            "Epoch 8/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3107 - accuracy: 0.8518 - val_loss: 0.3248 - val_accuracy: 0.8499\n",
            "Epoch 9/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3062 - accuracy: 0.8554 - val_loss: 0.3248 - val_accuracy: 0.8515\n",
            "Epoch 10/50\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.2984 - accuracy: 0.8602 - val_loss: 0.3249 - val_accuracy: 0.8526\n",
            "Epoch 11/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.2997 - accuracy: 0.8575 - val_loss: 0.3256 - val_accuracy: 0.8521\n",
            "300/300 [==============================] - 0s 1ms/step - loss: 0.3260 - accuracy: 0.8447\n",
            "Epoch 1/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.4341 - accuracy: 0.7967 - val_loss: 0.3427 - val_accuracy: 0.8448\n",
            "Epoch 2/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3444 - accuracy: 0.8367 - val_loss: 0.3500 - val_accuracy: 0.8398\n",
            "Epoch 3/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3247 - accuracy: 0.8465 - val_loss: 0.3261 - val_accuracy: 0.8501\n",
            "Epoch 4/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3192 - accuracy: 0.8484 - val_loss: 0.3286 - val_accuracy: 0.8491\n",
            "Epoch 5/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3166 - accuracy: 0.8528 - val_loss: 0.3215 - val_accuracy: 0.8567\n",
            "Epoch 6/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3092 - accuracy: 0.8560 - val_loss: 0.3228 - val_accuracy: 0.8529\n",
            "Epoch 7/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3088 - accuracy: 0.8569 - val_loss: 0.3279 - val_accuracy: 0.8514\n",
            "Epoch 8/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3042 - accuracy: 0.8585 - val_loss: 0.3210 - val_accuracy: 0.8528\n",
            "Epoch 9/50\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.2949 - accuracy: 0.8641 - val_loss: 0.3274 - val_accuracy: 0.8495\n",
            "Epoch 10/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.2924 - accuracy: 0.8659 - val_loss: 0.3361 - val_accuracy: 0.8454\n",
            "Epoch 11/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.2968 - accuracy: 0.8617 - val_loss: 0.3351 - val_accuracy: 0.8522\n",
            "Epoch 12/50\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.2934 - accuracy: 0.8618 - val_loss: 0.3348 - val_accuracy: 0.8465\n",
            "Epoch 13/50\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.2863 - accuracy: 0.8676 - val_loss: 0.3310 - val_accuracy: 0.8524\n",
            "300/300 [==============================] - 0s 1ms/step - loss: 0.3292 - accuracy: 0.8507\n",
            "Epoch 1/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.4247 - accuracy: 0.8008 - val_loss: 0.3415 - val_accuracy: 0.8396\n",
            "Epoch 2/50\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3329 - accuracy: 0.8448 - val_loss: 0.3264 - val_accuracy: 0.8502\n",
            "Epoch 3/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3244 - accuracy: 0.8445 - val_loss: 0.3338 - val_accuracy: 0.8467\n",
            "Epoch 4/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3214 - accuracy: 0.8478 - val_loss: 0.3225 - val_accuracy: 0.8540\n",
            "Epoch 5/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3155 - accuracy: 0.8470 - val_loss: 0.3293 - val_accuracy: 0.8501\n",
            "Epoch 6/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3046 - accuracy: 0.8553 - val_loss: 0.3268 - val_accuracy: 0.8546\n",
            "Epoch 7/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3148 - accuracy: 0.8502 - val_loss: 0.3279 - val_accuracy: 0.8470\n",
            "Epoch 8/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3106 - accuracy: 0.8543 - val_loss: 0.3279 - val_accuracy: 0.8528\n",
            "Epoch 9/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3061 - accuracy: 0.8583 - val_loss: 0.3240 - val_accuracy: 0.8522\n",
            "300/300 [==============================] - 0s 1ms/step - loss: 0.3246 - accuracy: 0.8473\n",
            "Epoch 1/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.4264 - accuracy: 0.8025 - val_loss: 0.3451 - val_accuracy: 0.8422\n",
            "Epoch 2/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3418 - accuracy: 0.8399 - val_loss: 0.3298 - val_accuracy: 0.8475\n",
            "Epoch 3/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3264 - accuracy: 0.8464 - val_loss: 0.3293 - val_accuracy: 0.8492\n",
            "Epoch 4/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3217 - accuracy: 0.8475 - val_loss: 0.3243 - val_accuracy: 0.8517\n",
            "Epoch 5/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3124 - accuracy: 0.8485 - val_loss: 0.3223 - val_accuracy: 0.8517\n",
            "Epoch 6/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3148 - accuracy: 0.8506 - val_loss: 0.3239 - val_accuracy: 0.8536\n",
            "Epoch 7/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3153 - accuracy: 0.8525 - val_loss: 0.3230 - val_accuracy: 0.8504\n",
            "Epoch 8/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3070 - accuracy: 0.8541 - val_loss: 0.3209 - val_accuracy: 0.8551\n",
            "Epoch 9/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3045 - accuracy: 0.8623 - val_loss: 0.3354 - val_accuracy: 0.8422\n",
            "Epoch 10/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.2990 - accuracy: 0.8608 - val_loss: 0.3451 - val_accuracy: 0.8391\n",
            "Epoch 11/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.2874 - accuracy: 0.8664 - val_loss: 0.3328 - val_accuracy: 0.8460\n",
            "Epoch 12/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.2893 - accuracy: 0.8651 - val_loss: 0.3274 - val_accuracy: 0.8525\n",
            "Epoch 13/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.2869 - accuracy: 0.8642 - val_loss: 0.3248 - val_accuracy: 0.8538\n",
            "300/300 [==============================] - 0s 1ms/step - loss: 0.3156 - accuracy: 0.8527\n",
            "Epoch 1/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.4217 - accuracy: 0.8025 - val_loss: 0.3488 - val_accuracy: 0.8400\n",
            "Epoch 2/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3395 - accuracy: 0.8351 - val_loss: 0.3308 - val_accuracy: 0.8484\n",
            "Epoch 3/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3165 - accuracy: 0.8543 - val_loss: 0.3279 - val_accuracy: 0.8452\n",
            "Epoch 4/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3138 - accuracy: 0.8539 - val_loss: 0.3344 - val_accuracy: 0.8429\n",
            "Epoch 5/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3106 - accuracy: 0.8553 - val_loss: 0.3239 - val_accuracy: 0.8514\n",
            "Epoch 6/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3116 - accuracy: 0.8486 - val_loss: 0.3260 - val_accuracy: 0.8508\n",
            "Epoch 7/50\n",
            "2700/2700 [==============================] - 7s 2ms/step - loss: 0.3048 - accuracy: 0.8593 - val_loss: 0.3418 - val_accuracy: 0.8392\n",
            "Epoch 8/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3028 - accuracy: 0.8541 - val_loss: 0.3366 - val_accuracy: 0.8389\n",
            "Epoch 9/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3038 - accuracy: 0.8564 - val_loss: 0.3331 - val_accuracy: 0.8446\n",
            "Epoch 10/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.2992 - accuracy: 0.8575 - val_loss: 0.3284 - val_accuracy: 0.8479\n",
            "300/300 [==============================] - 0s 1ms/step - loss: 0.3280 - accuracy: 0.8407\n",
            "Epoch 1/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.4057 - accuracy: 0.8001 - val_loss: 0.3606 - val_accuracy: 0.8400\n",
            "Epoch 2/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3516 - accuracy: 0.8376 - val_loss: 0.3417 - val_accuracy: 0.8456\n",
            "Epoch 3/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3315 - accuracy: 0.8462 - val_loss: 0.3329 - val_accuracy: 0.8489\n",
            "Epoch 4/50\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3274 - accuracy: 0.8478 - val_loss: 0.3381 - val_accuracy: 0.8493\n",
            "Epoch 5/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3217 - accuracy: 0.8474 - val_loss: 0.3313 - val_accuracy: 0.8481\n",
            "Epoch 6/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3131 - accuracy: 0.8572 - val_loss: 0.3331 - val_accuracy: 0.8467\n",
            "Epoch 7/50\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3110 - accuracy: 0.8533 - val_loss: 0.3343 - val_accuracy: 0.8508\n",
            "Epoch 8/50\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3142 - accuracy: 0.8544 - val_loss: 0.3452 - val_accuracy: 0.8486\n",
            "Epoch 9/50\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3089 - accuracy: 0.8554 - val_loss: 0.3451 - val_accuracy: 0.8460\n",
            "Epoch 10/50\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3088 - accuracy: 0.8597 - val_loss: 0.3405 - val_accuracy: 0.8468\n",
            "300/300 [==============================] - 0s 1ms/step - loss: 0.3327 - accuracy: 0.8567\n",
            "Epoch 1/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3916 - accuracy: 0.8098 - val_loss: 0.3389 - val_accuracy: 0.8449\n",
            "Epoch 2/50\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3468 - accuracy: 0.8358 - val_loss: 0.3272 - val_accuracy: 0.8498\n",
            "Epoch 3/50\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3341 - accuracy: 0.8419 - val_loss: 0.3355 - val_accuracy: 0.8448\n",
            "Epoch 4/50\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3296 - accuracy: 0.8433 - val_loss: 0.3313 - val_accuracy: 0.8523\n",
            "Epoch 5/50\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3201 - accuracy: 0.8479 - val_loss: 0.3371 - val_accuracy: 0.8442\n",
            "Epoch 6/50\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3061 - accuracy: 0.8551 - val_loss: 0.3368 - val_accuracy: 0.8494\n",
            "Epoch 7/50\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3168 - accuracy: 0.8483 - val_loss: 0.3284 - val_accuracy: 0.8509\n",
            "300/300 [==============================] - 0s 994us/step - loss: 0.3221 - accuracy: 0.8480\n",
            "Epoch 1/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.4050 - accuracy: 0.8059 - val_loss: 0.3584 - val_accuracy: 0.8425\n",
            "Epoch 2/50\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3489 - accuracy: 0.8375 - val_loss: 0.3399 - val_accuracy: 0.8419\n",
            "Epoch 3/50\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3358 - accuracy: 0.8434 - val_loss: 0.3379 - val_accuracy: 0.8418\n",
            "Epoch 4/50\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3290 - accuracy: 0.8493 - val_loss: 0.3363 - val_accuracy: 0.8453\n",
            "Epoch 5/50\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3209 - accuracy: 0.8489 - val_loss: 0.3318 - val_accuracy: 0.8522\n",
            "Epoch 6/50\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3133 - accuracy: 0.8499 - val_loss: 0.3306 - val_accuracy: 0.8489\n",
            "Epoch 7/50\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3209 - accuracy: 0.8471 - val_loss: 0.3285 - val_accuracy: 0.8483\n",
            "Epoch 8/50\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3111 - accuracy: 0.8553 - val_loss: 0.3360 - val_accuracy: 0.8433\n",
            "Epoch 9/50\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.2954 - accuracy: 0.8601 - val_loss: 0.3501 - val_accuracy: 0.8459\n",
            "Epoch 10/50\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3015 - accuracy: 0.8617 - val_loss: 0.3479 - val_accuracy: 0.8453\n",
            "Epoch 11/50\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.2999 - accuracy: 0.8569 - val_loss: 0.3391 - val_accuracy: 0.8493\n",
            "Epoch 12/50\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.2987 - accuracy: 0.8607 - val_loss: 0.3568 - val_accuracy: 0.8406\n",
            "300/300 [==============================] - 0s 941us/step - loss: 0.3431 - accuracy: 0.8380\n",
            "Epoch 1/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.4049 - accuracy: 0.8010 - val_loss: 0.3497 - val_accuracy: 0.8398\n",
            "Epoch 2/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3462 - accuracy: 0.8394 - val_loss: 0.3297 - val_accuracy: 0.8504\n",
            "Epoch 3/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3295 - accuracy: 0.8459 - val_loss: 0.3360 - val_accuracy: 0.8481\n",
            "Epoch 4/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3205 - accuracy: 0.8522 - val_loss: 0.3373 - val_accuracy: 0.8461\n",
            "Epoch 5/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3184 - accuracy: 0.8481 - val_loss: 0.3429 - val_accuracy: 0.8450\n",
            "Epoch 6/50\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3202 - accuracy: 0.8483 - val_loss: 0.3342 - val_accuracy: 0.8522\n",
            "Epoch 7/50\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3151 - accuracy: 0.8513 - val_loss: 0.3634 - val_accuracy: 0.8197\n",
            "300/300 [==============================] - 0s 956us/step - loss: 0.3680 - accuracy: 0.8067\n",
            "Epoch 1/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.4074 - accuracy: 0.8070 - val_loss: 0.3365 - val_accuracy: 0.8438\n",
            "Epoch 2/50\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3439 - accuracy: 0.8414 - val_loss: 0.3304 - val_accuracy: 0.8508\n",
            "Epoch 3/50\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3336 - accuracy: 0.8359 - val_loss: 0.3364 - val_accuracy: 0.8503\n",
            "Epoch 4/50\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3292 - accuracy: 0.8422 - val_loss: 0.3284 - val_accuracy: 0.8502\n",
            "Epoch 5/50\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3184 - accuracy: 0.8495 - val_loss: 0.3369 - val_accuracy: 0.8444\n",
            "Epoch 6/50\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3147 - accuracy: 0.8528 - val_loss: 0.3370 - val_accuracy: 0.8494\n",
            "Epoch 7/50\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3105 - accuracy: 0.8552 - val_loss: 0.3318 - val_accuracy: 0.8474\n",
            "Epoch 8/50\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3104 - accuracy: 0.8555 - val_loss: 0.3433 - val_accuracy: 0.8491\n",
            "Epoch 9/50\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3056 - accuracy: 0.8600 - val_loss: 0.3367 - val_accuracy: 0.8516\n",
            "300/300 [==============================] - 0s 994us/step - loss: 0.3436 - accuracy: 0.8413\n",
            "Epoch 1/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.4001 - accuracy: 0.8094 - val_loss: 0.3439 - val_accuracy: 0.8458\n",
            "Epoch 2/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3479 - accuracy: 0.8377 - val_loss: 0.3302 - val_accuracy: 0.8490\n",
            "Epoch 3/50\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3343 - accuracy: 0.8468 - val_loss: 0.3279 - val_accuracy: 0.8512\n",
            "Epoch 4/50\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3211 - accuracy: 0.8494 - val_loss: 0.3298 - val_accuracy: 0.8488\n",
            "Epoch 5/50\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3246 - accuracy: 0.8464 - val_loss: 0.3431 - val_accuracy: 0.8499\n",
            "Epoch 6/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3165 - accuracy: 0.8526 - val_loss: 0.3273 - val_accuracy: 0.8523\n",
            "Epoch 7/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3168 - accuracy: 0.8511 - val_loss: 0.3456 - val_accuracy: 0.8340\n",
            "Epoch 8/50\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3026 - accuracy: 0.8555 - val_loss: 0.3335 - val_accuracy: 0.8522\n",
            "Epoch 9/50\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3012 - accuracy: 0.8609 - val_loss: 0.3540 - val_accuracy: 0.8292\n",
            "Epoch 10/50\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3067 - accuracy: 0.8558 - val_loss: 0.3400 - val_accuracy: 0.8529\n",
            "Epoch 11/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.2966 - accuracy: 0.8629 - val_loss: 0.3346 - val_accuracy: 0.8512\n",
            "300/300 [==============================] - 0s 966us/step - loss: 0.3335 - accuracy: 0.8520\n",
            "Epoch 1/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.4124 - accuracy: 0.8020 - val_loss: 0.3593 - val_accuracy: 0.8351\n",
            "Epoch 2/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3497 - accuracy: 0.8362 - val_loss: 0.3368 - val_accuracy: 0.8504\n",
            "Epoch 3/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3367 - accuracy: 0.8441 - val_loss: 0.3418 - val_accuracy: 0.8521\n",
            "Epoch 4/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3307 - accuracy: 0.8502 - val_loss: 0.3348 - val_accuracy: 0.8520\n",
            "Epoch 5/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3227 - accuracy: 0.8545 - val_loss: 0.3323 - val_accuracy: 0.8525\n",
            "Epoch 6/50\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3205 - accuracy: 0.8519 - val_loss: 0.3390 - val_accuracy: 0.8433\n",
            "Epoch 7/50\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3167 - accuracy: 0.8518 - val_loss: 0.3350 - val_accuracy: 0.8470\n",
            "Epoch 8/50\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3197 - accuracy: 0.8455 - val_loss: 0.3365 - val_accuracy: 0.8483\n",
            "Epoch 9/50\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3090 - accuracy: 0.8541 - val_loss: 0.3347 - val_accuracy: 0.8476\n",
            "Epoch 10/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3077 - accuracy: 0.8523 - val_loss: 0.3360 - val_accuracy: 0.8527\n",
            "300/300 [==============================] - 0s 999us/step - loss: 0.3336 - accuracy: 0.8540\n",
            "Epoch 1/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.4131 - accuracy: 0.7882 - val_loss: 0.3780 - val_accuracy: 0.8402\n",
            "Epoch 2/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3340 - accuracy: 0.8440 - val_loss: 0.3542 - val_accuracy: 0.8412\n",
            "Epoch 3/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3362 - accuracy: 0.8450 - val_loss: 0.3283 - val_accuracy: 0.8519\n",
            "Epoch 4/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3228 - accuracy: 0.8482 - val_loss: 0.3567 - val_accuracy: 0.8432\n",
            "Epoch 5/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3222 - accuracy: 0.8480 - val_loss: 0.3383 - val_accuracy: 0.8485\n",
            "Epoch 6/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3174 - accuracy: 0.8531 - val_loss: 0.3333 - val_accuracy: 0.8455\n",
            "Epoch 7/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3140 - accuracy: 0.8524 - val_loss: 0.3374 - val_accuracy: 0.8441\n",
            "Epoch 8/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3100 - accuracy: 0.8550 - val_loss: 0.3331 - val_accuracy: 0.8515\n",
            "300/300 [==============================] - 0s 984us/step - loss: 0.3334 - accuracy: 0.8487\n",
            "Epoch 1/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.4155 - accuracy: 0.7959 - val_loss: 0.3654 - val_accuracy: 0.8310\n",
            "Epoch 2/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3591 - accuracy: 0.8319 - val_loss: 0.3411 - val_accuracy: 0.8409\n",
            "Epoch 3/50\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3359 - accuracy: 0.8420 - val_loss: 0.3273 - val_accuracy: 0.8515\n",
            "Epoch 4/50\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3258 - accuracy: 0.8494 - val_loss: 0.3383 - val_accuracy: 0.8452\n",
            "Epoch 5/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3304 - accuracy: 0.8467 - val_loss: 0.3305 - val_accuracy: 0.8474\n",
            "Epoch 6/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3228 - accuracy: 0.8490 - val_loss: 0.3370 - val_accuracy: 0.8483\n",
            "Epoch 7/50\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3166 - accuracy: 0.8501 - val_loss: 0.3428 - val_accuracy: 0.8459\n",
            "Epoch 8/50\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3172 - accuracy: 0.8454 - val_loss: 0.3287 - val_accuracy: 0.8495\n",
            "300/300 [==============================] - 0s 1ms/step - loss: 0.3218 - accuracy: 0.8560\n",
            "Epoch 1/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.4105 - accuracy: 0.7973 - val_loss: 0.3457 - val_accuracy: 0.8415\n",
            "Epoch 2/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3433 - accuracy: 0.8430 - val_loss: 0.3315 - val_accuracy: 0.8521\n",
            "Epoch 3/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3382 - accuracy: 0.8411 - val_loss: 0.3263 - val_accuracy: 0.8535\n",
            "Epoch 4/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3220 - accuracy: 0.8550 - val_loss: 0.3296 - val_accuracy: 0.8501\n",
            "Epoch 5/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3260 - accuracy: 0.8488 - val_loss: 0.3385 - val_accuracy: 0.8422\n",
            "Epoch 6/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3190 - accuracy: 0.8490 - val_loss: 0.3445 - val_accuracy: 0.8451\n",
            "Epoch 7/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3162 - accuracy: 0.8584 - val_loss: 0.3585 - val_accuracy: 0.8198\n",
            "Epoch 8/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3104 - accuracy: 0.8553 - val_loss: 0.3307 - val_accuracy: 0.8527\n",
            "300/300 [==============================] - 0s 1ms/step - loss: 0.3328 - accuracy: 0.8447\n",
            "Epoch 1/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.4106 - accuracy: 0.8018 - val_loss: 0.3453 - val_accuracy: 0.8432\n",
            "Epoch 2/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3513 - accuracy: 0.8366 - val_loss: 0.3450 - val_accuracy: 0.8436\n",
            "Epoch 3/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3377 - accuracy: 0.8427 - val_loss: 0.3666 - val_accuracy: 0.8387\n",
            "Epoch 4/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3220 - accuracy: 0.8436 - val_loss: 0.3358 - val_accuracy: 0.8468\n",
            "Epoch 5/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3238 - accuracy: 0.8500 - val_loss: 0.3312 - val_accuracy: 0.8482\n",
            "Epoch 6/50\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3171 - accuracy: 0.8533 - val_loss: 0.3410 - val_accuracy: 0.8396\n",
            "Epoch 7/50\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3239 - accuracy: 0.8435 - val_loss: 0.3339 - val_accuracy: 0.8443\n",
            "Epoch 8/50\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3084 - accuracy: 0.8569 - val_loss: 0.3370 - val_accuracy: 0.8500\n",
            "Epoch 9/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3073 - accuracy: 0.8549 - val_loss: 0.3512 - val_accuracy: 0.8328\n",
            "Epoch 10/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3026 - accuracy: 0.8553 - val_loss: 0.3442 - val_accuracy: 0.8424\n",
            "300/300 [==============================] - 0s 935us/step - loss: 0.3435 - accuracy: 0.8460\n",
            "Epoch 1/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.4109 - accuracy: 0.7984 - val_loss: 0.3533 - val_accuracy: 0.8401\n",
            "Epoch 2/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3505 - accuracy: 0.8322 - val_loss: 0.3408 - val_accuracy: 0.8467\n",
            "Epoch 3/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3373 - accuracy: 0.8387 - val_loss: 0.3304 - val_accuracy: 0.8525\n",
            "Epoch 4/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3237 - accuracy: 0.8458 - val_loss: 0.3330 - val_accuracy: 0.8521\n",
            "Epoch 5/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3278 - accuracy: 0.8450 - val_loss: 0.3512 - val_accuracy: 0.8508\n",
            "Epoch 6/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3269 - accuracy: 0.8434 - val_loss: 0.3412 - val_accuracy: 0.8403\n",
            "Epoch 7/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3046 - accuracy: 0.8558 - val_loss: 0.3414 - val_accuracy: 0.8414\n",
            "Epoch 8/50\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3157 - accuracy: 0.8504 - val_loss: 0.3359 - val_accuracy: 0.8503\n",
            "300/300 [==============================] - 0s 1ms/step - loss: 0.3326 - accuracy: 0.8533\n",
            "Epoch 1/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3992 - accuracy: 0.8046 - val_loss: 0.3646 - val_accuracy: 0.8431\n",
            "Epoch 2/50\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3473 - accuracy: 0.8355 - val_loss: 0.3322 - val_accuracy: 0.8508\n",
            "Epoch 3/50\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3344 - accuracy: 0.8385 - val_loss: 0.3360 - val_accuracy: 0.8460\n",
            "Epoch 4/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3278 - accuracy: 0.8435 - val_loss: 0.3251 - val_accuracy: 0.8518\n",
            "Epoch 5/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3271 - accuracy: 0.8402 - val_loss: 0.3312 - val_accuracy: 0.8499\n",
            "Epoch 6/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3102 - accuracy: 0.8545 - val_loss: 0.3295 - val_accuracy: 0.8523\n",
            "Epoch 7/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3266 - accuracy: 0.8450 - val_loss: 0.3523 - val_accuracy: 0.8355\n",
            "Epoch 8/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3121 - accuracy: 0.8566 - val_loss: 0.3311 - val_accuracy: 0.8479\n",
            "Epoch 9/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.2977 - accuracy: 0.8574 - val_loss: 0.3321 - val_accuracy: 0.8515\n",
            "300/300 [==============================] - 0s 977us/step - loss: 0.3291 - accuracy: 0.8447\n",
            "Epoch 1/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.4052 - accuracy: 0.8074 - val_loss: 0.3623 - val_accuracy: 0.8343\n",
            "Epoch 2/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3473 - accuracy: 0.8386 - val_loss: 0.3522 - val_accuracy: 0.8466\n",
            "Epoch 3/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3355 - accuracy: 0.8444 - val_loss: 0.3305 - val_accuracy: 0.8504\n",
            "Epoch 4/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3183 - accuracy: 0.8446 - val_loss: 0.3288 - val_accuracy: 0.8532\n",
            "Epoch 5/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3234 - accuracy: 0.8483 - val_loss: 0.3389 - val_accuracy: 0.8509\n",
            "Epoch 6/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3201 - accuracy: 0.8438 - val_loss: 0.3448 - val_accuracy: 0.8460\n",
            "Epoch 7/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3175 - accuracy: 0.8474 - val_loss: 0.3346 - val_accuracy: 0.8490\n",
            "Epoch 8/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3093 - accuracy: 0.8551 - val_loss: 0.3397 - val_accuracy: 0.8406\n",
            "Epoch 9/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.2980 - accuracy: 0.8598 - val_loss: 0.3437 - val_accuracy: 0.8442\n",
            "300/300 [==============================] - 0s 1ms/step - loss: 0.3601 - accuracy: 0.8440\n",
            "Epoch 1/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.4192 - accuracy: 0.7925 - val_loss: 0.3703 - val_accuracy: 0.8408\n",
            "Epoch 2/50\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3544 - accuracy: 0.8329 - val_loss: 0.4184 - val_accuracy: 0.8041\n",
            "Epoch 3/50\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3257 - accuracy: 0.8472 - val_loss: 0.3348 - val_accuracy: 0.8453\n",
            "Epoch 4/50\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3238 - accuracy: 0.8438 - val_loss: 0.3275 - val_accuracy: 0.8536\n",
            "Epoch 5/50\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3230 - accuracy: 0.8472 - val_loss: 0.3278 - val_accuracy: 0.8499\n",
            "Epoch 6/50\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3098 - accuracy: 0.8542 - val_loss: 0.3377 - val_accuracy: 0.8541\n",
            "Epoch 7/50\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3234 - accuracy: 0.8473 - val_loss: 0.3451 - val_accuracy: 0.8505\n",
            "Epoch 8/50\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3046 - accuracy: 0.8591 - val_loss: 0.3742 - val_accuracy: 0.8351\n",
            "Epoch 9/50\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3107 - accuracy: 0.8523 - val_loss: 0.3326 - val_accuracy: 0.8495\n",
            "300/300 [==============================] - 0s 1ms/step - loss: 0.3365 - accuracy: 0.8420\n",
            "Epoch 1/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.4062 - accuracy: 0.8046 - val_loss: 0.3595 - val_accuracy: 0.8282\n",
            "Epoch 2/50\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3499 - accuracy: 0.8375 - val_loss: 0.3414 - val_accuracy: 0.8508\n",
            "Epoch 3/50\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3320 - accuracy: 0.8457 - val_loss: 0.3278 - val_accuracy: 0.8477\n",
            "Epoch 4/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3307 - accuracy: 0.8430 - val_loss: 0.3463 - val_accuracy: 0.8494\n",
            "Epoch 5/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3232 - accuracy: 0.8495 - val_loss: 0.3320 - val_accuracy: 0.8474\n",
            "Epoch 6/50\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3210 - accuracy: 0.8488 - val_loss: 0.3299 - val_accuracy: 0.8500\n",
            "Epoch 7/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3121 - accuracy: 0.8547 - val_loss: 0.3276 - val_accuracy: 0.8533\n",
            "Epoch 8/50\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3061 - accuracy: 0.8584 - val_loss: 0.3363 - val_accuracy: 0.8513\n",
            "Epoch 9/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3090 - accuracy: 0.8578 - val_loss: 0.3361 - val_accuracy: 0.8477\n",
            "Epoch 10/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3054 - accuracy: 0.8524 - val_loss: 0.3496 - val_accuracy: 0.8501\n",
            "Epoch 11/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.2991 - accuracy: 0.8597 - val_loss: 0.3666 - val_accuracy: 0.8433\n",
            "Epoch 12/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3021 - accuracy: 0.8600 - val_loss: 0.3458 - val_accuracy: 0.8464\n",
            "300/300 [==============================] - 0s 1ms/step - loss: 0.3470 - accuracy: 0.8460\n",
            "Epoch 1/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3977 - accuracy: 0.8094 - val_loss: 0.3799 - val_accuracy: 0.8381\n",
            "Epoch 2/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3482 - accuracy: 0.8337 - val_loss: 0.3418 - val_accuracy: 0.8466\n",
            "Epoch 3/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3317 - accuracy: 0.8461 - val_loss: 0.3290 - val_accuracy: 0.8516\n",
            "Epoch 4/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3347 - accuracy: 0.8403 - val_loss: 0.3386 - val_accuracy: 0.8455\n",
            "Epoch 5/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3284 - accuracy: 0.8484 - val_loss: 0.3587 - val_accuracy: 0.8397\n",
            "Epoch 6/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3192 - accuracy: 0.8462 - val_loss: 0.3334 - val_accuracy: 0.8484\n",
            "Epoch 7/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3162 - accuracy: 0.8499 - val_loss: 0.3446 - val_accuracy: 0.8427\n",
            "Epoch 8/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3026 - accuracy: 0.8587 - val_loss: 0.3404 - val_accuracy: 0.8488\n",
            "300/300 [==============================] - 0s 1ms/step - loss: 0.3370 - accuracy: 0.8480\n",
            "Epoch 1/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.4010 - accuracy: 0.8020 - val_loss: 0.3657 - val_accuracy: 0.8300\n",
            "Epoch 2/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3439 - accuracy: 0.8407 - val_loss: 0.3683 - val_accuracy: 0.8271\n",
            "Epoch 3/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3293 - accuracy: 0.8495 - val_loss: 0.3399 - val_accuracy: 0.8510\n",
            "Epoch 4/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3289 - accuracy: 0.8492 - val_loss: 0.3270 - val_accuracy: 0.8545\n",
            "Epoch 5/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3199 - accuracy: 0.8511 - val_loss: 0.3294 - val_accuracy: 0.8469\n",
            "Epoch 6/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3266 - accuracy: 0.8466 - val_loss: 0.3322 - val_accuracy: 0.8472\n",
            "Epoch 7/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3091 - accuracy: 0.8572 - val_loss: 0.3388 - val_accuracy: 0.8488\n",
            "Epoch 8/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3260 - accuracy: 0.8502 - val_loss: 0.3339 - val_accuracy: 0.8523\n",
            "Epoch 9/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3150 - accuracy: 0.8504 - val_loss: 0.3576 - val_accuracy: 0.8454\n",
            "300/300 [==============================] - 0s 1ms/step - loss: 0.3508 - accuracy: 0.8407\n",
            "Epoch 1/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.4111 - accuracy: 0.7858 - val_loss: 0.3677 - val_accuracy: 0.8330\n",
            "Epoch 2/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3597 - accuracy: 0.8295 - val_loss: 0.3371 - val_accuracy: 0.8438\n",
            "Epoch 3/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3347 - accuracy: 0.8442 - val_loss: 0.3302 - val_accuracy: 0.8434\n",
            "Epoch 4/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3228 - accuracy: 0.8459 - val_loss: 0.3308 - val_accuracy: 0.8504\n",
            "Epoch 5/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3194 - accuracy: 0.8414 - val_loss: 0.3269 - val_accuracy: 0.8530\n",
            "Epoch 6/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3102 - accuracy: 0.8565 - val_loss: 0.3426 - val_accuracy: 0.8372\n",
            "Epoch 7/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3219 - accuracy: 0.8378 - val_loss: 0.3379 - val_accuracy: 0.8519\n",
            "Epoch 8/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3163 - accuracy: 0.8552 - val_loss: 0.3349 - val_accuracy: 0.8425\n",
            "Epoch 9/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3032 - accuracy: 0.8553 - val_loss: 0.3374 - val_accuracy: 0.8497\n",
            "Epoch 10/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3053 - accuracy: 0.8565 - val_loss: 0.3482 - val_accuracy: 0.8468\n",
            "300/300 [==============================] - 0s 1ms/step - loss: 0.3119 - accuracy: 0.8533\n",
            "Epoch 1/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.4102 - accuracy: 0.8027 - val_loss: 0.3491 - val_accuracy: 0.8442\n",
            "Epoch 2/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3561 - accuracy: 0.8300 - val_loss: 0.3635 - val_accuracy: 0.8388\n",
            "Epoch 3/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3361 - accuracy: 0.8482 - val_loss: 0.3289 - val_accuracy: 0.8510\n",
            "Epoch 4/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3331 - accuracy: 0.8456 - val_loss: 0.3323 - val_accuracy: 0.8507\n",
            "Epoch 5/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3249 - accuracy: 0.8520 - val_loss: 0.3247 - val_accuracy: 0.8531\n",
            "Epoch 6/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3244 - accuracy: 0.8450 - val_loss: 0.3307 - val_accuracy: 0.8532\n",
            "Epoch 7/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3105 - accuracy: 0.8575 - val_loss: 0.3334 - val_accuracy: 0.8419\n",
            "Epoch 8/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3167 - accuracy: 0.8508 - val_loss: 0.3309 - val_accuracy: 0.8491\n",
            "Epoch 9/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3088 - accuracy: 0.8551 - val_loss: 0.3357 - val_accuracy: 0.8443\n",
            "Epoch 10/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3154 - accuracy: 0.8506 - val_loss: 0.3383 - val_accuracy: 0.8515\n",
            "300/300 [==============================] - 0s 1ms/step - loss: 0.3376 - accuracy: 0.8473\n",
            "Epoch 1/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.4100 - accuracy: 0.8033 - val_loss: 0.3411 - val_accuracy: 0.8434\n",
            "Epoch 2/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3523 - accuracy: 0.8385 - val_loss: 0.3552 - val_accuracy: 0.8449\n",
            "Epoch 3/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3379 - accuracy: 0.8405 - val_loss: 0.3314 - val_accuracy: 0.8511\n",
            "Epoch 4/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3325 - accuracy: 0.8474 - val_loss: 0.3318 - val_accuracy: 0.8517\n",
            "Epoch 5/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3263 - accuracy: 0.8452 - val_loss: 0.3377 - val_accuracy: 0.8461\n",
            "Epoch 6/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3218 - accuracy: 0.8479 - val_loss: 0.3345 - val_accuracy: 0.8445\n",
            "Epoch 7/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3146 - accuracy: 0.8548 - val_loss: 0.3484 - val_accuracy: 0.8373\n",
            "Epoch 8/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3181 - accuracy: 0.8498 - val_loss: 0.3421 - val_accuracy: 0.8433\n",
            "300/300 [==============================] - 0s 1ms/step - loss: 0.3357 - accuracy: 0.8540\n",
            "Epoch 1/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.4021 - accuracy: 0.8044 - val_loss: 0.3597 - val_accuracy: 0.8106\n",
            "Epoch 2/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3496 - accuracy: 0.8320 - val_loss: 0.3266 - val_accuracy: 0.8518\n",
            "Epoch 3/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3318 - accuracy: 0.8426 - val_loss: 0.3281 - val_accuracy: 0.8474\n",
            "Epoch 4/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3211 - accuracy: 0.8503 - val_loss: 0.3391 - val_accuracy: 0.8436\n",
            "Epoch 5/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3223 - accuracy: 0.8496 - val_loss: 0.3309 - val_accuracy: 0.8503\n",
            "Epoch 6/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3158 - accuracy: 0.8529 - val_loss: 0.3303 - val_accuracy: 0.8467\n",
            "Epoch 7/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3137 - accuracy: 0.8487 - val_loss: 0.3304 - val_accuracy: 0.8455\n",
            "300/300 [==============================] - 0s 1ms/step - loss: 0.3234 - accuracy: 0.8493\n",
            "Epoch 1/50\n",
            "2700/2700 [==============================] - 7s 2ms/step - loss: 0.4112 - accuracy: 0.8057 - val_loss: 0.3492 - val_accuracy: 0.8429\n",
            "Epoch 2/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3453 - accuracy: 0.8389 - val_loss: 0.3318 - val_accuracy: 0.8501\n",
            "Epoch 3/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3351 - accuracy: 0.8410 - val_loss: 0.3514 - val_accuracy: 0.8404\n",
            "Epoch 4/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3273 - accuracy: 0.8483 - val_loss: 0.3260 - val_accuracy: 0.8527\n",
            "Epoch 5/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3173 - accuracy: 0.8501 - val_loss: 0.3297 - val_accuracy: 0.8532\n",
            "Epoch 6/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3185 - accuracy: 0.8460 - val_loss: 0.3354 - val_accuracy: 0.8473\n",
            "Epoch 7/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3139 - accuracy: 0.8539 - val_loss: 0.3362 - val_accuracy: 0.8447\n",
            "Epoch 8/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3104 - accuracy: 0.8561 - val_loss: 0.3406 - val_accuracy: 0.8472\n",
            "Epoch 9/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3112 - accuracy: 0.8590 - val_loss: 0.3533 - val_accuracy: 0.8295\n",
            "300/300 [==============================] - 0s 1ms/step - loss: 0.3510 - accuracy: 0.8273\n",
            "Epoch 1/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.4079 - accuracy: 0.7979 - val_loss: 0.3387 - val_accuracy: 0.8439\n",
            "Epoch 2/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3412 - accuracy: 0.8379 - val_loss: 0.3562 - val_accuracy: 0.8046\n",
            "Epoch 3/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3348 - accuracy: 0.8390 - val_loss: 0.3303 - val_accuracy: 0.8494\n",
            "Epoch 4/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3272 - accuracy: 0.8399 - val_loss: 0.3320 - val_accuracy: 0.8523\n",
            "Epoch 5/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3207 - accuracy: 0.8472 - val_loss: 0.3644 - val_accuracy: 0.8381\n",
            "Epoch 6/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3229 - accuracy: 0.8445 - val_loss: 0.3500 - val_accuracy: 0.8452\n",
            "Epoch 7/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3091 - accuracy: 0.8543 - val_loss: 0.3351 - val_accuracy: 0.8478\n",
            "Epoch 8/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3157 - accuracy: 0.8522 - val_loss: 0.3320 - val_accuracy: 0.8496\n",
            "300/300 [==============================] - 0s 1ms/step - loss: 0.3475 - accuracy: 0.8420\n",
            "Epoch 1/50\n",
            "2700/2700 [==============================] - 7s 2ms/step - loss: 0.4089 - accuracy: 0.8002 - val_loss: 0.3594 - val_accuracy: 0.8400\n",
            "Epoch 2/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3605 - accuracy: 0.8332 - val_loss: 0.3348 - val_accuracy: 0.8473\n",
            "Epoch 3/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3250 - accuracy: 0.8447 - val_loss: 0.3301 - val_accuracy: 0.8493\n",
            "Epoch 4/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3310 - accuracy: 0.8476 - val_loss: 0.3278 - val_accuracy: 0.8530\n",
            "Epoch 5/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3278 - accuracy: 0.8452 - val_loss: 0.3290 - val_accuracy: 0.8535\n",
            "Epoch 6/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3197 - accuracy: 0.8501 - val_loss: 0.3301 - val_accuracy: 0.8494\n",
            "Epoch 7/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3180 - accuracy: 0.8484 - val_loss: 0.3351 - val_accuracy: 0.8483\n",
            "Epoch 8/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3137 - accuracy: 0.8508 - val_loss: 0.3490 - val_accuracy: 0.8494\n",
            "Epoch 9/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.2983 - accuracy: 0.8579 - val_loss: 0.3626 - val_accuracy: 0.8276\n",
            "300/300 [==============================] - 0s 1ms/step - loss: 0.3782 - accuracy: 0.8247\n",
            "Epoch 1/50\n",
            "2700/2700 [==============================] - 7s 2ms/step - loss: 0.4108 - accuracy: 0.7996 - val_loss: 0.3448 - val_accuracy: 0.8460\n",
            "Epoch 2/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3487 - accuracy: 0.8369 - val_loss: 0.3507 - val_accuracy: 0.8324\n",
            "Epoch 3/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3448 - accuracy: 0.8375 - val_loss: 0.3344 - val_accuracy: 0.8472\n",
            "Epoch 4/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3378 - accuracy: 0.8430 - val_loss: 0.3318 - val_accuracy: 0.8488\n",
            "Epoch 5/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3274 - accuracy: 0.8410 - val_loss: 0.3592 - val_accuracy: 0.8473\n",
            "Epoch 6/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3225 - accuracy: 0.8519 - val_loss: 0.3457 - val_accuracy: 0.8451\n",
            "Epoch 7/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3151 - accuracy: 0.8527 - val_loss: 0.3481 - val_accuracy: 0.8401\n",
            "Epoch 8/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3127 - accuracy: 0.8572 - val_loss: 0.3435 - val_accuracy: 0.8516\n",
            "Epoch 9/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3122 - accuracy: 0.8491 - val_loss: 0.3363 - val_accuracy: 0.8478\n",
            "300/300 [==============================] - 0s 1ms/step - loss: 0.3367 - accuracy: 0.8407\n",
            "Epoch 1/50\n",
            "2700/2700 [==============================] - 7s 2ms/step - loss: 0.4103 - accuracy: 0.7966 - val_loss: 0.3621 - val_accuracy: 0.8224\n",
            "Epoch 2/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3445 - accuracy: 0.8350 - val_loss: 0.3573 - val_accuracy: 0.8334\n",
            "Epoch 3/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3416 - accuracy: 0.8407 - val_loss: 0.3325 - val_accuracy: 0.8483\n",
            "Epoch 4/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3242 - accuracy: 0.8478 - val_loss: 0.3264 - val_accuracy: 0.8528\n",
            "Epoch 5/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3215 - accuracy: 0.8515 - val_loss: 0.3286 - val_accuracy: 0.8525\n",
            "Epoch 6/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3199 - accuracy: 0.8519 - val_loss: 0.3530 - val_accuracy: 0.8429\n",
            "Epoch 7/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3186 - accuracy: 0.8509 - val_loss: 0.3431 - val_accuracy: 0.8523\n",
            "Epoch 8/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3073 - accuracy: 0.8541 - val_loss: 0.3458 - val_accuracy: 0.8467\n",
            "Epoch 9/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3032 - accuracy: 0.8569 - val_loss: 0.3331 - val_accuracy: 0.8486\n",
            "300/300 [==============================] - 0s 1ms/step - loss: 0.3364 - accuracy: 0.8427\n",
            "Epoch 1/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.4039 - accuracy: 0.7984 - val_loss: 0.3534 - val_accuracy: 0.8390\n",
            "Epoch 2/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3373 - accuracy: 0.8420 - val_loss: 0.3329 - val_accuracy: 0.8465\n",
            "Epoch 3/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3379 - accuracy: 0.8372 - val_loss: 0.3567 - val_accuracy: 0.8462\n",
            "Epoch 4/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3263 - accuracy: 0.8428 - val_loss: 0.3323 - val_accuracy: 0.8507\n",
            "Epoch 5/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3282 - accuracy: 0.8418 - val_loss: 0.3405 - val_accuracy: 0.8450\n",
            "Epoch 6/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3227 - accuracy: 0.8542 - val_loss: 0.3325 - val_accuracy: 0.8512\n",
            "Epoch 7/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3052 - accuracy: 0.8545 - val_loss: 0.3348 - val_accuracy: 0.8511\n",
            "Epoch 8/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3075 - accuracy: 0.8602 - val_loss: 0.3459 - val_accuracy: 0.8470\n",
            "Epoch 9/50\n",
            "2700/2700 [==============================] - 7s 2ms/step - loss: 0.2965 - accuracy: 0.8605 - val_loss: 0.3365 - val_accuracy: 0.8477\n",
            "300/300 [==============================] - 0s 1ms/step - loss: 0.3334 - accuracy: 0.8347\n",
            "Epoch 1/50\n",
            "2700/2700 [==============================] - 7s 2ms/step - loss: 0.4037 - accuracy: 0.8020 - val_loss: 0.3521 - val_accuracy: 0.8320\n",
            "Epoch 2/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3423 - accuracy: 0.8365 - val_loss: 0.3285 - val_accuracy: 0.8547\n",
            "Epoch 3/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3233 - accuracy: 0.8488 - val_loss: 0.3422 - val_accuracy: 0.8386\n",
            "Epoch 4/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3211 - accuracy: 0.8545 - val_loss: 0.3344 - val_accuracy: 0.8490\n",
            "Epoch 5/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3292 - accuracy: 0.8477 - val_loss: 0.3434 - val_accuracy: 0.8332\n",
            "Epoch 6/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3236 - accuracy: 0.8433 - val_loss: 0.3356 - val_accuracy: 0.8494\n",
            "Epoch 7/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3179 - accuracy: 0.8518 - val_loss: 0.3385 - val_accuracy: 0.8481\n",
            "300/300 [==============================] - 0s 1ms/step - loss: 0.3235 - accuracy: 0.8547\n",
            "Epoch 1/50\n",
            "2700/2700 [==============================] - 7s 3ms/step - loss: 0.4095 - accuracy: 0.7980 - val_loss: 0.4484 - val_accuracy: 0.8152\n",
            "Epoch 2/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3539 - accuracy: 0.8396 - val_loss: 0.3327 - val_accuracy: 0.8500\n",
            "Epoch 3/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3279 - accuracy: 0.8450 - val_loss: 0.3299 - val_accuracy: 0.8466\n",
            "Epoch 4/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3305 - accuracy: 0.8448 - val_loss: 0.3427 - val_accuracy: 0.8454\n",
            "Epoch 5/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3182 - accuracy: 0.8516 - val_loss: 0.3380 - val_accuracy: 0.8481\n",
            "Epoch 6/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3188 - accuracy: 0.8507 - val_loss: 0.3562 - val_accuracy: 0.8322\n",
            "Epoch 7/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3142 - accuracy: 0.8545 - val_loss: 0.3511 - val_accuracy: 0.8473\n",
            "Epoch 8/50\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3110 - accuracy: 0.8524 - val_loss: 0.3597 - val_accuracy: 0.8250\n",
            "300/300 [==============================] - 0s 1ms/step - loss: 0.3524 - accuracy: 0.8260\n",
            "Epoch 1/100\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.4304 - accuracy: 0.7979 - val_loss: 0.3423 - val_accuracy: 0.8437\n",
            "Epoch 2/100\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3365 - accuracy: 0.8423 - val_loss: 0.3373 - val_accuracy: 0.8405\n",
            "Epoch 3/100\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3231 - accuracy: 0.8475 - val_loss: 0.3252 - val_accuracy: 0.8499\n",
            "Epoch 4/100\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3151 - accuracy: 0.8534 - val_loss: 0.3214 - val_accuracy: 0.8520\n",
            "Epoch 5/100\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3179 - accuracy: 0.8512 - val_loss: 0.3255 - val_accuracy: 0.8463\n",
            "Epoch 6/100\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3203 - accuracy: 0.8474 - val_loss: 0.3222 - val_accuracy: 0.8497\n",
            "Epoch 7/100\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3118 - accuracy: 0.8512 - val_loss: 0.3216 - val_accuracy: 0.8536\n",
            "Epoch 8/100\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3080 - accuracy: 0.8534 - val_loss: 0.3240 - val_accuracy: 0.8525\n",
            "Epoch 9/100\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.2992 - accuracy: 0.8583 - val_loss: 0.3287 - val_accuracy: 0.8509\n",
            "300/300 [==============================] - 0s 1ms/step - loss: 0.3190 - accuracy: 0.8560\n",
            "Epoch 1/100\n",
            "2700/2700 [==============================] - 7s 2ms/step - loss: 0.4305 - accuracy: 0.7979 - val_loss: 0.3518 - val_accuracy: 0.8394\n",
            "Epoch 2/100\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3406 - accuracy: 0.8423 - val_loss: 0.3320 - val_accuracy: 0.8494\n",
            "Epoch 3/100\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3313 - accuracy: 0.8457 - val_loss: 0.3263 - val_accuracy: 0.8513\n",
            "Epoch 4/100\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3229 - accuracy: 0.8458 - val_loss: 0.3255 - val_accuracy: 0.8485\n",
            "Epoch 5/100\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3101 - accuracy: 0.8543 - val_loss: 0.3217 - val_accuracy: 0.8519\n",
            "Epoch 6/100\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3089 - accuracy: 0.8556 - val_loss: 0.3311 - val_accuracy: 0.8447\n",
            "Epoch 7/100\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3132 - accuracy: 0.8516 - val_loss: 0.3273 - val_accuracy: 0.8508\n",
            "Epoch 8/100\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3107 - accuracy: 0.8509 - val_loss: 0.3306 - val_accuracy: 0.8473\n",
            "Epoch 9/100\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3040 - accuracy: 0.8591 - val_loss: 0.3296 - val_accuracy: 0.8490\n",
            "Epoch 10/100\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3061 - accuracy: 0.8569 - val_loss: 0.3250 - val_accuracy: 0.8496\n",
            "300/300 [==============================] - 0s 1ms/step - loss: 0.3154 - accuracy: 0.8533\n",
            "Epoch 1/100\n",
            "2700/2700 [==============================] - 7s 2ms/step - loss: 0.4327 - accuracy: 0.7977 - val_loss: 0.3492 - val_accuracy: 0.8398\n",
            "Epoch 2/100\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3418 - accuracy: 0.8390 - val_loss: 0.3259 - val_accuracy: 0.8505\n",
            "Epoch 3/100\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3363 - accuracy: 0.8412 - val_loss: 0.3227 - val_accuracy: 0.8540\n",
            "Epoch 4/100\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3220 - accuracy: 0.8485 - val_loss: 0.3251 - val_accuracy: 0.8532\n",
            "Epoch 5/100\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3108 - accuracy: 0.8584 - val_loss: 0.3221 - val_accuracy: 0.8525\n",
            "Epoch 6/100\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3088 - accuracy: 0.8559 - val_loss: 0.3218 - val_accuracy: 0.8528\n",
            "Epoch 7/100\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3110 - accuracy: 0.8561 - val_loss: 0.3218 - val_accuracy: 0.8506\n",
            "Epoch 8/100\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3057 - accuracy: 0.8574 - val_loss: 0.3350 - val_accuracy: 0.8495\n",
            "Epoch 9/100\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3082 - accuracy: 0.8567 - val_loss: 0.3249 - val_accuracy: 0.8525\n",
            "Epoch 10/100\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3014 - accuracy: 0.8582 - val_loss: 0.3386 - val_accuracy: 0.8419\n",
            "Epoch 11/100\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3032 - accuracy: 0.8580 - val_loss: 0.3248 - val_accuracy: 0.8515\n",
            "Epoch 12/100\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.2939 - accuracy: 0.8646 - val_loss: 0.3288 - val_accuracy: 0.8503\n",
            "300/300 [==============================] - 0s 1ms/step - loss: 0.3233 - accuracy: 0.8453\n",
            "Epoch 1/100\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.4297 - accuracy: 0.7969 - val_loss: 0.3498 - val_accuracy: 0.8411\n",
            "Epoch 2/100\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3474 - accuracy: 0.8365 - val_loss: 0.3258 - val_accuracy: 0.8495\n",
            "Epoch 3/100\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3261 - accuracy: 0.8467 - val_loss: 0.3315 - val_accuracy: 0.8460\n",
            "Epoch 4/100\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3229 - accuracy: 0.8479 - val_loss: 0.3239 - val_accuracy: 0.8499\n",
            "Epoch 5/100\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3183 - accuracy: 0.8502 - val_loss: 0.3231 - val_accuracy: 0.8508\n",
            "Epoch 6/100\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3165 - accuracy: 0.8485 - val_loss: 0.3259 - val_accuracy: 0.8527\n",
            "Epoch 7/100\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3089 - accuracy: 0.8542 - val_loss: 0.3351 - val_accuracy: 0.8461\n",
            "Epoch 8/100\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3031 - accuracy: 0.8603 - val_loss: 0.3251 - val_accuracy: 0.8511\n",
            "Epoch 9/100\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3165 - accuracy: 0.8476 - val_loss: 0.3329 - val_accuracy: 0.8400\n",
            "Epoch 10/100\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.2997 - accuracy: 0.8603 - val_loss: 0.3262 - val_accuracy: 0.8481\n",
            "300/300 [==============================] - 0s 999us/step - loss: 0.3262 - accuracy: 0.8500\n",
            "Epoch 1/100\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.4349 - accuracy: 0.7988 - val_loss: 0.3428 - val_accuracy: 0.8409\n",
            "Epoch 2/100\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3475 - accuracy: 0.8362 - val_loss: 0.3253 - val_accuracy: 0.8508\n",
            "Epoch 3/100\n",
            "2700/2700 [==============================] - 7s 2ms/step - loss: 0.3223 - accuracy: 0.8451 - val_loss: 0.3302 - val_accuracy: 0.8490\n",
            "Epoch 4/100\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3144 - accuracy: 0.8482 - val_loss: 0.3223 - val_accuracy: 0.8531\n",
            "Epoch 5/100\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3194 - accuracy: 0.8529 - val_loss: 0.3322 - val_accuracy: 0.8408\n",
            "Epoch 6/100\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3193 - accuracy: 0.8487 - val_loss: 0.3213 - val_accuracy: 0.8513\n",
            "Epoch 7/100\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3093 - accuracy: 0.8542 - val_loss: 0.3242 - val_accuracy: 0.8505\n",
            "Epoch 8/100\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3100 - accuracy: 0.8538 - val_loss: 0.3299 - val_accuracy: 0.8455\n",
            "Epoch 9/100\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.2985 - accuracy: 0.8591 - val_loss: 0.3289 - val_accuracy: 0.8501\n",
            "Epoch 10/100\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3029 - accuracy: 0.8557 - val_loss: 0.3292 - val_accuracy: 0.8520\n",
            "Epoch 11/100\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.2934 - accuracy: 0.8608 - val_loss: 0.3250 - val_accuracy: 0.8533\n",
            "300/300 [==============================] - 0s 987us/step - loss: 0.3426 - accuracy: 0.8413\n",
            "Epoch 1/100\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.4372 - accuracy: 0.7861 - val_loss: 0.3624 - val_accuracy: 0.8379\n",
            "Epoch 2/100\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3522 - accuracy: 0.8384 - val_loss: 0.3573 - val_accuracy: 0.8370\n",
            "Epoch 3/100\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3450 - accuracy: 0.8410 - val_loss: 0.3351 - val_accuracy: 0.8501\n",
            "Epoch 4/100\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3262 - accuracy: 0.8473 - val_loss: 0.3399 - val_accuracy: 0.8475\n",
            "Epoch 5/100\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3182 - accuracy: 0.8545 - val_loss: 0.3281 - val_accuracy: 0.8529\n",
            "Epoch 6/100\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3221 - accuracy: 0.8515 - val_loss: 0.3287 - val_accuracy: 0.8535\n",
            "Epoch 7/100\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3080 - accuracy: 0.8603 - val_loss: 0.3290 - val_accuracy: 0.8499\n",
            "Epoch 8/100\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3088 - accuracy: 0.8563 - val_loss: 0.3263 - val_accuracy: 0.8528\n",
            "Epoch 9/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3052 - accuracy: 0.8563 - val_loss: 0.3329 - val_accuracy: 0.8440\n",
            "Epoch 10/100\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3071 - accuracy: 0.8591 - val_loss: 0.3270 - val_accuracy: 0.8487\n",
            "Epoch 11/100\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.2950 - accuracy: 0.8616 - val_loss: 0.3278 - val_accuracy: 0.8538\n",
            "Epoch 12/100\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.2966 - accuracy: 0.8630 - val_loss: 0.3315 - val_accuracy: 0.8489\n",
            "Epoch 13/100\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3005 - accuracy: 0.8590 - val_loss: 0.3351 - val_accuracy: 0.8499\n",
            "300/300 [==============================] - 0s 1ms/step - loss: 0.3320 - accuracy: 0.8513\n",
            "Epoch 1/100\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.4281 - accuracy: 0.7980 - val_loss: 0.3460 - val_accuracy: 0.8406\n",
            "Epoch 2/100\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3502 - accuracy: 0.8285 - val_loss: 0.3447 - val_accuracy: 0.8384\n",
            "Epoch 3/100\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3264 - accuracy: 0.8501 - val_loss: 0.3226 - val_accuracy: 0.8542\n",
            "Epoch 4/100\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3245 - accuracy: 0.8486 - val_loss: 0.3257 - val_accuracy: 0.8535\n",
            "Epoch 5/100\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3187 - accuracy: 0.8503 - val_loss: 0.3233 - val_accuracy: 0.8504\n",
            "Epoch 6/100\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3189 - accuracy: 0.8462 - val_loss: 0.3222 - val_accuracy: 0.8541\n",
            "Epoch 7/100\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3058 - accuracy: 0.8569 - val_loss: 0.3213 - val_accuracy: 0.8561\n",
            "Epoch 8/100\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3105 - accuracy: 0.8489 - val_loss: 0.3266 - val_accuracy: 0.8526\n",
            "Epoch 9/100\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3029 - accuracy: 0.8594 - val_loss: 0.3231 - val_accuracy: 0.8513\n",
            "Epoch 10/100\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3034 - accuracy: 0.8598 - val_loss: 0.3256 - val_accuracy: 0.8516\n",
            "Epoch 11/100\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.2884 - accuracy: 0.8651 - val_loss: 0.3247 - val_accuracy: 0.8530\n",
            "Epoch 12/100\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3022 - accuracy: 0.8600 - val_loss: 0.3311 - val_accuracy: 0.8494\n",
            "300/300 [==============================] - 0s 1ms/step - loss: 0.3287 - accuracy: 0.8500\n",
            "Epoch 1/100\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.4257 - accuracy: 0.7999 - val_loss: 0.3494 - val_accuracy: 0.8402\n",
            "Epoch 2/100\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3462 - accuracy: 0.8376 - val_loss: 0.3733 - val_accuracy: 0.8256\n",
            "Epoch 3/100\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3243 - accuracy: 0.8479 - val_loss: 0.3262 - val_accuracy: 0.8504\n",
            "Epoch 4/100\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3090 - accuracy: 0.8560 - val_loss: 0.3310 - val_accuracy: 0.8469\n",
            "Epoch 5/100\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3145 - accuracy: 0.8525 - val_loss: 0.3236 - val_accuracy: 0.8542\n",
            "Epoch 6/100\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3073 - accuracy: 0.8565 - val_loss: 0.3272 - val_accuracy: 0.8493\n",
            "Epoch 7/100\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3105 - accuracy: 0.8533 - val_loss: 0.3255 - val_accuracy: 0.8520\n",
            "Epoch 8/100\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3073 - accuracy: 0.8576 - val_loss: 0.3261 - val_accuracy: 0.8500\n",
            "Epoch 9/100\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.2957 - accuracy: 0.8630 - val_loss: 0.3259 - val_accuracy: 0.8533\n",
            "Epoch 10/100\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3097 - accuracy: 0.8559 - val_loss: 0.3320 - val_accuracy: 0.8474\n",
            "300/300 [==============================] - 0s 1ms/step - loss: 0.3309 - accuracy: 0.8460\n",
            "Epoch 1/100\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.4281 - accuracy: 0.8011 - val_loss: 0.3470 - val_accuracy: 0.8409\n",
            "Epoch 2/100\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3466 - accuracy: 0.8356 - val_loss: 0.3333 - val_accuracy: 0.8498\n",
            "Epoch 3/100\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3256 - accuracy: 0.8447 - val_loss: 0.3258 - val_accuracy: 0.8537\n",
            "Epoch 4/100\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3282 - accuracy: 0.8418 - val_loss: 0.3226 - val_accuracy: 0.8533\n",
            "Epoch 5/100\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3218 - accuracy: 0.8455 - val_loss: 0.3376 - val_accuracy: 0.8414\n",
            "Epoch 6/100\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3067 - accuracy: 0.8567 - val_loss: 0.3218 - val_accuracy: 0.8521\n",
            "Epoch 7/100\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3227 - accuracy: 0.8448 - val_loss: 0.3225 - val_accuracy: 0.8565\n",
            "Epoch 8/100\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3101 - accuracy: 0.8557 - val_loss: 0.3207 - val_accuracy: 0.8526\n",
            "Epoch 9/100\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3054 - accuracy: 0.8590 - val_loss: 0.3236 - val_accuracy: 0.8529\n",
            "Epoch 10/100\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3029 - accuracy: 0.8600 - val_loss: 0.3343 - val_accuracy: 0.8458\n",
            "Epoch 11/100\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3040 - accuracy: 0.8582 - val_loss: 0.3227 - val_accuracy: 0.8512\n",
            "Epoch 12/100\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3010 - accuracy: 0.8564 - val_loss: 0.3267 - val_accuracy: 0.8521\n",
            "Epoch 13/100\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.2967 - accuracy: 0.8599 - val_loss: 0.3282 - val_accuracy: 0.8507\n",
            "300/300 [==============================] - 0s 1ms/step - loss: 0.3122 - accuracy: 0.8587\n",
            "Epoch 1/100\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.4373 - accuracy: 0.7945 - val_loss: 0.3551 - val_accuracy: 0.8398\n",
            "Epoch 2/100\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3410 - accuracy: 0.8439 - val_loss: 0.3338 - val_accuracy: 0.8470\n",
            "Epoch 3/100\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3329 - accuracy: 0.8470 - val_loss: 0.3255 - val_accuracy: 0.8537\n",
            "Epoch 4/100\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3183 - accuracy: 0.8537 - val_loss: 0.3202 - val_accuracy: 0.8528\n",
            "Epoch 5/100\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3177 - accuracy: 0.8506 - val_loss: 0.3291 - val_accuracy: 0.8483\n",
            "Epoch 6/100\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3096 - accuracy: 0.8523 - val_loss: 0.3212 - val_accuracy: 0.8532\n",
            "Epoch 7/100\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3063 - accuracy: 0.8606 - val_loss: 0.3256 - val_accuracy: 0.8509\n",
            "Epoch 8/100\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3088 - accuracy: 0.8554 - val_loss: 0.3383 - val_accuracy: 0.8447\n",
            "Epoch 9/100\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3005 - accuracy: 0.8539 - val_loss: 0.3261 - val_accuracy: 0.8531\n",
            "300/300 [==============================] - 0s 958us/step - loss: 0.3245 - accuracy: 0.8473\n",
            "Epoch 1/100\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.4309 - accuracy: 0.7928 - val_loss: 0.3459 - val_accuracy: 0.8393\n",
            "Epoch 2/100\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3466 - accuracy: 0.8390 - val_loss: 0.3327 - val_accuracy: 0.8466\n",
            "Epoch 3/100\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3210 - accuracy: 0.8520 - val_loss: 0.3240 - val_accuracy: 0.8523\n",
            "Epoch 4/100\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3229 - accuracy: 0.8457 - val_loss: 0.3268 - val_accuracy: 0.8525\n",
            "Epoch 5/100\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3181 - accuracy: 0.8501 - val_loss: 0.3265 - val_accuracy: 0.8550\n",
            "Epoch 6/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3155 - accuracy: 0.8488 - val_loss: 0.3234 - val_accuracy: 0.8522\n",
            "Epoch 7/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3150 - accuracy: 0.8480 - val_loss: 0.3222 - val_accuracy: 0.8522\n",
            "Epoch 8/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3091 - accuracy: 0.8557 - val_loss: 0.3689 - val_accuracy: 0.8223\n",
            "Epoch 9/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3063 - accuracy: 0.8544 - val_loss: 0.3246 - val_accuracy: 0.8512\n",
            "Epoch 10/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3044 - accuracy: 0.8549 - val_loss: 0.3238 - val_accuracy: 0.8535\n",
            "Epoch 11/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3071 - accuracy: 0.8545 - val_loss: 0.3263 - val_accuracy: 0.8505\n",
            "Epoch 12/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.2989 - accuracy: 0.8622 - val_loss: 0.3276 - val_accuracy: 0.8535\n",
            "300/300 [==============================] - 0s 914us/step - loss: 0.3193 - accuracy: 0.8560\n",
            "Epoch 1/100\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.4316 - accuracy: 0.7898 - val_loss: 0.3436 - val_accuracy: 0.8410\n",
            "Epoch 2/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3347 - accuracy: 0.8415 - val_loss: 0.3267 - val_accuracy: 0.8515\n",
            "Epoch 3/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3287 - accuracy: 0.8462 - val_loss: 0.3319 - val_accuracy: 0.8449\n",
            "Epoch 4/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3219 - accuracy: 0.8493 - val_loss: 0.3227 - val_accuracy: 0.8528\n",
            "Epoch 5/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3154 - accuracy: 0.8517 - val_loss: 0.3314 - val_accuracy: 0.8442\n",
            "Epoch 6/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3122 - accuracy: 0.8534 - val_loss: 0.3308 - val_accuracy: 0.8473\n",
            "Epoch 7/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3141 - accuracy: 0.8483 - val_loss: 0.3600 - val_accuracy: 0.8331\n",
            "Epoch 8/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3063 - accuracy: 0.8547 - val_loss: 0.3234 - val_accuracy: 0.8528\n",
            "Epoch 9/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3104 - accuracy: 0.8494 - val_loss: 0.3263 - val_accuracy: 0.8509\n",
            "300/300 [==============================] - 0s 888us/step - loss: 0.3166 - accuracy: 0.8580\n",
            "Epoch 1/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.4280 - accuracy: 0.7992 - val_loss: 0.3532 - val_accuracy: 0.8407\n",
            "Epoch 2/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3449 - accuracy: 0.8397 - val_loss: 0.3293 - val_accuracy: 0.8497\n",
            "Epoch 3/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3207 - accuracy: 0.8481 - val_loss: 0.3240 - val_accuracy: 0.8532\n",
            "Epoch 4/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3218 - accuracy: 0.8512 - val_loss: 0.3234 - val_accuracy: 0.8519\n",
            "Epoch 5/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3145 - accuracy: 0.8517 - val_loss: 0.3231 - val_accuracy: 0.8539\n",
            "Epoch 6/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3135 - accuracy: 0.8495 - val_loss: 0.3238 - val_accuracy: 0.8524\n",
            "Epoch 7/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3203 - accuracy: 0.8505 - val_loss: 0.3242 - val_accuracy: 0.8501\n",
            "Epoch 8/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3076 - accuracy: 0.8598 - val_loss: 0.3339 - val_accuracy: 0.8385\n",
            "Epoch 9/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.2989 - accuracy: 0.8623 - val_loss: 0.3226 - val_accuracy: 0.8503\n",
            "Epoch 10/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.2996 - accuracy: 0.8613 - val_loss: 0.3239 - val_accuracy: 0.8507\n",
            "Epoch 11/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3006 - accuracy: 0.8560 - val_loss: 0.3238 - val_accuracy: 0.8508\n",
            "Epoch 12/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.2985 - accuracy: 0.8605 - val_loss: 0.3360 - val_accuracy: 0.8418\n",
            "Epoch 13/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.2977 - accuracy: 0.8643 - val_loss: 0.3261 - val_accuracy: 0.8497\n",
            "Epoch 14/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.2880 - accuracy: 0.8662 - val_loss: 0.3319 - val_accuracy: 0.8509\n",
            "300/300 [==============================] - 0s 929us/step - loss: 0.3311 - accuracy: 0.8393\n",
            "Epoch 1/100\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.4213 - accuracy: 0.8001 - val_loss: 0.3413 - val_accuracy: 0.8414\n",
            "Epoch 2/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3397 - accuracy: 0.8352 - val_loss: 0.3333 - val_accuracy: 0.8476\n",
            "Epoch 3/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3249 - accuracy: 0.8491 - val_loss: 0.3259 - val_accuracy: 0.8480\n",
            "Epoch 4/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3237 - accuracy: 0.8437 - val_loss: 0.3235 - val_accuracy: 0.8493\n",
            "Epoch 5/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3130 - accuracy: 0.8496 - val_loss: 0.3278 - val_accuracy: 0.8493\n",
            "Epoch 6/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3095 - accuracy: 0.8547 - val_loss: 0.3318 - val_accuracy: 0.8481\n",
            "Epoch 7/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3007 - accuracy: 0.8604 - val_loss: 0.3357 - val_accuracy: 0.8442\n",
            "Epoch 8/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3099 - accuracy: 0.8511 - val_loss: 0.3233 - val_accuracy: 0.8544\n",
            "Epoch 9/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3070 - accuracy: 0.8520 - val_loss: 0.3236 - val_accuracy: 0.8512\n",
            "Epoch 10/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.2969 - accuracy: 0.8614 - val_loss: 0.3289 - val_accuracy: 0.8497\n",
            "Epoch 11/100\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.2972 - accuracy: 0.8550 - val_loss: 0.3312 - val_accuracy: 0.8470\n",
            "Epoch 12/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.2918 - accuracy: 0.8621 - val_loss: 0.3293 - val_accuracy: 0.8507\n",
            "Epoch 13/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.2947 - accuracy: 0.8601 - val_loss: 0.3296 - val_accuracy: 0.8521\n",
            "300/300 [==============================] - 0s 929us/step - loss: 0.3303 - accuracy: 0.8513\n",
            "Epoch 1/100\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.4276 - accuracy: 0.7977 - val_loss: 0.3497 - val_accuracy: 0.8331\n",
            "Epoch 2/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3399 - accuracy: 0.8399 - val_loss: 0.3216 - val_accuracy: 0.8551\n",
            "Epoch 3/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3231 - accuracy: 0.8480 - val_loss: 0.3271 - val_accuracy: 0.8525\n",
            "Epoch 4/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3133 - accuracy: 0.8488 - val_loss: 0.3384 - val_accuracy: 0.8369\n",
            "Epoch 5/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3106 - accuracy: 0.8524 - val_loss: 0.3253 - val_accuracy: 0.8508\n",
            "Epoch 6/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3131 - accuracy: 0.8541 - val_loss: 0.3391 - val_accuracy: 0.8410\n",
            "Epoch 7/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3132 - accuracy: 0.8502 - val_loss: 0.3261 - val_accuracy: 0.8535\n",
            "300/300 [==============================] - 0s 823us/step - loss: 0.3392 - accuracy: 0.8393\n",
            "Epoch 1/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.4298 - accuracy: 0.8003 - val_loss: 0.3510 - val_accuracy: 0.8408\n",
            "Epoch 2/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3428 - accuracy: 0.8389 - val_loss: 0.3294 - val_accuracy: 0.8507\n",
            "Epoch 3/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3241 - accuracy: 0.8475 - val_loss: 0.3245 - val_accuracy: 0.8517\n",
            "Epoch 4/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3251 - accuracy: 0.8420 - val_loss: 0.3290 - val_accuracy: 0.8494\n",
            "Epoch 5/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3248 - accuracy: 0.8441 - val_loss: 0.3296 - val_accuracy: 0.8472\n",
            "Epoch 6/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3202 - accuracy: 0.8462 - val_loss: 0.3249 - val_accuracy: 0.8530\n",
            "Epoch 7/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3109 - accuracy: 0.8532 - val_loss: 0.3311 - val_accuracy: 0.8492\n",
            "Epoch 8/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3080 - accuracy: 0.8581 - val_loss: 0.3228 - val_accuracy: 0.8523\n",
            "Epoch 9/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3020 - accuracy: 0.8571 - val_loss: 0.3324 - val_accuracy: 0.8515\n",
            "Epoch 10/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.2959 - accuracy: 0.8613 - val_loss: 0.3263 - val_accuracy: 0.8520\n",
            "Epoch 11/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.2901 - accuracy: 0.8603 - val_loss: 0.3305 - val_accuracy: 0.8487\n",
            "Epoch 12/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.2960 - accuracy: 0.8625 - val_loss: 0.3338 - val_accuracy: 0.8460\n",
            "Epoch 13/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.2838 - accuracy: 0.8670 - val_loss: 0.3344 - val_accuracy: 0.8502\n",
            "300/300 [==============================] - 0s 957us/step - loss: 0.3377 - accuracy: 0.8467\n",
            "Epoch 1/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.4259 - accuracy: 0.8016 - val_loss: 0.3425 - val_accuracy: 0.8421\n",
            "Epoch 2/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3495 - accuracy: 0.8329 - val_loss: 0.3497 - val_accuracy: 0.8446\n",
            "Epoch 3/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3305 - accuracy: 0.8459 - val_loss: 0.3248 - val_accuracy: 0.8511\n",
            "Epoch 4/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3179 - accuracy: 0.8473 - val_loss: 0.3279 - val_accuracy: 0.8525\n",
            "Epoch 5/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3220 - accuracy: 0.8474 - val_loss: 0.3227 - val_accuracy: 0.8515\n",
            "Epoch 6/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3203 - accuracy: 0.8505 - val_loss: 0.3240 - val_accuracy: 0.8520\n",
            "Epoch 7/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3050 - accuracy: 0.8567 - val_loss: 0.3235 - val_accuracy: 0.8514\n",
            "Epoch 8/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3136 - accuracy: 0.8552 - val_loss: 0.3332 - val_accuracy: 0.8513\n",
            "Epoch 9/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3069 - accuracy: 0.8541 - val_loss: 0.3270 - val_accuracy: 0.8535\n",
            "Epoch 10/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.2981 - accuracy: 0.8614 - val_loss: 0.3311 - val_accuracy: 0.8511\n",
            "300/300 [==============================] - 0s 925us/step - loss: 0.3264 - accuracy: 0.8473\n",
            "Epoch 1/100\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.4188 - accuracy: 0.8088 - val_loss: 0.3466 - val_accuracy: 0.8425\n",
            "Epoch 2/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3359 - accuracy: 0.8378 - val_loss: 0.3255 - val_accuracy: 0.8507\n",
            "Epoch 3/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3162 - accuracy: 0.8508 - val_loss: 0.3298 - val_accuracy: 0.8525\n",
            "Epoch 4/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3190 - accuracy: 0.8489 - val_loss: 0.3247 - val_accuracy: 0.8501\n",
            "Epoch 5/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3146 - accuracy: 0.8521 - val_loss: 0.3260 - val_accuracy: 0.8492\n",
            "Epoch 6/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3077 - accuracy: 0.8533 - val_loss: 0.3219 - val_accuracy: 0.8522\n",
            "Epoch 7/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3108 - accuracy: 0.8561 - val_loss: 0.3343 - val_accuracy: 0.8463\n",
            "Epoch 8/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3048 - accuracy: 0.8532 - val_loss: 0.3303 - val_accuracy: 0.8511\n",
            "Epoch 9/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.2928 - accuracy: 0.8628 - val_loss: 0.3284 - val_accuracy: 0.8508\n",
            "Epoch 10/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3022 - accuracy: 0.8554 - val_loss: 0.3318 - val_accuracy: 0.8473\n",
            "Epoch 11/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.2914 - accuracy: 0.8655 - val_loss: 0.3273 - val_accuracy: 0.8509\n",
            "300/300 [==============================] - 0s 918us/step - loss: 0.3280 - accuracy: 0.8440\n",
            "Epoch 1/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.4311 - accuracy: 0.7961 - val_loss: 0.3422 - val_accuracy: 0.8425\n",
            "Epoch 2/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3416 - accuracy: 0.8367 - val_loss: 0.3353 - val_accuracy: 0.8470\n",
            "Epoch 3/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3242 - accuracy: 0.8504 - val_loss: 0.3313 - val_accuracy: 0.8448\n",
            "Epoch 4/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3105 - accuracy: 0.8580 - val_loss: 0.3253 - val_accuracy: 0.8527\n",
            "Epoch 5/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3148 - accuracy: 0.8526 - val_loss: 0.3219 - val_accuracy: 0.8539\n",
            "Epoch 6/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3123 - accuracy: 0.8558 - val_loss: 0.3303 - val_accuracy: 0.8454\n",
            "Epoch 7/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3069 - accuracy: 0.8541 - val_loss: 0.3264 - val_accuracy: 0.8488\n",
            "Epoch 8/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.2982 - accuracy: 0.8647 - val_loss: 0.3283 - val_accuracy: 0.8490\n",
            "Epoch 9/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3053 - accuracy: 0.8547 - val_loss: 0.3255 - val_accuracy: 0.8491\n",
            "Epoch 10/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.2966 - accuracy: 0.8609 - val_loss: 0.3258 - val_accuracy: 0.8500\n",
            "300/300 [==============================] - 0s 867us/step - loss: 0.3145 - accuracy: 0.8547\n",
            "Epoch 1/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.4319 - accuracy: 0.7970 - val_loss: 0.3421 - val_accuracy: 0.8415\n",
            "Epoch 2/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3375 - accuracy: 0.8428 - val_loss: 0.3299 - val_accuracy: 0.8464\n",
            "Epoch 3/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3218 - accuracy: 0.8456 - val_loss: 0.3447 - val_accuracy: 0.8401\n",
            "Epoch 4/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3179 - accuracy: 0.8511 - val_loss: 0.3215 - val_accuracy: 0.8538\n",
            "Epoch 5/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3177 - accuracy: 0.8473 - val_loss: 0.3255 - val_accuracy: 0.8513\n",
            "Epoch 6/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3077 - accuracy: 0.8560 - val_loss: 0.3280 - val_accuracy: 0.8490\n",
            "Epoch 7/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3037 - accuracy: 0.8534 - val_loss: 0.3246 - val_accuracy: 0.8507\n",
            "Epoch 8/100\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3116 - accuracy: 0.8517 - val_loss: 0.3232 - val_accuracy: 0.8512\n",
            "Epoch 9/100\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3093 - accuracy: 0.8528 - val_loss: 0.3424 - val_accuracy: 0.8339\n",
            "300/300 [==============================] - 0s 976us/step - loss: 0.3399 - accuracy: 0.8293\n",
            "Epoch 1/100\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.4238 - accuracy: 0.8010 - val_loss: 0.3457 - val_accuracy: 0.8430\n",
            "Epoch 2/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3409 - accuracy: 0.8382 - val_loss: 0.3378 - val_accuracy: 0.8403\n",
            "Epoch 3/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3200 - accuracy: 0.8469 - val_loss: 0.3251 - val_accuracy: 0.8505\n",
            "Epoch 4/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3154 - accuracy: 0.8527 - val_loss: 0.3258 - val_accuracy: 0.8508\n",
            "Epoch 5/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3201 - accuracy: 0.8516 - val_loss: 0.3304 - val_accuracy: 0.8408\n",
            "Epoch 6/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3149 - accuracy: 0.8494 - val_loss: 0.3231 - val_accuracy: 0.8533\n",
            "Epoch 7/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3132 - accuracy: 0.8519 - val_loss: 0.3313 - val_accuracy: 0.8456\n",
            "Epoch 8/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3090 - accuracy: 0.8527 - val_loss: 0.3243 - val_accuracy: 0.8542\n",
            "Epoch 9/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3023 - accuracy: 0.8601 - val_loss: 0.3341 - val_accuracy: 0.8501\n",
            "Epoch 10/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3052 - accuracy: 0.8545 - val_loss: 0.3267 - val_accuracy: 0.8483\n",
            "Epoch 11/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3033 - accuracy: 0.8599 - val_loss: 0.3296 - val_accuracy: 0.8531\n",
            "300/300 [==============================] - 0s 910us/step - loss: 0.3233 - accuracy: 0.8627\n",
            "Epoch 1/100\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.4271 - accuracy: 0.8037 - val_loss: 0.3634 - val_accuracy: 0.8226\n",
            "Epoch 2/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3367 - accuracy: 0.8387 - val_loss: 0.3270 - val_accuracy: 0.8504\n",
            "Epoch 3/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3321 - accuracy: 0.8396 - val_loss: 0.3367 - val_accuracy: 0.8379\n",
            "Epoch 4/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3280 - accuracy: 0.8417 - val_loss: 0.3248 - val_accuracy: 0.8498\n",
            "Epoch 5/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3061 - accuracy: 0.8563 - val_loss: 0.3343 - val_accuracy: 0.8442\n",
            "Epoch 6/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3133 - accuracy: 0.8528 - val_loss: 0.3234 - val_accuracy: 0.8515\n",
            "Epoch 7/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3121 - accuracy: 0.8517 - val_loss: 0.3250 - val_accuracy: 0.8498\n",
            "Epoch 8/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3005 - accuracy: 0.8579 - val_loss: 0.3388 - val_accuracy: 0.8466\n",
            "Epoch 9/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3064 - accuracy: 0.8553 - val_loss: 0.3243 - val_accuracy: 0.8492\n",
            "Epoch 10/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.2989 - accuracy: 0.8580 - val_loss: 0.3274 - val_accuracy: 0.8494\n",
            "Epoch 11/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.2911 - accuracy: 0.8619 - val_loss: 0.3302 - val_accuracy: 0.8454\n",
            "300/300 [==============================] - 0s 860us/step - loss: 0.3176 - accuracy: 0.8527\n",
            "Epoch 1/100\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.4285 - accuracy: 0.7953 - val_loss: 0.3422 - val_accuracy: 0.8394\n",
            "Epoch 2/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3362 - accuracy: 0.8425 - val_loss: 0.3252 - val_accuracy: 0.8524\n",
            "Epoch 3/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3330 - accuracy: 0.8427 - val_loss: 0.3234 - val_accuracy: 0.8539\n",
            "Epoch 4/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3123 - accuracy: 0.8534 - val_loss: 0.3223 - val_accuracy: 0.8535\n",
            "Epoch 5/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3168 - accuracy: 0.8506 - val_loss: 0.3255 - val_accuracy: 0.8493\n",
            "Epoch 6/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3137 - accuracy: 0.8500 - val_loss: 0.3412 - val_accuracy: 0.8364\n",
            "Epoch 7/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3143 - accuracy: 0.8499 - val_loss: 0.3244 - val_accuracy: 0.8532\n",
            "Epoch 8/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3041 - accuracy: 0.8580 - val_loss: 0.3278 - val_accuracy: 0.8486\n",
            "Epoch 9/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3061 - accuracy: 0.8550 - val_loss: 0.3218 - val_accuracy: 0.8534\n",
            "Epoch 10/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.2969 - accuracy: 0.8614 - val_loss: 0.3318 - val_accuracy: 0.8473\n",
            "Epoch 11/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3007 - accuracy: 0.8581 - val_loss: 0.3348 - val_accuracy: 0.8447\n",
            "Epoch 12/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3036 - accuracy: 0.8579 - val_loss: 0.3270 - val_accuracy: 0.8526\n",
            "Epoch 13/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.2893 - accuracy: 0.8630 - val_loss: 0.3275 - val_accuracy: 0.8526\n",
            "Epoch 14/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.2851 - accuracy: 0.8656 - val_loss: 0.3279 - val_accuracy: 0.8500\n",
            "300/300 [==============================] - 0s 957us/step - loss: 0.3228 - accuracy: 0.8460\n",
            "Epoch 1/100\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.4301 - accuracy: 0.7897 - val_loss: 0.3441 - val_accuracy: 0.8413\n",
            "Epoch 2/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3351 - accuracy: 0.8416 - val_loss: 0.3262 - val_accuracy: 0.8539\n",
            "Epoch 3/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3291 - accuracy: 0.8439 - val_loss: 0.3378 - val_accuracy: 0.8441\n",
            "Epoch 4/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3171 - accuracy: 0.8488 - val_loss: 0.3225 - val_accuracy: 0.8526\n",
            "Epoch 5/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3163 - accuracy: 0.8490 - val_loss: 0.3221 - val_accuracy: 0.8545\n",
            "Epoch 6/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3130 - accuracy: 0.8470 - val_loss: 0.3243 - val_accuracy: 0.8539\n",
            "Epoch 7/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3060 - accuracy: 0.8562 - val_loss: 0.3349 - val_accuracy: 0.8392\n",
            "Epoch 8/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3078 - accuracy: 0.8554 - val_loss: 0.3239 - val_accuracy: 0.8525\n",
            "Epoch 9/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3063 - accuracy: 0.8557 - val_loss: 0.3276 - val_accuracy: 0.8516\n",
            "Epoch 10/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3033 - accuracy: 0.8555 - val_loss: 0.3232 - val_accuracy: 0.8525\n",
            "300/300 [==============================] - 0s 913us/step - loss: 0.3237 - accuracy: 0.8593\n",
            "Epoch 1/100\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.4200 - accuracy: 0.8078 - val_loss: 0.3447 - val_accuracy: 0.8430\n",
            "Epoch 2/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3351 - accuracy: 0.8404 - val_loss: 0.3313 - val_accuracy: 0.8501\n",
            "Epoch 3/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3297 - accuracy: 0.8434 - val_loss: 0.3314 - val_accuracy: 0.8499\n",
            "Epoch 4/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3182 - accuracy: 0.8510 - val_loss: 0.3256 - val_accuracy: 0.8486\n",
            "Epoch 5/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3109 - accuracy: 0.8574 - val_loss: 0.3268 - val_accuracy: 0.8502\n",
            "Epoch 6/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3095 - accuracy: 0.8571 - val_loss: 0.3391 - val_accuracy: 0.8366\n",
            "Epoch 7/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3089 - accuracy: 0.8553 - val_loss: 0.3259 - val_accuracy: 0.8509\n",
            "Epoch 8/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3074 - accuracy: 0.8598 - val_loss: 0.3539 - val_accuracy: 0.8405\n",
            "Epoch 9/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.2998 - accuracy: 0.8596 - val_loss: 0.3301 - val_accuracy: 0.8487\n",
            "300/300 [==============================] - 0s 925us/step - loss: 0.3416 - accuracy: 0.8420\n",
            "Epoch 1/100\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.4322 - accuracy: 0.7931 - val_loss: 0.3570 - val_accuracy: 0.8348\n",
            "Epoch 2/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3444 - accuracy: 0.8365 - val_loss: 0.3281 - val_accuracy: 0.8507\n",
            "Epoch 3/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3314 - accuracy: 0.8438 - val_loss: 0.3324 - val_accuracy: 0.8450\n",
            "Epoch 4/100\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3168 - accuracy: 0.8477 - val_loss: 0.3234 - val_accuracy: 0.8540\n",
            "Epoch 5/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3176 - accuracy: 0.8492 - val_loss: 0.3255 - val_accuracy: 0.8505\n",
            "Epoch 6/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3141 - accuracy: 0.8504 - val_loss: 0.3288 - val_accuracy: 0.8507\n",
            "Epoch 7/100\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3063 - accuracy: 0.8575 - val_loss: 0.3264 - val_accuracy: 0.8523\n",
            "Epoch 8/100\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3061 - accuracy: 0.8550 - val_loss: 0.3239 - val_accuracy: 0.8534\n",
            "Epoch 9/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.2986 - accuracy: 0.8616 - val_loss: 0.3253 - val_accuracy: 0.8510\n",
            "300/300 [==============================] - 0s 966us/step - loss: 0.3225 - accuracy: 0.8580\n",
            "Epoch 1/100\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.4266 - accuracy: 0.8013 - val_loss: 0.3475 - val_accuracy: 0.8364\n",
            "Epoch 2/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3459 - accuracy: 0.8365 - val_loss: 0.3421 - val_accuracy: 0.8363\n",
            "Epoch 3/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3294 - accuracy: 0.8434 - val_loss: 0.3212 - val_accuracy: 0.8561\n",
            "Epoch 4/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3226 - accuracy: 0.8499 - val_loss: 0.3238 - val_accuracy: 0.8517\n",
            "Epoch 5/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3130 - accuracy: 0.8534 - val_loss: 0.3230 - val_accuracy: 0.8545\n",
            "Epoch 6/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3043 - accuracy: 0.8575 - val_loss: 0.3262 - val_accuracy: 0.8476\n",
            "Epoch 7/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3148 - accuracy: 0.8517 - val_loss: 0.3239 - val_accuracy: 0.8550\n",
            "Epoch 8/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3070 - accuracy: 0.8536 - val_loss: 0.3245 - val_accuracy: 0.8541\n",
            "300/300 [==============================] - 0s 937us/step - loss: 0.3267 - accuracy: 0.8493\n",
            "Epoch 1/100\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.4325 - accuracy: 0.7973 - val_loss: 0.3500 - val_accuracy: 0.8368\n",
            "Epoch 2/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3361 - accuracy: 0.8434 - val_loss: 0.3304 - val_accuracy: 0.8487\n",
            "Epoch 3/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3223 - accuracy: 0.8449 - val_loss: 0.3236 - val_accuracy: 0.8539\n",
            "Epoch 4/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3259 - accuracy: 0.8496 - val_loss: 0.3245 - val_accuracy: 0.8523\n",
            "Epoch 5/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3125 - accuracy: 0.8544 - val_loss: 0.3232 - val_accuracy: 0.8526\n",
            "Epoch 6/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3067 - accuracy: 0.8571 - val_loss: 0.3285 - val_accuracy: 0.8479\n",
            "Epoch 7/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3088 - accuracy: 0.8528 - val_loss: 0.3222 - val_accuracy: 0.8531\n",
            "Epoch 8/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3014 - accuracy: 0.8603 - val_loss: 0.3300 - val_accuracy: 0.8473\n",
            "Epoch 9/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.2983 - accuracy: 0.8602 - val_loss: 0.3270 - val_accuracy: 0.8515\n",
            "Epoch 10/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3036 - accuracy: 0.8569 - val_loss: 0.3278 - val_accuracy: 0.8508\n",
            "Epoch 11/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.2976 - accuracy: 0.8591 - val_loss: 0.3301 - val_accuracy: 0.8475\n",
            "Epoch 12/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3029 - accuracy: 0.8577 - val_loss: 0.3279 - val_accuracy: 0.8508\n",
            "300/300 [==============================] - 0s 873us/step - loss: 0.3295 - accuracy: 0.8467\n",
            "Epoch 1/100\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.4197 - accuracy: 0.8050 - val_loss: 0.3413 - val_accuracy: 0.8425\n",
            "Epoch 2/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3391 - accuracy: 0.8354 - val_loss: 0.3291 - val_accuracy: 0.8495\n",
            "Epoch 3/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3283 - accuracy: 0.8431 - val_loss: 0.3256 - val_accuracy: 0.8502\n",
            "Epoch 4/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3223 - accuracy: 0.8470 - val_loss: 0.3315 - val_accuracy: 0.8457\n",
            "Epoch 5/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3197 - accuracy: 0.8498 - val_loss: 0.3279 - val_accuracy: 0.8509\n",
            "Epoch 6/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3119 - accuracy: 0.8565 - val_loss: 0.3203 - val_accuracy: 0.8523\n",
            "Epoch 7/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3196 - accuracy: 0.8489 - val_loss: 0.3255 - val_accuracy: 0.8493\n",
            "Epoch 8/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3063 - accuracy: 0.8579 - val_loss: 0.3216 - val_accuracy: 0.8539\n",
            "Epoch 9/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.2978 - accuracy: 0.8618 - val_loss: 0.3248 - val_accuracy: 0.8539\n",
            "Epoch 10/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.2974 - accuracy: 0.8615 - val_loss: 0.3271 - val_accuracy: 0.8500\n",
            "Epoch 11/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.2942 - accuracy: 0.8622 - val_loss: 0.3234 - val_accuracy: 0.8530\n",
            "300/300 [==============================] - 0s 914us/step - loss: 0.3126 - accuracy: 0.8527\n",
            "Epoch 1/100\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.4204 - accuracy: 0.8020 - val_loss: 0.3455 - val_accuracy: 0.8443\n",
            "Epoch 2/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3425 - accuracy: 0.8397 - val_loss: 0.3263 - val_accuracy: 0.8513\n",
            "Epoch 3/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3259 - accuracy: 0.8466 - val_loss: 0.3286 - val_accuracy: 0.8471\n",
            "Epoch 4/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3244 - accuracy: 0.8467 - val_loss: 0.3222 - val_accuracy: 0.8520\n",
            "Epoch 5/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3137 - accuracy: 0.8548 - val_loss: 0.3290 - val_accuracy: 0.8500\n",
            "Epoch 6/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3074 - accuracy: 0.8589 - val_loss: 0.3218 - val_accuracy: 0.8519\n",
            "Epoch 7/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3083 - accuracy: 0.8543 - val_loss: 0.3249 - val_accuracy: 0.8520\n",
            "Epoch 8/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3137 - accuracy: 0.8484 - val_loss: 0.3247 - val_accuracy: 0.8521\n",
            "Epoch 9/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3015 - accuracy: 0.8623 - val_loss: 0.3240 - val_accuracy: 0.8532\n",
            "Epoch 10/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.2939 - accuracy: 0.8628 - val_loss: 0.3245 - val_accuracy: 0.8545\n",
            "Epoch 11/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.2909 - accuracy: 0.8641 - val_loss: 0.3275 - val_accuracy: 0.8502\n",
            "300/300 [==============================] - 0s 969us/step - loss: 0.3263 - accuracy: 0.8420\n",
            "Epoch 1/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.4067 - accuracy: 0.7987 - val_loss: 0.3516 - val_accuracy: 0.8434\n",
            "Epoch 2/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3475 - accuracy: 0.8374 - val_loss: 0.3317 - val_accuracy: 0.8505\n",
            "Epoch 3/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3338 - accuracy: 0.8408 - val_loss: 0.3353 - val_accuracy: 0.8458\n",
            "Epoch 4/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3304 - accuracy: 0.8406 - val_loss: 0.3386 - val_accuracy: 0.8462\n",
            "Epoch 5/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3182 - accuracy: 0.8542 - val_loss: 0.3267 - val_accuracy: 0.8525\n",
            "Epoch 6/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3199 - accuracy: 0.8489 - val_loss: 0.3366 - val_accuracy: 0.8460\n",
            "Epoch 7/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3200 - accuracy: 0.8470 - val_loss: 0.3416 - val_accuracy: 0.8432\n",
            "Epoch 8/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3141 - accuracy: 0.8500 - val_loss: 0.3397 - val_accuracy: 0.8428\n",
            "Epoch 9/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3131 - accuracy: 0.8508 - val_loss: 0.3406 - val_accuracy: 0.8489\n",
            "Epoch 10/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3023 - accuracy: 0.8577 - val_loss: 0.3461 - val_accuracy: 0.8391\n",
            "300/300 [==============================] - 0s 921us/step - loss: 0.3471 - accuracy: 0.8387\n",
            "Epoch 1/100\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.4109 - accuracy: 0.7995 - val_loss: 0.3522 - val_accuracy: 0.8395\n",
            "Epoch 2/100\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3457 - accuracy: 0.8374 - val_loss: 0.3424 - val_accuracy: 0.8433\n",
            "Epoch 3/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3254 - accuracy: 0.8465 - val_loss: 0.3344 - val_accuracy: 0.8450\n",
            "Epoch 4/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3229 - accuracy: 0.8429 - val_loss: 0.3394 - val_accuracy: 0.8432\n",
            "Epoch 5/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3210 - accuracy: 0.8500 - val_loss: 0.3304 - val_accuracy: 0.8514\n",
            "Epoch 6/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3210 - accuracy: 0.8515 - val_loss: 0.3355 - val_accuracy: 0.8456\n",
            "Epoch 7/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3165 - accuracy: 0.8494 - val_loss: 0.3363 - val_accuracy: 0.8442\n",
            "Epoch 8/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3136 - accuracy: 0.8521 - val_loss: 0.3320 - val_accuracy: 0.8531\n",
            "Epoch 9/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3061 - accuracy: 0.8554 - val_loss: 0.3361 - val_accuracy: 0.8468\n",
            "Epoch 10/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3066 - accuracy: 0.8559 - val_loss: 0.3338 - val_accuracy: 0.8551\n",
            "300/300 [==============================] - 0s 1ms/step - loss: 0.3279 - accuracy: 0.8580\n",
            "Epoch 1/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.4090 - accuracy: 0.7973 - val_loss: 0.3452 - val_accuracy: 0.8455\n",
            "Epoch 2/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3423 - accuracy: 0.8412 - val_loss: 0.3375 - val_accuracy: 0.8510\n",
            "Epoch 3/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3368 - accuracy: 0.8458 - val_loss: 0.3315 - val_accuracy: 0.8457\n",
            "Epoch 4/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3286 - accuracy: 0.8520 - val_loss: 0.3300 - val_accuracy: 0.8508\n",
            "Epoch 5/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3275 - accuracy: 0.8448 - val_loss: 0.3328 - val_accuracy: 0.8511\n",
            "Epoch 6/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3272 - accuracy: 0.8469 - val_loss: 0.3287 - val_accuracy: 0.8498\n",
            "Epoch 7/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3179 - accuracy: 0.8483 - val_loss: 0.3295 - val_accuracy: 0.8495\n",
            "Epoch 8/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3140 - accuracy: 0.8553 - val_loss: 0.3415 - val_accuracy: 0.8440\n",
            "Epoch 9/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3204 - accuracy: 0.8515 - val_loss: 0.3320 - val_accuracy: 0.8493\n",
            "Epoch 10/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3109 - accuracy: 0.8532 - val_loss: 0.3523 - val_accuracy: 0.8461\n",
            "Epoch 11/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3047 - accuracy: 0.8568 - val_loss: 0.3399 - val_accuracy: 0.8453\n",
            "300/300 [==============================] - 0s 905us/step - loss: 0.3228 - accuracy: 0.8493\n",
            "Epoch 1/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.4022 - accuracy: 0.8055 - val_loss: 0.3438 - val_accuracy: 0.8445\n",
            "Epoch 2/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3456 - accuracy: 0.8376 - val_loss: 0.3542 - val_accuracy: 0.8368\n",
            "Epoch 3/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3380 - accuracy: 0.8356 - val_loss: 0.3297 - val_accuracy: 0.8528\n",
            "Epoch 4/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3273 - accuracy: 0.8427 - val_loss: 0.3334 - val_accuracy: 0.8518\n",
            "Epoch 5/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3233 - accuracy: 0.8445 - val_loss: 0.3386 - val_accuracy: 0.8467\n",
            "Epoch 6/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3124 - accuracy: 0.8527 - val_loss: 0.3343 - val_accuracy: 0.8481\n",
            "Epoch 7/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3113 - accuracy: 0.8496 - val_loss: 0.3290 - val_accuracy: 0.8526\n",
            "Epoch 8/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3123 - accuracy: 0.8540 - val_loss: 0.3396 - val_accuracy: 0.8496\n",
            "Epoch 9/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3160 - accuracy: 0.8483 - val_loss: 0.3362 - val_accuracy: 0.8511\n",
            "Epoch 10/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3154 - accuracy: 0.8518 - val_loss: 0.3338 - val_accuracy: 0.8488\n",
            "Epoch 11/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3069 - accuracy: 0.8581 - val_loss: 0.3347 - val_accuracy: 0.8478\n",
            "Epoch 12/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3034 - accuracy: 0.8533 - val_loss: 0.3388 - val_accuracy: 0.8428\n",
            "300/300 [==============================] - 0s 898us/step - loss: 0.3444 - accuracy: 0.8520\n",
            "Epoch 1/100\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.4127 - accuracy: 0.7932 - val_loss: 0.3380 - val_accuracy: 0.8414\n",
            "Epoch 2/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3406 - accuracy: 0.8411 - val_loss: 0.3646 - val_accuracy: 0.8099\n",
            "Epoch 3/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3281 - accuracy: 0.8447 - val_loss: 0.3430 - val_accuracy: 0.8374\n",
            "Epoch 4/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3235 - accuracy: 0.8472 - val_loss: 0.3319 - val_accuracy: 0.8458\n",
            "Epoch 5/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3222 - accuracy: 0.8468 - val_loss: 0.3255 - val_accuracy: 0.8508\n",
            "Epoch 6/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3179 - accuracy: 0.8480 - val_loss: 0.3385 - val_accuracy: 0.8520\n",
            "Epoch 7/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3105 - accuracy: 0.8535 - val_loss: 0.3302 - val_accuracy: 0.8515\n",
            "Epoch 8/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3145 - accuracy: 0.8516 - val_loss: 0.3325 - val_accuracy: 0.8542\n",
            "Epoch 9/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3045 - accuracy: 0.8575 - val_loss: 0.3537 - val_accuracy: 0.8450\n",
            "Epoch 10/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3173 - accuracy: 0.8501 - val_loss: 0.3539 - val_accuracy: 0.8492\n",
            "300/300 [==============================] - 0s 915us/step - loss: 0.3735 - accuracy: 0.8447\n",
            "Epoch 1/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.4214 - accuracy: 0.7855 - val_loss: 0.3416 - val_accuracy: 0.8434\n",
            "Epoch 2/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3418 - accuracy: 0.8351 - val_loss: 0.3474 - val_accuracy: 0.8372\n",
            "Epoch 3/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3300 - accuracy: 0.8497 - val_loss: 0.3370 - val_accuracy: 0.8472\n",
            "Epoch 4/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3225 - accuracy: 0.8455 - val_loss: 0.3353 - val_accuracy: 0.8501\n",
            "Epoch 5/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3215 - accuracy: 0.8537 - val_loss: 0.3276 - val_accuracy: 0.8509\n",
            "Epoch 6/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3189 - accuracy: 0.8459 - val_loss: 0.3339 - val_accuracy: 0.8484\n",
            "Epoch 7/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3195 - accuracy: 0.8491 - val_loss: 0.3505 - val_accuracy: 0.8436\n",
            "Epoch 8/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3065 - accuracy: 0.8508 - val_loss: 0.3459 - val_accuracy: 0.8472\n",
            "Epoch 9/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3033 - accuracy: 0.8599 - val_loss: 0.3384 - val_accuracy: 0.8503\n",
            "Epoch 10/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3023 - accuracy: 0.8567 - val_loss: 0.3557 - val_accuracy: 0.8406\n",
            "300/300 [==============================] - 0s 868us/step - loss: 0.3578 - accuracy: 0.8453\n",
            "Epoch 1/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.4055 - accuracy: 0.8047 - val_loss: 0.3552 - val_accuracy: 0.8224\n",
            "Epoch 2/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3420 - accuracy: 0.8372 - val_loss: 0.3453 - val_accuracy: 0.8489\n",
            "Epoch 3/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3296 - accuracy: 0.8470 - val_loss: 0.4158 - val_accuracy: 0.8448\n",
            "Epoch 4/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3341 - accuracy: 0.8433 - val_loss: 0.3310 - val_accuracy: 0.8458\n",
            "Epoch 5/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3218 - accuracy: 0.8484 - val_loss: 0.3332 - val_accuracy: 0.8504\n",
            "Epoch 6/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3190 - accuracy: 0.8494 - val_loss: 0.3415 - val_accuracy: 0.8471\n",
            "Epoch 7/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3141 - accuracy: 0.8537 - val_loss: 0.3315 - val_accuracy: 0.8496\n",
            "Epoch 8/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3087 - accuracy: 0.8552 - val_loss: 0.3287 - val_accuracy: 0.8519\n",
            "Epoch 9/100\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3077 - accuracy: 0.8534 - val_loss: 0.3368 - val_accuracy: 0.8523\n",
            "Epoch 10/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3052 - accuracy: 0.8580 - val_loss: 0.3372 - val_accuracy: 0.8490\n",
            "Epoch 11/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3002 - accuracy: 0.8559 - val_loss: 0.3529 - val_accuracy: 0.8502\n",
            "Epoch 12/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3069 - accuracy: 0.8555 - val_loss: 0.3497 - val_accuracy: 0.8491\n",
            "Epoch 13/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3054 - accuracy: 0.8597 - val_loss: 0.3418 - val_accuracy: 0.8507\n",
            "300/300 [==============================] - 0s 949us/step - loss: 0.3423 - accuracy: 0.8527\n",
            "Epoch 1/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.4011 - accuracy: 0.8112 - val_loss: 0.3467 - val_accuracy: 0.8376\n",
            "Epoch 2/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3391 - accuracy: 0.8413 - val_loss: 0.3523 - val_accuracy: 0.8453\n",
            "Epoch 3/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3326 - accuracy: 0.8464 - val_loss: 0.3465 - val_accuracy: 0.8357\n",
            "Epoch 4/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3254 - accuracy: 0.8450 - val_loss: 0.3220 - val_accuracy: 0.8540\n",
            "Epoch 5/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3243 - accuracy: 0.8441 - val_loss: 0.3420 - val_accuracy: 0.8489\n",
            "Epoch 6/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3171 - accuracy: 0.8508 - val_loss: 0.3310 - val_accuracy: 0.8466\n",
            "Epoch 7/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3064 - accuracy: 0.8591 - val_loss: 0.3443 - val_accuracy: 0.8444\n",
            "Epoch 8/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3151 - accuracy: 0.8535 - val_loss: 0.3402 - val_accuracy: 0.8456\n",
            "Epoch 9/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3112 - accuracy: 0.8566 - val_loss: 0.3450 - val_accuracy: 0.8464\n",
            "300/300 [==============================] - 0s 875us/step - loss: 0.3367 - accuracy: 0.8420\n",
            "Epoch 1/100\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.4171 - accuracy: 0.7932 - val_loss: 0.3525 - val_accuracy: 0.8342\n",
            "Epoch 2/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3536 - accuracy: 0.8316 - val_loss: 0.3324 - val_accuracy: 0.8491\n",
            "Epoch 3/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3409 - accuracy: 0.8364 - val_loss: 0.3508 - val_accuracy: 0.8124\n",
            "Epoch 4/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3319 - accuracy: 0.8433 - val_loss: 0.3287 - val_accuracy: 0.8393\n",
            "Epoch 5/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3313 - accuracy: 0.8367 - val_loss: 0.3406 - val_accuracy: 0.8456\n",
            "Epoch 6/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3148 - accuracy: 0.8557 - val_loss: 0.3387 - val_accuracy: 0.8447\n",
            "Epoch 7/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3216 - accuracy: 0.8491 - val_loss: 0.3322 - val_accuracy: 0.8541\n",
            "Epoch 8/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3218 - accuracy: 0.8494 - val_loss: 0.3335 - val_accuracy: 0.8453\n",
            "Epoch 9/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3078 - accuracy: 0.8546 - val_loss: 0.3299 - val_accuracy: 0.8529\n",
            "300/300 [==============================] - 0s 892us/step - loss: 0.3179 - accuracy: 0.8507\n",
            "Epoch 1/100\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.4003 - accuracy: 0.8059 - val_loss: 0.3615 - val_accuracy: 0.8405\n",
            "Epoch 2/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3489 - accuracy: 0.8366 - val_loss: 0.3328 - val_accuracy: 0.8489\n",
            "Epoch 3/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3383 - accuracy: 0.8432 - val_loss: 0.3329 - val_accuracy: 0.8487\n",
            "Epoch 4/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3272 - accuracy: 0.8428 - val_loss: 0.3313 - val_accuracy: 0.8477\n",
            "Epoch 5/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3164 - accuracy: 0.8541 - val_loss: 0.3349 - val_accuracy: 0.8510\n",
            "Epoch 6/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3161 - accuracy: 0.8527 - val_loss: 0.3357 - val_accuracy: 0.8440\n",
            "Epoch 7/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3079 - accuracy: 0.8552 - val_loss: 0.3315 - val_accuracy: 0.8499\n",
            "Epoch 8/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3084 - accuracy: 0.8591 - val_loss: 0.3354 - val_accuracy: 0.8442\n",
            "Epoch 9/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3155 - accuracy: 0.8521 - val_loss: 0.3850 - val_accuracy: 0.8352\n",
            "300/300 [==============================] - 0s 926us/step - loss: 0.3859 - accuracy: 0.8300\n",
            "Epoch 1/100\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.4112 - accuracy: 0.7942 - val_loss: 0.3445 - val_accuracy: 0.8413\n",
            "Epoch 2/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3547 - accuracy: 0.8295 - val_loss: 0.3294 - val_accuracy: 0.8470\n",
            "Epoch 3/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3254 - accuracy: 0.8449 - val_loss: 0.3297 - val_accuracy: 0.8490\n",
            "Epoch 4/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3286 - accuracy: 0.8495 - val_loss: 0.3320 - val_accuracy: 0.8446\n",
            "Epoch 5/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3221 - accuracy: 0.8451 - val_loss: 0.3252 - val_accuracy: 0.8508\n",
            "Epoch 6/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3074 - accuracy: 0.8590 - val_loss: 0.3307 - val_accuracy: 0.8492\n",
            "Epoch 7/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3103 - accuracy: 0.8528 - val_loss: 0.3401 - val_accuracy: 0.8489\n",
            "Epoch 8/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3044 - accuracy: 0.8559 - val_loss: 0.3334 - val_accuracy: 0.8469\n",
            "Epoch 9/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3133 - accuracy: 0.8541 - val_loss: 0.3391 - val_accuracy: 0.8464\n",
            "Epoch 10/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3034 - accuracy: 0.8596 - val_loss: 0.3623 - val_accuracy: 0.8498\n",
            "300/300 [==============================] - 0s 943us/step - loss: 0.3517 - accuracy: 0.8480\n",
            "Epoch 1/100\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.4052 - accuracy: 0.7976 - val_loss: 0.3604 - val_accuracy: 0.8309\n",
            "Epoch 2/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3532 - accuracy: 0.8374 - val_loss: 0.3474 - val_accuracy: 0.8406\n",
            "Epoch 3/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3395 - accuracy: 0.8376 - val_loss: 0.3411 - val_accuracy: 0.8438\n",
            "Epoch 4/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3302 - accuracy: 0.8397 - val_loss: 0.3409 - val_accuracy: 0.8384\n",
            "Epoch 5/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3228 - accuracy: 0.8445 - val_loss: 0.3334 - val_accuracy: 0.8444\n",
            "Epoch 6/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3146 - accuracy: 0.8531 - val_loss: 0.3400 - val_accuracy: 0.8487\n",
            "Epoch 7/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3166 - accuracy: 0.8470 - val_loss: 0.3439 - val_accuracy: 0.8317\n",
            "Epoch 8/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3193 - accuracy: 0.8485 - val_loss: 0.3428 - val_accuracy: 0.8371\n",
            "Epoch 9/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3139 - accuracy: 0.8458 - val_loss: 0.3417 - val_accuracy: 0.8423\n",
            "Epoch 10/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.2999 - accuracy: 0.8588 - val_loss: 0.3498 - val_accuracy: 0.8476\n",
            "300/300 [==============================] - 0s 943us/step - loss: 0.3347 - accuracy: 0.8533\n",
            "Epoch 1/100\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.4139 - accuracy: 0.7941 - val_loss: 0.3518 - val_accuracy: 0.8351\n",
            "Epoch 2/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3470 - accuracy: 0.8346 - val_loss: 0.3488 - val_accuracy: 0.8442\n",
            "Epoch 3/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3348 - accuracy: 0.8487 - val_loss: 0.3779 - val_accuracy: 0.8155\n",
            "Epoch 4/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3358 - accuracy: 0.8356 - val_loss: 0.3450 - val_accuracy: 0.8450\n",
            "Epoch 5/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3240 - accuracy: 0.8485 - val_loss: 0.3524 - val_accuracy: 0.8356\n",
            "Epoch 6/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3137 - accuracy: 0.8518 - val_loss: 0.3474 - val_accuracy: 0.8338\n",
            "Epoch 7/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3086 - accuracy: 0.8553 - val_loss: 0.3387 - val_accuracy: 0.8515\n",
            "Epoch 8/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3024 - accuracy: 0.8597 - val_loss: 0.3601 - val_accuracy: 0.8284\n",
            "Epoch 9/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3162 - accuracy: 0.8471 - val_loss: 0.3438 - val_accuracy: 0.8440\n",
            "Epoch 10/100\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3019 - accuracy: 0.8565 - val_loss: 0.3578 - val_accuracy: 0.8331\n",
            "Epoch 11/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3011 - accuracy: 0.8600 - val_loss: 0.3571 - val_accuracy: 0.8355\n",
            "Epoch 12/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3080 - accuracy: 0.8559 - val_loss: 0.3490 - val_accuracy: 0.8432\n",
            "300/300 [==============================] - 0s 901us/step - loss: 0.3467 - accuracy: 0.8320\n",
            "Epoch 1/100\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.4072 - accuracy: 0.8013 - val_loss: 0.3736 - val_accuracy: 0.8361\n",
            "Epoch 2/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3492 - accuracy: 0.8333 - val_loss: 0.3386 - val_accuracy: 0.8450\n",
            "Epoch 3/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3354 - accuracy: 0.8450 - val_loss: 0.3274 - val_accuracy: 0.8533\n",
            "Epoch 4/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3306 - accuracy: 0.8404 - val_loss: 0.3280 - val_accuracy: 0.8501\n",
            "Epoch 5/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3207 - accuracy: 0.8514 - val_loss: 0.3418 - val_accuracy: 0.8368\n",
            "Epoch 6/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3186 - accuracy: 0.8497 - val_loss: 0.3263 - val_accuracy: 0.8523\n",
            "Epoch 7/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3153 - accuracy: 0.8541 - val_loss: 0.3358 - val_accuracy: 0.8473\n",
            "Epoch 8/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3158 - accuracy: 0.8536 - val_loss: 0.3369 - val_accuracy: 0.8498\n",
            "Epoch 9/100\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3049 - accuracy: 0.8567 - val_loss: 0.3467 - val_accuracy: 0.8457\n",
            "Epoch 10/100\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3033 - accuracy: 0.8577 - val_loss: 0.3592 - val_accuracy: 0.8309\n",
            "Epoch 11/100\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.2996 - accuracy: 0.8589 - val_loss: 0.3498 - val_accuracy: 0.8481\n",
            "300/300 [==============================] - 0s 960us/step - loss: 0.3630 - accuracy: 0.8513\n",
            "Epoch 1/100\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.4132 - accuracy: 0.8014 - val_loss: 0.3488 - val_accuracy: 0.8422\n",
            "Epoch 2/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3570 - accuracy: 0.8356 - val_loss: 0.3398 - val_accuracy: 0.8374\n",
            "Epoch 3/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3239 - accuracy: 0.8496 - val_loss: 0.3303 - val_accuracy: 0.8519\n",
            "Epoch 4/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3207 - accuracy: 0.8481 - val_loss: 0.3315 - val_accuracy: 0.8506\n",
            "Epoch 5/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3182 - accuracy: 0.8499 - val_loss: 0.3252 - val_accuracy: 0.8493\n",
            "Epoch 6/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3193 - accuracy: 0.8502 - val_loss: 0.3304 - val_accuracy: 0.8485\n",
            "Epoch 7/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3092 - accuracy: 0.8576 - val_loss: 0.3470 - val_accuracy: 0.8509\n",
            "Epoch 8/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3144 - accuracy: 0.8493 - val_loss: 0.3353 - val_accuracy: 0.8458\n",
            "Epoch 9/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3025 - accuracy: 0.8543 - val_loss: 0.3415 - val_accuracy: 0.8506\n",
            "Epoch 10/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3018 - accuracy: 0.8592 - val_loss: 0.3330 - val_accuracy: 0.8460\n",
            "300/300 [==============================] - 0s 967us/step - loss: 0.3494 - accuracy: 0.8413\n",
            "Epoch 1/100\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.4201 - accuracy: 0.7872 - val_loss: 0.3425 - val_accuracy: 0.8447\n",
            "Epoch 2/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3430 - accuracy: 0.8382 - val_loss: 0.3287 - val_accuracy: 0.8495\n",
            "Epoch 3/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3303 - accuracy: 0.8448 - val_loss: 0.3258 - val_accuracy: 0.8546\n",
            "Epoch 4/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3253 - accuracy: 0.8470 - val_loss: 0.3267 - val_accuracy: 0.8525\n",
            "Epoch 5/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3282 - accuracy: 0.8449 - val_loss: 0.3300 - val_accuracy: 0.8496\n",
            "Epoch 6/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3245 - accuracy: 0.8490 - val_loss: 0.3294 - val_accuracy: 0.8511\n",
            "Epoch 7/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3161 - accuracy: 0.8539 - val_loss: 0.3381 - val_accuracy: 0.8466\n",
            "Epoch 8/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3162 - accuracy: 0.8507 - val_loss: 0.3386 - val_accuracy: 0.8460\n",
            "300/300 [==============================] - 0s 960us/step - loss: 0.3360 - accuracy: 0.8473\n",
            "Epoch 1/100\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.4168 - accuracy: 0.7916 - val_loss: 0.3583 - val_accuracy: 0.8270\n",
            "Epoch 2/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3432 - accuracy: 0.8371 - val_loss: 0.3515 - val_accuracy: 0.8283\n",
            "Epoch 3/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3261 - accuracy: 0.8458 - val_loss: 0.3357 - val_accuracy: 0.8496\n",
            "Epoch 4/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3356 - accuracy: 0.8438 - val_loss: 0.3300 - val_accuracy: 0.8481\n",
            "Epoch 5/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3268 - accuracy: 0.8435 - val_loss: 0.3489 - val_accuracy: 0.8495\n",
            "Epoch 6/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3217 - accuracy: 0.8507 - val_loss: 0.3326 - val_accuracy: 0.8517\n",
            "Epoch 7/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3215 - accuracy: 0.8494 - val_loss: 0.3414 - val_accuracy: 0.8466\n",
            "Epoch 8/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3050 - accuracy: 0.8562 - val_loss: 0.3305 - val_accuracy: 0.8529\n",
            "Epoch 9/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3124 - accuracy: 0.8568 - val_loss: 0.3346 - val_accuracy: 0.8517\n",
            "300/300 [==============================] - 0s 946us/step - loss: 0.3296 - accuracy: 0.8507\n",
            "Epoch 1/100\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.4130 - accuracy: 0.7978 - val_loss: 0.3580 - val_accuracy: 0.8294\n",
            "Epoch 2/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3518 - accuracy: 0.8332 - val_loss: 0.3434 - val_accuracy: 0.8487\n",
            "Epoch 3/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3307 - accuracy: 0.8465 - val_loss: 0.3352 - val_accuracy: 0.8482\n",
            "Epoch 4/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3256 - accuracy: 0.8470 - val_loss: 0.3301 - val_accuracy: 0.8505\n",
            "Epoch 5/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3235 - accuracy: 0.8485 - val_loss: 0.3403 - val_accuracy: 0.8472\n",
            "Epoch 6/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3231 - accuracy: 0.8487 - val_loss: 0.3354 - val_accuracy: 0.8481\n",
            "Epoch 7/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3188 - accuracy: 0.8532 - val_loss: 0.3341 - val_accuracy: 0.8502\n",
            "Epoch 8/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3101 - accuracy: 0.8559 - val_loss: 0.3676 - val_accuracy: 0.8406\n",
            "Epoch 9/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3144 - accuracy: 0.8511 - val_loss: 0.3578 - val_accuracy: 0.8475\n",
            "300/300 [==============================] - 0s 894us/step - loss: 0.3605 - accuracy: 0.8353\n",
            "Epoch 1/100\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.4087 - accuracy: 0.7969 - val_loss: 0.3463 - val_accuracy: 0.8409\n",
            "Epoch 2/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3433 - accuracy: 0.8388 - val_loss: 0.3308 - val_accuracy: 0.8501\n",
            "Epoch 3/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3435 - accuracy: 0.8407 - val_loss: 0.3341 - val_accuracy: 0.8494\n",
            "Epoch 4/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3242 - accuracy: 0.8491 - val_loss: 0.3354 - val_accuracy: 0.8495\n",
            "Epoch 5/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3216 - accuracy: 0.8510 - val_loss: 0.3290 - val_accuracy: 0.8487\n",
            "Epoch 6/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3178 - accuracy: 0.8522 - val_loss: 0.3292 - val_accuracy: 0.8519\n",
            "Epoch 7/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3133 - accuracy: 0.8513 - val_loss: 0.3264 - val_accuracy: 0.8519\n",
            "Epoch 8/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.2969 - accuracy: 0.8566 - val_loss: 0.3243 - val_accuracy: 0.8533\n",
            "Epoch 9/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3137 - accuracy: 0.8508 - val_loss: 0.3355 - val_accuracy: 0.8470\n",
            "Epoch 10/100\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3093 - accuracy: 0.8574 - val_loss: 0.3323 - val_accuracy: 0.8524\n",
            "Epoch 11/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.2992 - accuracy: 0.8621 - val_loss: 0.3406 - val_accuracy: 0.8534\n",
            "Epoch 12/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3010 - accuracy: 0.8561 - val_loss: 0.3489 - val_accuracy: 0.8423\n",
            "Epoch 13/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3006 - accuracy: 0.8630 - val_loss: 0.3435 - val_accuracy: 0.8504\n",
            "300/300 [==============================] - 0s 960us/step - loss: 0.3436 - accuracy: 0.8527\n",
            "Epoch 1/100\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.4078 - accuracy: 0.7972 - val_loss: 0.3449 - val_accuracy: 0.8455\n",
            "Epoch 2/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3365 - accuracy: 0.8428 - val_loss: 0.3280 - val_accuracy: 0.8527\n",
            "Epoch 3/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3356 - accuracy: 0.8388 - val_loss: 0.3320 - val_accuracy: 0.8478\n",
            "Epoch 4/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3245 - accuracy: 0.8495 - val_loss: 0.3289 - val_accuracy: 0.8509\n",
            "Epoch 5/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3209 - accuracy: 0.8459 - val_loss: 0.3524 - val_accuracy: 0.8176\n",
            "Epoch 6/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3176 - accuracy: 0.8512 - val_loss: 0.3509 - val_accuracy: 0.8342\n",
            "Epoch 7/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3054 - accuracy: 0.8560 - val_loss: 0.3361 - val_accuracy: 0.8486\n",
            "300/300 [==============================] - 0s 941us/step - loss: 0.3362 - accuracy: 0.8447\n",
            "Epoch 1/100\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.4199 - accuracy: 0.7943 - val_loss: 0.3458 - val_accuracy: 0.8425\n",
            "Epoch 2/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3536 - accuracy: 0.8333 - val_loss: 0.3393 - val_accuracy: 0.8432\n",
            "Epoch 3/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3383 - accuracy: 0.8424 - val_loss: 0.3346 - val_accuracy: 0.8465\n",
            "Epoch 4/100\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3252 - accuracy: 0.8430 - val_loss: 0.3270 - val_accuracy: 0.8491\n",
            "Epoch 5/100\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3153 - accuracy: 0.8483 - val_loss: 0.3270 - val_accuracy: 0.8496\n",
            "Epoch 6/100\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3178 - accuracy: 0.8502 - val_loss: 0.3340 - val_accuracy: 0.8522\n",
            "Epoch 7/100\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3219 - accuracy: 0.8499 - val_loss: 0.3352 - val_accuracy: 0.8459\n",
            "Epoch 8/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3197 - accuracy: 0.8471 - val_loss: 0.3365 - val_accuracy: 0.8453\n",
            "Epoch 9/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3122 - accuracy: 0.8499 - val_loss: 0.3682 - val_accuracy: 0.8491\n",
            "Epoch 10/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3121 - accuracy: 0.8565 - val_loss: 0.3442 - val_accuracy: 0.8472\n",
            "300/300 [==============================] - 0s 891us/step - loss: 0.3391 - accuracy: 0.8527\n",
            "Epoch 1/100\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.4030 - accuracy: 0.8067 - val_loss: 0.3419 - val_accuracy: 0.8430\n",
            "Epoch 2/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3484 - accuracy: 0.8411 - val_loss: 0.3374 - val_accuracy: 0.8479\n",
            "Epoch 3/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3279 - accuracy: 0.8439 - val_loss: 0.3271 - val_accuracy: 0.8545\n",
            "Epoch 4/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3292 - accuracy: 0.8401 - val_loss: 0.3457 - val_accuracy: 0.8384\n",
            "Epoch 5/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3217 - accuracy: 0.8455 - val_loss: 0.3308 - val_accuracy: 0.8477\n",
            "Epoch 6/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3149 - accuracy: 0.8543 - val_loss: 0.3440 - val_accuracy: 0.8347\n",
            "Epoch 7/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3149 - accuracy: 0.8557 - val_loss: 0.3353 - val_accuracy: 0.8482\n",
            "Epoch 8/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3153 - accuracy: 0.8531 - val_loss: 0.3383 - val_accuracy: 0.8443\n",
            "300/300 [==============================] - 0s 868us/step - loss: 0.3284 - accuracy: 0.8500\n",
            "Epoch 1/100\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.4063 - accuracy: 0.8015 - val_loss: 0.4207 - val_accuracy: 0.8247\n",
            "Epoch 2/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3443 - accuracy: 0.8405 - val_loss: 0.3631 - val_accuracy: 0.8388\n",
            "Epoch 3/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3413 - accuracy: 0.8406 - val_loss: 0.3350 - val_accuracy: 0.8473\n",
            "Epoch 4/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3273 - accuracy: 0.8455 - val_loss: 0.3314 - val_accuracy: 0.8508\n",
            "Epoch 5/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3293 - accuracy: 0.8474 - val_loss: 0.3236 - val_accuracy: 0.8505\n",
            "Epoch 6/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3136 - accuracy: 0.8560 - val_loss: 0.3315 - val_accuracy: 0.8510\n",
            "Epoch 7/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3102 - accuracy: 0.8546 - val_loss: 0.3255 - val_accuracy: 0.8502\n",
            "Epoch 8/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3031 - accuracy: 0.8569 - val_loss: 0.3440 - val_accuracy: 0.8516\n",
            "Epoch 9/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3075 - accuracy: 0.8579 - val_loss: 0.3407 - val_accuracy: 0.8441\n",
            "Epoch 10/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3027 - accuracy: 0.8602 - val_loss: 0.3387 - val_accuracy: 0.8485\n",
            "300/300 [==============================] - 0s 932us/step - loss: 0.3324 - accuracy: 0.8440\n",
            "Epoch 1/100\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.4094 - accuracy: 0.8012 - val_loss: 0.3967 - val_accuracy: 0.8190\n",
            "Epoch 2/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3463 - accuracy: 0.8380 - val_loss: 0.3286 - val_accuracy: 0.8528\n",
            "Epoch 3/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3306 - accuracy: 0.8465 - val_loss: 0.3403 - val_accuracy: 0.8468\n",
            "Epoch 4/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3218 - accuracy: 0.8483 - val_loss: 0.3305 - val_accuracy: 0.8460\n",
            "Epoch 5/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3236 - accuracy: 0.8509 - val_loss: 0.3279 - val_accuracy: 0.8523\n",
            "Epoch 6/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3251 - accuracy: 0.8451 - val_loss: 0.3483 - val_accuracy: 0.8359\n",
            "Epoch 7/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3094 - accuracy: 0.8512 - val_loss: 0.3516 - val_accuracy: 0.8292\n",
            "Epoch 8/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3073 - accuracy: 0.8564 - val_loss: 0.3342 - val_accuracy: 0.8514\n",
            "Epoch 9/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3086 - accuracy: 0.8551 - val_loss: 0.3354 - val_accuracy: 0.8512\n",
            "Epoch 10/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3064 - accuracy: 0.8557 - val_loss: 0.3424 - val_accuracy: 0.8511\n",
            "300/300 [==============================] - 0s 920us/step - loss: 0.3692 - accuracy: 0.8413\n",
            "Epoch 1/100\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.4041 - accuracy: 0.8030 - val_loss: 0.3435 - val_accuracy: 0.8442\n",
            "Epoch 2/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3468 - accuracy: 0.8383 - val_loss: 0.3341 - val_accuracy: 0.8454\n",
            "Epoch 3/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3343 - accuracy: 0.8416 - val_loss: 0.3295 - val_accuracy: 0.8523\n",
            "Epoch 4/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3225 - accuracy: 0.8465 - val_loss: 0.3335 - val_accuracy: 0.8481\n",
            "Epoch 5/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3122 - accuracy: 0.8577 - val_loss: 0.3517 - val_accuracy: 0.8413\n",
            "Epoch 6/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3245 - accuracy: 0.8440 - val_loss: 0.3378 - val_accuracy: 0.8497\n",
            "Epoch 7/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3086 - accuracy: 0.8550 - val_loss: 0.3460 - val_accuracy: 0.8442\n",
            "Epoch 8/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3102 - accuracy: 0.8561 - val_loss: 0.3365 - val_accuracy: 0.8497\n",
            "300/300 [==============================] - 0s 935us/step - loss: 0.3501 - accuracy: 0.8360\n",
            "Epoch 1/100\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.4098 - accuracy: 0.8061 - val_loss: 0.3361 - val_accuracy: 0.8458\n",
            "Epoch 2/100\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3465 - accuracy: 0.8331 - val_loss: 0.3335 - val_accuracy: 0.8463\n",
            "Epoch 3/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3268 - accuracy: 0.8465 - val_loss: 0.3362 - val_accuracy: 0.8455\n",
            "Epoch 4/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3264 - accuracy: 0.8442 - val_loss: 0.3268 - val_accuracy: 0.8502\n",
            "Epoch 5/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3210 - accuracy: 0.8547 - val_loss: 0.3305 - val_accuracy: 0.8480\n",
            "Epoch 6/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3153 - accuracy: 0.8523 - val_loss: 0.3304 - val_accuracy: 0.8483\n",
            "Epoch 7/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3099 - accuracy: 0.8546 - val_loss: 0.3471 - val_accuracy: 0.8459\n",
            "Epoch 8/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3061 - accuracy: 0.8596 - val_loss: 0.3443 - val_accuracy: 0.8466\n",
            "Epoch 9/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3060 - accuracy: 0.8597 - val_loss: 0.3508 - val_accuracy: 0.8434\n",
            "300/300 [==============================] - 0s 910us/step - loss: 0.3518 - accuracy: 0.8527\n",
            "Epoch 1/100\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.4034 - accuracy: 0.8034 - val_loss: 0.3478 - val_accuracy: 0.8421\n",
            "Epoch 2/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3489 - accuracy: 0.8346 - val_loss: 0.3338 - val_accuracy: 0.8438\n",
            "Epoch 3/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3277 - accuracy: 0.8453 - val_loss: 0.3721 - val_accuracy: 0.8424\n",
            "Epoch 4/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3228 - accuracy: 0.8541 - val_loss: 0.3303 - val_accuracy: 0.8511\n",
            "Epoch 5/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3226 - accuracy: 0.8499 - val_loss: 0.3349 - val_accuracy: 0.8481\n",
            "Epoch 6/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3147 - accuracy: 0.8519 - val_loss: 0.3578 - val_accuracy: 0.8441\n",
            "Epoch 7/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3081 - accuracy: 0.8531 - val_loss: 0.3378 - val_accuracy: 0.8494\n",
            "Epoch 8/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3080 - accuracy: 0.8539 - val_loss: 0.3404 - val_accuracy: 0.8523\n",
            "Epoch 9/100\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3028 - accuracy: 0.8624 - val_loss: 0.3599 - val_accuracy: 0.8344\n",
            "300/300 [==============================] - 0s 951us/step - loss: 0.3557 - accuracy: 0.8413\n",
            "Epoch 1/100\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.4097 - accuracy: 0.8028 - val_loss: 0.3445 - val_accuracy: 0.8459\n",
            "Epoch 2/100\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3520 - accuracy: 0.8338 - val_loss: 0.3334 - val_accuracy: 0.8460\n",
            "Epoch 3/100\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3314 - accuracy: 0.8430 - val_loss: 0.3321 - val_accuracy: 0.8527\n",
            "Epoch 4/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3220 - accuracy: 0.8522 - val_loss: 0.3337 - val_accuracy: 0.8477\n",
            "Epoch 5/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3325 - accuracy: 0.8443 - val_loss: 0.3348 - val_accuracy: 0.8494\n",
            "Epoch 6/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3131 - accuracy: 0.8545 - val_loss: 0.3308 - val_accuracy: 0.8486\n",
            "Epoch 7/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3139 - accuracy: 0.8557 - val_loss: 0.3293 - val_accuracy: 0.8505\n",
            "Epoch 8/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3136 - accuracy: 0.8536 - val_loss: 0.3424 - val_accuracy: 0.8522\n",
            "Epoch 9/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3066 - accuracy: 0.8571 - val_loss: 0.3363 - val_accuracy: 0.8465\n",
            "Epoch 10/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3060 - accuracy: 0.8580 - val_loss: 0.3418 - val_accuracy: 0.8445\n",
            "Epoch 11/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.2977 - accuracy: 0.8619 - val_loss: 0.3473 - val_accuracy: 0.8450\n",
            "Epoch 12/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.2970 - accuracy: 0.8623 - val_loss: 0.3605 - val_accuracy: 0.8261\n",
            "300/300 [==============================] - 0s 923us/step - loss: 0.3545 - accuracy: 0.8273\n",
            "Epoch 1/100\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.4103 - accuracy: 0.7983 - val_loss: 0.3519 - val_accuracy: 0.8417\n",
            "Epoch 2/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3541 - accuracy: 0.8367 - val_loss: 0.3368 - val_accuracy: 0.8508\n",
            "Epoch 3/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3412 - accuracy: 0.8401 - val_loss: 0.3341 - val_accuracy: 0.8491\n",
            "Epoch 4/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3333 - accuracy: 0.8475 - val_loss: 0.3379 - val_accuracy: 0.8501\n",
            "Epoch 5/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3260 - accuracy: 0.8441 - val_loss: 0.3346 - val_accuracy: 0.8484\n",
            "Epoch 6/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3167 - accuracy: 0.8505 - val_loss: 0.3369 - val_accuracy: 0.8440\n",
            "Epoch 7/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3145 - accuracy: 0.8520 - val_loss: 0.3348 - val_accuracy: 0.8476\n",
            "Epoch 8/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3162 - accuracy: 0.8534 - val_loss: 0.3325 - val_accuracy: 0.8503\n",
            "Epoch 9/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3149 - accuracy: 0.8534 - val_loss: 0.3571 - val_accuracy: 0.8480\n",
            "Epoch 10/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3076 - accuracy: 0.8622 - val_loss: 0.3401 - val_accuracy: 0.8493\n",
            "Epoch 11/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3066 - accuracy: 0.8569 - val_loss: 0.3544 - val_accuracy: 0.8342\n",
            "Epoch 12/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3012 - accuracy: 0.8531 - val_loss: 0.3549 - val_accuracy: 0.8483\n",
            "Epoch 13/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.2946 - accuracy: 0.8630 - val_loss: 0.3655 - val_accuracy: 0.8504\n",
            "300/300 [==============================] - 0s 937us/step - loss: 0.3693 - accuracy: 0.8507\n",
            "Epoch 1/100\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.4028 - accuracy: 0.8063 - val_loss: 0.3879 - val_accuracy: 0.8260\n",
            "Epoch 2/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3403 - accuracy: 0.8434 - val_loss: 0.3370 - val_accuracy: 0.8501\n",
            "Epoch 3/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3298 - accuracy: 0.8480 - val_loss: 0.3292 - val_accuracy: 0.8513\n",
            "Epoch 4/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3217 - accuracy: 0.8520 - val_loss: 0.3332 - val_accuracy: 0.8490\n",
            "Epoch 5/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3262 - accuracy: 0.8460 - val_loss: 0.3267 - val_accuracy: 0.8499\n",
            "Epoch 6/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3209 - accuracy: 0.8455 - val_loss: 0.3363 - val_accuracy: 0.8487\n",
            "Epoch 7/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3198 - accuracy: 0.8464 - val_loss: 0.3336 - val_accuracy: 0.8470\n",
            "Epoch 8/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3090 - accuracy: 0.8540 - val_loss: 0.3325 - val_accuracy: 0.8510\n",
            "Epoch 9/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3033 - accuracy: 0.8544 - val_loss: 0.3555 - val_accuracy: 0.8315\n",
            "Epoch 10/100\n",
            "2700/2700 [==============================] - 5s 2ms/step - loss: 0.3026 - accuracy: 0.8553 - val_loss: 0.3447 - val_accuracy: 0.8467\n",
            "300/300 [==============================] - 0s 895us/step - loss: 0.3405 - accuracy: 0.8400\n",
            "Epoch 1/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.4467 - accuracy: 0.7944 - val_loss: 0.3519 - val_accuracy: 0.8371\n",
            "Epoch 2/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3478 - accuracy: 0.8357 - val_loss: 0.3414 - val_accuracy: 0.8456\n",
            "Epoch 3/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3323 - accuracy: 0.8462 - val_loss: 0.3286 - val_accuracy: 0.8501\n",
            "Epoch 4/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3257 - accuracy: 0.8415 - val_loss: 0.3240 - val_accuracy: 0.8495\n",
            "Epoch 5/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3298 - accuracy: 0.8452 - val_loss: 0.3202 - val_accuracy: 0.8535\n",
            "Epoch 6/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3150 - accuracy: 0.8441 - val_loss: 0.3407 - val_accuracy: 0.8428\n",
            "Epoch 7/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3110 - accuracy: 0.8533 - val_loss: 0.3221 - val_accuracy: 0.8524\n",
            "Epoch 8/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3081 - accuracy: 0.8541 - val_loss: 0.3205 - val_accuracy: 0.8521\n",
            "Epoch 9/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3177 - accuracy: 0.8525 - val_loss: 0.3219 - val_accuracy: 0.8526\n",
            "Epoch 10/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3071 - accuracy: 0.8624 - val_loss: 0.3266 - val_accuracy: 0.8501\n",
            "150/150 [==============================] - 0s 991us/step - loss: 0.3175 - accuracy: 0.8547\n",
            "Epoch 1/50\n",
            "1350/1350 [==============================] - 4s 2ms/step - loss: 0.4603 - accuracy: 0.7852 - val_loss: 0.3619 - val_accuracy: 0.8332\n",
            "Epoch 2/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3478 - accuracy: 0.8315 - val_loss: 0.3303 - val_accuracy: 0.8478\n",
            "Epoch 3/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3260 - accuracy: 0.8455 - val_loss: 0.3506 - val_accuracy: 0.8272\n",
            "Epoch 4/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3209 - accuracy: 0.8463 - val_loss: 0.3257 - val_accuracy: 0.8492\n",
            "Epoch 5/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3179 - accuracy: 0.8485 - val_loss: 0.3222 - val_accuracy: 0.8542\n",
            "Epoch 6/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3133 - accuracy: 0.8510 - val_loss: 0.3253 - val_accuracy: 0.8468\n",
            "Epoch 7/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3079 - accuracy: 0.8521 - val_loss: 0.3214 - val_accuracy: 0.8539\n",
            "Epoch 8/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3049 - accuracy: 0.8567 - val_loss: 0.3256 - val_accuracy: 0.8476\n",
            "Epoch 9/50\n",
            "1350/1350 [==============================] - 2s 2ms/step - loss: 0.3052 - accuracy: 0.8534 - val_loss: 0.3245 - val_accuracy: 0.8509\n",
            "Epoch 10/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3018 - accuracy: 0.8598 - val_loss: 0.3286 - val_accuracy: 0.8502\n",
            "Epoch 11/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3032 - accuracy: 0.8578 - val_loss: 0.3248 - val_accuracy: 0.8514\n",
            "Epoch 12/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.2964 - accuracy: 0.8626 - val_loss: 0.3303 - val_accuracy: 0.8473\n",
            "150/150 [==============================] - 0s 930us/step - loss: 0.3200 - accuracy: 0.8560\n",
            "Epoch 1/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.4709 - accuracy: 0.7877 - val_loss: 0.3593 - val_accuracy: 0.8325\n",
            "Epoch 2/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3514 - accuracy: 0.8323 - val_loss: 0.3380 - val_accuracy: 0.8434\n",
            "Epoch 3/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3317 - accuracy: 0.8422 - val_loss: 0.3244 - val_accuracy: 0.8505\n",
            "Epoch 4/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3239 - accuracy: 0.8505 - val_loss: 0.3252 - val_accuracy: 0.8496\n",
            "Epoch 5/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3146 - accuracy: 0.8524 - val_loss: 0.3231 - val_accuracy: 0.8549\n",
            "Epoch 6/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3093 - accuracy: 0.8534 - val_loss: 0.3215 - val_accuracy: 0.8526\n",
            "Epoch 7/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3252 - accuracy: 0.8450 - val_loss: 0.3215 - val_accuracy: 0.8534\n",
            "Epoch 8/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3146 - accuracy: 0.8515 - val_loss: 0.3275 - val_accuracy: 0.8531\n",
            "Epoch 9/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3130 - accuracy: 0.8554 - val_loss: 0.3239 - val_accuracy: 0.8547\n",
            "Epoch 10/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3190 - accuracy: 0.8484 - val_loss: 0.3228 - val_accuracy: 0.8533\n",
            "Epoch 11/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3206 - accuracy: 0.8524 - val_loss: 0.3237 - val_accuracy: 0.8511\n",
            "Epoch 12/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3077 - accuracy: 0.8527 - val_loss: 0.3247 - val_accuracy: 0.8518\n",
            "150/150 [==============================] - 0s 1ms/step - loss: 0.3225 - accuracy: 0.8393\n",
            "Epoch 1/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.4441 - accuracy: 0.7846 - val_loss: 0.3516 - val_accuracy: 0.8370\n",
            "Epoch 2/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3460 - accuracy: 0.8376 - val_loss: 0.3290 - val_accuracy: 0.8484\n",
            "Epoch 3/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3265 - accuracy: 0.8436 - val_loss: 0.3279 - val_accuracy: 0.8498\n",
            "Epoch 4/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3241 - accuracy: 0.8501 - val_loss: 0.3268 - val_accuracy: 0.8449\n",
            "Epoch 5/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3196 - accuracy: 0.8512 - val_loss: 0.3207 - val_accuracy: 0.8541\n",
            "Epoch 6/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.2981 - accuracy: 0.8602 - val_loss: 0.3279 - val_accuracy: 0.8517\n",
            "Epoch 7/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3054 - accuracy: 0.8499 - val_loss: 0.3199 - val_accuracy: 0.8517\n",
            "Epoch 8/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3038 - accuracy: 0.8560 - val_loss: 0.3218 - val_accuracy: 0.8523\n",
            "Epoch 9/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3018 - accuracy: 0.8562 - val_loss: 0.3225 - val_accuracy: 0.8484\n",
            "Epoch 10/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3074 - accuracy: 0.8552 - val_loss: 0.3240 - val_accuracy: 0.8519\n",
            "Epoch 11/50\n",
            "1350/1350 [==============================] - 2s 2ms/step - loss: 0.3086 - accuracy: 0.8511 - val_loss: 0.3211 - val_accuracy: 0.8519\n",
            "Epoch 12/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3023 - accuracy: 0.8546 - val_loss: 0.3246 - val_accuracy: 0.8530\n",
            "150/150 [==============================] - 0s 952us/step - loss: 0.3269 - accuracy: 0.8547\n",
            "Epoch 1/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.4474 - accuracy: 0.8018 - val_loss: 0.3459 - val_accuracy: 0.8361\n",
            "Epoch 2/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3399 - accuracy: 0.8401 - val_loss: 0.3292 - val_accuracy: 0.8513\n",
            "Epoch 3/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3298 - accuracy: 0.8442 - val_loss: 0.3266 - val_accuracy: 0.8480\n",
            "Epoch 4/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3093 - accuracy: 0.8575 - val_loss: 0.3216 - val_accuracy: 0.8538\n",
            "Epoch 5/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3121 - accuracy: 0.8538 - val_loss: 0.3258 - val_accuracy: 0.8526\n",
            "Epoch 6/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3179 - accuracy: 0.8530 - val_loss: 0.3204 - val_accuracy: 0.8544\n",
            "Epoch 7/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3092 - accuracy: 0.8571 - val_loss: 0.3229 - val_accuracy: 0.8523\n",
            "Epoch 8/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3110 - accuracy: 0.8526 - val_loss: 0.3231 - val_accuracy: 0.8515\n",
            "Epoch 9/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3061 - accuracy: 0.8573 - val_loss: 0.3232 - val_accuracy: 0.8526\n",
            "Epoch 10/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3019 - accuracy: 0.8602 - val_loss: 0.3284 - val_accuracy: 0.8487\n",
            "Epoch 11/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3074 - accuracy: 0.8523 - val_loss: 0.3224 - val_accuracy: 0.8532\n",
            "150/150 [==============================] - 0s 919us/step - loss: 0.3432 - accuracy: 0.8387\n",
            "Epoch 1/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.4587 - accuracy: 0.7911 - val_loss: 0.3564 - val_accuracy: 0.8373\n",
            "Epoch 2/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3493 - accuracy: 0.8305 - val_loss: 0.3284 - val_accuracy: 0.8482\n",
            "Epoch 3/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3296 - accuracy: 0.8454 - val_loss: 0.3224 - val_accuracy: 0.8523\n",
            "Epoch 4/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3196 - accuracy: 0.8492 - val_loss: 0.3245 - val_accuracy: 0.8485\n",
            "Epoch 5/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3142 - accuracy: 0.8525 - val_loss: 0.3193 - val_accuracy: 0.8558\n",
            "Epoch 6/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3068 - accuracy: 0.8558 - val_loss: 0.3240 - val_accuracy: 0.8530\n",
            "Epoch 7/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3127 - accuracy: 0.8460 - val_loss: 0.3221 - val_accuracy: 0.8547\n",
            "Epoch 8/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3051 - accuracy: 0.8563 - val_loss: 0.3208 - val_accuracy: 0.8551\n",
            "Epoch 9/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3044 - accuracy: 0.8557 - val_loss: 0.3215 - val_accuracy: 0.8530\n",
            "Epoch 10/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.2968 - accuracy: 0.8605 - val_loss: 0.3407 - val_accuracy: 0.8457\n",
            "150/150 [==============================] - 0s 1ms/step - loss: 0.3380 - accuracy: 0.8433\n",
            "Epoch 1/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.4548 - accuracy: 0.7861 - val_loss: 0.3564 - val_accuracy: 0.8356\n",
            "Epoch 2/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3498 - accuracy: 0.8364 - val_loss: 0.3333 - val_accuracy: 0.8475\n",
            "Epoch 3/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3289 - accuracy: 0.8469 - val_loss: 0.3269 - val_accuracy: 0.8495\n",
            "Epoch 4/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3144 - accuracy: 0.8571 - val_loss: 0.3317 - val_accuracy: 0.8526\n",
            "Epoch 5/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3207 - accuracy: 0.8471 - val_loss: 0.3241 - val_accuracy: 0.8543\n",
            "Epoch 6/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3135 - accuracy: 0.8516 - val_loss: 0.3252 - val_accuracy: 0.8465\n",
            "Epoch 7/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3120 - accuracy: 0.8525 - val_loss: 0.3248 - val_accuracy: 0.8542\n",
            "Epoch 8/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3074 - accuracy: 0.8568 - val_loss: 0.3218 - val_accuracy: 0.8564\n",
            "Epoch 9/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3064 - accuracy: 0.8593 - val_loss: 0.3234 - val_accuracy: 0.8523\n",
            "Epoch 10/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3068 - accuracy: 0.8549 - val_loss: 0.3224 - val_accuracy: 0.8533\n",
            "Epoch 11/50\n",
            "1350/1350 [==============================] - 2s 2ms/step - loss: 0.2960 - accuracy: 0.8613 - val_loss: 0.3244 - val_accuracy: 0.8540\n",
            "Epoch 12/50\n",
            "1350/1350 [==============================] - 2s 2ms/step - loss: 0.2978 - accuracy: 0.8587 - val_loss: 0.3254 - val_accuracy: 0.8491\n",
            "Epoch 13/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.2985 - accuracy: 0.8562 - val_loss: 0.3240 - val_accuracy: 0.8521\n",
            "150/150 [==============================] - 0s 898us/step - loss: 0.3224 - accuracy: 0.8513\n",
            "Epoch 1/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.4628 - accuracy: 0.7899 - val_loss: 0.3535 - val_accuracy: 0.8379\n",
            "Epoch 2/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3489 - accuracy: 0.8396 - val_loss: 0.3329 - val_accuracy: 0.8443\n",
            "Epoch 3/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3329 - accuracy: 0.8436 - val_loss: 0.3329 - val_accuracy: 0.8491\n",
            "Epoch 4/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3169 - accuracy: 0.8497 - val_loss: 0.3260 - val_accuracy: 0.8483\n",
            "Epoch 5/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3206 - accuracy: 0.8488 - val_loss: 0.3202 - val_accuracy: 0.8531\n",
            "Epoch 6/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3129 - accuracy: 0.8545 - val_loss: 0.3240 - val_accuracy: 0.8516\n",
            "Epoch 7/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3085 - accuracy: 0.8602 - val_loss: 0.3235 - val_accuracy: 0.8523\n",
            "Epoch 8/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3126 - accuracy: 0.8536 - val_loss: 0.3211 - val_accuracy: 0.8506\n",
            "Epoch 9/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3035 - accuracy: 0.8600 - val_loss: 0.3227 - val_accuracy: 0.8535\n",
            "Epoch 10/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3035 - accuracy: 0.8575 - val_loss: 0.3223 - val_accuracy: 0.8504\n",
            "150/150 [==============================] - 0s 929us/step - loss: 0.3267 - accuracy: 0.8393\n",
            "Epoch 1/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.4489 - accuracy: 0.7944 - val_loss: 0.3535 - val_accuracy: 0.8364\n",
            "Epoch 2/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3486 - accuracy: 0.8356 - val_loss: 0.3309 - val_accuracy: 0.8483\n",
            "Epoch 3/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3295 - accuracy: 0.8454 - val_loss: 0.3255 - val_accuracy: 0.8482\n",
            "Epoch 4/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3199 - accuracy: 0.8532 - val_loss: 0.3185 - val_accuracy: 0.8551\n",
            "Epoch 5/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3151 - accuracy: 0.8501 - val_loss: 0.3282 - val_accuracy: 0.8466\n",
            "Epoch 6/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3112 - accuracy: 0.8527 - val_loss: 0.3222 - val_accuracy: 0.8515\n",
            "Epoch 7/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3153 - accuracy: 0.8482 - val_loss: 0.3200 - val_accuracy: 0.8511\n",
            "Epoch 8/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3111 - accuracy: 0.8537 - val_loss: 0.3275 - val_accuracy: 0.8498\n",
            "Epoch 9/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3067 - accuracy: 0.8559 - val_loss: 0.3306 - val_accuracy: 0.8427\n",
            "150/150 [==============================] - 0s 890us/step - loss: 0.3263 - accuracy: 0.8467\n",
            "Epoch 1/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.4481 - accuracy: 0.7946 - val_loss: 0.3479 - val_accuracy: 0.8386\n",
            "Epoch 2/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3413 - accuracy: 0.8404 - val_loss: 0.3288 - val_accuracy: 0.8483\n",
            "Epoch 3/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3360 - accuracy: 0.8433 - val_loss: 0.3272 - val_accuracy: 0.8502\n",
            "Epoch 4/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3234 - accuracy: 0.8501 - val_loss: 0.3230 - val_accuracy: 0.8531\n",
            "Epoch 5/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3184 - accuracy: 0.8488 - val_loss: 0.3218 - val_accuracy: 0.8511\n",
            "Epoch 6/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3105 - accuracy: 0.8512 - val_loss: 0.3240 - val_accuracy: 0.8510\n",
            "Epoch 7/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3143 - accuracy: 0.8530 - val_loss: 0.3195 - val_accuracy: 0.8540\n",
            "Epoch 8/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3056 - accuracy: 0.8548 - val_loss: 0.3238 - val_accuracy: 0.8509\n",
            "Epoch 9/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3042 - accuracy: 0.8566 - val_loss: 0.3217 - val_accuracy: 0.8509\n",
            "Epoch 10/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3023 - accuracy: 0.8587 - val_loss: 0.3229 - val_accuracy: 0.8541\n",
            "Epoch 11/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.2924 - accuracy: 0.8620 - val_loss: 0.3223 - val_accuracy: 0.8547\n",
            "Epoch 12/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.2917 - accuracy: 0.8614 - val_loss: 0.3218 - val_accuracy: 0.8532\n",
            "150/150 [==============================] - 0s 936us/step - loss: 0.3253 - accuracy: 0.8507\n",
            "Epoch 1/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.4402 - accuracy: 0.7968 - val_loss: 0.3522 - val_accuracy: 0.8369\n",
            "Epoch 2/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3523 - accuracy: 0.8331 - val_loss: 0.3280 - val_accuracy: 0.8508\n",
            "Epoch 3/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3259 - accuracy: 0.8447 - val_loss: 0.3272 - val_accuracy: 0.8472\n",
            "Epoch 4/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3148 - accuracy: 0.8528 - val_loss: 0.3234 - val_accuracy: 0.8510\n",
            "Epoch 5/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3247 - accuracy: 0.8445 - val_loss: 0.3252 - val_accuracy: 0.8534\n",
            "Epoch 6/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3140 - accuracy: 0.8507 - val_loss: 0.3253 - val_accuracy: 0.8507\n",
            "Epoch 7/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3045 - accuracy: 0.8599 - val_loss: 0.3297 - val_accuracy: 0.8481\n",
            "Epoch 8/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3055 - accuracy: 0.8538 - val_loss: 0.3229 - val_accuracy: 0.8524\n",
            "Epoch 9/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.2943 - accuracy: 0.8655 - val_loss: 0.3447 - val_accuracy: 0.8319\n",
            "Epoch 10/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.2979 - accuracy: 0.8574 - val_loss: 0.3325 - val_accuracy: 0.8532\n",
            "Epoch 11/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.2947 - accuracy: 0.8632 - val_loss: 0.3242 - val_accuracy: 0.8525\n",
            "Epoch 12/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.2948 - accuracy: 0.8605 - val_loss: 0.3262 - val_accuracy: 0.8524\n",
            "Epoch 13/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.2937 - accuracy: 0.8638 - val_loss: 0.3357 - val_accuracy: 0.8404\n",
            "150/150 [==============================] - 0s 986us/step - loss: 0.3286 - accuracy: 0.8380\n",
            "Epoch 1/50\n",
            "1350/1350 [==============================] - 4s 2ms/step - loss: 0.4388 - accuracy: 0.7961 - val_loss: 0.3536 - val_accuracy: 0.8385\n",
            "Epoch 2/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3400 - accuracy: 0.8382 - val_loss: 0.3290 - val_accuracy: 0.8516\n",
            "Epoch 3/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3219 - accuracy: 0.8478 - val_loss: 0.3245 - val_accuracy: 0.8500\n",
            "Epoch 4/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3235 - accuracy: 0.8479 - val_loss: 0.3279 - val_accuracy: 0.8489\n",
            "Epoch 5/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3225 - accuracy: 0.8486 - val_loss: 0.3225 - val_accuracy: 0.8488\n",
            "Epoch 6/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3104 - accuracy: 0.8571 - val_loss: 0.3263 - val_accuracy: 0.8515\n",
            "Epoch 7/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3104 - accuracy: 0.8500 - val_loss: 0.3227 - val_accuracy: 0.8513\n",
            "Epoch 8/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3132 - accuracy: 0.8525 - val_loss: 0.3227 - val_accuracy: 0.8524\n",
            "Epoch 9/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3052 - accuracy: 0.8551 - val_loss: 0.3293 - val_accuracy: 0.8510\n",
            "Epoch 10/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3140 - accuracy: 0.8532 - val_loss: 0.3237 - val_accuracy: 0.8524\n",
            "150/150 [==============================] - 0s 952us/step - loss: 0.3189 - accuracy: 0.8473\n",
            "Epoch 1/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.4440 - accuracy: 0.7905 - val_loss: 0.3482 - val_accuracy: 0.8406\n",
            "Epoch 2/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3467 - accuracy: 0.8389 - val_loss: 0.3322 - val_accuracy: 0.8477\n",
            "Epoch 3/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3262 - accuracy: 0.8497 - val_loss: 0.3233 - val_accuracy: 0.8504\n",
            "Epoch 4/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3223 - accuracy: 0.8457 - val_loss: 0.3204 - val_accuracy: 0.8512\n",
            "Epoch 5/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3138 - accuracy: 0.8519 - val_loss: 0.3254 - val_accuracy: 0.8503\n",
            "Epoch 6/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3122 - accuracy: 0.8544 - val_loss: 0.3261 - val_accuracy: 0.8491\n",
            "Epoch 7/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3065 - accuracy: 0.8580 - val_loss: 0.3256 - val_accuracy: 0.8475\n",
            "Epoch 8/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3013 - accuracy: 0.8607 - val_loss: 0.3220 - val_accuracy: 0.8537\n",
            "Epoch 9/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3002 - accuracy: 0.8600 - val_loss: 0.3232 - val_accuracy: 0.8518\n",
            "150/150 [==============================] - 0s 948us/step - loss: 0.3258 - accuracy: 0.8433\n",
            "Epoch 1/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.4443 - accuracy: 0.7938 - val_loss: 0.3511 - val_accuracy: 0.8373\n",
            "Epoch 2/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3498 - accuracy: 0.8358 - val_loss: 0.3326 - val_accuracy: 0.8483\n",
            "Epoch 3/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3203 - accuracy: 0.8516 - val_loss: 0.3257 - val_accuracy: 0.8501\n",
            "Epoch 4/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3245 - accuracy: 0.8437 - val_loss: 0.3251 - val_accuracy: 0.8497\n",
            "Epoch 5/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3185 - accuracy: 0.8484 - val_loss: 0.3258 - val_accuracy: 0.8518\n",
            "Epoch 6/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3126 - accuracy: 0.8546 - val_loss: 0.3219 - val_accuracy: 0.8500\n",
            "Epoch 7/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3088 - accuracy: 0.8538 - val_loss: 0.3242 - val_accuracy: 0.8499\n",
            "Epoch 8/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3089 - accuracy: 0.8547 - val_loss: 0.3248 - val_accuracy: 0.8505\n",
            "Epoch 9/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3006 - accuracy: 0.8565 - val_loss: 0.3201 - val_accuracy: 0.8528\n",
            "Epoch 10/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3052 - accuracy: 0.8566 - val_loss: 0.3259 - val_accuracy: 0.8482\n",
            "Epoch 11/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.2968 - accuracy: 0.8583 - val_loss: 0.3259 - val_accuracy: 0.8506\n",
            "Epoch 12/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.2992 - accuracy: 0.8589 - val_loss: 0.3270 - val_accuracy: 0.8520\n",
            "Epoch 13/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.2875 - accuracy: 0.8645 - val_loss: 0.3282 - val_accuracy: 0.8518\n",
            "Epoch 14/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.2930 - accuracy: 0.8571 - val_loss: 0.3308 - val_accuracy: 0.8474\n",
            "150/150 [==============================] - 0s 896us/step - loss: 0.3367 - accuracy: 0.8500\n",
            "Epoch 1/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.4533 - accuracy: 0.7897 - val_loss: 0.3495 - val_accuracy: 0.8376\n",
            "Epoch 2/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3497 - accuracy: 0.8381 - val_loss: 0.3287 - val_accuracy: 0.8464\n",
            "Epoch 3/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3194 - accuracy: 0.8455 - val_loss: 0.3252 - val_accuracy: 0.8515\n",
            "Epoch 4/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3183 - accuracy: 0.8487 - val_loss: 0.3433 - val_accuracy: 0.8375\n",
            "Epoch 5/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3121 - accuracy: 0.8516 - val_loss: 0.3208 - val_accuracy: 0.8540\n",
            "Epoch 6/50\n",
            "1350/1350 [==============================] - 2s 2ms/step - loss: 0.3132 - accuracy: 0.8525 - val_loss: 0.3236 - val_accuracy: 0.8494\n",
            "Epoch 7/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3109 - accuracy: 0.8538 - val_loss: 0.3300 - val_accuracy: 0.8440\n",
            "Epoch 8/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3104 - accuracy: 0.8558 - val_loss: 0.3218 - val_accuracy: 0.8535\n",
            "Epoch 9/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3019 - accuracy: 0.8540 - val_loss: 0.3232 - val_accuracy: 0.8518\n",
            "Epoch 10/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3056 - accuracy: 0.8538 - val_loss: 0.3254 - val_accuracy: 0.8521\n",
            "150/150 [==============================] - 0s 935us/step - loss: 0.3438 - accuracy: 0.8420\n",
            "Epoch 1/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.4424 - accuracy: 0.7899 - val_loss: 0.3618 - val_accuracy: 0.8321\n",
            "Epoch 2/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3527 - accuracy: 0.8352 - val_loss: 0.3416 - val_accuracy: 0.8423\n",
            "Epoch 3/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3351 - accuracy: 0.8437 - val_loss: 0.3380 - val_accuracy: 0.8442\n",
            "Epoch 4/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3240 - accuracy: 0.8519 - val_loss: 0.3369 - val_accuracy: 0.8369\n",
            "Epoch 5/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3184 - accuracy: 0.8505 - val_loss: 0.3271 - val_accuracy: 0.8498\n",
            "Epoch 6/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3115 - accuracy: 0.8520 - val_loss: 0.3257 - val_accuracy: 0.8493\n",
            "Epoch 7/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3149 - accuracy: 0.8508 - val_loss: 0.3201 - val_accuracy: 0.8543\n",
            "Epoch 8/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3059 - accuracy: 0.8592 - val_loss: 0.3245 - val_accuracy: 0.8513\n",
            "Epoch 9/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3110 - accuracy: 0.8545 - val_loss: 0.3233 - val_accuracy: 0.8525\n",
            "Epoch 10/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3041 - accuracy: 0.8531 - val_loss: 0.3312 - val_accuracy: 0.8471\n",
            "Epoch 11/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3026 - accuracy: 0.8587 - val_loss: 0.3241 - val_accuracy: 0.8529\n",
            "Epoch 12/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.2923 - accuracy: 0.8637 - val_loss: 0.3286 - val_accuracy: 0.8506\n",
            "150/150 [==============================] - 0s 952us/step - loss: 0.3208 - accuracy: 0.8527\n",
            "Epoch 1/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.4443 - accuracy: 0.7948 - val_loss: 0.3466 - val_accuracy: 0.8397\n",
            "Epoch 2/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3438 - accuracy: 0.8389 - val_loss: 0.3305 - val_accuracy: 0.8487\n",
            "Epoch 3/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3309 - accuracy: 0.8421 - val_loss: 0.3206 - val_accuracy: 0.8545\n",
            "Epoch 4/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3260 - accuracy: 0.8478 - val_loss: 0.3279 - val_accuracy: 0.8504\n",
            "Epoch 5/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3243 - accuracy: 0.8471 - val_loss: 0.3197 - val_accuracy: 0.8514\n",
            "Epoch 6/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3147 - accuracy: 0.8538 - val_loss: 0.3232 - val_accuracy: 0.8503\n",
            "Epoch 7/50\n",
            "1350/1350 [==============================] - 2s 2ms/step - loss: 0.3121 - accuracy: 0.8517 - val_loss: 0.3232 - val_accuracy: 0.8534\n",
            "Epoch 8/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3119 - accuracy: 0.8547 - val_loss: 0.3212 - val_accuracy: 0.8547\n",
            "Epoch 9/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3088 - accuracy: 0.8578 - val_loss: 0.3266 - val_accuracy: 0.8513\n",
            "Epoch 10/50\n",
            "1350/1350 [==============================] - 2s 2ms/step - loss: 0.3017 - accuracy: 0.8607 - val_loss: 0.3249 - val_accuracy: 0.8518\n",
            "150/150 [==============================] - 0s 943us/step - loss: 0.3229 - accuracy: 0.8527\n",
            "Epoch 1/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.4528 - accuracy: 0.7899 - val_loss: 0.3480 - val_accuracy: 0.8367\n",
            "Epoch 2/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3348 - accuracy: 0.8417 - val_loss: 0.3322 - val_accuracy: 0.8442\n",
            "Epoch 3/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3276 - accuracy: 0.8445 - val_loss: 0.3255 - val_accuracy: 0.8534\n",
            "Epoch 4/50\n",
            "1350/1350 [==============================] - 2s 2ms/step - loss: 0.3256 - accuracy: 0.8474 - val_loss: 0.3247 - val_accuracy: 0.8533\n",
            "Epoch 5/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3131 - accuracy: 0.8530 - val_loss: 0.3269 - val_accuracy: 0.8511\n",
            "Epoch 6/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3105 - accuracy: 0.8529 - val_loss: 0.3312 - val_accuracy: 0.8417\n",
            "Epoch 7/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3075 - accuracy: 0.8552 - val_loss: 0.3277 - val_accuracy: 0.8502\n",
            "Epoch 8/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3098 - accuracy: 0.8546 - val_loss: 0.3245 - val_accuracy: 0.8496\n",
            "Epoch 9/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3083 - accuracy: 0.8558 - val_loss: 0.3232 - val_accuracy: 0.8532\n",
            "Epoch 10/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3105 - accuracy: 0.8565 - val_loss: 0.3268 - val_accuracy: 0.8495\n",
            "Epoch 11/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3048 - accuracy: 0.8582 - val_loss: 0.3402 - val_accuracy: 0.8482\n",
            "Epoch 12/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.2986 - accuracy: 0.8604 - val_loss: 0.3256 - val_accuracy: 0.8519\n",
            "Epoch 13/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.2901 - accuracy: 0.8655 - val_loss: 0.3291 - val_accuracy: 0.8487\n",
            "Epoch 14/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.2982 - accuracy: 0.8546 - val_loss: 0.3264 - val_accuracy: 0.8488\n",
            "150/150 [==============================] - 0s 1ms/step - loss: 0.3262 - accuracy: 0.8413\n",
            "Epoch 1/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.4501 - accuracy: 0.7813 - val_loss: 0.3503 - val_accuracy: 0.8402\n",
            "Epoch 2/50\n",
            "1350/1350 [==============================] - 2s 2ms/step - loss: 0.3572 - accuracy: 0.8278 - val_loss: 0.3346 - val_accuracy: 0.8459\n",
            "Epoch 3/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3290 - accuracy: 0.8446 - val_loss: 0.3540 - val_accuracy: 0.8356\n",
            "Epoch 4/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3252 - accuracy: 0.8452 - val_loss: 0.3223 - val_accuracy: 0.8541\n",
            "Epoch 5/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3125 - accuracy: 0.8496 - val_loss: 0.3201 - val_accuracy: 0.8520\n",
            "Epoch 6/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3114 - accuracy: 0.8534 - val_loss: 0.3227 - val_accuracy: 0.8502\n",
            "Epoch 7/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3051 - accuracy: 0.8582 - val_loss: 0.3234 - val_accuracy: 0.8506\n",
            "Epoch 8/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3087 - accuracy: 0.8575 - val_loss: 0.3214 - val_accuracy: 0.8536\n",
            "Epoch 9/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3073 - accuracy: 0.8517 - val_loss: 0.3221 - val_accuracy: 0.8542\n",
            "Epoch 10/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3047 - accuracy: 0.8538 - val_loss: 0.3255 - val_accuracy: 0.8529\n",
            "150/150 [==============================] - 0s 908us/step - loss: 0.3085 - accuracy: 0.8500\n",
            "Epoch 1/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.4455 - accuracy: 0.7980 - val_loss: 0.3483 - val_accuracy: 0.8410\n",
            "Epoch 2/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3456 - accuracy: 0.8343 - val_loss: 0.3276 - val_accuracy: 0.8483\n",
            "Epoch 3/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3258 - accuracy: 0.8456 - val_loss: 0.3255 - val_accuracy: 0.8494\n",
            "Epoch 4/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3091 - accuracy: 0.8560 - val_loss: 0.3333 - val_accuracy: 0.8423\n",
            "Epoch 5/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3037 - accuracy: 0.8573 - val_loss: 0.3346 - val_accuracy: 0.8470\n",
            "Epoch 6/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3091 - accuracy: 0.8515 - val_loss: 0.3206 - val_accuracy: 0.8519\n",
            "Epoch 7/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3028 - accuracy: 0.8579 - val_loss: 0.3224 - val_accuracy: 0.8510\n",
            "Epoch 8/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3070 - accuracy: 0.8558 - val_loss: 0.3230 - val_accuracy: 0.8508\n",
            "Epoch 9/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3090 - accuracy: 0.8530 - val_loss: 0.3238 - val_accuracy: 0.8493\n",
            "Epoch 10/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3041 - accuracy: 0.8533 - val_loss: 0.3409 - val_accuracy: 0.8484\n",
            "Epoch 11/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.2984 - accuracy: 0.8600 - val_loss: 0.3346 - val_accuracy: 0.8414\n",
            "150/150 [==============================] - 0s 923us/step - loss: 0.3370 - accuracy: 0.8347\n",
            "Epoch 1/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.4423 - accuracy: 0.7938 - val_loss: 0.3450 - val_accuracy: 0.8394\n",
            "Epoch 2/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3440 - accuracy: 0.8386 - val_loss: 0.3453 - val_accuracy: 0.8348\n",
            "Epoch 3/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3300 - accuracy: 0.8429 - val_loss: 0.3248 - val_accuracy: 0.8520\n",
            "Epoch 4/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3227 - accuracy: 0.8492 - val_loss: 0.3241 - val_accuracy: 0.8510\n",
            "Epoch 5/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3070 - accuracy: 0.8594 - val_loss: 0.3225 - val_accuracy: 0.8527\n",
            "Epoch 6/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3138 - accuracy: 0.8512 - val_loss: 0.3224 - val_accuracy: 0.8554\n",
            "Epoch 7/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3115 - accuracy: 0.8628 - val_loss: 0.3225 - val_accuracy: 0.8517\n",
            "Epoch 8/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3092 - accuracy: 0.8563 - val_loss: 0.3250 - val_accuracy: 0.8509\n",
            "Epoch 9/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3033 - accuracy: 0.8568 - val_loss: 0.3397 - val_accuracy: 0.8411\n",
            "Epoch 10/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.2930 - accuracy: 0.8588 - val_loss: 0.3230 - val_accuracy: 0.8511\n",
            "Epoch 11/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3000 - accuracy: 0.8609 - val_loss: 0.3254 - val_accuracy: 0.8501\n",
            "150/150 [==============================] - 0s 916us/step - loss: 0.3199 - accuracy: 0.8533\n",
            "Epoch 1/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.4433 - accuracy: 0.7957 - val_loss: 0.3525 - val_accuracy: 0.8405\n",
            "Epoch 2/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3460 - accuracy: 0.8376 - val_loss: 0.3416 - val_accuracy: 0.8444\n",
            "Epoch 3/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3266 - accuracy: 0.8443 - val_loss: 0.3246 - val_accuracy: 0.8520\n",
            "Epoch 4/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3228 - accuracy: 0.8458 - val_loss: 0.3253 - val_accuracy: 0.8486\n",
            "Epoch 5/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3183 - accuracy: 0.8494 - val_loss: 0.3201 - val_accuracy: 0.8552\n",
            "Epoch 6/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3104 - accuracy: 0.8537 - val_loss: 0.3209 - val_accuracy: 0.8532\n",
            "Epoch 7/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3070 - accuracy: 0.8541 - val_loss: 0.3322 - val_accuracy: 0.8514\n",
            "Epoch 8/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3010 - accuracy: 0.8601 - val_loss: 0.3257 - val_accuracy: 0.8482\n",
            "Epoch 9/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3027 - accuracy: 0.8577 - val_loss: 0.3295 - val_accuracy: 0.8481\n",
            "Epoch 10/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3015 - accuracy: 0.8528 - val_loss: 0.3242 - val_accuracy: 0.8524\n",
            "150/150 [==============================] - 0s 962us/step - loss: 0.3141 - accuracy: 0.8567\n",
            "Epoch 1/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.4449 - accuracy: 0.7891 - val_loss: 0.3762 - val_accuracy: 0.8114\n",
            "Epoch 2/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3396 - accuracy: 0.8399 - val_loss: 0.3319 - val_accuracy: 0.8480\n",
            "Epoch 3/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3400 - accuracy: 0.8406 - val_loss: 0.3260 - val_accuracy: 0.8484\n",
            "Epoch 4/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3123 - accuracy: 0.8554 - val_loss: 0.3267 - val_accuracy: 0.8531\n",
            "Epoch 5/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3135 - accuracy: 0.8538 - val_loss: 0.3208 - val_accuracy: 0.8526\n",
            "Epoch 6/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3139 - accuracy: 0.8515 - val_loss: 0.3248 - val_accuracy: 0.8500\n",
            "Epoch 7/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3003 - accuracy: 0.8619 - val_loss: 0.3322 - val_accuracy: 0.8434\n",
            "Epoch 8/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3067 - accuracy: 0.8545 - val_loss: 0.3239 - val_accuracy: 0.8500\n",
            "Epoch 9/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3003 - accuracy: 0.8581 - val_loss: 0.3228 - val_accuracy: 0.8516\n",
            "Epoch 10/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3109 - accuracy: 0.8578 - val_loss: 0.3366 - val_accuracy: 0.8390\n",
            "150/150 [==============================] - 0s 891us/step - loss: 0.3342 - accuracy: 0.8347\n",
            "Epoch 1/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.4418 - accuracy: 0.7974 - val_loss: 0.3505 - val_accuracy: 0.8324\n",
            "Epoch 2/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3422 - accuracy: 0.8377 - val_loss: 0.3316 - val_accuracy: 0.8490\n",
            "Epoch 3/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3264 - accuracy: 0.8469 - val_loss: 0.3288 - val_accuracy: 0.8446\n",
            "Epoch 4/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3244 - accuracy: 0.8443 - val_loss: 0.3510 - val_accuracy: 0.8404\n",
            "Epoch 5/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3066 - accuracy: 0.8581 - val_loss: 0.3256 - val_accuracy: 0.8494\n",
            "Epoch 6/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3130 - accuracy: 0.8498 - val_loss: 0.3194 - val_accuracy: 0.8536\n",
            "Epoch 7/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3083 - accuracy: 0.8514 - val_loss: 0.3235 - val_accuracy: 0.8530\n",
            "Epoch 8/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3087 - accuracy: 0.8562 - val_loss: 0.3217 - val_accuracy: 0.8535\n",
            "Epoch 9/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3139 - accuracy: 0.8520 - val_loss: 0.3331 - val_accuracy: 0.8501\n",
            "Epoch 10/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3017 - accuracy: 0.8601 - val_loss: 0.3249 - val_accuracy: 0.8548\n",
            "Epoch 11/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.2981 - accuracy: 0.8580 - val_loss: 0.3267 - val_accuracy: 0.8507\n",
            "150/150 [==============================] - 0s 969us/step - loss: 0.3286 - accuracy: 0.8520\n",
            "Epoch 1/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.4535 - accuracy: 0.7838 - val_loss: 0.3538 - val_accuracy: 0.8365\n",
            "Epoch 2/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3421 - accuracy: 0.8395 - val_loss: 0.3314 - val_accuracy: 0.8503\n",
            "Epoch 3/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3240 - accuracy: 0.8455 - val_loss: 0.3239 - val_accuracy: 0.8513\n",
            "Epoch 4/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3138 - accuracy: 0.8524 - val_loss: 0.3405 - val_accuracy: 0.8388\n",
            "Epoch 5/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3089 - accuracy: 0.8532 - val_loss: 0.3260 - val_accuracy: 0.8529\n",
            "Epoch 6/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3085 - accuracy: 0.8572 - val_loss: 0.3239 - val_accuracy: 0.8517\n",
            "Epoch 7/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3026 - accuracy: 0.8566 - val_loss: 0.3263 - val_accuracy: 0.8495\n",
            "Epoch 8/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3055 - accuracy: 0.8523 - val_loss: 0.3234 - val_accuracy: 0.8498\n",
            "Epoch 9/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.2921 - accuracy: 0.8627 - val_loss: 0.3242 - val_accuracy: 0.8516\n",
            "Epoch 10/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.2979 - accuracy: 0.8596 - val_loss: 0.3247 - val_accuracy: 0.8522\n",
            "Epoch 11/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.2896 - accuracy: 0.8602 - val_loss: 0.3297 - val_accuracy: 0.8498\n",
            "Epoch 12/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.2927 - accuracy: 0.8605 - val_loss: 0.3304 - val_accuracy: 0.8489\n",
            "Epoch 13/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.2958 - accuracy: 0.8609 - val_loss: 0.3330 - val_accuracy: 0.8480\n",
            "150/150 [==============================] - 0s 919us/step - loss: 0.3560 - accuracy: 0.8407\n",
            "Epoch 1/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.4476 - accuracy: 0.7879 - val_loss: 0.3477 - val_accuracy: 0.8378\n",
            "Epoch 2/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3413 - accuracy: 0.8378 - val_loss: 0.3310 - val_accuracy: 0.8474\n",
            "Epoch 3/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3248 - accuracy: 0.8510 - val_loss: 0.3246 - val_accuracy: 0.8525\n",
            "Epoch 4/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3243 - accuracy: 0.8459 - val_loss: 0.3247 - val_accuracy: 0.8509\n",
            "Epoch 5/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3118 - accuracy: 0.8535 - val_loss: 0.3245 - val_accuracy: 0.8488\n",
            "Epoch 6/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3140 - accuracy: 0.8524 - val_loss: 0.3250 - val_accuracy: 0.8498\n",
            "Epoch 7/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3060 - accuracy: 0.8547 - val_loss: 0.3325 - val_accuracy: 0.8442\n",
            "Epoch 8/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.2989 - accuracy: 0.8598 - val_loss: 0.3393 - val_accuracy: 0.8457\n",
            "Epoch 9/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3024 - accuracy: 0.8596 - val_loss: 0.3224 - val_accuracy: 0.8522\n",
            "Epoch 10/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.2976 - accuracy: 0.8624 - val_loss: 0.3284 - val_accuracy: 0.8506\n",
            "Epoch 11/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3023 - accuracy: 0.8595 - val_loss: 0.3280 - val_accuracy: 0.8498\n",
            "Epoch 12/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.2946 - accuracy: 0.8631 - val_loss: 0.3306 - val_accuracy: 0.8484\n",
            "Epoch 13/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.2886 - accuracy: 0.8666 - val_loss: 0.3307 - val_accuracy: 0.8500\n",
            "Epoch 14/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.2845 - accuracy: 0.8667 - val_loss: 0.3324 - val_accuracy: 0.8477\n",
            "150/150 [==============================] - 0s 925us/step - loss: 0.3299 - accuracy: 0.8520\n",
            "Epoch 1/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.4418 - accuracy: 0.7978 - val_loss: 0.3484 - val_accuracy: 0.8403\n",
            "Epoch 2/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3453 - accuracy: 0.8322 - val_loss: 0.3351 - val_accuracy: 0.8455\n",
            "Epoch 3/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3318 - accuracy: 0.8433 - val_loss: 0.3259 - val_accuracy: 0.8546\n",
            "Epoch 4/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3184 - accuracy: 0.8484 - val_loss: 0.3228 - val_accuracy: 0.8512\n",
            "Epoch 5/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3255 - accuracy: 0.8464 - val_loss: 0.3207 - val_accuracy: 0.8517\n",
            "Epoch 6/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3142 - accuracy: 0.8543 - val_loss: 0.3326 - val_accuracy: 0.8433\n",
            "Epoch 7/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3154 - accuracy: 0.8548 - val_loss: 0.3242 - val_accuracy: 0.8545\n",
            "Epoch 8/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3142 - accuracy: 0.8537 - val_loss: 0.3269 - val_accuracy: 0.8533\n",
            "Epoch 9/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3063 - accuracy: 0.8564 - val_loss: 0.3225 - val_accuracy: 0.8549\n",
            "Epoch 10/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3045 - accuracy: 0.8568 - val_loss: 0.3221 - val_accuracy: 0.8546\n",
            "150/150 [==============================] - 0s 907us/step - loss: 0.3203 - accuracy: 0.8527\n",
            "Epoch 1/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.4408 - accuracy: 0.7933 - val_loss: 0.3504 - val_accuracy: 0.8361\n",
            "Epoch 2/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3461 - accuracy: 0.8369 - val_loss: 0.3398 - val_accuracy: 0.8420\n",
            "Epoch 3/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3336 - accuracy: 0.8406 - val_loss: 0.3266 - val_accuracy: 0.8526\n",
            "Epoch 4/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3148 - accuracy: 0.8512 - val_loss: 0.3451 - val_accuracy: 0.8356\n",
            "Epoch 5/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3124 - accuracy: 0.8532 - val_loss: 0.3272 - val_accuracy: 0.8465\n",
            "Epoch 6/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3104 - accuracy: 0.8567 - val_loss: 0.3243 - val_accuracy: 0.8512\n",
            "Epoch 7/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3143 - accuracy: 0.8518 - val_loss: 0.3217 - val_accuracy: 0.8521\n",
            "Epoch 8/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3095 - accuracy: 0.8520 - val_loss: 0.3259 - val_accuracy: 0.8459\n",
            "Epoch 9/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3124 - accuracy: 0.8493 - val_loss: 0.3389 - val_accuracy: 0.8357\n",
            "Epoch 10/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3043 - accuracy: 0.8548 - val_loss: 0.3276 - val_accuracy: 0.8480\n",
            "Epoch 11/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3054 - accuracy: 0.8572 - val_loss: 0.3234 - val_accuracy: 0.8503\n",
            "Epoch 12/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3114 - accuracy: 0.8544 - val_loss: 0.3283 - val_accuracy: 0.8528\n",
            "150/150 [==============================] - 0s 909us/step - loss: 0.3337 - accuracy: 0.8380\n",
            "Epoch 1/50\n",
            "1350/1350 [==============================] - 4s 2ms/step - loss: 0.4477 - accuracy: 0.7880 - val_loss: 0.3454 - val_accuracy: 0.8405\n",
            "Epoch 2/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3459 - accuracy: 0.8335 - val_loss: 0.3608 - val_accuracy: 0.8381\n",
            "Epoch 3/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3280 - accuracy: 0.8494 - val_loss: 0.3277 - val_accuracy: 0.8497\n",
            "Epoch 4/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3189 - accuracy: 0.8520 - val_loss: 0.3275 - val_accuracy: 0.8493\n",
            "Epoch 5/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3139 - accuracy: 0.8523 - val_loss: 0.3201 - val_accuracy: 0.8533\n",
            "Epoch 6/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3033 - accuracy: 0.8607 - val_loss: 0.3248 - val_accuracy: 0.8512\n",
            "Epoch 7/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3143 - accuracy: 0.8580 - val_loss: 0.3292 - val_accuracy: 0.8476\n",
            "Epoch 8/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3065 - accuracy: 0.8587 - val_loss: 0.3289 - val_accuracy: 0.8502\n",
            "Epoch 9/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3067 - accuracy: 0.8561 - val_loss: 0.3283 - val_accuracy: 0.8479\n",
            "Epoch 10/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3025 - accuracy: 0.8561 - val_loss: 0.3212 - val_accuracy: 0.8539\n",
            "150/150 [==============================] - 0s 989us/step - loss: 0.3083 - accuracy: 0.8547\n",
            "Epoch 1/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.4472 - accuracy: 0.7973 - val_loss: 0.3489 - val_accuracy: 0.8389\n",
            "Epoch 2/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3467 - accuracy: 0.8359 - val_loss: 0.3298 - val_accuracy: 0.8465\n",
            "Epoch 3/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3289 - accuracy: 0.8456 - val_loss: 0.3264 - val_accuracy: 0.8471\n",
            "Epoch 4/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3195 - accuracy: 0.8454 - val_loss: 0.3225 - val_accuracy: 0.8501\n",
            "Epoch 5/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3176 - accuracy: 0.8479 - val_loss: 0.3278 - val_accuracy: 0.8500\n",
            "Epoch 6/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3085 - accuracy: 0.8593 - val_loss: 0.3213 - val_accuracy: 0.8522\n",
            "Epoch 7/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3145 - accuracy: 0.8526 - val_loss: 0.3386 - val_accuracy: 0.8344\n",
            "Epoch 8/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3081 - accuracy: 0.8572 - val_loss: 0.3198 - val_accuracy: 0.8523\n",
            "Epoch 9/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3072 - accuracy: 0.8525 - val_loss: 0.3203 - val_accuracy: 0.8509\n",
            "Epoch 10/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3061 - accuracy: 0.8545 - val_loss: 0.3257 - val_accuracy: 0.8528\n",
            "Epoch 11/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.2960 - accuracy: 0.8626 - val_loss: 0.3257 - val_accuracy: 0.8501\n",
            "Epoch 12/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3026 - accuracy: 0.8587 - val_loss: 0.3242 - val_accuracy: 0.8521\n",
            "Epoch 13/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.2938 - accuracy: 0.8593 - val_loss: 0.3279 - val_accuracy: 0.8507\n",
            "150/150 [==============================] - 0s 972us/step - loss: 0.3326 - accuracy: 0.8480\n",
            "Epoch 1/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.4199 - accuracy: 0.7912 - val_loss: 0.3741 - val_accuracy: 0.8350\n",
            "Epoch 2/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3481 - accuracy: 0.8359 - val_loss: 0.3350 - val_accuracy: 0.8481\n",
            "Epoch 3/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3352 - accuracy: 0.8451 - val_loss: 0.3264 - val_accuracy: 0.8519\n",
            "Epoch 4/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3249 - accuracy: 0.8499 - val_loss: 0.3289 - val_accuracy: 0.8516\n",
            "Epoch 5/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3186 - accuracy: 0.8525 - val_loss: 0.3284 - val_accuracy: 0.8509\n",
            "Epoch 6/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3234 - accuracy: 0.8489 - val_loss: 0.3477 - val_accuracy: 0.8291\n",
            "Epoch 7/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3113 - accuracy: 0.8517 - val_loss: 0.3323 - val_accuracy: 0.8503\n",
            "Epoch 8/50\n",
            "1350/1350 [==============================] - 2s 2ms/step - loss: 0.3173 - accuracy: 0.8460 - val_loss: 0.3338 - val_accuracy: 0.8475\n",
            "150/150 [==============================] - 0s 985us/step - loss: 0.3300 - accuracy: 0.8553\n",
            "Epoch 1/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.4070 - accuracy: 0.8050 - val_loss: 0.3442 - val_accuracy: 0.8383\n",
            "Epoch 2/50\n",
            "1350/1350 [==============================] - 2s 2ms/step - loss: 0.3571 - accuracy: 0.8284 - val_loss: 0.3358 - val_accuracy: 0.8493\n",
            "Epoch 3/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3304 - accuracy: 0.8450 - val_loss: 0.3429 - val_accuracy: 0.8411\n",
            "Epoch 4/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3193 - accuracy: 0.8490 - val_loss: 0.3319 - val_accuracy: 0.8510\n",
            "Epoch 5/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3281 - accuracy: 0.8403 - val_loss: 0.3385 - val_accuracy: 0.8449\n",
            "Epoch 6/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3096 - accuracy: 0.8568 - val_loss: 0.3360 - val_accuracy: 0.8485\n",
            "Epoch 7/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3157 - accuracy: 0.8523 - val_loss: 0.3394 - val_accuracy: 0.8406\n",
            "Epoch 8/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3119 - accuracy: 0.8516 - val_loss: 0.3318 - val_accuracy: 0.8484\n",
            "Epoch 9/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3054 - accuracy: 0.8510 - val_loss: 0.3408 - val_accuracy: 0.8450\n",
            "Epoch 10/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3050 - accuracy: 0.8557 - val_loss: 0.3395 - val_accuracy: 0.8488\n",
            "Epoch 11/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3005 - accuracy: 0.8577 - val_loss: 0.3484 - val_accuracy: 0.8485\n",
            "Epoch 12/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3010 - accuracy: 0.8536 - val_loss: 0.3382 - val_accuracy: 0.8485\n",
            "Epoch 13/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.2925 - accuracy: 0.8621 - val_loss: 0.3595 - val_accuracy: 0.8469\n",
            "150/150 [==============================] - 0s 988us/step - loss: 0.3380 - accuracy: 0.8547\n",
            "Epoch 1/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.4041 - accuracy: 0.8013 - val_loss: 0.3563 - val_accuracy: 0.8117\n",
            "Epoch 2/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3452 - accuracy: 0.8360 - val_loss: 0.3391 - val_accuracy: 0.8473\n",
            "Epoch 3/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3334 - accuracy: 0.8471 - val_loss: 0.3730 - val_accuracy: 0.8331\n",
            "Epoch 4/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3298 - accuracy: 0.8463 - val_loss: 0.3254 - val_accuracy: 0.8521\n",
            "Epoch 5/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3225 - accuracy: 0.8464 - val_loss: 0.3653 - val_accuracy: 0.8375\n",
            "Epoch 6/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3114 - accuracy: 0.8571 - val_loss: 0.3452 - val_accuracy: 0.8401\n",
            "Epoch 7/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3125 - accuracy: 0.8524 - val_loss: 0.3295 - val_accuracy: 0.8501\n",
            "Epoch 8/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3160 - accuracy: 0.8480 - val_loss: 0.3411 - val_accuracy: 0.8414\n",
            "Epoch 9/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3098 - accuracy: 0.8540 - val_loss: 0.3358 - val_accuracy: 0.8405\n",
            "150/150 [==============================] - 0s 930us/step - loss: 0.3347 - accuracy: 0.8387\n",
            "Epoch 1/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.4155 - accuracy: 0.7967 - val_loss: 0.3532 - val_accuracy: 0.8399\n",
            "Epoch 2/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3411 - accuracy: 0.8450 - val_loss: 0.3419 - val_accuracy: 0.8377\n",
            "Epoch 3/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3312 - accuracy: 0.8474 - val_loss: 0.3292 - val_accuracy: 0.8485\n",
            "Epoch 4/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3322 - accuracy: 0.8476 - val_loss: 0.3454 - val_accuracy: 0.8510\n",
            "Epoch 5/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3256 - accuracy: 0.8453 - val_loss: 0.3425 - val_accuracy: 0.8341\n",
            "Epoch 6/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3166 - accuracy: 0.8530 - val_loss: 0.3309 - val_accuracy: 0.8498\n",
            "Epoch 7/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3120 - accuracy: 0.8539 - val_loss: 0.3391 - val_accuracy: 0.8488\n",
            "Epoch 8/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3047 - accuracy: 0.8551 - val_loss: 0.3338 - val_accuracy: 0.8467\n",
            "150/150 [==============================] - 0s 932us/step - loss: 0.3355 - accuracy: 0.8560\n",
            "Epoch 1/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.4110 - accuracy: 0.7974 - val_loss: 0.3655 - val_accuracy: 0.8269\n",
            "Epoch 2/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3524 - accuracy: 0.8352 - val_loss: 0.3367 - val_accuracy: 0.8469\n",
            "Epoch 3/50\n",
            "1350/1350 [==============================] - 2s 2ms/step - loss: 0.3365 - accuracy: 0.8432 - val_loss: 0.3353 - val_accuracy: 0.8483\n",
            "Epoch 4/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3273 - accuracy: 0.8500 - val_loss: 0.3351 - val_accuracy: 0.8475\n",
            "Epoch 5/50\n",
            "1350/1350 [==============================] - 2s 2ms/step - loss: 0.3188 - accuracy: 0.8499 - val_loss: 0.3447 - val_accuracy: 0.8354\n",
            "Epoch 6/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3182 - accuracy: 0.8536 - val_loss: 0.3315 - val_accuracy: 0.8478\n",
            "Epoch 7/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3149 - accuracy: 0.8535 - val_loss: 0.3379 - val_accuracy: 0.8482\n",
            "Epoch 8/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3082 - accuracy: 0.8550 - val_loss: 0.3406 - val_accuracy: 0.8387\n",
            "Epoch 9/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3082 - accuracy: 0.8531 - val_loss: 0.3430 - val_accuracy: 0.8453\n",
            "Epoch 10/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3047 - accuracy: 0.8561 - val_loss: 0.3504 - val_accuracy: 0.8472\n",
            "Epoch 11/50\n",
            "1350/1350 [==============================] - 2s 2ms/step - loss: 0.2959 - accuracy: 0.8611 - val_loss: 0.3439 - val_accuracy: 0.8523\n",
            "150/150 [==============================] - 0s 994us/step - loss: 0.3616 - accuracy: 0.8413\n",
            "Epoch 1/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.4015 - accuracy: 0.8113 - val_loss: 0.4026 - val_accuracy: 0.8177\n",
            "Epoch 2/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3392 - accuracy: 0.8435 - val_loss: 0.3335 - val_accuracy: 0.8431\n",
            "Epoch 3/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3333 - accuracy: 0.8445 - val_loss: 0.3521 - val_accuracy: 0.8202\n",
            "Epoch 4/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3211 - accuracy: 0.8502 - val_loss: 0.3392 - val_accuracy: 0.8433\n",
            "Epoch 5/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3243 - accuracy: 0.8471 - val_loss: 0.3275 - val_accuracy: 0.8486\n",
            "Epoch 6/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3167 - accuracy: 0.8556 - val_loss: 0.3429 - val_accuracy: 0.8510\n",
            "Epoch 7/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3236 - accuracy: 0.8473 - val_loss: 0.3298 - val_accuracy: 0.8494\n",
            "Epoch 8/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3099 - accuracy: 0.8562 - val_loss: 0.3353 - val_accuracy: 0.8470\n",
            "Epoch 9/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3074 - accuracy: 0.8524 - val_loss: 0.3306 - val_accuracy: 0.8486\n",
            "Epoch 10/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3022 - accuracy: 0.8582 - val_loss: 0.3490 - val_accuracy: 0.8417\n",
            "150/150 [==============================] - 0s 913us/step - loss: 0.3474 - accuracy: 0.8493\n",
            "Epoch 1/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.4166 - accuracy: 0.7922 - val_loss: 0.3451 - val_accuracy: 0.8420\n",
            "Epoch 2/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3439 - accuracy: 0.8358 - val_loss: 0.3295 - val_accuracy: 0.8539\n",
            "Epoch 3/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3296 - accuracy: 0.8429 - val_loss: 0.3308 - val_accuracy: 0.8492\n",
            "Epoch 4/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3295 - accuracy: 0.8433 - val_loss: 0.3287 - val_accuracy: 0.8511\n",
            "Epoch 5/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3132 - accuracy: 0.8549 - val_loss: 0.3319 - val_accuracy: 0.8474\n",
            "Epoch 6/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3243 - accuracy: 0.8486 - val_loss: 0.3303 - val_accuracy: 0.8512\n",
            "Epoch 7/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3160 - accuracy: 0.8529 - val_loss: 0.3301 - val_accuracy: 0.8527\n",
            "Epoch 8/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3100 - accuracy: 0.8544 - val_loss: 0.3308 - val_accuracy: 0.8513\n",
            "Epoch 9/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3077 - accuracy: 0.8576 - val_loss: 0.3372 - val_accuracy: 0.8516\n",
            "150/150 [==============================] - 0s 932us/step - loss: 0.3403 - accuracy: 0.8500\n",
            "Epoch 1/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.4076 - accuracy: 0.7992 - val_loss: 0.3731 - val_accuracy: 0.8360\n",
            "Epoch 2/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3501 - accuracy: 0.8376 - val_loss: 0.3359 - val_accuracy: 0.8482\n",
            "Epoch 3/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3329 - accuracy: 0.8437 - val_loss: 0.3304 - val_accuracy: 0.8504\n",
            "Epoch 4/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3255 - accuracy: 0.8502 - val_loss: 0.3379 - val_accuracy: 0.8346\n",
            "Epoch 5/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3225 - accuracy: 0.8459 - val_loss: 0.3307 - val_accuracy: 0.8476\n",
            "Epoch 6/50\n",
            "1350/1350 [==============================] - 2s 2ms/step - loss: 0.3116 - accuracy: 0.8540 - val_loss: 0.3549 - val_accuracy: 0.8317\n",
            "Epoch 7/50\n",
            "1350/1350 [==============================] - 2s 2ms/step - loss: 0.3065 - accuracy: 0.8556 - val_loss: 0.3327 - val_accuracy: 0.8407\n",
            "Epoch 8/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3066 - accuracy: 0.8564 - val_loss: 0.3477 - val_accuracy: 0.8378\n",
            "150/150 [==============================] - 0s 889us/step - loss: 0.3426 - accuracy: 0.8367\n",
            "Epoch 1/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.4157 - accuracy: 0.7902 - val_loss: 0.3466 - val_accuracy: 0.8442\n",
            "Epoch 2/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3493 - accuracy: 0.8378 - val_loss: 0.3525 - val_accuracy: 0.8376\n",
            "Epoch 3/50\n",
            "1350/1350 [==============================] - 2s 2ms/step - loss: 0.3408 - accuracy: 0.8385 - val_loss: 0.3540 - val_accuracy: 0.8346\n",
            "Epoch 4/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3263 - accuracy: 0.8451 - val_loss: 0.3320 - val_accuracy: 0.8476\n",
            "Epoch 5/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3257 - accuracy: 0.8447 - val_loss: 0.3239 - val_accuracy: 0.8498\n",
            "Epoch 6/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3156 - accuracy: 0.8488 - val_loss: 0.3245 - val_accuracy: 0.8491\n",
            "Epoch 7/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3108 - accuracy: 0.8530 - val_loss: 0.3500 - val_accuracy: 0.8416\n",
            "Epoch 8/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3101 - accuracy: 0.8485 - val_loss: 0.3367 - val_accuracy: 0.8477\n",
            "Epoch 9/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.2933 - accuracy: 0.8608 - val_loss: 0.3276 - val_accuracy: 0.8530\n",
            "Epoch 10/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3071 - accuracy: 0.8565 - val_loss: 0.3308 - val_accuracy: 0.8534\n",
            "150/150 [==============================] - 0s 930us/step - loss: 0.3149 - accuracy: 0.8560\n",
            "Epoch 1/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.4054 - accuracy: 0.7996 - val_loss: 0.3781 - val_accuracy: 0.8242\n",
            "Epoch 2/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3612 - accuracy: 0.8308 - val_loss: 0.3314 - val_accuracy: 0.8505\n",
            "Epoch 3/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3396 - accuracy: 0.8419 - val_loss: 0.3264 - val_accuracy: 0.8538\n",
            "Epoch 4/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3292 - accuracy: 0.8426 - val_loss: 0.3392 - val_accuracy: 0.8507\n",
            "Epoch 5/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3179 - accuracy: 0.8545 - val_loss: 0.3642 - val_accuracy: 0.8448\n",
            "Epoch 6/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3245 - accuracy: 0.8421 - val_loss: 0.3314 - val_accuracy: 0.8490\n",
            "Epoch 7/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3069 - accuracy: 0.8572 - val_loss: 0.3265 - val_accuracy: 0.8538\n",
            "Epoch 8/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3107 - accuracy: 0.8547 - val_loss: 0.3365 - val_accuracy: 0.8506\n",
            "150/150 [==============================] - 0s 878us/step - loss: 0.3371 - accuracy: 0.8400\n",
            "Epoch 1/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.4117 - accuracy: 0.7967 - val_loss: 0.3473 - val_accuracy: 0.8398\n",
            "Epoch 2/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3503 - accuracy: 0.8375 - val_loss: 0.3513 - val_accuracy: 0.8314\n",
            "Epoch 3/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3397 - accuracy: 0.8434 - val_loss: 0.3369 - val_accuracy: 0.8510\n",
            "Epoch 4/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3215 - accuracy: 0.8505 - val_loss: 0.3384 - val_accuracy: 0.8426\n",
            "Epoch 5/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3136 - accuracy: 0.8545 - val_loss: 0.3349 - val_accuracy: 0.8475\n",
            "Epoch 6/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3123 - accuracy: 0.8522 - val_loss: 0.3295 - val_accuracy: 0.8491\n",
            "Epoch 7/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3066 - accuracy: 0.8541 - val_loss: 0.3339 - val_accuracy: 0.8483\n",
            "Epoch 8/50\n",
            "1350/1350 [==============================] - 2s 2ms/step - loss: 0.2990 - accuracy: 0.8627 - val_loss: 0.3413 - val_accuracy: 0.8451\n",
            "Epoch 9/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3043 - accuracy: 0.8545 - val_loss: 0.3370 - val_accuracy: 0.8458\n",
            "Epoch 10/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3013 - accuracy: 0.8608 - val_loss: 0.3362 - val_accuracy: 0.8493\n",
            "Epoch 11/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3035 - accuracy: 0.8606 - val_loss: 0.3518 - val_accuracy: 0.8442\n",
            "150/150 [==============================] - 0s 932us/step - loss: 0.3506 - accuracy: 0.8480\n",
            "Epoch 1/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.4132 - accuracy: 0.7982 - val_loss: 0.3543 - val_accuracy: 0.8404\n",
            "Epoch 2/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3412 - accuracy: 0.8379 - val_loss: 0.3461 - val_accuracy: 0.8417\n",
            "Epoch 3/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3322 - accuracy: 0.8405 - val_loss: 0.3291 - val_accuracy: 0.8527\n",
            "Epoch 4/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3229 - accuracy: 0.8451 - val_loss: 0.3351 - val_accuracy: 0.8481\n",
            "Epoch 5/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3273 - accuracy: 0.8460 - val_loss: 0.3280 - val_accuracy: 0.8508\n",
            "Epoch 6/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3122 - accuracy: 0.8556 - val_loss: 0.3256 - val_accuracy: 0.8474\n",
            "Epoch 7/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3162 - accuracy: 0.8530 - val_loss: 0.3401 - val_accuracy: 0.8402\n",
            "Epoch 8/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3079 - accuracy: 0.8522 - val_loss: 0.3385 - val_accuracy: 0.8496\n",
            "Epoch 9/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3247 - accuracy: 0.8445 - val_loss: 0.3365 - val_accuracy: 0.8513\n",
            "Epoch 10/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3016 - accuracy: 0.8544 - val_loss: 0.3433 - val_accuracy: 0.8387\n",
            "Epoch 11/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3039 - accuracy: 0.8528 - val_loss: 0.3363 - val_accuracy: 0.8489\n",
            "150/150 [==============================] - 0s 970us/step - loss: 0.3241 - accuracy: 0.8500\n",
            "Epoch 1/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.4161 - accuracy: 0.7971 - val_loss: 0.3672 - val_accuracy: 0.8318\n",
            "Epoch 2/50\n",
            "1350/1350 [==============================] - 2s 2ms/step - loss: 0.3511 - accuracy: 0.8309 - val_loss: 0.3359 - val_accuracy: 0.8488\n",
            "Epoch 3/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3338 - accuracy: 0.8433 - val_loss: 0.3440 - val_accuracy: 0.8447\n",
            "Epoch 4/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3298 - accuracy: 0.8442 - val_loss: 0.3449 - val_accuracy: 0.8481\n",
            "Epoch 5/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3196 - accuracy: 0.8491 - val_loss: 0.3291 - val_accuracy: 0.8502\n",
            "Epoch 6/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3096 - accuracy: 0.8533 - val_loss: 0.3317 - val_accuracy: 0.8499\n",
            "Epoch 7/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3144 - accuracy: 0.8558 - val_loss: 0.3370 - val_accuracy: 0.8468\n",
            "Epoch 8/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3058 - accuracy: 0.8554 - val_loss: 0.3447 - val_accuracy: 0.8325\n",
            "Epoch 9/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3077 - accuracy: 0.8590 - val_loss: 0.3395 - val_accuracy: 0.8456\n",
            "Epoch 10/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3021 - accuracy: 0.8586 - val_loss: 0.3460 - val_accuracy: 0.8504\n",
            "150/150 [==============================] - 0s 977us/step - loss: 0.3402 - accuracy: 0.8473\n",
            "Epoch 1/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.4182 - accuracy: 0.7948 - val_loss: 0.3449 - val_accuracy: 0.8427\n",
            "Epoch 2/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3419 - accuracy: 0.8408 - val_loss: 0.3347 - val_accuracy: 0.8466\n",
            "Epoch 3/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3224 - accuracy: 0.8501 - val_loss: 0.3357 - val_accuracy: 0.8418\n",
            "Epoch 4/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3153 - accuracy: 0.8529 - val_loss: 0.3300 - val_accuracy: 0.8498\n",
            "Epoch 5/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3177 - accuracy: 0.8532 - val_loss: 0.3328 - val_accuracy: 0.8482\n",
            "Epoch 6/50\n",
            "1350/1350 [==============================] - 2s 2ms/step - loss: 0.3173 - accuracy: 0.8501 - val_loss: 0.3290 - val_accuracy: 0.8514\n",
            "Epoch 7/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3142 - accuracy: 0.8466 - val_loss: 0.3324 - val_accuracy: 0.8515\n",
            "Epoch 8/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3136 - accuracy: 0.8488 - val_loss: 0.3349 - val_accuracy: 0.8492\n",
            "Epoch 9/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3067 - accuracy: 0.8554 - val_loss: 0.3369 - val_accuracy: 0.8531\n",
            "Epoch 10/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.2986 - accuracy: 0.8592 - val_loss: 0.3353 - val_accuracy: 0.8487\n",
            "Epoch 11/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.2998 - accuracy: 0.8575 - val_loss: 0.3420 - val_accuracy: 0.8449\n",
            "150/150 [==============================] - 0s 919us/step - loss: 0.3484 - accuracy: 0.8493\n",
            "Epoch 1/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.4064 - accuracy: 0.8027 - val_loss: 0.3440 - val_accuracy: 0.8391\n",
            "Epoch 2/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3399 - accuracy: 0.8393 - val_loss: 0.3318 - val_accuracy: 0.8502\n",
            "Epoch 3/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3259 - accuracy: 0.8496 - val_loss: 0.3268 - val_accuracy: 0.8520\n",
            "Epoch 4/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3204 - accuracy: 0.8448 - val_loss: 0.3373 - val_accuracy: 0.8462\n",
            "Epoch 5/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3232 - accuracy: 0.8452 - val_loss: 0.3290 - val_accuracy: 0.8472\n",
            "Epoch 6/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3126 - accuracy: 0.8518 - val_loss: 0.3435 - val_accuracy: 0.8479\n",
            "Epoch 7/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3002 - accuracy: 0.8582 - val_loss: 0.3351 - val_accuracy: 0.8492\n",
            "Epoch 8/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3078 - accuracy: 0.8566 - val_loss: 0.3331 - val_accuracy: 0.8533\n",
            "150/150 [==============================] - 0s 996us/step - loss: 0.3415 - accuracy: 0.8427\n",
            "Epoch 1/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.4155 - accuracy: 0.7957 - val_loss: 0.3464 - val_accuracy: 0.8459\n",
            "Epoch 2/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3404 - accuracy: 0.8399 - val_loss: 0.3359 - val_accuracy: 0.8498\n",
            "Epoch 3/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3340 - accuracy: 0.8458 - val_loss: 0.3377 - val_accuracy: 0.8499\n",
            "Epoch 4/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3200 - accuracy: 0.8457 - val_loss: 0.3303 - val_accuracy: 0.8477\n",
            "Epoch 5/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3145 - accuracy: 0.8525 - val_loss: 0.3444 - val_accuracy: 0.8475\n",
            "Epoch 6/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3165 - accuracy: 0.8538 - val_loss: 0.3392 - val_accuracy: 0.8408\n",
            "Epoch 7/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3127 - accuracy: 0.8517 - val_loss: 0.3324 - val_accuracy: 0.8460\n",
            "Epoch 8/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3055 - accuracy: 0.8552 - val_loss: 0.3345 - val_accuracy: 0.8502\n",
            "Epoch 9/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3041 - accuracy: 0.8588 - val_loss: 0.3409 - val_accuracy: 0.8454\n",
            "150/150 [==============================] - 0s 977us/step - loss: 0.3288 - accuracy: 0.8513\n",
            "Epoch 1/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.4143 - accuracy: 0.7979 - val_loss: 0.3518 - val_accuracy: 0.8385\n",
            "Epoch 2/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3527 - accuracy: 0.8352 - val_loss: 0.3469 - val_accuracy: 0.8475\n",
            "Epoch 3/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3355 - accuracy: 0.8417 - val_loss: 0.3320 - val_accuracy: 0.8523\n",
            "Epoch 4/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3294 - accuracy: 0.8454 - val_loss: 0.3305 - val_accuracy: 0.8498\n",
            "Epoch 5/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3265 - accuracy: 0.8461 - val_loss: 0.3285 - val_accuracy: 0.8500\n",
            "Epoch 6/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3108 - accuracy: 0.8539 - val_loss: 0.3322 - val_accuracy: 0.8509\n",
            "Epoch 7/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3124 - accuracy: 0.8528 - val_loss: 0.3431 - val_accuracy: 0.8424\n",
            "Epoch 8/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3168 - accuracy: 0.8475 - val_loss: 0.3694 - val_accuracy: 0.8158\n",
            "Epoch 9/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3081 - accuracy: 0.8531 - val_loss: 0.3307 - val_accuracy: 0.8486\n",
            "Epoch 10/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3014 - accuracy: 0.8553 - val_loss: 0.3499 - val_accuracy: 0.8496\n",
            "150/150 [==============================] - 0s 975us/step - loss: 0.3532 - accuracy: 0.8493\n",
            "Epoch 1/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.4129 - accuracy: 0.7908 - val_loss: 0.3520 - val_accuracy: 0.8414\n",
            "Epoch 2/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3542 - accuracy: 0.8362 - val_loss: 0.3566 - val_accuracy: 0.8375\n",
            "Epoch 3/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3387 - accuracy: 0.8397 - val_loss: 0.3378 - val_accuracy: 0.8424\n",
            "Epoch 4/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3225 - accuracy: 0.8518 - val_loss: 0.3338 - val_accuracy: 0.8481\n",
            "Epoch 5/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3242 - accuracy: 0.8438 - val_loss: 0.3276 - val_accuracy: 0.8461\n",
            "Epoch 6/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3233 - accuracy: 0.8404 - val_loss: 0.3326 - val_accuracy: 0.8485\n",
            "Epoch 7/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3093 - accuracy: 0.8569 - val_loss: 0.3329 - val_accuracy: 0.8454\n",
            "Epoch 8/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3047 - accuracy: 0.8610 - val_loss: 0.3317 - val_accuracy: 0.8493\n",
            "Epoch 9/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3077 - accuracy: 0.8541 - val_loss: 0.3387 - val_accuracy: 0.8465\n",
            "Epoch 10/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.2904 - accuracy: 0.8697 - val_loss: 0.3353 - val_accuracy: 0.8505\n",
            "150/150 [==============================] - 0s 988us/step - loss: 0.3380 - accuracy: 0.8380\n",
            "Epoch 1/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.4214 - accuracy: 0.7901 - val_loss: 0.3528 - val_accuracy: 0.8354\n",
            "Epoch 2/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3545 - accuracy: 0.8332 - val_loss: 0.3399 - val_accuracy: 0.8409\n",
            "Epoch 3/50\n",
            "1350/1350 [==============================] - 5s 3ms/step - loss: 0.3417 - accuracy: 0.8360 - val_loss: 0.3483 - val_accuracy: 0.8375\n",
            "Epoch 4/50\n",
            "1350/1350 [==============================] - 4s 3ms/step - loss: 0.3227 - accuracy: 0.8496 - val_loss: 0.3292 - val_accuracy: 0.8501\n",
            "Epoch 5/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3239 - accuracy: 0.8470 - val_loss: 0.3287 - val_accuracy: 0.8467\n",
            "Epoch 6/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3091 - accuracy: 0.8566 - val_loss: 0.3316 - val_accuracy: 0.8462\n",
            "Epoch 7/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3126 - accuracy: 0.8550 - val_loss: 0.3271 - val_accuracy: 0.8494\n",
            "Epoch 8/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3136 - accuracy: 0.8526 - val_loss: 0.3294 - val_accuracy: 0.8511\n",
            "Epoch 9/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3062 - accuracy: 0.8585 - val_loss: 0.3391 - val_accuracy: 0.8395\n",
            "Epoch 10/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.2999 - accuracy: 0.8580 - val_loss: 0.3419 - val_accuracy: 0.8509\n",
            "Epoch 11/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3142 - accuracy: 0.8521 - val_loss: 0.3329 - val_accuracy: 0.8503\n",
            "Epoch 12/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.2963 - accuracy: 0.8581 - val_loss: 0.3361 - val_accuracy: 0.8487\n",
            "150/150 [==============================] - 0s 1ms/step - loss: 0.3205 - accuracy: 0.8547\n",
            "Epoch 1/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.4112 - accuracy: 0.7986 - val_loss: 0.3473 - val_accuracy: 0.8405\n",
            "Epoch 2/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3521 - accuracy: 0.8352 - val_loss: 0.3376 - val_accuracy: 0.8491\n",
            "Epoch 3/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3320 - accuracy: 0.8465 - val_loss: 0.3328 - val_accuracy: 0.8427\n",
            "Epoch 4/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3209 - accuracy: 0.8485 - val_loss: 0.3319 - val_accuracy: 0.8518\n",
            "Epoch 5/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3166 - accuracy: 0.8528 - val_loss: 0.3264 - val_accuracy: 0.8494\n",
            "Epoch 6/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3236 - accuracy: 0.8481 - val_loss: 0.3489 - val_accuracy: 0.8520\n",
            "Epoch 7/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3117 - accuracy: 0.8541 - val_loss: 0.3308 - val_accuracy: 0.8484\n",
            "Epoch 8/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3076 - accuracy: 0.8522 - val_loss: 0.3289 - val_accuracy: 0.8493\n",
            "Epoch 9/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3037 - accuracy: 0.8569 - val_loss: 0.3277 - val_accuracy: 0.8509\n",
            "Epoch 10/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.2935 - accuracy: 0.8645 - val_loss: 0.3320 - val_accuracy: 0.8527\n",
            "150/150 [==============================] - 0s 922us/step - loss: 0.3317 - accuracy: 0.8493\n",
            "Epoch 1/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.4019 - accuracy: 0.8011 - val_loss: 0.3360 - val_accuracy: 0.8426\n",
            "Epoch 2/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3299 - accuracy: 0.8481 - val_loss: 0.3446 - val_accuracy: 0.8412\n",
            "Epoch 3/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3238 - accuracy: 0.8468 - val_loss: 0.3375 - val_accuracy: 0.8399\n",
            "Epoch 4/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3246 - accuracy: 0.8436 - val_loss: 0.3289 - val_accuracy: 0.8522\n",
            "Epoch 5/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3201 - accuracy: 0.8477 - val_loss: 0.3291 - val_accuracy: 0.8480\n",
            "Epoch 6/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3111 - accuracy: 0.8538 - val_loss: 0.3351 - val_accuracy: 0.8443\n",
            "Epoch 7/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3010 - accuracy: 0.8554 - val_loss: 0.3396 - val_accuracy: 0.8514\n",
            "Epoch 8/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3116 - accuracy: 0.8539 - val_loss: 0.3351 - val_accuracy: 0.8483\n",
            "Epoch 9/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3070 - accuracy: 0.8550 - val_loss: 0.3551 - val_accuracy: 0.8518\n",
            "150/150 [==============================] - 0s 975us/step - loss: 0.3379 - accuracy: 0.8593\n",
            "Epoch 1/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.4156 - accuracy: 0.7886 - val_loss: 0.3443 - val_accuracy: 0.8448\n",
            "Epoch 2/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3487 - accuracy: 0.8373 - val_loss: 0.3320 - val_accuracy: 0.8492\n",
            "Epoch 3/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3318 - accuracy: 0.8473 - val_loss: 0.3240 - val_accuracy: 0.8485\n",
            "Epoch 4/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3154 - accuracy: 0.8488 - val_loss: 0.3341 - val_accuracy: 0.8511\n",
            "Epoch 5/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3199 - accuracy: 0.8487 - val_loss: 0.3334 - val_accuracy: 0.8424\n",
            "Epoch 6/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3104 - accuracy: 0.8485 - val_loss: 0.3319 - val_accuracy: 0.8442\n",
            "Epoch 7/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3234 - accuracy: 0.8478 - val_loss: 0.3342 - val_accuracy: 0.8432\n",
            "Epoch 8/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3180 - accuracy: 0.8458 - val_loss: 0.3430 - val_accuracy: 0.8439\n",
            "150/150 [==============================] - 0s 979us/step - loss: 0.3375 - accuracy: 0.8553\n",
            "Epoch 1/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.4017 - accuracy: 0.8029 - val_loss: 0.3642 - val_accuracy: 0.8250\n",
            "Epoch 2/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3445 - accuracy: 0.8389 - val_loss: 0.3361 - val_accuracy: 0.8448\n",
            "Epoch 3/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3279 - accuracy: 0.8464 - val_loss: 0.3300 - val_accuracy: 0.8492\n",
            "Epoch 4/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3242 - accuracy: 0.8484 - val_loss: 0.3295 - val_accuracy: 0.8507\n",
            "Epoch 5/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3156 - accuracy: 0.8526 - val_loss: 0.3262 - val_accuracy: 0.8514\n",
            "Epoch 6/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3123 - accuracy: 0.8544 - val_loss: 0.3301 - val_accuracy: 0.8434\n",
            "Epoch 7/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3077 - accuracy: 0.8552 - val_loss: 0.3304 - val_accuracy: 0.8507\n",
            "Epoch 8/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3032 - accuracy: 0.8568 - val_loss: 0.3343 - val_accuracy: 0.8499\n",
            "Epoch 9/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.2946 - accuracy: 0.8592 - val_loss: 0.3324 - val_accuracy: 0.8523\n",
            "Epoch 10/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.2999 - accuracy: 0.8562 - val_loss: 0.3436 - val_accuracy: 0.8482\n",
            "150/150 [==============================] - 0s 933us/step - loss: 0.3448 - accuracy: 0.8400\n",
            "Epoch 1/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3989 - accuracy: 0.8073 - val_loss: 0.3463 - val_accuracy: 0.8434\n",
            "Epoch 2/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3361 - accuracy: 0.8402 - val_loss: 0.3395 - val_accuracy: 0.8474\n",
            "Epoch 3/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3250 - accuracy: 0.8453 - val_loss: 0.3366 - val_accuracy: 0.8374\n",
            "Epoch 4/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3230 - accuracy: 0.8456 - val_loss: 0.3359 - val_accuracy: 0.8464\n",
            "Epoch 5/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3183 - accuracy: 0.8501 - val_loss: 0.3260 - val_accuracy: 0.8517\n",
            "Epoch 6/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3085 - accuracy: 0.8562 - val_loss: 0.3269 - val_accuracy: 0.8497\n",
            "Epoch 7/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3038 - accuracy: 0.8571 - val_loss: 0.3337 - val_accuracy: 0.8500\n",
            "Epoch 8/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3086 - accuracy: 0.8516 - val_loss: 0.3570 - val_accuracy: 0.8473\n",
            "Epoch 9/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3027 - accuracy: 0.8587 - val_loss: 0.3442 - val_accuracy: 0.8472\n",
            "Epoch 10/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.2951 - accuracy: 0.8602 - val_loss: 0.3356 - val_accuracy: 0.8508\n",
            "150/150 [==============================] - 0s 925us/step - loss: 0.3397 - accuracy: 0.8487\n",
            "Epoch 1/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.4060 - accuracy: 0.8022 - val_loss: 0.3761 - val_accuracy: 0.8211\n",
            "Epoch 2/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3539 - accuracy: 0.8339 - val_loss: 0.3403 - val_accuracy: 0.8467\n",
            "Epoch 3/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3266 - accuracy: 0.8443 - val_loss: 0.3500 - val_accuracy: 0.8346\n",
            "Epoch 4/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3268 - accuracy: 0.8492 - val_loss: 0.3313 - val_accuracy: 0.8506\n",
            "Epoch 5/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3178 - accuracy: 0.8486 - val_loss: 0.3319 - val_accuracy: 0.8529\n",
            "Epoch 6/50\n",
            "1350/1350 [==============================] - 4s 3ms/step - loss: 0.3061 - accuracy: 0.8564 - val_loss: 0.3391 - val_accuracy: 0.8368\n",
            "Epoch 7/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3077 - accuracy: 0.8545 - val_loss: 0.3330 - val_accuracy: 0.8447\n",
            "Epoch 8/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3007 - accuracy: 0.8587 - val_loss: 0.3397 - val_accuracy: 0.8406\n",
            "Epoch 9/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3068 - accuracy: 0.8508 - val_loss: 0.3533 - val_accuracy: 0.8486\n",
            "150/150 [==============================] - 0s 909us/step - loss: 0.3623 - accuracy: 0.8440\n",
            "Epoch 1/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.4101 - accuracy: 0.7973 - val_loss: 0.3738 - val_accuracy: 0.8343\n",
            "Epoch 2/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3507 - accuracy: 0.8343 - val_loss: 0.3361 - val_accuracy: 0.8504\n",
            "Epoch 3/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3337 - accuracy: 0.8448 - val_loss: 0.3377 - val_accuracy: 0.8433\n",
            "Epoch 4/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3271 - accuracy: 0.8486 - val_loss: 0.3270 - val_accuracy: 0.8507\n",
            "Epoch 5/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3177 - accuracy: 0.8484 - val_loss: 0.3317 - val_accuracy: 0.8491\n",
            "Epoch 6/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3165 - accuracy: 0.8588 - val_loss: 0.3466 - val_accuracy: 0.8511\n",
            "Epoch 7/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3089 - accuracy: 0.8549 - val_loss: 0.3399 - val_accuracy: 0.8454\n",
            "Epoch 8/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3030 - accuracy: 0.8547 - val_loss: 0.3353 - val_accuracy: 0.8481\n",
            "Epoch 9/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3051 - accuracy: 0.8559 - val_loss: 0.3350 - val_accuracy: 0.8489\n",
            "150/150 [==============================] - 0s 951us/step - loss: 0.3358 - accuracy: 0.8487\n",
            "Epoch 1/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.4086 - accuracy: 0.7967 - val_loss: 0.3527 - val_accuracy: 0.8394\n",
            "Epoch 2/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3495 - accuracy: 0.8352 - val_loss: 0.3357 - val_accuracy: 0.8487\n",
            "Epoch 3/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3364 - accuracy: 0.8393 - val_loss: 0.3294 - val_accuracy: 0.8518\n",
            "Epoch 4/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3267 - accuracy: 0.8472 - val_loss: 0.3317 - val_accuracy: 0.8476\n",
            "Epoch 5/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3213 - accuracy: 0.8518 - val_loss: 0.3231 - val_accuracy: 0.8524\n",
            "Epoch 6/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3138 - accuracy: 0.8560 - val_loss: 0.3495 - val_accuracy: 0.8313\n",
            "Epoch 7/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3107 - accuracy: 0.8524 - val_loss: 0.3282 - val_accuracy: 0.8516\n",
            "Epoch 8/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3066 - accuracy: 0.8559 - val_loss: 0.3352 - val_accuracy: 0.8439\n",
            "Epoch 9/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3024 - accuracy: 0.8562 - val_loss: 0.3330 - val_accuracy: 0.8502\n",
            "Epoch 10/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3119 - accuracy: 0.8504 - val_loss: 0.3321 - val_accuracy: 0.8483\n",
            "150/150 [==============================] - 0s 989us/step - loss: 0.3328 - accuracy: 0.8440\n",
            "Epoch 1/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.4046 - accuracy: 0.8025 - val_loss: 0.3531 - val_accuracy: 0.8379\n",
            "Epoch 2/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3603 - accuracy: 0.8307 - val_loss: 0.3454 - val_accuracy: 0.8391\n",
            "Epoch 3/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3391 - accuracy: 0.8417 - val_loss: 0.3358 - val_accuracy: 0.8531\n",
            "Epoch 4/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3302 - accuracy: 0.8418 - val_loss: 0.3473 - val_accuracy: 0.8340\n",
            "Epoch 5/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3112 - accuracy: 0.8557 - val_loss: 0.3354 - val_accuracy: 0.8493\n",
            "Epoch 6/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3163 - accuracy: 0.8520 - val_loss: 0.3323 - val_accuracy: 0.8510\n",
            "Epoch 7/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3175 - accuracy: 0.8548 - val_loss: 0.3439 - val_accuracy: 0.8485\n",
            "Epoch 8/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3100 - accuracy: 0.8488 - val_loss: 0.3359 - val_accuracy: 0.8488\n",
            "Epoch 9/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3107 - accuracy: 0.8519 - val_loss: 0.3385 - val_accuracy: 0.8507\n",
            "Epoch 10/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3065 - accuracy: 0.8543 - val_loss: 0.3408 - val_accuracy: 0.8445\n",
            "Epoch 11/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.2858 - accuracy: 0.8635 - val_loss: 0.3471 - val_accuracy: 0.8478\n",
            "150/150 [==============================] - 0s 986us/step - loss: 0.3378 - accuracy: 0.8427\n",
            "Epoch 1/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.4209 - accuracy: 0.7896 - val_loss: 0.3568 - val_accuracy: 0.8394\n",
            "Epoch 2/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3458 - accuracy: 0.8380 - val_loss: 0.3388 - val_accuracy: 0.8466\n",
            "Epoch 3/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3425 - accuracy: 0.8356 - val_loss: 0.3334 - val_accuracy: 0.8491\n",
            "Epoch 4/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3360 - accuracy: 0.8415 - val_loss: 0.3404 - val_accuracy: 0.8495\n",
            "Epoch 5/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3150 - accuracy: 0.8474 - val_loss: 0.3318 - val_accuracy: 0.8497\n",
            "Epoch 6/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3209 - accuracy: 0.8454 - val_loss: 0.3273 - val_accuracy: 0.8502\n",
            "Epoch 7/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3125 - accuracy: 0.8574 - val_loss: 0.3307 - val_accuracy: 0.8508\n",
            "Epoch 8/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3064 - accuracy: 0.8565 - val_loss: 0.3443 - val_accuracy: 0.8508\n",
            "Epoch 9/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3153 - accuracy: 0.8507 - val_loss: 0.3365 - val_accuracy: 0.8465\n",
            "Epoch 10/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3007 - accuracy: 0.8603 - val_loss: 0.3426 - val_accuracy: 0.8495\n",
            "Epoch 11/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3000 - accuracy: 0.8561 - val_loss: 0.3393 - val_accuracy: 0.8464\n",
            "150/150 [==============================] - 0s 928us/step - loss: 0.3245 - accuracy: 0.8587\n",
            "Epoch 1/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.4093 - accuracy: 0.7998 - val_loss: 0.3407 - val_accuracy: 0.8423\n",
            "Epoch 2/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3390 - accuracy: 0.8426 - val_loss: 0.3346 - val_accuracy: 0.8476\n",
            "Epoch 3/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3363 - accuracy: 0.8389 - val_loss: 0.3282 - val_accuracy: 0.8548\n",
            "Epoch 4/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3271 - accuracy: 0.8470 - val_loss: 0.3349 - val_accuracy: 0.8462\n",
            "Epoch 5/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3134 - accuracy: 0.8536 - val_loss: 0.3269 - val_accuracy: 0.8499\n",
            "Epoch 6/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3239 - accuracy: 0.8420 - val_loss: 0.3365 - val_accuracy: 0.8418\n",
            "Epoch 7/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3103 - accuracy: 0.8507 - val_loss: 0.3973 - val_accuracy: 0.8380\n",
            "Epoch 8/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3094 - accuracy: 0.8511 - val_loss: 0.3328 - val_accuracy: 0.8514\n",
            "Epoch 9/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3065 - accuracy: 0.8581 - val_loss: 0.3409 - val_accuracy: 0.8492\n",
            "Epoch 10/50\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3024 - accuracy: 0.8534 - val_loss: 0.3417 - val_accuracy: 0.8512\n",
            "150/150 [==============================] - 0s 926us/step - loss: 0.3347 - accuracy: 0.8400\n",
            "Epoch 1/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.4523 - accuracy: 0.7824 - val_loss: 0.3710 - val_accuracy: 0.8328\n",
            "Epoch 2/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3684 - accuracy: 0.8273 - val_loss: 0.3523 - val_accuracy: 0.8452\n",
            "Epoch 3/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3441 - accuracy: 0.8389 - val_loss: 0.3371 - val_accuracy: 0.8500\n",
            "Epoch 4/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3281 - accuracy: 0.8495 - val_loss: 0.3473 - val_accuracy: 0.8455\n",
            "Epoch 5/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3282 - accuracy: 0.8506 - val_loss: 0.3315 - val_accuracy: 0.8536\n",
            "Epoch 6/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3245 - accuracy: 0.8509 - val_loss: 0.3312 - val_accuracy: 0.8503\n",
            "Epoch 7/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3147 - accuracy: 0.8548 - val_loss: 0.3345 - val_accuracy: 0.8530\n",
            "Epoch 8/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3127 - accuracy: 0.8535 - val_loss: 0.3273 - val_accuracy: 0.8497\n",
            "Epoch 9/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3080 - accuracy: 0.8600 - val_loss: 0.3372 - val_accuracy: 0.8449\n",
            "Epoch 10/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3048 - accuracy: 0.8574 - val_loss: 0.3266 - val_accuracy: 0.8526\n",
            "Epoch 11/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3094 - accuracy: 0.8582 - val_loss: 0.3296 - val_accuracy: 0.8525\n",
            "Epoch 12/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3045 - accuracy: 0.8568 - val_loss: 0.3280 - val_accuracy: 0.8502\n",
            "Epoch 13/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3052 - accuracy: 0.8570 - val_loss: 0.3286 - val_accuracy: 0.8541\n",
            "Epoch 14/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.2974 - accuracy: 0.8606 - val_loss: 0.3309 - val_accuracy: 0.8484\n",
            "Epoch 15/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.2968 - accuracy: 0.8607 - val_loss: 0.3279 - val_accuracy: 0.8533\n",
            "150/150 [==============================] - 0s 925us/step - loss: 0.3201 - accuracy: 0.8580\n",
            "Epoch 1/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.4493 - accuracy: 0.7939 - val_loss: 0.3668 - val_accuracy: 0.8294\n",
            "Epoch 2/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3540 - accuracy: 0.8298 - val_loss: 0.3377 - val_accuracy: 0.8400\n",
            "Epoch 3/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3328 - accuracy: 0.8422 - val_loss: 0.3212 - val_accuracy: 0.8522\n",
            "Epoch 4/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3165 - accuracy: 0.8452 - val_loss: 0.3222 - val_accuracy: 0.8508\n",
            "Epoch 5/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3122 - accuracy: 0.8511 - val_loss: 0.3223 - val_accuracy: 0.8499\n",
            "Epoch 6/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3171 - accuracy: 0.8420 - val_loss: 0.3280 - val_accuracy: 0.8528\n",
            "Epoch 7/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3139 - accuracy: 0.8554 - val_loss: 0.3228 - val_accuracy: 0.8493\n",
            "Epoch 8/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3065 - accuracy: 0.8529 - val_loss: 0.3230 - val_accuracy: 0.8510\n",
            "150/150 [==============================] - 0s 927us/step - loss: 0.3200 - accuracy: 0.8587\n",
            "Epoch 1/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.4559 - accuracy: 0.7825 - val_loss: 0.3560 - val_accuracy: 0.8387\n",
            "Epoch 2/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3537 - accuracy: 0.8349 - val_loss: 0.3297 - val_accuracy: 0.8458\n",
            "Epoch 3/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3251 - accuracy: 0.8456 - val_loss: 0.3490 - val_accuracy: 0.8339\n",
            "Epoch 4/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3193 - accuracy: 0.8489 - val_loss: 0.3227 - val_accuracy: 0.8518\n",
            "Epoch 5/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3178 - accuracy: 0.8514 - val_loss: 0.3233 - val_accuracy: 0.8496\n",
            "Epoch 6/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3113 - accuracy: 0.8552 - val_loss: 0.3230 - val_accuracy: 0.8558\n",
            "Epoch 7/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3097 - accuracy: 0.8547 - val_loss: 0.3261 - val_accuracy: 0.8474\n",
            "Epoch 8/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3117 - accuracy: 0.8539 - val_loss: 0.3304 - val_accuracy: 0.8460\n",
            "Epoch 9/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3022 - accuracy: 0.8584 - val_loss: 0.3227 - val_accuracy: 0.8516\n",
            "150/150 [==============================] - 0s 962us/step - loss: 0.3229 - accuracy: 0.8407\n",
            "Epoch 1/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.4501 - accuracy: 0.7845 - val_loss: 0.3506 - val_accuracy: 0.8327\n",
            "Epoch 2/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3459 - accuracy: 0.8315 - val_loss: 0.3287 - val_accuracy: 0.8475\n",
            "Epoch 3/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3224 - accuracy: 0.8500 - val_loss: 0.3275 - val_accuracy: 0.8473\n",
            "Epoch 4/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3157 - accuracy: 0.8455 - val_loss: 0.3274 - val_accuracy: 0.8517\n",
            "Epoch 5/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3204 - accuracy: 0.8503 - val_loss: 0.3253 - val_accuracy: 0.8511\n",
            "Epoch 6/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3077 - accuracy: 0.8569 - val_loss: 0.3286 - val_accuracy: 0.8467\n",
            "Epoch 7/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3096 - accuracy: 0.8502 - val_loss: 0.3207 - val_accuracy: 0.8520\n",
            "Epoch 8/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3029 - accuracy: 0.8605 - val_loss: 0.3270 - val_accuracy: 0.8504\n",
            "Epoch 9/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3025 - accuracy: 0.8562 - val_loss: 0.3249 - val_accuracy: 0.8491\n",
            "Epoch 10/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3029 - accuracy: 0.8549 - val_loss: 0.3308 - val_accuracy: 0.8503\n",
            "Epoch 11/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3011 - accuracy: 0.8608 - val_loss: 0.3298 - val_accuracy: 0.8524\n",
            "Epoch 12/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3020 - accuracy: 0.8580 - val_loss: 0.3299 - val_accuracy: 0.8526\n",
            "150/150 [==============================] - 0s 916us/step - loss: 0.3389 - accuracy: 0.8513\n",
            "Epoch 1/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.4447 - accuracy: 0.7923 - val_loss: 0.3575 - val_accuracy: 0.8349\n",
            "Epoch 2/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3496 - accuracy: 0.8345 - val_loss: 0.3346 - val_accuracy: 0.8454\n",
            "Epoch 3/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3297 - accuracy: 0.8430 - val_loss: 0.3250 - val_accuracy: 0.8515\n",
            "Epoch 4/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3151 - accuracy: 0.8508 - val_loss: 0.3362 - val_accuracy: 0.8487\n",
            "Epoch 5/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3114 - accuracy: 0.8572 - val_loss: 0.3248 - val_accuracy: 0.8504\n",
            "Epoch 6/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3207 - accuracy: 0.8445 - val_loss: 0.3215 - val_accuracy: 0.8540\n",
            "Epoch 7/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3075 - accuracy: 0.8556 - val_loss: 0.3254 - val_accuracy: 0.8530\n",
            "Epoch 8/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3058 - accuracy: 0.8573 - val_loss: 0.3289 - val_accuracy: 0.8452\n",
            "Epoch 9/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3088 - accuracy: 0.8561 - val_loss: 0.3230 - val_accuracy: 0.8525\n",
            "Epoch 10/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3090 - accuracy: 0.8519 - val_loss: 0.3214 - val_accuracy: 0.8528\n",
            "Epoch 11/100\n",
            "1350/1350 [==============================] - 3s 3ms/step - loss: 0.2890 - accuracy: 0.8608 - val_loss: 0.3263 - val_accuracy: 0.8503\n",
            "Epoch 12/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3010 - accuracy: 0.8575 - val_loss: 0.3246 - val_accuracy: 0.8499\n",
            "Epoch 13/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.2996 - accuracy: 0.8579 - val_loss: 0.3245 - val_accuracy: 0.8533\n",
            "Epoch 14/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.2938 - accuracy: 0.8612 - val_loss: 0.3246 - val_accuracy: 0.8519\n",
            "Epoch 15/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.2905 - accuracy: 0.8640 - val_loss: 0.3367 - val_accuracy: 0.8481\n",
            "150/150 [==============================] - 0s 918us/step - loss: 0.3523 - accuracy: 0.8447\n",
            "Epoch 1/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.4535 - accuracy: 0.7823 - val_loss: 0.3519 - val_accuracy: 0.8362\n",
            "Epoch 2/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3501 - accuracy: 0.8332 - val_loss: 0.3385 - val_accuracy: 0.8413\n",
            "Epoch 3/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3280 - accuracy: 0.8456 - val_loss: 0.3240 - val_accuracy: 0.8529\n",
            "Epoch 4/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3262 - accuracy: 0.8442 - val_loss: 0.3236 - val_accuracy: 0.8548\n",
            "Epoch 5/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3159 - accuracy: 0.8520 - val_loss: 0.3243 - val_accuracy: 0.8536\n",
            "Epoch 6/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3240 - accuracy: 0.8493 - val_loss: 0.3225 - val_accuracy: 0.8512\n",
            "Epoch 7/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3130 - accuracy: 0.8550 - val_loss: 0.3211 - val_accuracy: 0.8510\n",
            "Epoch 8/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3073 - accuracy: 0.8576 - val_loss: 0.3264 - val_accuracy: 0.8480\n",
            "Epoch 9/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3117 - accuracy: 0.8538 - val_loss: 0.3216 - val_accuracy: 0.8542\n",
            "Epoch 10/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.2907 - accuracy: 0.8625 - val_loss: 0.3335 - val_accuracy: 0.8435\n",
            "Epoch 11/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.2980 - accuracy: 0.8557 - val_loss: 0.3254 - val_accuracy: 0.8534\n",
            "Epoch 12/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3037 - accuracy: 0.8613 - val_loss: 0.3258 - val_accuracy: 0.8490\n",
            "150/150 [==============================] - 0s 970us/step - loss: 0.3214 - accuracy: 0.8500\n",
            "Epoch 1/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.4617 - accuracy: 0.7874 - val_loss: 0.3512 - val_accuracy: 0.8348\n",
            "Epoch 2/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3453 - accuracy: 0.8348 - val_loss: 0.3295 - val_accuracy: 0.8487\n",
            "Epoch 3/100\n",
            "1350/1350 [==============================] - 2s 2ms/step - loss: 0.3212 - accuracy: 0.8472 - val_loss: 0.3427 - val_accuracy: 0.8380\n",
            "Epoch 4/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3206 - accuracy: 0.8465 - val_loss: 0.3255 - val_accuracy: 0.8483\n",
            "Epoch 5/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3112 - accuracy: 0.8531 - val_loss: 0.3198 - val_accuracy: 0.8527\n",
            "Epoch 6/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3184 - accuracy: 0.8523 - val_loss: 0.3198 - val_accuracy: 0.8526\n",
            "Epoch 7/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3114 - accuracy: 0.8533 - val_loss: 0.3213 - val_accuracy: 0.8504\n",
            "Epoch 8/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3150 - accuracy: 0.8536 - val_loss: 0.3238 - val_accuracy: 0.8480\n",
            "Epoch 9/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3035 - accuracy: 0.8575 - val_loss: 0.3197 - val_accuracy: 0.8511\n",
            "Epoch 10/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3035 - accuracy: 0.8592 - val_loss: 0.3256 - val_accuracy: 0.8523\n",
            "Epoch 11/100\n",
            "1350/1350 [==============================] - 2s 2ms/step - loss: 0.2960 - accuracy: 0.8638 - val_loss: 0.3212 - val_accuracy: 0.8531\n",
            "Epoch 12/100\n",
            "1350/1350 [==============================] - 2s 2ms/step - loss: 0.2956 - accuracy: 0.8588 - val_loss: 0.3226 - val_accuracy: 0.8510\n",
            "Epoch 13/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3073 - accuracy: 0.8541 - val_loss: 0.3300 - val_accuracy: 0.8468\n",
            "Epoch 14/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.2925 - accuracy: 0.8617 - val_loss: 0.3352 - val_accuracy: 0.8474\n",
            "150/150 [==============================] - 0s 918us/step - loss: 0.3337 - accuracy: 0.8487\n",
            "Epoch 1/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.4510 - accuracy: 0.7925 - val_loss: 0.3523 - val_accuracy: 0.8360\n",
            "Epoch 2/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3521 - accuracy: 0.8347 - val_loss: 0.3324 - val_accuracy: 0.8427\n",
            "Epoch 3/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3227 - accuracy: 0.8475 - val_loss: 0.3261 - val_accuracy: 0.8520\n",
            "Epoch 4/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3113 - accuracy: 0.8536 - val_loss: 0.3219 - val_accuracy: 0.8530\n",
            "Epoch 5/100\n",
            "1350/1350 [==============================] - 2s 2ms/step - loss: 0.3152 - accuracy: 0.8496 - val_loss: 0.3237 - val_accuracy: 0.8544\n",
            "Epoch 6/100\n",
            "1350/1350 [==============================] - 2s 2ms/step - loss: 0.3136 - accuracy: 0.8539 - val_loss: 0.3202 - val_accuracy: 0.8528\n",
            "Epoch 7/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3100 - accuracy: 0.8556 - val_loss: 0.3209 - val_accuracy: 0.8544\n",
            "Epoch 8/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3112 - accuracy: 0.8548 - val_loss: 0.3237 - val_accuracy: 0.8477\n",
            "Epoch 9/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3017 - accuracy: 0.8604 - val_loss: 0.3226 - val_accuracy: 0.8528\n",
            "Epoch 10/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3001 - accuracy: 0.8598 - val_loss: 0.3370 - val_accuracy: 0.8465\n",
            "Epoch 11/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3053 - accuracy: 0.8575 - val_loss: 0.3283 - val_accuracy: 0.8493\n",
            "150/150 [==============================] - 0s 893us/step - loss: 0.3338 - accuracy: 0.8400\n",
            "Epoch 1/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.4567 - accuracy: 0.7824 - val_loss: 0.3512 - val_accuracy: 0.8384\n",
            "Epoch 2/100\n",
            "1350/1350 [==============================] - 2s 2ms/step - loss: 0.3499 - accuracy: 0.8367 - val_loss: 0.3395 - val_accuracy: 0.8417\n",
            "Epoch 3/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3374 - accuracy: 0.8395 - val_loss: 0.3214 - val_accuracy: 0.8516\n",
            "Epoch 4/100\n",
            "1350/1350 [==============================] - 2s 2ms/step - loss: 0.3289 - accuracy: 0.8466 - val_loss: 0.3259 - val_accuracy: 0.8517\n",
            "Epoch 5/100\n",
            "1350/1350 [==============================] - 2s 2ms/step - loss: 0.3165 - accuracy: 0.8495 - val_loss: 0.3269 - val_accuracy: 0.8527\n",
            "Epoch 6/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3104 - accuracy: 0.8597 - val_loss: 0.3212 - val_accuracy: 0.8547\n",
            "Epoch 7/100\n",
            "1350/1350 [==============================] - 2s 2ms/step - loss: 0.3262 - accuracy: 0.8452 - val_loss: 0.3215 - val_accuracy: 0.8521\n",
            "Epoch 8/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3177 - accuracy: 0.8501 - val_loss: 0.3204 - val_accuracy: 0.8525\n",
            "Epoch 9/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3147 - accuracy: 0.8535 - val_loss: 0.3312 - val_accuracy: 0.8501\n",
            "Epoch 10/100\n",
            "1350/1350 [==============================] - 2s 2ms/step - loss: 0.3097 - accuracy: 0.8542 - val_loss: 0.3199 - val_accuracy: 0.8518\n",
            "Epoch 11/100\n",
            "1350/1350 [==============================] - 2s 2ms/step - loss: 0.3075 - accuracy: 0.8566 - val_loss: 0.3189 - val_accuracy: 0.8538\n",
            "Epoch 12/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3080 - accuracy: 0.8541 - val_loss: 0.3247 - val_accuracy: 0.8493\n",
            "Epoch 13/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.2970 - accuracy: 0.8570 - val_loss: 0.3224 - val_accuracy: 0.8517\n",
            "Epoch 14/100\n",
            "1350/1350 [==============================] - 2s 2ms/step - loss: 0.3020 - accuracy: 0.8566 - val_loss: 0.3254 - val_accuracy: 0.8519\n",
            "Epoch 15/100\n",
            "1350/1350 [==============================] - 2s 2ms/step - loss: 0.3018 - accuracy: 0.8593 - val_loss: 0.3254 - val_accuracy: 0.8519\n",
            "Epoch 16/100\n",
            "1350/1350 [==============================] - 2s 2ms/step - loss: 0.3001 - accuracy: 0.8612 - val_loss: 0.3265 - val_accuracy: 0.8495\n",
            "150/150 [==============================] - 0s 889us/step - loss: 0.3191 - accuracy: 0.8560\n",
            "Epoch 1/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.4485 - accuracy: 0.7911 - val_loss: 0.3518 - val_accuracy: 0.8370\n",
            "Epoch 2/100\n",
            "1350/1350 [==============================] - 2s 2ms/step - loss: 0.3508 - accuracy: 0.8347 - val_loss: 0.3392 - val_accuracy: 0.8407\n",
            "Epoch 3/100\n",
            "1350/1350 [==============================] - 2s 2ms/step - loss: 0.3218 - accuracy: 0.8508 - val_loss: 0.3305 - val_accuracy: 0.8478\n",
            "Epoch 4/100\n",
            "1350/1350 [==============================] - 2s 2ms/step - loss: 0.3177 - accuracy: 0.8515 - val_loss: 0.3314 - val_accuracy: 0.8497\n",
            "Epoch 5/100\n",
            "1350/1350 [==============================] - 2s 2ms/step - loss: 0.3192 - accuracy: 0.8542 - val_loss: 0.3280 - val_accuracy: 0.8521\n",
            "Epoch 6/100\n",
            "1350/1350 [==============================] - 2s 2ms/step - loss: 0.3197 - accuracy: 0.8517 - val_loss: 0.3221 - val_accuracy: 0.8518\n",
            "Epoch 7/100\n",
            "1350/1350 [==============================] - 2s 2ms/step - loss: 0.3162 - accuracy: 0.8530 - val_loss: 0.3344 - val_accuracy: 0.8418\n",
            "Epoch 8/100\n",
            "1350/1350 [==============================] - 2s 2ms/step - loss: 0.3038 - accuracy: 0.8550 - val_loss: 0.3202 - val_accuracy: 0.8553\n",
            "Epoch 9/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3148 - accuracy: 0.8525 - val_loss: 0.3260 - val_accuracy: 0.8497\n",
            "Epoch 10/100\n",
            "1350/1350 [==============================] - 2s 2ms/step - loss: 0.3048 - accuracy: 0.8541 - val_loss: 0.3245 - val_accuracy: 0.8517\n",
            "Epoch 11/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.2987 - accuracy: 0.8568 - val_loss: 0.3224 - val_accuracy: 0.8532\n",
            "Epoch 12/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.2985 - accuracy: 0.8588 - val_loss: 0.3260 - val_accuracy: 0.8515\n",
            "Epoch 13/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3022 - accuracy: 0.8557 - val_loss: 0.3224 - val_accuracy: 0.8530\n",
            "150/150 [==============================] - 0s 1ms/step - loss: 0.3219 - accuracy: 0.8453\n",
            "Epoch 1/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.4555 - accuracy: 0.7903 - val_loss: 0.3467 - val_accuracy: 0.8393\n",
            "Epoch 2/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3542 - accuracy: 0.8278 - val_loss: 0.3287 - val_accuracy: 0.8481\n",
            "Epoch 3/100\n",
            "1350/1350 [==============================] - 2s 2ms/step - loss: 0.3258 - accuracy: 0.8436 - val_loss: 0.3237 - val_accuracy: 0.8512\n",
            "Epoch 4/100\n",
            "1350/1350 [==============================] - 2s 2ms/step - loss: 0.3115 - accuracy: 0.8523 - val_loss: 0.3290 - val_accuracy: 0.8477\n",
            "Epoch 5/100\n",
            "1350/1350 [==============================] - 2s 2ms/step - loss: 0.3126 - accuracy: 0.8546 - val_loss: 0.3287 - val_accuracy: 0.8439\n",
            "Epoch 6/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3095 - accuracy: 0.8544 - val_loss: 0.3280 - val_accuracy: 0.8468\n",
            "Epoch 7/100\n",
            "1350/1350 [==============================] - 2s 2ms/step - loss: 0.3233 - accuracy: 0.8473 - val_loss: 0.3210 - val_accuracy: 0.8527\n",
            "Epoch 8/100\n",
            "1350/1350 [==============================] - 2s 2ms/step - loss: 0.3084 - accuracy: 0.8527 - val_loss: 0.3215 - val_accuracy: 0.8515\n",
            "Epoch 9/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3095 - accuracy: 0.8547 - val_loss: 0.3205 - val_accuracy: 0.8513\n",
            "Epoch 10/100\n",
            "1350/1350 [==============================] - 2s 2ms/step - loss: 0.3043 - accuracy: 0.8573 - val_loss: 0.3244 - val_accuracy: 0.8483\n",
            "Epoch 11/100\n",
            "1350/1350 [==============================] - 2s 2ms/step - loss: 0.3061 - accuracy: 0.8554 - val_loss: 0.3246 - val_accuracy: 0.8514\n",
            "Epoch 12/100\n",
            "1350/1350 [==============================] - 2s 2ms/step - loss: 0.3012 - accuracy: 0.8565 - val_loss: 0.3236 - val_accuracy: 0.8511\n",
            "Epoch 13/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.2930 - accuracy: 0.8600 - val_loss: 0.3252 - val_accuracy: 0.8499\n",
            "Epoch 14/100\n",
            "1350/1350 [==============================] - 2s 2ms/step - loss: 0.2931 - accuracy: 0.8619 - val_loss: 0.3293 - val_accuracy: 0.8508\n",
            "150/150 [==============================] - 0s 996us/step - loss: 0.3184 - accuracy: 0.8580\n",
            "Epoch 1/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.4502 - accuracy: 0.7954 - val_loss: 0.3487 - val_accuracy: 0.8350\n",
            "Epoch 2/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3401 - accuracy: 0.8437 - val_loss: 0.3270 - val_accuracy: 0.8482\n",
            "Epoch 3/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3248 - accuracy: 0.8445 - val_loss: 0.3252 - val_accuracy: 0.8526\n",
            "Epoch 4/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3203 - accuracy: 0.8513 - val_loss: 0.3291 - val_accuracy: 0.8459\n",
            "Epoch 5/100\n",
            "1350/1350 [==============================] - 2s 2ms/step - loss: 0.3288 - accuracy: 0.8415 - val_loss: 0.3282 - val_accuracy: 0.8495\n",
            "Epoch 6/100\n",
            "1350/1350 [==============================] - 2s 2ms/step - loss: 0.3142 - accuracy: 0.8504 - val_loss: 0.3279 - val_accuracy: 0.8449\n",
            "Epoch 7/100\n",
            "1350/1350 [==============================] - 2s 2ms/step - loss: 0.3123 - accuracy: 0.8537 - val_loss: 0.3242 - val_accuracy: 0.8490\n",
            "Epoch 8/100\n",
            "1350/1350 [==============================] - 2s 2ms/step - loss: 0.3085 - accuracy: 0.8515 - val_loss: 0.3261 - val_accuracy: 0.8461\n",
            "Epoch 9/100\n",
            "1350/1350 [==============================] - 2s 2ms/step - loss: 0.3023 - accuracy: 0.8554 - val_loss: 0.3267 - val_accuracy: 0.8506\n",
            "Epoch 10/100\n",
            "1350/1350 [==============================] - 2s 2ms/step - loss: 0.3128 - accuracy: 0.8507 - val_loss: 0.3307 - val_accuracy: 0.8458\n",
            "Epoch 11/100\n",
            "1350/1350 [==============================] - 2s 2ms/step - loss: 0.3056 - accuracy: 0.8553 - val_loss: 0.3303 - val_accuracy: 0.8539\n",
            "Epoch 12/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3012 - accuracy: 0.8562 - val_loss: 0.3306 - val_accuracy: 0.8517\n",
            "150/150 [==============================] - 0s 920us/step - loss: 0.3200 - accuracy: 0.8573\n",
            "Epoch 1/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.4402 - accuracy: 0.7911 - val_loss: 0.3480 - val_accuracy: 0.8359\n",
            "Epoch 2/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3506 - accuracy: 0.8349 - val_loss: 0.3312 - val_accuracy: 0.8488\n",
            "Epoch 3/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3348 - accuracy: 0.8428 - val_loss: 0.3230 - val_accuracy: 0.8511\n",
            "Epoch 4/100\n",
            "1350/1350 [==============================] - 2s 2ms/step - loss: 0.3225 - accuracy: 0.8479 - val_loss: 0.3329 - val_accuracy: 0.8492\n",
            "Epoch 5/100\n",
            "1350/1350 [==============================] - 2s 2ms/step - loss: 0.3188 - accuracy: 0.8523 - val_loss: 0.3221 - val_accuracy: 0.8489\n",
            "Epoch 6/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3081 - accuracy: 0.8565 - val_loss: 0.3401 - val_accuracy: 0.8454\n",
            "Epoch 7/100\n",
            "1350/1350 [==============================] - 2s 2ms/step - loss: 0.3127 - accuracy: 0.8542 - val_loss: 0.3231 - val_accuracy: 0.8552\n",
            "Epoch 8/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3120 - accuracy: 0.8484 - val_loss: 0.3270 - val_accuracy: 0.8495\n",
            "Epoch 9/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3089 - accuracy: 0.8602 - val_loss: 0.3215 - val_accuracy: 0.8514\n",
            "Epoch 10/100\n",
            "1350/1350 [==============================] - 2s 2ms/step - loss: 0.3075 - accuracy: 0.8557 - val_loss: 0.3220 - val_accuracy: 0.8519\n",
            "Epoch 11/100\n",
            "1350/1350 [==============================] - 2s 2ms/step - loss: 0.2995 - accuracy: 0.8597 - val_loss: 0.3339 - val_accuracy: 0.8450\n",
            "Epoch 12/100\n",
            "1350/1350 [==============================] - 2s 2ms/step - loss: 0.2992 - accuracy: 0.8617 - val_loss: 0.3266 - val_accuracy: 0.8503\n",
            "Epoch 13/100\n",
            "1350/1350 [==============================] - 2s 2ms/step - loss: 0.2963 - accuracy: 0.8610 - val_loss: 0.3245 - val_accuracy: 0.8490\n",
            "Epoch 14/100\n",
            "1350/1350 [==============================] - 2s 2ms/step - loss: 0.2942 - accuracy: 0.8617 - val_loss: 0.3305 - val_accuracy: 0.8525\n",
            "150/150 [==============================] - 0s 1ms/step - loss: 0.3270 - accuracy: 0.8507\n",
            "Epoch 1/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.4448 - accuracy: 0.7940 - val_loss: 0.3477 - val_accuracy: 0.8379\n",
            "Epoch 2/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3500 - accuracy: 0.8364 - val_loss: 0.3365 - val_accuracy: 0.8419\n",
            "Epoch 3/100\n",
            "1350/1350 [==============================] - 2s 2ms/step - loss: 0.3231 - accuracy: 0.8478 - val_loss: 0.3342 - val_accuracy: 0.8463\n",
            "Epoch 4/100\n",
            "1350/1350 [==============================] - 2s 2ms/step - loss: 0.3213 - accuracy: 0.8489 - val_loss: 0.3206 - val_accuracy: 0.8554\n",
            "Epoch 5/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3215 - accuracy: 0.8455 - val_loss: 0.3228 - val_accuracy: 0.8537\n",
            "Epoch 6/100\n",
            "1350/1350 [==============================] - 2s 2ms/step - loss: 0.3134 - accuracy: 0.8516 - val_loss: 0.3258 - val_accuracy: 0.8501\n",
            "Epoch 7/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3137 - accuracy: 0.8506 - val_loss: 0.3232 - val_accuracy: 0.8512\n",
            "Epoch 8/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3143 - accuracy: 0.8497 - val_loss: 0.3238 - val_accuracy: 0.8507\n",
            "Epoch 9/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3067 - accuracy: 0.8539 - val_loss: 0.3285 - val_accuracy: 0.8478\n",
            "150/150 [==============================] - 0s 955us/step - loss: 0.3333 - accuracy: 0.8480\n",
            "Epoch 1/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.4505 - accuracy: 0.7891 - val_loss: 0.3600 - val_accuracy: 0.8369\n",
            "Epoch 2/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3505 - accuracy: 0.8331 - val_loss: 0.3258 - val_accuracy: 0.8518\n",
            "Epoch 3/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3256 - accuracy: 0.8438 - val_loss: 0.3269 - val_accuracy: 0.8475\n",
            "Epoch 4/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3272 - accuracy: 0.8472 - val_loss: 0.3265 - val_accuracy: 0.8494\n",
            "Epoch 5/100\n",
            "1350/1350 [==============================] - 2s 2ms/step - loss: 0.3146 - accuracy: 0.8544 - val_loss: 0.3308 - val_accuracy: 0.8495\n",
            "Epoch 6/100\n",
            "1350/1350 [==============================] - 2s 2ms/step - loss: 0.3109 - accuracy: 0.8496 - val_loss: 0.3365 - val_accuracy: 0.8471\n",
            "Epoch 7/100\n",
            "1350/1350 [==============================] - 2s 2ms/step - loss: 0.3026 - accuracy: 0.8581 - val_loss: 0.3223 - val_accuracy: 0.8520\n",
            "Epoch 8/100\n",
            "1350/1350 [==============================] - 2s 2ms/step - loss: 0.3050 - accuracy: 0.8568 - val_loss: 0.3216 - val_accuracy: 0.8508\n",
            "Epoch 9/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.2993 - accuracy: 0.8604 - val_loss: 0.3219 - val_accuracy: 0.8520\n",
            "Epoch 10/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.2967 - accuracy: 0.8630 - val_loss: 0.3386 - val_accuracy: 0.8457\n",
            "Epoch 11/100\n",
            "1350/1350 [==============================] - 2s 2ms/step - loss: 0.2959 - accuracy: 0.8616 - val_loss: 0.3255 - val_accuracy: 0.8503\n",
            "Epoch 12/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.2926 - accuracy: 0.8628 - val_loss: 0.3267 - val_accuracy: 0.8504\n",
            "Epoch 13/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.2875 - accuracy: 0.8668 - val_loss: 0.3348 - val_accuracy: 0.8505\n",
            "150/150 [==============================] - 0s 946us/step - loss: 0.3535 - accuracy: 0.8427\n",
            "Epoch 1/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.4414 - accuracy: 0.7936 - val_loss: 0.3490 - val_accuracy: 0.8376\n",
            "Epoch 2/100\n",
            "1350/1350 [==============================] - 2s 2ms/step - loss: 0.3614 - accuracy: 0.8279 - val_loss: 0.3376 - val_accuracy: 0.8420\n",
            "Epoch 3/100\n",
            "1350/1350 [==============================] - 2s 2ms/step - loss: 0.3177 - accuracy: 0.8487 - val_loss: 0.3262 - val_accuracy: 0.8483\n",
            "Epoch 4/100\n",
            "1350/1350 [==============================] - 2s 2ms/step - loss: 0.3176 - accuracy: 0.8511 - val_loss: 0.3249 - val_accuracy: 0.8530\n",
            "Epoch 5/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3158 - accuracy: 0.8509 - val_loss: 0.3231 - val_accuracy: 0.8505\n",
            "Epoch 6/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3148 - accuracy: 0.8501 - val_loss: 0.3257 - val_accuracy: 0.8518\n",
            "Epoch 7/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3124 - accuracy: 0.8556 - val_loss: 0.3313 - val_accuracy: 0.8503\n",
            "Epoch 8/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3093 - accuracy: 0.8540 - val_loss: 0.3249 - val_accuracy: 0.8528\n",
            "Epoch 9/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3039 - accuracy: 0.8578 - val_loss: 0.3266 - val_accuracy: 0.8512\n",
            "Epoch 10/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3046 - accuracy: 0.8559 - val_loss: 0.3280 - val_accuracy: 0.8511\n",
            "150/150 [==============================] - 0s 902us/step - loss: 0.3248 - accuracy: 0.8540\n",
            "Epoch 1/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.4458 - accuracy: 0.7915 - val_loss: 0.3548 - val_accuracy: 0.8344\n",
            "Epoch 2/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3498 - accuracy: 0.8332 - val_loss: 0.3362 - val_accuracy: 0.8482\n",
            "Epoch 3/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3340 - accuracy: 0.8425 - val_loss: 0.3319 - val_accuracy: 0.8495\n",
            "Epoch 4/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3201 - accuracy: 0.8497 - val_loss: 0.3222 - val_accuracy: 0.8528\n",
            "Epoch 5/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3233 - accuracy: 0.8484 - val_loss: 0.3250 - val_accuracy: 0.8475\n",
            "Epoch 6/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3136 - accuracy: 0.8523 - val_loss: 0.3244 - val_accuracy: 0.8500\n",
            "Epoch 7/100\n",
            "1350/1350 [==============================] - 2s 2ms/step - loss: 0.3151 - accuracy: 0.8501 - val_loss: 0.3215 - val_accuracy: 0.8518\n",
            "Epoch 8/100\n",
            "1350/1350 [==============================] - 2s 2ms/step - loss: 0.3080 - accuracy: 0.8544 - val_loss: 0.3351 - val_accuracy: 0.8471\n",
            "Epoch 9/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3031 - accuracy: 0.8588 - val_loss: 0.3240 - val_accuracy: 0.8537\n",
            "Epoch 10/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.2999 - accuracy: 0.8598 - val_loss: 0.3242 - val_accuracy: 0.8510\n",
            "Epoch 11/100\n",
            "1350/1350 [==============================] - 2s 2ms/step - loss: 0.3038 - accuracy: 0.8568 - val_loss: 0.3259 - val_accuracy: 0.8530\n",
            "Epoch 12/100\n",
            "1350/1350 [==============================] - 2s 2ms/step - loss: 0.2958 - accuracy: 0.8651 - val_loss: 0.3256 - val_accuracy: 0.8528\n",
            "150/150 [==============================] - 0s 940us/step - loss: 0.3214 - accuracy: 0.8547\n",
            "Epoch 1/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.4514 - accuracy: 0.7905 - val_loss: 0.3515 - val_accuracy: 0.8362\n",
            "Epoch 2/100\n",
            "1350/1350 [==============================] - 2s 2ms/step - loss: 0.3557 - accuracy: 0.8290 - val_loss: 0.3293 - val_accuracy: 0.8470\n",
            "Epoch 3/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3293 - accuracy: 0.8446 - val_loss: 0.3229 - val_accuracy: 0.8521\n",
            "Epoch 4/100\n",
            "1350/1350 [==============================] - 2s 2ms/step - loss: 0.3235 - accuracy: 0.8462 - val_loss: 0.3221 - val_accuracy: 0.8524\n",
            "Epoch 5/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3191 - accuracy: 0.8456 - val_loss: 0.3243 - val_accuracy: 0.8545\n",
            "Epoch 6/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3144 - accuracy: 0.8515 - val_loss: 0.3207 - val_accuracy: 0.8514\n",
            "Epoch 7/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3142 - accuracy: 0.8515 - val_loss: 0.3211 - val_accuracy: 0.8516\n",
            "Epoch 8/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3118 - accuracy: 0.8509 - val_loss: 0.3232 - val_accuracy: 0.8499\n",
            "Epoch 9/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3031 - accuracy: 0.8576 - val_loss: 0.3228 - val_accuracy: 0.8521\n",
            "Epoch 10/100\n",
            "1350/1350 [==============================] - 2s 2ms/step - loss: 0.2988 - accuracy: 0.8633 - val_loss: 0.3332 - val_accuracy: 0.8423\n",
            "Epoch 11/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3039 - accuracy: 0.8550 - val_loss: 0.3254 - val_accuracy: 0.8516\n",
            "150/150 [==============================] - 0s 926us/step - loss: 0.3286 - accuracy: 0.8453\n",
            "Epoch 1/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.4521 - accuracy: 0.7908 - val_loss: 0.3536 - val_accuracy: 0.8397\n",
            "Epoch 2/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3530 - accuracy: 0.8345 - val_loss: 0.3311 - val_accuracy: 0.8453\n",
            "Epoch 3/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3337 - accuracy: 0.8434 - val_loss: 0.3276 - val_accuracy: 0.8466\n",
            "Epoch 4/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3228 - accuracy: 0.8467 - val_loss: 0.3304 - val_accuracy: 0.8431\n",
            "Epoch 5/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3153 - accuracy: 0.8507 - val_loss: 0.3209 - val_accuracy: 0.8536\n",
            "Epoch 6/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3142 - accuracy: 0.8526 - val_loss: 0.3216 - val_accuracy: 0.8511\n",
            "Epoch 7/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3191 - accuracy: 0.8516 - val_loss: 0.3322 - val_accuracy: 0.8438\n",
            "Epoch 8/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3068 - accuracy: 0.8547 - val_loss: 0.3259 - val_accuracy: 0.8505\n",
            "Epoch 9/100\n",
            "1350/1350 [==============================] - 2s 2ms/step - loss: 0.3106 - accuracy: 0.8562 - val_loss: 0.3260 - val_accuracy: 0.8469\n",
            "Epoch 10/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3058 - accuracy: 0.8546 - val_loss: 0.3279 - val_accuracy: 0.8480\n",
            "150/150 [==============================] - 0s 981us/step - loss: 0.3224 - accuracy: 0.8427\n",
            "Epoch 1/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.4566 - accuracy: 0.7873 - val_loss: 0.3612 - val_accuracy: 0.8368\n",
            "Epoch 2/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3521 - accuracy: 0.8380 - val_loss: 0.3359 - val_accuracy: 0.8489\n",
            "Epoch 3/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3290 - accuracy: 0.8448 - val_loss: 0.3283 - val_accuracy: 0.8465\n",
            "Epoch 4/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3233 - accuracy: 0.8511 - val_loss: 0.3302 - val_accuracy: 0.8427\n",
            "Epoch 5/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3128 - accuracy: 0.8527 - val_loss: 0.3213 - val_accuracy: 0.8518\n",
            "Epoch 6/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3122 - accuracy: 0.8526 - val_loss: 0.3216 - val_accuracy: 0.8535\n",
            "Epoch 7/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3049 - accuracy: 0.8553 - val_loss: 0.3213 - val_accuracy: 0.8517\n",
            "Epoch 8/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.2998 - accuracy: 0.8625 - val_loss: 0.3244 - val_accuracy: 0.8532\n",
            "Epoch 9/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3040 - accuracy: 0.8573 - val_loss: 0.3236 - val_accuracy: 0.8501\n",
            "Epoch 10/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.2917 - accuracy: 0.8647 - val_loss: 0.3267 - val_accuracy: 0.8486\n",
            "Epoch 11/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3000 - accuracy: 0.8636 - val_loss: 0.3242 - val_accuracy: 0.8541\n",
            "Epoch 12/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.2921 - accuracy: 0.8633 - val_loss: 0.3248 - val_accuracy: 0.8514\n",
            "150/150 [==============================] - 0s 1ms/step - loss: 0.3279 - accuracy: 0.8467\n",
            "Epoch 1/100\n",
            "1350/1350 [==============================] - 4s 2ms/step - loss: 0.4422 - accuracy: 0.7926 - val_loss: 0.3491 - val_accuracy: 0.8397\n",
            "Epoch 2/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3473 - accuracy: 0.8388 - val_loss: 0.3280 - val_accuracy: 0.8489\n",
            "Epoch 3/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3192 - accuracy: 0.8473 - val_loss: 0.3238 - val_accuracy: 0.8501\n",
            "Epoch 4/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3191 - accuracy: 0.8520 - val_loss: 0.3230 - val_accuracy: 0.8516\n",
            "Epoch 5/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3224 - accuracy: 0.8463 - val_loss: 0.3293 - val_accuracy: 0.8463\n",
            "Epoch 6/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3170 - accuracy: 0.8500 - val_loss: 0.3203 - val_accuracy: 0.8523\n",
            "Epoch 7/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3082 - accuracy: 0.8551 - val_loss: 0.3242 - val_accuracy: 0.8505\n",
            "Epoch 8/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.2981 - accuracy: 0.8606 - val_loss: 0.3265 - val_accuracy: 0.8522\n",
            "Epoch 9/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3048 - accuracy: 0.8540 - val_loss: 0.3281 - val_accuracy: 0.8460\n",
            "Epoch 10/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3108 - accuracy: 0.8518 - val_loss: 0.3239 - val_accuracy: 0.8524\n",
            "Epoch 11/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.2947 - accuracy: 0.8616 - val_loss: 0.3378 - val_accuracy: 0.8503\n",
            "150/150 [==============================] - 0s 964us/step - loss: 0.3269 - accuracy: 0.8580\n",
            "Epoch 1/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.4453 - accuracy: 0.7924 - val_loss: 0.3528 - val_accuracy: 0.8379\n",
            "Epoch 2/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3460 - accuracy: 0.8369 - val_loss: 0.3307 - val_accuracy: 0.8478\n",
            "Epoch 3/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3392 - accuracy: 0.8409 - val_loss: 0.3247 - val_accuracy: 0.8523\n",
            "Epoch 4/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3187 - accuracy: 0.8527 - val_loss: 0.3229 - val_accuracy: 0.8521\n",
            "Epoch 5/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3110 - accuracy: 0.8507 - val_loss: 0.3255 - val_accuracy: 0.8473\n",
            "Epoch 6/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3099 - accuracy: 0.8513 - val_loss: 0.3253 - val_accuracy: 0.8493\n",
            "Epoch 7/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3123 - accuracy: 0.8498 - val_loss: 0.3287 - val_accuracy: 0.8470\n",
            "Epoch 8/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3051 - accuracy: 0.8549 - val_loss: 0.3271 - val_accuracy: 0.8482\n",
            "Epoch 9/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3106 - accuracy: 0.8541 - val_loss: 0.3435 - val_accuracy: 0.8468\n",
            "150/150 [==============================] - 0s 913us/step - loss: 0.3372 - accuracy: 0.8533\n",
            "Epoch 1/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.4469 - accuracy: 0.7945 - val_loss: 0.3503 - val_accuracy: 0.8383\n",
            "Epoch 2/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3511 - accuracy: 0.8325 - val_loss: 0.3322 - val_accuracy: 0.8489\n",
            "Epoch 3/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3282 - accuracy: 0.8455 - val_loss: 0.3307 - val_accuracy: 0.8475\n",
            "Epoch 4/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3229 - accuracy: 0.8495 - val_loss: 0.3233 - val_accuracy: 0.8531\n",
            "Epoch 5/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3166 - accuracy: 0.8510 - val_loss: 0.3306 - val_accuracy: 0.8423\n",
            "Epoch 6/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3157 - accuracy: 0.8506 - val_loss: 0.3202 - val_accuracy: 0.8521\n",
            "Epoch 7/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3111 - accuracy: 0.8539 - val_loss: 0.3235 - val_accuracy: 0.8539\n",
            "Epoch 8/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3127 - accuracy: 0.8531 - val_loss: 0.3212 - val_accuracy: 0.8511\n",
            "Epoch 9/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3008 - accuracy: 0.8585 - val_loss: 0.3259 - val_accuracy: 0.8520\n",
            "Epoch 10/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3046 - accuracy: 0.8562 - val_loss: 0.3309 - val_accuracy: 0.8425\n",
            "Epoch 11/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3088 - accuracy: 0.8565 - val_loss: 0.3268 - val_accuracy: 0.8514\n",
            "150/150 [==============================] - 0s 899us/step - loss: 0.3243 - accuracy: 0.8487\n",
            "Epoch 1/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.4514 - accuracy: 0.7902 - val_loss: 0.3563 - val_accuracy: 0.8325\n",
            "Epoch 2/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3494 - accuracy: 0.8303 - val_loss: 0.3274 - val_accuracy: 0.8480\n",
            "Epoch 3/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3265 - accuracy: 0.8508 - val_loss: 0.3276 - val_accuracy: 0.8485\n",
            "Epoch 4/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3155 - accuracy: 0.8499 - val_loss: 0.3241 - val_accuracy: 0.8508\n",
            "Epoch 5/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3234 - accuracy: 0.8442 - val_loss: 0.3277 - val_accuracy: 0.8502\n",
            "Epoch 6/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3096 - accuracy: 0.8554 - val_loss: 0.3271 - val_accuracy: 0.8499\n",
            "Epoch 7/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3041 - accuracy: 0.8562 - val_loss: 0.3262 - val_accuracy: 0.8469\n",
            "Epoch 8/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3091 - accuracy: 0.8498 - val_loss: 0.3256 - val_accuracy: 0.8485\n",
            "Epoch 9/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.2979 - accuracy: 0.8614 - val_loss: 0.3230 - val_accuracy: 0.8501\n",
            "Epoch 10/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3015 - accuracy: 0.8563 - val_loss: 0.3269 - val_accuracy: 0.8489\n",
            "Epoch 11/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.2927 - accuracy: 0.8613 - val_loss: 0.3261 - val_accuracy: 0.8523\n",
            "Epoch 12/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3001 - accuracy: 0.8567 - val_loss: 0.3283 - val_accuracy: 0.8516\n",
            "Epoch 13/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.2943 - accuracy: 0.8612 - val_loss: 0.3295 - val_accuracy: 0.8483\n",
            "Epoch 14/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.2866 - accuracy: 0.8652 - val_loss: 0.3322 - val_accuracy: 0.8464\n",
            "150/150 [==============================] - 0s 1ms/step - loss: 0.3336 - accuracy: 0.8573\n",
            "Epoch 1/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.4435 - accuracy: 0.7971 - val_loss: 0.3425 - val_accuracy: 0.8417\n",
            "Epoch 2/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3499 - accuracy: 0.8332 - val_loss: 0.3261 - val_accuracy: 0.8497\n",
            "Epoch 3/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3207 - accuracy: 0.8498 - val_loss: 0.3362 - val_accuracy: 0.8422\n",
            "Epoch 4/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3090 - accuracy: 0.8588 - val_loss: 0.3233 - val_accuracy: 0.8517\n",
            "Epoch 5/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3165 - accuracy: 0.8529 - val_loss: 0.3254 - val_accuracy: 0.8456\n",
            "Epoch 6/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3149 - accuracy: 0.8505 - val_loss: 0.3289 - val_accuracy: 0.8489\n",
            "Epoch 7/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3036 - accuracy: 0.8598 - val_loss: 0.3277 - val_accuracy: 0.8454\n",
            "Epoch 8/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3043 - accuracy: 0.8572 - val_loss: 0.3226 - val_accuracy: 0.8522\n",
            "Epoch 9/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3037 - accuracy: 0.8598 - val_loss: 0.3220 - val_accuracy: 0.8519\n",
            "Epoch 10/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.2983 - accuracy: 0.8621 - val_loss: 0.3264 - val_accuracy: 0.8524\n",
            "Epoch 11/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.2991 - accuracy: 0.8576 - val_loss: 0.3309 - val_accuracy: 0.8528\n",
            "Epoch 12/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3013 - accuracy: 0.8591 - val_loss: 0.3307 - val_accuracy: 0.8487\n",
            "Epoch 13/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.2840 - accuracy: 0.8677 - val_loss: 0.3323 - val_accuracy: 0.8519\n",
            "Epoch 14/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.2942 - accuracy: 0.8611 - val_loss: 0.3301 - val_accuracy: 0.8527\n",
            "150/150 [==============================] - 0s 946us/step - loss: 0.3485 - accuracy: 0.8320\n",
            "Epoch 1/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.4410 - accuracy: 0.8013 - val_loss: 0.3598 - val_accuracy: 0.8349\n",
            "Epoch 2/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3424 - accuracy: 0.8371 - val_loss: 0.3534 - val_accuracy: 0.8331\n",
            "Epoch 3/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3240 - accuracy: 0.8479 - val_loss: 0.3378 - val_accuracy: 0.8431\n",
            "Epoch 4/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3240 - accuracy: 0.8454 - val_loss: 0.3223 - val_accuracy: 0.8521\n",
            "Epoch 5/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3120 - accuracy: 0.8530 - val_loss: 0.3377 - val_accuracy: 0.8460\n",
            "Epoch 6/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3142 - accuracy: 0.8518 - val_loss: 0.3206 - val_accuracy: 0.8518\n",
            "Epoch 7/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3101 - accuracy: 0.8555 - val_loss: 0.3277 - val_accuracy: 0.8479\n",
            "Epoch 8/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3056 - accuracy: 0.8568 - val_loss: 0.3232 - val_accuracy: 0.8538\n",
            "Epoch 9/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3068 - accuracy: 0.8540 - val_loss: 0.3298 - val_accuracy: 0.8467\n",
            "Epoch 10/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3028 - accuracy: 0.8571 - val_loss: 0.3265 - val_accuracy: 0.8511\n",
            "Epoch 11/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.2990 - accuracy: 0.8578 - val_loss: 0.3254 - val_accuracy: 0.8517\n",
            "150/150 [==============================] - 0s 969us/step - loss: 0.3249 - accuracy: 0.8540\n",
            "Epoch 1/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.4347 - accuracy: 0.8055 - val_loss: 0.3475 - val_accuracy: 0.8375\n",
            "Epoch 2/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3463 - accuracy: 0.8347 - val_loss: 0.3314 - val_accuracy: 0.8483\n",
            "Epoch 3/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3276 - accuracy: 0.8463 - val_loss: 0.3256 - val_accuracy: 0.8505\n",
            "Epoch 4/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3170 - accuracy: 0.8519 - val_loss: 0.3293 - val_accuracy: 0.8433\n",
            "Epoch 5/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3095 - accuracy: 0.8539 - val_loss: 0.3218 - val_accuracy: 0.8511\n",
            "Epoch 6/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3143 - accuracy: 0.8493 - val_loss: 0.3221 - val_accuracy: 0.8497\n",
            "Epoch 7/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3127 - accuracy: 0.8529 - val_loss: 0.3399 - val_accuracy: 0.8468\n",
            "Epoch 8/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3145 - accuracy: 0.8516 - val_loss: 0.3276 - val_accuracy: 0.8478\n",
            "Epoch 9/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3078 - accuracy: 0.8537 - val_loss: 0.3201 - val_accuracy: 0.8551\n",
            "Epoch 10/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3041 - accuracy: 0.8580 - val_loss: 0.3198 - val_accuracy: 0.8548\n",
            "Epoch 11/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3024 - accuracy: 0.8579 - val_loss: 0.3250 - val_accuracy: 0.8520\n",
            "Epoch 12/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3021 - accuracy: 0.8583 - val_loss: 0.3257 - val_accuracy: 0.8518\n",
            "Epoch 13/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.2995 - accuracy: 0.8588 - val_loss: 0.3308 - val_accuracy: 0.8486\n",
            "Epoch 14/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.2889 - accuracy: 0.8688 - val_loss: 0.3301 - val_accuracy: 0.8529\n",
            "Epoch 15/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.2904 - accuracy: 0.8639 - val_loss: 0.3288 - val_accuracy: 0.8505\n",
            "150/150 [==============================] - 0s 917us/step - loss: 0.3313 - accuracy: 0.8500\n",
            "Epoch 1/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.4350 - accuracy: 0.7988 - val_loss: 0.3459 - val_accuracy: 0.8398\n",
            "Epoch 2/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3475 - accuracy: 0.8350 - val_loss: 0.3349 - val_accuracy: 0.8456\n",
            "Epoch 3/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3228 - accuracy: 0.8495 - val_loss: 0.3229 - val_accuracy: 0.8532\n",
            "Epoch 4/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3242 - accuracy: 0.8463 - val_loss: 0.3253 - val_accuracy: 0.8504\n",
            "Epoch 5/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3112 - accuracy: 0.8526 - val_loss: 0.3221 - val_accuracy: 0.8511\n",
            "Epoch 6/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3202 - accuracy: 0.8487 - val_loss: 0.3222 - val_accuracy: 0.8509\n",
            "Epoch 7/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3028 - accuracy: 0.8587 - val_loss: 0.3299 - val_accuracy: 0.8470\n",
            "Epoch 8/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3027 - accuracy: 0.8570 - val_loss: 0.3244 - val_accuracy: 0.8521\n",
            "Epoch 9/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3041 - accuracy: 0.8566 - val_loss: 0.3287 - val_accuracy: 0.8488\n",
            "Epoch 10/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3060 - accuracy: 0.8557 - val_loss: 0.3264 - val_accuracy: 0.8485\n",
            "150/150 [==============================] - 0s 918us/step - loss: 0.3289 - accuracy: 0.8407\n",
            "Epoch 1/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.4444 - accuracy: 0.7936 - val_loss: 0.3471 - val_accuracy: 0.8398\n",
            "Epoch 2/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3544 - accuracy: 0.8319 - val_loss: 0.3329 - val_accuracy: 0.8455\n",
            "Epoch 3/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3326 - accuracy: 0.8430 - val_loss: 0.3302 - val_accuracy: 0.8470\n",
            "Epoch 4/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3219 - accuracy: 0.8479 - val_loss: 0.3288 - val_accuracy: 0.8469\n",
            "Epoch 5/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3234 - accuracy: 0.8514 - val_loss: 0.3198 - val_accuracy: 0.8531\n",
            "Epoch 6/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3114 - accuracy: 0.8509 - val_loss: 0.3207 - val_accuracy: 0.8542\n",
            "Epoch 7/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3110 - accuracy: 0.8546 - val_loss: 0.3209 - val_accuracy: 0.8552\n",
            "Epoch 8/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3118 - accuracy: 0.8555 - val_loss: 0.3209 - val_accuracy: 0.8528\n",
            "Epoch 9/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3098 - accuracy: 0.8510 - val_loss: 0.3207 - val_accuracy: 0.8559\n",
            "Epoch 10/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3053 - accuracy: 0.8586 - val_loss: 0.3288 - val_accuracy: 0.8501\n",
            "150/150 [==============================] - 0s 899us/step - loss: 0.3227 - accuracy: 0.8547\n",
            "Epoch 1/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.4500 - accuracy: 0.7947 - val_loss: 0.3695 - val_accuracy: 0.8277\n",
            "Epoch 2/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3521 - accuracy: 0.8340 - val_loss: 0.3305 - val_accuracy: 0.8491\n",
            "Epoch 3/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3230 - accuracy: 0.8474 - val_loss: 0.3251 - val_accuracy: 0.8506\n",
            "Epoch 4/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3221 - accuracy: 0.8503 - val_loss: 0.3223 - val_accuracy: 0.8542\n",
            "Epoch 5/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3134 - accuracy: 0.8508 - val_loss: 0.3205 - val_accuracy: 0.8566\n",
            "Epoch 6/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3072 - accuracy: 0.8517 - val_loss: 0.3211 - val_accuracy: 0.8498\n",
            "Epoch 7/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3122 - accuracy: 0.8520 - val_loss: 0.3242 - val_accuracy: 0.8522\n",
            "Epoch 8/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3156 - accuracy: 0.8501 - val_loss: 0.3213 - val_accuracy: 0.8538\n",
            "Epoch 9/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3146 - accuracy: 0.8517 - val_loss: 0.3216 - val_accuracy: 0.8530\n",
            "Epoch 10/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3029 - accuracy: 0.8618 - val_loss: 0.3214 - val_accuracy: 0.8533\n",
            "150/150 [==============================] - 0s 1ms/step - loss: 0.3201 - accuracy: 0.8513\n",
            "Epoch 1/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.4134 - accuracy: 0.7988 - val_loss: 0.3477 - val_accuracy: 0.8404\n",
            "Epoch 2/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3522 - accuracy: 0.8289 - val_loss: 0.3456 - val_accuracy: 0.8317\n",
            "Epoch 3/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3305 - accuracy: 0.8434 - val_loss: 0.3331 - val_accuracy: 0.8470\n",
            "Epoch 4/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3280 - accuracy: 0.8453 - val_loss: 0.3405 - val_accuracy: 0.8397\n",
            "Epoch 5/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3220 - accuracy: 0.8444 - val_loss: 0.3498 - val_accuracy: 0.8264\n",
            "Epoch 6/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3130 - accuracy: 0.8481 - val_loss: 0.3288 - val_accuracy: 0.8511\n",
            "Epoch 7/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3114 - accuracy: 0.8554 - val_loss: 0.3285 - val_accuracy: 0.8505\n",
            "Epoch 8/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3140 - accuracy: 0.8506 - val_loss: 0.3385 - val_accuracy: 0.8404\n",
            "Epoch 9/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3072 - accuracy: 0.8529 - val_loss: 0.3313 - val_accuracy: 0.8500\n",
            "Epoch 10/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3043 - accuracy: 0.8603 - val_loss: 0.3336 - val_accuracy: 0.8514\n",
            "Epoch 11/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3045 - accuracy: 0.8610 - val_loss: 0.3341 - val_accuracy: 0.8514\n",
            "Epoch 12/100\n",
            "1350/1350 [==============================] - 2s 2ms/step - loss: 0.3023 - accuracy: 0.8582 - val_loss: 0.3708 - val_accuracy: 0.8477\n",
            "150/150 [==============================] - 0s 899us/step - loss: 0.3624 - accuracy: 0.8547\n",
            "Epoch 1/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.4097 - accuracy: 0.7980 - val_loss: 0.3616 - val_accuracy: 0.8365\n",
            "Epoch 2/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3562 - accuracy: 0.8290 - val_loss: 0.3462 - val_accuracy: 0.8436\n",
            "Epoch 3/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3401 - accuracy: 0.8432 - val_loss: 0.3473 - val_accuracy: 0.8359\n",
            "Epoch 4/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3293 - accuracy: 0.8477 - val_loss: 0.3438 - val_accuracy: 0.8475\n",
            "Epoch 5/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3240 - accuracy: 0.8507 - val_loss: 0.3280 - val_accuracy: 0.8527\n",
            "Epoch 6/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3177 - accuracy: 0.8507 - val_loss: 0.3319 - val_accuracy: 0.8488\n",
            "Epoch 7/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3191 - accuracy: 0.8505 - val_loss: 0.3306 - val_accuracy: 0.8495\n",
            "Epoch 8/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3114 - accuracy: 0.8527 - val_loss: 0.3937 - val_accuracy: 0.8299\n",
            "Epoch 9/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3108 - accuracy: 0.8534 - val_loss: 0.3397 - val_accuracy: 0.8407\n",
            "Epoch 10/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3105 - accuracy: 0.8509 - val_loss: 0.3395 - val_accuracy: 0.8442\n",
            "150/150 [==============================] - 0s 956us/step - loss: 0.3342 - accuracy: 0.8520\n",
            "Epoch 1/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.4132 - accuracy: 0.8022 - val_loss: 0.3626 - val_accuracy: 0.8412\n",
            "Epoch 2/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3500 - accuracy: 0.8334 - val_loss: 0.3353 - val_accuracy: 0.8499\n",
            "Epoch 3/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3382 - accuracy: 0.8432 - val_loss: 0.3282 - val_accuracy: 0.8497\n",
            "Epoch 4/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3254 - accuracy: 0.8501 - val_loss: 0.3393 - val_accuracy: 0.8415\n",
            "Epoch 5/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3248 - accuracy: 0.8482 - val_loss: 0.3404 - val_accuracy: 0.8510\n",
            "Epoch 6/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3240 - accuracy: 0.8461 - val_loss: 0.3325 - val_accuracy: 0.8405\n",
            "Epoch 7/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3196 - accuracy: 0.8496 - val_loss: 0.3286 - val_accuracy: 0.8485\n",
            "Epoch 8/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3088 - accuracy: 0.8562 - val_loss: 0.3324 - val_accuracy: 0.8471\n",
            "150/150 [==============================] - 0s 983us/step - loss: 0.3273 - accuracy: 0.8460\n",
            "Epoch 1/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.4082 - accuracy: 0.8012 - val_loss: 0.3429 - val_accuracy: 0.8407\n",
            "Epoch 2/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3471 - accuracy: 0.8352 - val_loss: 0.3315 - val_accuracy: 0.8471\n",
            "Epoch 3/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3279 - accuracy: 0.8434 - val_loss: 0.3269 - val_accuracy: 0.8494\n",
            "Epoch 4/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3226 - accuracy: 0.8505 - val_loss: 0.3392 - val_accuracy: 0.8498\n",
            "Epoch 5/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3147 - accuracy: 0.8500 - val_loss: 0.3269 - val_accuracy: 0.8512\n",
            "Epoch 6/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3089 - accuracy: 0.8543 - val_loss: 0.3416 - val_accuracy: 0.8414\n",
            "Epoch 7/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3191 - accuracy: 0.8468 - val_loss: 0.3360 - val_accuracy: 0.8438\n",
            "Epoch 8/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3067 - accuracy: 0.8502 - val_loss: 0.3308 - val_accuracy: 0.8492\n",
            "Epoch 9/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3063 - accuracy: 0.8549 - val_loss: 0.3671 - val_accuracy: 0.8461\n",
            "Epoch 10/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3131 - accuracy: 0.8540 - val_loss: 0.3341 - val_accuracy: 0.8498\n",
            "150/150 [==============================] - 0s 1ms/step - loss: 0.3423 - accuracy: 0.8520\n",
            "Epoch 1/100\n",
            "1350/1350 [==============================] - 4s 3ms/step - loss: 0.4039 - accuracy: 0.8088 - val_loss: 0.3352 - val_accuracy: 0.8472\n",
            "Epoch 2/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3446 - accuracy: 0.8377 - val_loss: 0.3401 - val_accuracy: 0.8431\n",
            "Epoch 3/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3239 - accuracy: 0.8470 - val_loss: 0.3271 - val_accuracy: 0.8526\n",
            "Epoch 4/100\n",
            "1350/1350 [==============================] - 2s 2ms/step - loss: 0.3209 - accuracy: 0.8488 - val_loss: 0.3418 - val_accuracy: 0.8388\n",
            "Epoch 5/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3176 - accuracy: 0.8546 - val_loss: 0.3256 - val_accuracy: 0.8514\n",
            "Epoch 6/100\n",
            "1350/1350 [==============================] - 2s 2ms/step - loss: 0.3201 - accuracy: 0.8512 - val_loss: 0.3274 - val_accuracy: 0.8489\n",
            "Epoch 7/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3134 - accuracy: 0.8563 - val_loss: 0.3438 - val_accuracy: 0.8447\n",
            "Epoch 8/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3069 - accuracy: 0.8555 - val_loss: 0.3437 - val_accuracy: 0.8455\n",
            "Epoch 9/100\n",
            "1350/1350 [==============================] - 2s 2ms/step - loss: 0.3057 - accuracy: 0.8572 - val_loss: 0.3339 - val_accuracy: 0.8501\n",
            "Epoch 10/100\n",
            "1350/1350 [==============================] - 2s 2ms/step - loss: 0.2900 - accuracy: 0.8638 - val_loss: 0.3341 - val_accuracy: 0.8473\n",
            "150/150 [==============================] - 0s 890us/step - loss: 0.3443 - accuracy: 0.8433\n",
            "Epoch 1/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.4181 - accuracy: 0.7938 - val_loss: 0.3504 - val_accuracy: 0.8404\n",
            "Epoch 2/100\n",
            "1350/1350 [==============================] - 2s 2ms/step - loss: 0.3504 - accuracy: 0.8379 - val_loss: 0.3387 - val_accuracy: 0.8472\n",
            "Epoch 3/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3311 - accuracy: 0.8442 - val_loss: 0.3310 - val_accuracy: 0.8459\n",
            "Epoch 4/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3196 - accuracy: 0.8501 - val_loss: 0.3300 - val_accuracy: 0.8503\n",
            "Epoch 5/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3252 - accuracy: 0.8468 - val_loss: 0.3279 - val_accuracy: 0.8521\n",
            "Epoch 6/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3131 - accuracy: 0.8525 - val_loss: 0.3436 - val_accuracy: 0.8475\n",
            "Epoch 7/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3118 - accuracy: 0.8549 - val_loss: 0.3302 - val_accuracy: 0.8502\n",
            "Epoch 8/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3020 - accuracy: 0.8617 - val_loss: 0.3392 - val_accuracy: 0.8497\n",
            "Epoch 9/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3027 - accuracy: 0.8600 - val_loss: 0.3567 - val_accuracy: 0.8363\n",
            "Epoch 10/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3008 - accuracy: 0.8585 - val_loss: 0.3379 - val_accuracy: 0.8499\n",
            "150/150 [==============================] - 0s 989us/step - loss: 0.3350 - accuracy: 0.8540\n",
            "Epoch 1/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.4155 - accuracy: 0.8007 - val_loss: 0.3603 - val_accuracy: 0.8267\n",
            "Epoch 2/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3547 - accuracy: 0.8296 - val_loss: 0.3356 - val_accuracy: 0.8500\n",
            "Epoch 3/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3397 - accuracy: 0.8394 - val_loss: 0.3348 - val_accuracy: 0.8451\n",
            "Epoch 4/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3291 - accuracy: 0.8463 - val_loss: 0.3265 - val_accuracy: 0.8527\n",
            "Epoch 5/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3232 - accuracy: 0.8520 - val_loss: 0.3265 - val_accuracy: 0.8456\n",
            "Epoch 6/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3129 - accuracy: 0.8531 - val_loss: 0.3285 - val_accuracy: 0.8505\n",
            "Epoch 7/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3214 - accuracy: 0.8491 - val_loss: 0.3311 - val_accuracy: 0.8479\n",
            "Epoch 8/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3116 - accuracy: 0.8559 - val_loss: 0.3308 - val_accuracy: 0.8490\n",
            "Epoch 9/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3058 - accuracy: 0.8576 - val_loss: 0.3291 - val_accuracy: 0.8539\n",
            "150/150 [==============================] - 0s 933us/step - loss: 0.3288 - accuracy: 0.8507\n",
            "Epoch 1/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.4122 - accuracy: 0.7973 - val_loss: 0.3551 - val_accuracy: 0.8429\n",
            "Epoch 2/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3514 - accuracy: 0.8381 - val_loss: 0.3308 - val_accuracy: 0.8485\n",
            "Epoch 3/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3338 - accuracy: 0.8416 - val_loss: 0.3333 - val_accuracy: 0.8458\n",
            "Epoch 4/100\n",
            "1350/1350 [==============================] - 2s 2ms/step - loss: 0.3267 - accuracy: 0.8477 - val_loss: 0.3278 - val_accuracy: 0.8522\n",
            "Epoch 5/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3154 - accuracy: 0.8500 - val_loss: 0.3328 - val_accuracy: 0.8486\n",
            "Epoch 6/100\n",
            "1350/1350 [==============================] - 2s 2ms/step - loss: 0.3156 - accuracy: 0.8483 - val_loss: 0.3371 - val_accuracy: 0.8434\n",
            "Epoch 7/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3135 - accuracy: 0.8528 - val_loss: 0.3328 - val_accuracy: 0.8505\n",
            "Epoch 8/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3076 - accuracy: 0.8567 - val_loss: 0.3372 - val_accuracy: 0.8510\n",
            "Epoch 9/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3077 - accuracy: 0.8523 - val_loss: 0.3682 - val_accuracy: 0.8489\n",
            "150/150 [==============================] - 0s 957us/step - loss: 0.3929 - accuracy: 0.8307\n",
            "Epoch 1/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.4050 - accuracy: 0.7997 - val_loss: 0.3402 - val_accuracy: 0.8464\n",
            "Epoch 2/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3475 - accuracy: 0.8372 - val_loss: 0.3272 - val_accuracy: 0.8504\n",
            "Epoch 3/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3262 - accuracy: 0.8450 - val_loss: 0.3353 - val_accuracy: 0.8422\n",
            "Epoch 4/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3163 - accuracy: 0.8477 - val_loss: 0.3368 - val_accuracy: 0.8464\n",
            "Epoch 5/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3212 - accuracy: 0.8466 - val_loss: 0.3291 - val_accuracy: 0.8465\n",
            "Epoch 6/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3053 - accuracy: 0.8535 - val_loss: 0.3300 - val_accuracy: 0.8511\n",
            "Epoch 7/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3177 - accuracy: 0.8488 - val_loss: 0.3307 - val_accuracy: 0.8505\n",
            "150/150 [==============================] - 0s 968us/step - loss: 0.3190 - accuracy: 0.8480\n",
            "Epoch 1/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.4036 - accuracy: 0.8042 - val_loss: 0.3626 - val_accuracy: 0.8251\n",
            "Epoch 2/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3380 - accuracy: 0.8436 - val_loss: 0.3239 - val_accuracy: 0.8540\n",
            "Epoch 3/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3297 - accuracy: 0.8457 - val_loss: 0.3408 - val_accuracy: 0.8538\n",
            "Epoch 4/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3322 - accuracy: 0.8432 - val_loss: 0.3323 - val_accuracy: 0.8511\n",
            "Epoch 5/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3218 - accuracy: 0.8449 - val_loss: 0.3335 - val_accuracy: 0.8487\n",
            "Epoch 6/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3153 - accuracy: 0.8551 - val_loss: 0.3384 - val_accuracy: 0.8343\n",
            "Epoch 7/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3024 - accuracy: 0.8563 - val_loss: 0.3437 - val_accuracy: 0.8403\n",
            "150/150 [==============================] - 0s 975us/step - loss: 0.3385 - accuracy: 0.8387\n",
            "Epoch 1/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3991 - accuracy: 0.8091 - val_loss: 0.3394 - val_accuracy: 0.8444\n",
            "Epoch 2/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3426 - accuracy: 0.8340 - val_loss: 0.3328 - val_accuracy: 0.8498\n",
            "Epoch 3/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3292 - accuracy: 0.8412 - val_loss: 0.3373 - val_accuracy: 0.8418\n",
            "Epoch 4/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3296 - accuracy: 0.8413 - val_loss: 0.3368 - val_accuracy: 0.8341\n",
            "Epoch 5/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3218 - accuracy: 0.8489 - val_loss: 0.3253 - val_accuracy: 0.8537\n",
            "Epoch 6/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3123 - accuracy: 0.8519 - val_loss: 0.3367 - val_accuracy: 0.8503\n",
            "Epoch 7/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3147 - accuracy: 0.8468 - val_loss: 0.3406 - val_accuracy: 0.8496\n",
            "Epoch 8/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3106 - accuracy: 0.8538 - val_loss: 0.3403 - val_accuracy: 0.8485\n",
            "Epoch 9/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3030 - accuracy: 0.8587 - val_loss: 0.3540 - val_accuracy: 0.8403\n",
            "Epoch 10/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3028 - accuracy: 0.8569 - val_loss: 0.3406 - val_accuracy: 0.8509\n",
            "150/150 [==============================] - 0s 949us/step - loss: 0.3405 - accuracy: 0.8527\n",
            "Epoch 1/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.4147 - accuracy: 0.7911 - val_loss: 0.3479 - val_accuracy: 0.8409\n",
            "Epoch 2/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3447 - accuracy: 0.8395 - val_loss: 0.3538 - val_accuracy: 0.8332\n",
            "Epoch 3/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3372 - accuracy: 0.8391 - val_loss: 0.3323 - val_accuracy: 0.8481\n",
            "Epoch 4/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3279 - accuracy: 0.8439 - val_loss: 0.3295 - val_accuracy: 0.8492\n",
            "Epoch 5/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3155 - accuracy: 0.8517 - val_loss: 0.3327 - val_accuracy: 0.8524\n",
            "Epoch 6/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3001 - accuracy: 0.8565 - val_loss: 0.3339 - val_accuracy: 0.8464\n",
            "Epoch 7/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3038 - accuracy: 0.8576 - val_loss: 0.3384 - val_accuracy: 0.8442\n",
            "Epoch 8/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3100 - accuracy: 0.8532 - val_loss: 0.3370 - val_accuracy: 0.8465\n",
            "Epoch 9/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3050 - accuracy: 0.8552 - val_loss: 0.3384 - val_accuracy: 0.8526\n",
            "150/150 [==============================] - 0s 857us/step - loss: 0.3315 - accuracy: 0.8500\n",
            "Epoch 1/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.4164 - accuracy: 0.7839 - val_loss: 0.3603 - val_accuracy: 0.8408\n",
            "Epoch 2/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3520 - accuracy: 0.8374 - val_loss: 0.3582 - val_accuracy: 0.8247\n",
            "Epoch 3/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3365 - accuracy: 0.8445 - val_loss: 0.3387 - val_accuracy: 0.8442\n",
            "Epoch 4/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3292 - accuracy: 0.8518 - val_loss: 0.3291 - val_accuracy: 0.8513\n",
            "Epoch 5/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3201 - accuracy: 0.8524 - val_loss: 0.3491 - val_accuracy: 0.8277\n",
            "Epoch 6/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3184 - accuracy: 0.8508 - val_loss: 0.3366 - val_accuracy: 0.8416\n",
            "Epoch 7/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3126 - accuracy: 0.8514 - val_loss: 0.3286 - val_accuracy: 0.8512\n",
            "Epoch 8/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3129 - accuracy: 0.8548 - val_loss: 0.3361 - val_accuracy: 0.8518\n",
            "Epoch 9/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3019 - accuracy: 0.8590 - val_loss: 0.3314 - val_accuracy: 0.8490\n",
            "Epoch 10/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3114 - accuracy: 0.8551 - val_loss: 0.3329 - val_accuracy: 0.8520\n",
            "Epoch 11/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3081 - accuracy: 0.8546 - val_loss: 0.3370 - val_accuracy: 0.8423\n",
            "Epoch 12/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.2949 - accuracy: 0.8639 - val_loss: 0.3363 - val_accuracy: 0.8447\n",
            "150/150 [==============================] - 0s 952us/step - loss: 0.3342 - accuracy: 0.8340\n",
            "Epoch 1/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3950 - accuracy: 0.8070 - val_loss: 0.3348 - val_accuracy: 0.8454\n",
            "Epoch 2/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3474 - accuracy: 0.8357 - val_loss: 0.3375 - val_accuracy: 0.8510\n",
            "Epoch 3/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3275 - accuracy: 0.8433 - val_loss: 0.3306 - val_accuracy: 0.8483\n",
            "Epoch 4/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3224 - accuracy: 0.8468 - val_loss: 0.3366 - val_accuracy: 0.8504\n",
            "Epoch 5/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3179 - accuracy: 0.8497 - val_loss: 0.3411 - val_accuracy: 0.8399\n",
            "Epoch 6/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3158 - accuracy: 0.8523 - val_loss: 0.3374 - val_accuracy: 0.8494\n",
            "Epoch 7/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3060 - accuracy: 0.8571 - val_loss: 0.3345 - val_accuracy: 0.8480\n",
            "Epoch 8/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3040 - accuracy: 0.8575 - val_loss: 0.3323 - val_accuracy: 0.8515\n",
            "150/150 [==============================] - 0s 941us/step - loss: 0.3442 - accuracy: 0.8493\n",
            "Epoch 1/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.4098 - accuracy: 0.8023 - val_loss: 0.3459 - val_accuracy: 0.8444\n",
            "Epoch 2/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3494 - accuracy: 0.8389 - val_loss: 0.3816 - val_accuracy: 0.7993\n",
            "Epoch 3/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3373 - accuracy: 0.8395 - val_loss: 0.3449 - val_accuracy: 0.8396\n",
            "Epoch 4/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3275 - accuracy: 0.8490 - val_loss: 0.3409 - val_accuracy: 0.8521\n",
            "Epoch 5/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3251 - accuracy: 0.8481 - val_loss: 0.3312 - val_accuracy: 0.8527\n",
            "Epoch 6/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3117 - accuracy: 0.8538 - val_loss: 0.3346 - val_accuracy: 0.8440\n",
            "Epoch 7/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3170 - accuracy: 0.8494 - val_loss: 0.3640 - val_accuracy: 0.8140\n",
            "Epoch 8/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3149 - accuracy: 0.8535 - val_loss: 0.3373 - val_accuracy: 0.8517\n",
            "Epoch 9/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3055 - accuracy: 0.8593 - val_loss: 0.3369 - val_accuracy: 0.8517\n",
            "Epoch 10/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.2990 - accuracy: 0.8601 - val_loss: 0.3432 - val_accuracy: 0.8399\n",
            "150/150 [==============================] - 0s 901us/step - loss: 0.3600 - accuracy: 0.8247\n",
            "Epoch 1/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.4069 - accuracy: 0.8007 - val_loss: 0.3755 - val_accuracy: 0.8078\n",
            "Epoch 2/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3359 - accuracy: 0.8435 - val_loss: 0.3367 - val_accuracy: 0.8443\n",
            "Epoch 3/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3285 - accuracy: 0.8469 - val_loss: 0.3272 - val_accuracy: 0.8513\n",
            "Epoch 4/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3259 - accuracy: 0.8485 - val_loss: 0.3344 - val_accuracy: 0.8418\n",
            "Epoch 5/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3150 - accuracy: 0.8525 - val_loss: 0.3364 - val_accuracy: 0.8505\n",
            "Epoch 6/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3084 - accuracy: 0.8577 - val_loss: 0.3365 - val_accuracy: 0.8397\n",
            "Epoch 7/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3090 - accuracy: 0.8560 - val_loss: 0.3319 - val_accuracy: 0.8512\n",
            "Epoch 8/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3108 - accuracy: 0.8563 - val_loss: 0.3453 - val_accuracy: 0.8380\n",
            "150/150 [==============================] - 0s 908us/step - loss: 0.3403 - accuracy: 0.8400\n",
            "Epoch 1/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.4203 - accuracy: 0.7894 - val_loss: 0.3658 - val_accuracy: 0.8285\n",
            "Epoch 2/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3530 - accuracy: 0.8349 - val_loss: 0.3359 - val_accuracy: 0.8502\n",
            "Epoch 3/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3379 - accuracy: 0.8446 - val_loss: 0.3672 - val_accuracy: 0.8383\n",
            "Epoch 4/100\n",
            "1350/1350 [==============================] - 3s 3ms/step - loss: 0.3238 - accuracy: 0.8497 - val_loss: 0.3403 - val_accuracy: 0.8470\n",
            "Epoch 5/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3133 - accuracy: 0.8553 - val_loss: 0.3348 - val_accuracy: 0.8502\n",
            "Epoch 6/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3235 - accuracy: 0.8482 - val_loss: 0.3350 - val_accuracy: 0.8444\n",
            "Epoch 7/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3035 - accuracy: 0.8604 - val_loss: 0.3593 - val_accuracy: 0.8437\n",
            "Epoch 8/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3037 - accuracy: 0.8563 - val_loss: 0.3359 - val_accuracy: 0.8411\n",
            "Epoch 9/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3071 - accuracy: 0.8567 - val_loss: 0.3357 - val_accuracy: 0.8445\n",
            "Epoch 10/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.2946 - accuracy: 0.8582 - val_loss: 0.3690 - val_accuracy: 0.8482\n",
            "150/150 [==============================] - 0s 862us/step - loss: 0.3793 - accuracy: 0.8520\n",
            "Epoch 1/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.4126 - accuracy: 0.7998 - val_loss: 0.3432 - val_accuracy: 0.8394\n",
            "Epoch 2/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3429 - accuracy: 0.8412 - val_loss: 0.3379 - val_accuracy: 0.8393\n",
            "Epoch 3/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3326 - accuracy: 0.8475 - val_loss: 0.3347 - val_accuracy: 0.8426\n",
            "Epoch 4/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3269 - accuracy: 0.8425 - val_loss: 0.3268 - val_accuracy: 0.8505\n",
            "Epoch 5/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3219 - accuracy: 0.8504 - val_loss: 0.3389 - val_accuracy: 0.8378\n",
            "Epoch 6/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3129 - accuracy: 0.8550 - val_loss: 0.3279 - val_accuracy: 0.8481\n",
            "Epoch 7/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3111 - accuracy: 0.8539 - val_loss: 0.3303 - val_accuracy: 0.8473\n",
            "Epoch 8/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3138 - accuracy: 0.8525 - val_loss: 0.3341 - val_accuracy: 0.8479\n",
            "Epoch 9/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3099 - accuracy: 0.8582 - val_loss: 0.3454 - val_accuracy: 0.8489\n",
            "150/150 [==============================] - 0s 920us/step - loss: 0.3423 - accuracy: 0.8360\n",
            "Epoch 1/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.4081 - accuracy: 0.8041 - val_loss: 0.3493 - val_accuracy: 0.8359\n",
            "Epoch 2/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3557 - accuracy: 0.8305 - val_loss: 0.3500 - val_accuracy: 0.8318\n",
            "Epoch 3/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3381 - accuracy: 0.8405 - val_loss: 0.3366 - val_accuracy: 0.8501\n",
            "Epoch 4/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3238 - accuracy: 0.8469 - val_loss: 0.3641 - val_accuracy: 0.8145\n",
            "Epoch 5/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3297 - accuracy: 0.8417 - val_loss: 0.3325 - val_accuracy: 0.8501\n",
            "Epoch 6/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3127 - accuracy: 0.8567 - val_loss: 0.3383 - val_accuracy: 0.8459\n",
            "Epoch 7/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3111 - accuracy: 0.8536 - val_loss: 0.3421 - val_accuracy: 0.8509\n",
            "Epoch 8/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3057 - accuracy: 0.8589 - val_loss: 0.3325 - val_accuracy: 0.8518\n",
            "Epoch 9/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3056 - accuracy: 0.8562 - val_loss: 0.3378 - val_accuracy: 0.8489\n",
            "Epoch 10/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3041 - accuracy: 0.8530 - val_loss: 0.3486 - val_accuracy: 0.8476\n",
            "Epoch 11/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3059 - accuracy: 0.8591 - val_loss: 0.3406 - val_accuracy: 0.8499\n",
            "Epoch 12/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.2937 - accuracy: 0.8587 - val_loss: 0.3614 - val_accuracy: 0.8422\n",
            "Epoch 13/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.2925 - accuracy: 0.8624 - val_loss: 0.3653 - val_accuracy: 0.8501\n",
            "150/150 [==============================] - 0s 911us/step - loss: 0.3353 - accuracy: 0.8520\n",
            "Epoch 1/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.4068 - accuracy: 0.8100 - val_loss: 0.3414 - val_accuracy: 0.8407\n",
            "Epoch 2/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3549 - accuracy: 0.8306 - val_loss: 0.3413 - val_accuracy: 0.8506\n",
            "Epoch 3/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3324 - accuracy: 0.8430 - val_loss: 0.3344 - val_accuracy: 0.8449\n",
            "Epoch 4/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3248 - accuracy: 0.8489 - val_loss: 0.3325 - val_accuracy: 0.8502\n",
            "Epoch 5/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3064 - accuracy: 0.8582 - val_loss: 0.3369 - val_accuracy: 0.8444\n",
            "Epoch 6/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3060 - accuracy: 0.8573 - val_loss: 0.3403 - val_accuracy: 0.8485\n",
            "Epoch 7/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3129 - accuracy: 0.8506 - val_loss: 0.3396 - val_accuracy: 0.8424\n",
            "Epoch 8/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3062 - accuracy: 0.8520 - val_loss: 0.3509 - val_accuracy: 0.8415\n",
            "Epoch 9/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3060 - accuracy: 0.8516 - val_loss: 0.3446 - val_accuracy: 0.8397\n",
            "150/150 [==============================] - 0s 896us/step - loss: 0.3385 - accuracy: 0.8333\n",
            "Epoch 1/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.4076 - accuracy: 0.7994 - val_loss: 0.3458 - val_accuracy: 0.8410\n",
            "Epoch 2/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3534 - accuracy: 0.8345 - val_loss: 0.3736 - val_accuracy: 0.8230\n",
            "Epoch 3/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3491 - accuracy: 0.8377 - val_loss: 0.3497 - val_accuracy: 0.8308\n",
            "Epoch 4/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3246 - accuracy: 0.8502 - val_loss: 0.3415 - val_accuracy: 0.8445\n",
            "Epoch 5/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3278 - accuracy: 0.8437 - val_loss: 0.3297 - val_accuracy: 0.8507\n",
            "Epoch 6/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3190 - accuracy: 0.8502 - val_loss: 0.3505 - val_accuracy: 0.8314\n",
            "Epoch 7/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3222 - accuracy: 0.8466 - val_loss: 0.3658 - val_accuracy: 0.8451\n",
            "Epoch 8/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.2966 - accuracy: 0.8603 - val_loss: 0.3445 - val_accuracy: 0.8390\n",
            "Epoch 9/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.2980 - accuracy: 0.8596 - val_loss: 0.3521 - val_accuracy: 0.8473\n",
            "Epoch 10/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.2958 - accuracy: 0.8576 - val_loss: 0.3520 - val_accuracy: 0.8464\n",
            "150/150 [==============================] - 0s 947us/step - loss: 0.3472 - accuracy: 0.8513\n",
            "Epoch 1/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.4060 - accuracy: 0.8079 - val_loss: 0.3735 - val_accuracy: 0.8237\n",
            "Epoch 2/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3405 - accuracy: 0.8396 - val_loss: 0.3475 - val_accuracy: 0.8369\n",
            "Epoch 3/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3327 - accuracy: 0.8399 - val_loss: 0.3516 - val_accuracy: 0.8390\n",
            "Epoch 4/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3255 - accuracy: 0.8465 - val_loss: 0.3682 - val_accuracy: 0.8420\n",
            "Epoch 5/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3214 - accuracy: 0.8467 - val_loss: 0.3308 - val_accuracy: 0.8463\n",
            "Epoch 6/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3214 - accuracy: 0.8497 - val_loss: 0.3268 - val_accuracy: 0.8523\n",
            "Epoch 7/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3145 - accuracy: 0.8502 - val_loss: 0.3382 - val_accuracy: 0.8408\n",
            "Epoch 8/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3109 - accuracy: 0.8534 - val_loss: 0.3353 - val_accuracy: 0.8492\n",
            "Epoch 9/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3096 - accuracy: 0.8490 - val_loss: 0.3322 - val_accuracy: 0.8442\n",
            "Epoch 10/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3016 - accuracy: 0.8564 - val_loss: 0.3436 - val_accuracy: 0.8406\n",
            "Epoch 11/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.2941 - accuracy: 0.8626 - val_loss: 0.3376 - val_accuracy: 0.8440\n",
            "150/150 [==============================] - 0s 989us/step - loss: 0.3217 - accuracy: 0.8520\n",
            "Epoch 1/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.4051 - accuracy: 0.8031 - val_loss: 0.3523 - val_accuracy: 0.8392\n",
            "Epoch 2/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3529 - accuracy: 0.8376 - val_loss: 0.3397 - val_accuracy: 0.8392\n",
            "Epoch 3/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3358 - accuracy: 0.8464 - val_loss: 0.3251 - val_accuracy: 0.8536\n",
            "Epoch 4/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3239 - accuracy: 0.8451 - val_loss: 0.3268 - val_accuracy: 0.8487\n",
            "Epoch 5/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3316 - accuracy: 0.8404 - val_loss: 0.3328 - val_accuracy: 0.8504\n",
            "Epoch 6/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3137 - accuracy: 0.8502 - val_loss: 0.3290 - val_accuracy: 0.8475\n",
            "Epoch 7/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3077 - accuracy: 0.8595 - val_loss: 0.3407 - val_accuracy: 0.8378\n",
            "Epoch 8/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.2961 - accuracy: 0.8626 - val_loss: 0.3282 - val_accuracy: 0.8511\n",
            "150/150 [==============================] - 0s 913us/step - loss: 0.3283 - accuracy: 0.8420\n",
            "Epoch 1/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.4215 - accuracy: 0.7780 - val_loss: 0.3525 - val_accuracy: 0.8395\n",
            "Epoch 2/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3625 - accuracy: 0.8263 - val_loss: 0.3570 - val_accuracy: 0.8296\n",
            "Epoch 3/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3378 - accuracy: 0.8408 - val_loss: 0.3446 - val_accuracy: 0.8328\n",
            "Epoch 4/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3233 - accuracy: 0.8436 - val_loss: 0.3321 - val_accuracy: 0.8481\n",
            "Epoch 5/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3226 - accuracy: 0.8456 - val_loss: 0.3251 - val_accuracy: 0.8534\n",
            "Epoch 6/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3105 - accuracy: 0.8518 - val_loss: 0.3312 - val_accuracy: 0.8470\n",
            "Epoch 7/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3076 - accuracy: 0.8522 - val_loss: 0.3372 - val_accuracy: 0.8456\n",
            "Epoch 8/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3072 - accuracy: 0.8525 - val_loss: 0.3365 - val_accuracy: 0.8451\n",
            "Epoch 9/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3023 - accuracy: 0.8583 - val_loss: 0.3465 - val_accuracy: 0.8404\n",
            "Epoch 10/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3040 - accuracy: 0.8595 - val_loss: 0.3359 - val_accuracy: 0.8493\n",
            "150/150 [==============================] - 0s 960us/step - loss: 0.3417 - accuracy: 0.8573\n",
            "Epoch 1/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.4047 - accuracy: 0.8067 - val_loss: 0.3475 - val_accuracy: 0.8402\n",
            "Epoch 2/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3355 - accuracy: 0.8407 - val_loss: 0.3432 - val_accuracy: 0.8379\n",
            "Epoch 3/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3244 - accuracy: 0.8458 - val_loss: 0.3551 - val_accuracy: 0.8368\n",
            "Epoch 4/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3239 - accuracy: 0.8446 - val_loss: 0.3327 - val_accuracy: 0.8461\n",
            "Epoch 5/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3214 - accuracy: 0.8490 - val_loss: 0.3295 - val_accuracy: 0.8509\n",
            "Epoch 6/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3138 - accuracy: 0.8540 - val_loss: 0.3334 - val_accuracy: 0.8486\n",
            "Epoch 7/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3155 - accuracy: 0.8544 - val_loss: 0.3432 - val_accuracy: 0.8492\n",
            "Epoch 8/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3001 - accuracy: 0.8586 - val_loss: 0.3473 - val_accuracy: 0.8390\n",
            "Epoch 9/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3037 - accuracy: 0.8535 - val_loss: 0.3401 - val_accuracy: 0.8442\n",
            "Epoch 10/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3012 - accuracy: 0.8591 - val_loss: 0.3376 - val_accuracy: 0.8464\n",
            "150/150 [==============================] - 0s 1ms/step - loss: 0.3533 - accuracy: 0.8413\n",
            "Epoch 1/100\n",
            "1350/1350 [==============================] - 4s 2ms/step - loss: 0.4174 - accuracy: 0.7925 - val_loss: 0.3828 - val_accuracy: 0.8067\n",
            "Epoch 2/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3541 - accuracy: 0.8307 - val_loss: 0.3386 - val_accuracy: 0.8476\n",
            "Epoch 3/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3316 - accuracy: 0.8442 - val_loss: 0.3276 - val_accuracy: 0.8519\n",
            "Epoch 4/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3267 - accuracy: 0.8495 - val_loss: 0.3361 - val_accuracy: 0.8490\n",
            "Epoch 5/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3200 - accuracy: 0.8497 - val_loss: 0.3346 - val_accuracy: 0.8506\n",
            "Epoch 6/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3211 - accuracy: 0.8498 - val_loss: 0.3421 - val_accuracy: 0.8387\n",
            "Epoch 7/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3170 - accuracy: 0.8510 - val_loss: 0.3348 - val_accuracy: 0.8496\n",
            "Epoch 8/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3131 - accuracy: 0.8515 - val_loss: 0.3336 - val_accuracy: 0.8514\n",
            "150/150 [==============================] - 0s 883us/step - loss: 0.3278 - accuracy: 0.8440\n",
            "Epoch 1/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.4112 - accuracy: 0.7949 - val_loss: 0.3639 - val_accuracy: 0.8224\n",
            "Epoch 2/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3482 - accuracy: 0.8357 - val_loss: 0.3616 - val_accuracy: 0.8357\n",
            "Epoch 3/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3266 - accuracy: 0.8399 - val_loss: 0.3299 - val_accuracy: 0.8493\n",
            "Epoch 4/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3254 - accuracy: 0.8474 - val_loss: 0.3452 - val_accuracy: 0.8493\n",
            "Epoch 5/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3211 - accuracy: 0.8494 - val_loss: 0.3307 - val_accuracy: 0.8487\n",
            "Epoch 6/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3171 - accuracy: 0.8505 - val_loss: 0.3297 - val_accuracy: 0.8493\n",
            "Epoch 7/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3036 - accuracy: 0.8543 - val_loss: 0.3382 - val_accuracy: 0.8466\n",
            "Epoch 8/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3032 - accuracy: 0.8561 - val_loss: 0.3307 - val_accuracy: 0.8507\n",
            "Epoch 9/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3066 - accuracy: 0.8530 - val_loss: 0.3570 - val_accuracy: 0.8431\n",
            "Epoch 10/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.2923 - accuracy: 0.8662 - val_loss: 0.3450 - val_accuracy: 0.8491\n",
            "Epoch 11/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.2883 - accuracy: 0.8625 - val_loss: 0.3416 - val_accuracy: 0.8495\n",
            "150/150 [==============================] - 0s 978us/step - loss: 0.3342 - accuracy: 0.8440\n",
            "Epoch 1/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.4094 - accuracy: 0.7998 - val_loss: 0.3733 - val_accuracy: 0.8346\n",
            "Epoch 2/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3584 - accuracy: 0.8332 - val_loss: 0.3380 - val_accuracy: 0.8464\n",
            "Epoch 3/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3325 - accuracy: 0.8444 - val_loss: 0.3315 - val_accuracy: 0.8501\n",
            "Epoch 4/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3274 - accuracy: 0.8476 - val_loss: 0.3282 - val_accuracy: 0.8505\n",
            "Epoch 5/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3247 - accuracy: 0.8468 - val_loss: 0.3360 - val_accuracy: 0.8405\n",
            "Epoch 6/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3165 - accuracy: 0.8505 - val_loss: 0.3346 - val_accuracy: 0.8484\n",
            "Epoch 7/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3110 - accuracy: 0.8513 - val_loss: 0.3306 - val_accuracy: 0.8505\n",
            "Epoch 8/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3085 - accuracy: 0.8537 - val_loss: 0.3353 - val_accuracy: 0.8470\n",
            "Epoch 9/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3012 - accuracy: 0.8533 - val_loss: 0.3469 - val_accuracy: 0.8413\n",
            "150/150 [==============================] - 0s 912us/step - loss: 0.3470 - accuracy: 0.8340\n",
            "Epoch 1/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.4023 - accuracy: 0.8097 - val_loss: 0.3386 - val_accuracy: 0.8427\n",
            "Epoch 2/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3432 - accuracy: 0.8376 - val_loss: 0.3393 - val_accuracy: 0.8464\n",
            "Epoch 3/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3334 - accuracy: 0.8422 - val_loss: 0.3259 - val_accuracy: 0.8540\n",
            "Epoch 4/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3200 - accuracy: 0.8516 - val_loss: 0.3354 - val_accuracy: 0.8440\n",
            "Epoch 5/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3204 - accuracy: 0.8468 - val_loss: 0.3259 - val_accuracy: 0.8510\n",
            "Epoch 6/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3259 - accuracy: 0.8474 - val_loss: 0.3293 - val_accuracy: 0.8476\n",
            "Epoch 7/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3115 - accuracy: 0.8530 - val_loss: 0.3289 - val_accuracy: 0.8525\n",
            "Epoch 8/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3068 - accuracy: 0.8527 - val_loss: 0.3337 - val_accuracy: 0.8505\n",
            "150/150 [==============================] - 0s 951us/step - loss: 0.3147 - accuracy: 0.8553\n",
            "Epoch 1/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.4152 - accuracy: 0.7972 - val_loss: 0.3661 - val_accuracy: 0.8190\n",
            "Epoch 2/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3524 - accuracy: 0.8370 - val_loss: 0.3351 - val_accuracy: 0.8492\n",
            "Epoch 3/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3358 - accuracy: 0.8453 - val_loss: 0.3309 - val_accuracy: 0.8482\n",
            "Epoch 4/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3318 - accuracy: 0.8434 - val_loss: 0.3612 - val_accuracy: 0.8227\n",
            "Epoch 5/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3159 - accuracy: 0.8528 - val_loss: 0.3490 - val_accuracy: 0.8362\n",
            "Epoch 6/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3208 - accuracy: 0.8491 - val_loss: 0.3385 - val_accuracy: 0.8531\n",
            "Epoch 7/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3138 - accuracy: 0.8523 - val_loss: 0.3433 - val_accuracy: 0.8314\n",
            "Epoch 8/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3099 - accuracy: 0.8527 - val_loss: 0.3299 - val_accuracy: 0.8455\n",
            "Epoch 9/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3040 - accuracy: 0.8569 - val_loss: 0.3322 - val_accuracy: 0.8506\n",
            "Epoch 10/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.2964 - accuracy: 0.8631 - val_loss: 0.3367 - val_accuracy: 0.8433\n",
            "Epoch 11/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.3021 - accuracy: 0.8618 - val_loss: 0.3427 - val_accuracy: 0.8511\n",
            "Epoch 12/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.2841 - accuracy: 0.8677 - val_loss: 0.3462 - val_accuracy: 0.8422\n",
            "Epoch 13/100\n",
            "1350/1350 [==============================] - 3s 2ms/step - loss: 0.2862 - accuracy: 0.8667 - val_loss: 0.3486 - val_accuracy: 0.8428\n",
            "150/150 [==============================] - 0s 945us/step - loss: 0.3392 - accuracy: 0.8440\n",
            "Epoch 1/100\n",
            "3000/3000 [==============================] - 6s 2ms/step - loss: 0.4210 - accuracy: 0.8021 - val_loss: 0.3582 - val_accuracy: 0.8291\n",
            "Epoch 2/100\n",
            "3000/3000 [==============================] - 5s 2ms/step - loss: 0.3296 - accuracy: 0.8462 - val_loss: 0.3262 - val_accuracy: 0.8479\n",
            "Epoch 3/100\n",
            "3000/3000 [==============================] - 5s 2ms/step - loss: 0.3226 - accuracy: 0.8493 - val_loss: 0.3265 - val_accuracy: 0.8524\n",
            "Epoch 4/100\n",
            "3000/3000 [==============================] - 6s 2ms/step - loss: 0.3192 - accuracy: 0.8469 - val_loss: 0.3243 - val_accuracy: 0.8498\n",
            "Epoch 5/100\n",
            "3000/3000 [==============================] - 6s 2ms/step - loss: 0.3204 - accuracy: 0.8506 - val_loss: 0.3325 - val_accuracy: 0.8512\n",
            "Epoch 6/100\n",
            "3000/3000 [==============================] - 5s 2ms/step - loss: 0.3118 - accuracy: 0.8534 - val_loss: 0.3403 - val_accuracy: 0.8523\n",
            "Epoch 7/100\n",
            "3000/3000 [==============================] - 6s 2ms/step - loss: 0.3078 - accuracy: 0.8559 - val_loss: 0.3262 - val_accuracy: 0.8527\n",
            "Epoch 8/100\n",
            "3000/3000 [==============================] - 6s 2ms/step - loss: 0.3057 - accuracy: 0.8607 - val_loss: 0.3302 - val_accuracy: 0.8487\n",
            "Epoch 9/100\n",
            "3000/3000 [==============================] - 6s 2ms/step - loss: 0.3003 - accuracy: 0.8564 - val_loss: 0.3267 - val_accuracy: 0.8513\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TSoFvbroGvJD",
        "outputId": "92e51566-2f61-41c0-d10d-a84d25c3a498"
      },
      "source": [
        "# summarize results\n",
        "print('Best: %f using %s' % (grid_result.best_score_, grid_result.best_params_))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best: 0.851133 using {'batch_size': 5, 'epochs': 100, 'learning_rate': 0.001, 'neurons': 100}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uQcN0ywhGvJE",
        "outputId": "e63fda86-8432-4109-e80e-8eb7b3e83a21"
      },
      "source": [
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print('%f (%s) with %r' % (mean, stdev, param))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.849667 (0.006430828017965922) with {'batch_size': 5, 'epochs': 50, 'learning_rate': 0.001, 'neurons': 60}\n",
            "0.850400 (0.0053516303683139995) with {'batch_size': 5, 'epochs': 50, 'learning_rate': 0.001, 'neurons': 80}\n",
            "0.848267 (0.006162246006617268) with {'batch_size': 5, 'epochs': 50, 'learning_rate': 0.001, 'neurons': 100}\n",
            "0.844600 (0.013928227166909366) with {'batch_size': 5, 'epochs': 50, 'learning_rate': 0.01, 'neurons': 60}\n",
            "0.846533 (0.004008887621045862) with {'batch_size': 5, 'epochs': 50, 'learning_rate': 0.01, 'neurons': 80}\n",
            "0.839600 (0.010621568575204979) with {'batch_size': 5, 'epochs': 50, 'learning_rate': 0.01, 'neurons': 100}\n",
            "0.849933 (0.004939186220762856) with {'batch_size': 5, 'epochs': 100, 'learning_rate': 0.001, 'neurons': 60}\n",
            "0.846600 (0.008466664731056492) with {'batch_size': 5, 'epochs': 100, 'learning_rate': 0.001, 'neurons': 80}\n",
            "0.851133 (0.00684461830132255) with {'batch_size': 5, 'epochs': 100, 'learning_rate': 0.001, 'neurons': 100}\n",
            "0.846333 (0.0076434419840506794) with {'batch_size': 5, 'epochs': 100, 'learning_rate': 0.01, 'neurons': 60}\n",
            "0.845667 (0.006974551366404084) with {'batch_size': 5, 'epochs': 100, 'learning_rate': 0.01, 'neurons': 80}\n",
            "0.843600 (0.007752850196720381) with {'batch_size': 5, 'epochs': 100, 'learning_rate': 0.01, 'neurons': 100}\n",
            "0.847467 (0.006550986353414152) with {'batch_size': 10, 'epochs': 50, 'learning_rate': 0.001, 'neurons': 60}\n",
            "0.845200 (0.005946433268267152) with {'batch_size': 10, 'epochs': 50, 'learning_rate': 0.001, 'neurons': 80}\n",
            "0.848267 (0.007298100701991682) with {'batch_size': 10, 'epochs': 50, 'learning_rate': 0.001, 'neurons': 100}\n",
            "0.847800 (0.007453863544689222) with {'batch_size': 10, 'epochs': 50, 'learning_rate': 0.01, 'neurons': 60}\n",
            "0.848000 (0.004402016623614556) with {'batch_size': 10, 'epochs': 50, 'learning_rate': 0.01, 'neurons': 80}\n",
            "0.848133 (0.006965316393086776) with {'batch_size': 10, 'epochs': 50, 'learning_rate': 0.01, 'neurons': 100}\n",
            "0.849333 (0.0064152622634789) with {'batch_size': 10, 'epochs': 100, 'learning_rate': 0.001, 'neurons': 60}\n",
            "0.850000 (0.005481271845602674) with {'batch_size': 10, 'epochs': 100, 'learning_rate': 0.001, 'neurons': 80}\n",
            "0.850000 (0.00762451853250853) with {'batch_size': 10, 'epochs': 100, 'learning_rate': 0.001, 'neurons': 100}\n",
            "0.847000 (0.007231100839820487) with {'batch_size': 10, 'epochs': 100, 'learning_rate': 0.01, 'neurons': 60}\n",
            "0.842400 (0.009536831967409752) with {'batch_size': 10, 'epochs': 100, 'learning_rate': 0.01, 'neurons': 80}\n",
            "0.846533 (0.006862464405345037) with {'batch_size': 10, 'epochs': 100, 'learning_rate': 0.01, 'neurons': 100}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eLy7aMB8GvJE"
      },
      "source": [
        "# best full model\n",
        "best_model = grid_result.best_estimator_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9zo1SGR8-TYB",
        "outputId": "dc051fa3-3a3c-4466-d1cd-1d5cf4d52e12"
      },
      "source": [
        "best_model = load_model('best_model.h5') \r\n",
        "\r\n",
        "# evaluate the model\r\n",
        "_, train_acc =  best_model.evaluate(X_train, y_train)\r\n",
        "_, test_acc = best_model.evaluate(X_test, y_test)\r\n",
        "print('Train: %.3f, Test: %.3f' % (train_acc, test_acc))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "469/469 [==============================] - 0s 833us/step - loss: 0.3135 - accuracy: 0.8524\n",
            "313/313 [==============================] - 0s 849us/step - loss: 0.3245 - accuracy: 0.8513\n",
            "Train: 0.852, Test: 0.851\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AfrHmHguUvVo"
      },
      "source": [
        "As GridSearchCV took too long to compute, we decided to create a model with the optimized parameters for future use."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m6Wir8_QUY-2"
      },
      "source": [
        "# create model\r\n",
        "def create_model():\r\n",
        "    model = Sequential()\r\n",
        "    \r\n",
        "    # hidden layers\r\n",
        "    model.add(Dense(100, input_dim=91, kernel_initializer='uniform', activation='relu'))\r\n",
        "    model.add(Dense(20, kernel_initializer='uniform', activation='relu'))\r\n",
        "    \r\n",
        "    # output layer\r\n",
        "    model.add(Dense(1, kernel_initializer='uniform', activation='sigmoid'))\r\n",
        "    \r\n",
        "    adam = keras.optimizers.Adam(lr = 0.001)\r\n",
        "    model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])\r\n",
        "    \r\n",
        "    return model\r\n",
        "\r\n",
        "model=KerasClassifier(build_fn=create_model, epochs=100, batch_size=5, verbose=1, callbacks=[es,mc])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IejBkSpzVEAV",
        "outputId": "86f84905-8eaf-4188-eadb-84f17f53803b"
      },
      "source": [
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), callbacks=[es, mc], verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "3000/3000 [==============================] - 6s 2ms/step - loss: 0.4163 - accuracy: 0.8100 - val_loss: 0.3417 - val_accuracy: 0.8415\n",
            "Epoch 2/100\n",
            "3000/3000 [==============================] - 5s 2ms/step - loss: 0.3408 - accuracy: 0.8396 - val_loss: 0.3250 - val_accuracy: 0.8499\n",
            "Epoch 3/100\n",
            "3000/3000 [==============================] - 5s 2ms/step - loss: 0.3309 - accuracy: 0.8439 - val_loss: 0.3244 - val_accuracy: 0.8518\n",
            "Epoch 4/100\n",
            "3000/3000 [==============================] - 5s 2ms/step - loss: 0.3131 - accuracy: 0.8499 - val_loss: 0.3244 - val_accuracy: 0.8516\n",
            "Epoch 5/100\n",
            "3000/3000 [==============================] - 5s 2ms/step - loss: 0.3117 - accuracy: 0.8529 - val_loss: 0.3226 - val_accuracy: 0.8534\n",
            "Epoch 6/100\n",
            "3000/3000 [==============================] - 6s 2ms/step - loss: 0.3149 - accuracy: 0.8506 - val_loss: 0.3240 - val_accuracy: 0.8513\n",
            "Epoch 7/100\n",
            "3000/3000 [==============================] - 6s 2ms/step - loss: 0.3135 - accuracy: 0.8514 - val_loss: 0.3259 - val_accuracy: 0.8473\n",
            "Epoch 8/100\n",
            "3000/3000 [==============================] - 5s 2ms/step - loss: 0.3067 - accuracy: 0.8567 - val_loss: 0.3215 - val_accuracy: 0.8516\n",
            "Epoch 9/100\n",
            "3000/3000 [==============================] - 5s 2ms/step - loss: 0.3071 - accuracy: 0.8565 - val_loss: 0.3244 - val_accuracy: 0.8519\n",
            "Epoch 10/100\n",
            "3000/3000 [==============================] - 5s 2ms/step - loss: 0.2981 - accuracy: 0.8611 - val_loss: 0.3250 - val_accuracy: 0.8476\n",
            "Epoch 11/100\n",
            "3000/3000 [==============================] - 5s 2ms/step - loss: 0.2992 - accuracy: 0.8626 - val_loss: 0.3307 - val_accuracy: 0.8507\n",
            "Epoch 12/100\n",
            "3000/3000 [==============================] - 5s 2ms/step - loss: 0.2918 - accuracy: 0.8650 - val_loss: 0.3345 - val_accuracy: 0.8459\n",
            "Epoch 13/100\n",
            "3000/3000 [==============================] - 5s 2ms/step - loss: 0.2931 - accuracy: 0.8631 - val_loss: 0.3315 - val_accuracy: 0.8489\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7ffaa623cac8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iUseqL4NbQh2"
      },
      "source": [
        "Feature Selection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_yzcbcyT1isV"
      },
      "source": [
        "# sensitivity analysis\n",
        "X_mean = pd.DataFrame(X.mean().to_dict(),index=range(91))\n",
        "X_min = X_mean.copy()\n",
        "X_max = X_mean.copy()\n",
        "\n",
        "for i in range(91):\n",
        "  X_min.iloc[i,i] = 0\n",
        "  X_max.iloc[i,i] = 1\n",
        "\n",
        "df_y_min = pd.DataFrame(model.predict(X_min))\n",
        "df_y_min.columns=['income_min']\n",
        "df_y_max = pd.DataFrame(model.predict(X_max))\n",
        "df_y_max.columns=['income_max']\n",
        "df_y = pd.DataFrame(model.predict(X_mean),index=range(91))\n",
        "df_y.columns=['income_mean']\n",
        "names = pd.DataFrame(X.columns.tolist())\n",
        "y_output = names.join(df_y.join(df_y_min.join(df_y_max)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "QzDiXROI6GLY",
        "outputId": "40dbb5a5-db34-48c5-e449-0a6a2296b173"
      },
      "source": [
        "# y variation\r\n",
        "pd.set_option('display.max_rows', 100)\r\n",
        "y_output['Variation']=0\r\n",
        "for i in range(91):\r\n",
        "  if y_output['income_mean'][i] != y_output['income_min'][i] and y_output['income_mean'][i] != y_output['income_max'][i]:\r\n",
        "    y_output['Variation'][i] = 2\r\n",
        "  elif y_output['income_mean'][i] != y_output['income_min'][i]:\r\n",
        "    y_output['Variation'][i] = 1\r\n",
        "  elif y_output['income_mean'][i] !=  y_output['income_max'][i]:\r\n",
        "    y_output['Variation'][i] = 1\r\n",
        "  else:\r\n",
        "    y_output['Variation'][i] = 0\r\n",
        "\r\n",
        "y_output.sort_values(['Variation'], ascending=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if sys.path[0] == '':\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # Remove the CWD from sys.path while we load stuff.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>income_mean</th>\n",
              "      <th>income_min</th>\n",
              "      <th>income_max</th>\n",
              "      <th>Variation</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>race_Black</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>race_White</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>m_Married-civ-spouse</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>r_Husband</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>m_Divorced</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>r_Not-in-family</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>r_Own-child</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>r_Unmarried</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>o_Prof-specialty</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>o_Other-service</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>o_Handlers-cleaners</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>o_Farming-fishing</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>demogweight</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>o_Craft-repair</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>o_Adm-clerical</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>m_Never-married</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88</th>\n",
              "      <td>c_United-States</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>education-num</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>sex</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>w_Private</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>capital-gain</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>capital-loss</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60</th>\n",
              "      <td>c_Germany</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>hours-per-week</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59</th>\n",
              "      <td>c_France</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69</th>\n",
              "      <td>c_Iran</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>68</th>\n",
              "      <td>c_India</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65</th>\n",
              "      <td>c_Honduras</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64</th>\n",
              "      <td>c_Holand-Netherlands</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67</th>\n",
              "      <td>c_Hungary</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>66</th>\n",
              "      <td>c_Hong</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61</th>\n",
              "      <td>c_Greece</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62</th>\n",
              "      <td>c_Guatemala</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63</th>\n",
              "      <td>c_Haiti</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>70</th>\n",
              "      <td>c_Ireland</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>age</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75</th>\n",
              "      <td>c_Mexico</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>71</th>\n",
              "      <td>c_Italy</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>81</th>\n",
              "      <td>c_Portugal</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>89</th>\n",
              "      <td>c_Vietnam</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87</th>\n",
              "      <td>c_Trinadad&amp;Tobago</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>86</th>\n",
              "      <td>c_Thailand</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>85</th>\n",
              "      <td>c_Taiwan</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>84</th>\n",
              "      <td>c_South</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>83</th>\n",
              "      <td>c_Scotland</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>82</th>\n",
              "      <td>c_Puerto-Rico</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>80</th>\n",
              "      <td>c_Poland</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>72</th>\n",
              "      <td>c_Jamaica</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>79</th>\n",
              "      <td>c_Philippines</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>78</th>\n",
              "      <td>c_Peru</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>77</th>\n",
              "      <td>c_Outlying-US(Guam-USVI-etc)</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>76</th>\n",
              "      <td>c_Nicaragua</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57</th>\n",
              "      <td>c_El-Salvador</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>74</th>\n",
              "      <td>c_Laos</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>73</th>\n",
              "      <td>c_Japan</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>58</th>\n",
              "      <td>c_England</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>race_Asian-Pac-Islander</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56</th>\n",
              "      <td>c_Ecuador</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>w_Without-pay</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>o_Protective-serv</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>o_Priv-house-serv</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>o_Machine-op-inspct</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>o_Exec-managerial</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>o_Armed-Forces</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>o_?</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>w_State-gov</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55</th>\n",
              "      <td>c_Dominican-Republic</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>w_Self-emp-not-inc</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>w_Self-emp-inc</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>w_Never-worked</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>w_Local-gov</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>w_Federal-gov</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>w_?</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>o_Sales</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>o_Tech-support</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>o_Transport-moving</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>m_Married-AF-spouse</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>m_Married-spouse-absent</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>m_Separated</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>m_Widowed</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>r_Other-relative</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>r_Wife</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>race_Amer-Indian-Eskimo</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>race_Other</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>c_?</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50</th>\n",
              "      <td>c_Cambodia</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51</th>\n",
              "      <td>c_Canada</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52</th>\n",
              "      <td>c_China</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53</th>\n",
              "      <td>c_Columbia</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54</th>\n",
              "      <td>c_Cuba</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>90</th>\n",
              "      <td>c_Yugoslavia</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                               0  income_mean  ...  income_max  Variation\n",
              "46                    race_Black            0  ...           0          1\n",
              "48                    race_White            0  ...           0          1\n",
              "33          m_Married-civ-spouse            0  ...           1          1\n",
              "38                     r_Husband            0  ...           0          1\n",
              "31                    m_Divorced            0  ...           0          1\n",
              "39               r_Not-in-family            0  ...           0          1\n",
              "41                   r_Own-child            0  ...           0          1\n",
              "42                   r_Unmarried            0  ...           0          1\n",
              "26              o_Prof-specialty            0  ...           0          1\n",
              "24               o_Other-service            0  ...           0          1\n",
              "22           o_Handlers-cleaners            0  ...           0          1\n",
              "21             o_Farming-fishing            0  ...           0          1\n",
              "1                    demogweight            0  ...           1          1\n",
              "19                o_Craft-repair            0  ...           0          1\n",
              "17                o_Adm-clerical            0  ...           0          1\n",
              "35               m_Never-married            0  ...           0          1\n",
              "88               c_United-States            0  ...           0          1\n",
              "2                  education-num            0  ...           1          1\n",
              "3                            sex            0  ...           1          1\n",
              "11                     w_Private            0  ...           0          1\n",
              "4                   capital-gain            0  ...           1          1\n",
              "5                   capital-loss            0  ...           1          1\n",
              "60                     c_Germany            0  ...           1          1\n",
              "6                 hours-per-week            0  ...           1          1\n",
              "59                      c_France            0  ...           0          0\n",
              "69                        c_Iran            0  ...           0          0\n",
              "68                       c_India            0  ...           0          0\n",
              "65                    c_Honduras            0  ...           0          0\n",
              "64          c_Holand-Netherlands            0  ...           0          0\n",
              "67                     c_Hungary            0  ...           0          0\n",
              "66                        c_Hong            0  ...           0          0\n",
              "61                      c_Greece            0  ...           0          0\n",
              "62                   c_Guatemala            0  ...           0          0\n",
              "63                       c_Haiti            0  ...           0          0\n",
              "70                     c_Ireland            0  ...           0          0\n",
              "0                            age            0  ...           0          0\n",
              "75                      c_Mexico            0  ...           0          0\n",
              "71                       c_Italy            0  ...           0          0\n",
              "81                    c_Portugal            0  ...           0          0\n",
              "89                     c_Vietnam            0  ...           0          0\n",
              "87             c_Trinadad&Tobago            0  ...           0          0\n",
              "86                    c_Thailand            0  ...           0          0\n",
              "85                      c_Taiwan            0  ...           0          0\n",
              "84                       c_South            0  ...           0          0\n",
              "83                    c_Scotland            0  ...           0          0\n",
              "82                 c_Puerto-Rico            0  ...           0          0\n",
              "80                      c_Poland            0  ...           0          0\n",
              "72                     c_Jamaica            0  ...           0          0\n",
              "79                 c_Philippines            0  ...           0          0\n",
              "78                        c_Peru            0  ...           0          0\n",
              "77  c_Outlying-US(Guam-USVI-etc)            0  ...           0          0\n",
              "76                   c_Nicaragua            0  ...           0          0\n",
              "57                 c_El-Salvador            0  ...           0          0\n",
              "74                        c_Laos            0  ...           0          0\n",
              "73                       c_Japan            0  ...           0          0\n",
              "58                     c_England            0  ...           0          0\n",
              "45       race_Asian-Pac-Islander            0  ...           0          0\n",
              "56                     c_Ecuador            0  ...           0          0\n",
              "15                 w_Without-pay            0  ...           0          0\n",
              "27             o_Protective-serv            0  ...           0          0\n",
              "25             o_Priv-house-serv            0  ...           0          0\n",
              "23           o_Machine-op-inspct            0  ...           0          0\n",
              "20             o_Exec-managerial            0  ...           0          0\n",
              "18                o_Armed-Forces            0  ...           0          0\n",
              "16                           o_?            0  ...           0          0\n",
              "14                   w_State-gov            0  ...           0          0\n",
              "55          c_Dominican-Republic            0  ...           0          0\n",
              "13            w_Self-emp-not-inc            0  ...           0          0\n",
              "12                w_Self-emp-inc            0  ...           0          0\n",
              "10                w_Never-worked            0  ...           0          0\n",
              "9                    w_Local-gov            0  ...           0          0\n",
              "8                  w_Federal-gov            0  ...           0          0\n",
              "7                            w_?            0  ...           0          0\n",
              "28                       o_Sales            0  ...           0          0\n",
              "29                o_Tech-support            0  ...           0          0\n",
              "30            o_Transport-moving            0  ...           0          0\n",
              "32           m_Married-AF-spouse            0  ...           0          0\n",
              "34       m_Married-spouse-absent            0  ...           0          0\n",
              "36                   m_Separated            0  ...           0          0\n",
              "37                     m_Widowed            0  ...           0          0\n",
              "40              r_Other-relative            0  ...           0          0\n",
              "43                        r_Wife            0  ...           0          0\n",
              "44       race_Amer-Indian-Eskimo            0  ...           0          0\n",
              "47                    race_Other            0  ...           0          0\n",
              "49                           c_?            0  ...           0          0\n",
              "50                    c_Cambodia            0  ...           0          0\n",
              "51                      c_Canada            0  ...           0          0\n",
              "52                       c_China            0  ...           0          0\n",
              "53                    c_Columbia            0  ...           0          0\n",
              "54                        c_Cuba            0  ...           0          0\n",
              "90                  c_Yugoslavia            0  ...           0          0\n",
              "\n",
              "[91 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rZyb55isGvJF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "29cecbdf-68f8-460b-90f1-7594ef433cc4"
      },
      "source": [
        "# get importance\n",
        "perm = PermutationImportance(model).fit(X_train, y_train, callback=[es,mc])\n",
        "eli5.show_weights(perm, feature_names = X_train.columns.tolist(), top=100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3000/3000 [==============================] - 3s 884us/step - loss: 0.2843 - accuracy: 0.8661\n",
            "3000/3000 [==============================] - 3s 873us/step - loss: 0.3171 - accuracy: 0.8488\n",
            "3000/3000 [==============================] - 3s 879us/step - loss: 0.2851 - accuracy: 0.8653\n",
            "3000/3000 [==============================] - 3s 894us/step - loss: 0.3301 - accuracy: 0.8355\n",
            "3000/3000 [==============================] - 3s 883us/step - loss: 0.2938 - accuracy: 0.8625\n",
            "3000/3000 [==============================] - 3s 871us/step - loss: 0.4145 - accuracy: 0.8361\n",
            "3000/3000 [==============================] - 3s 887us/step - loss: 0.2953 - accuracy: 0.8602\n",
            "3000/3000 [==============================] - 3s 876us/step - loss: 0.3010 - accuracy: 0.8584\n",
            "3000/3000 [==============================] - 3s 875us/step - loss: 0.2898 - accuracy: 0.8645\n",
            "3000/3000 [==============================] - 3s 873us/step - loss: 0.2854 - accuracy: 0.8653\n",
            "3000/3000 [==============================] - 3s 883us/step - loss: 0.2909 - accuracy: 0.8622\n",
            "3000/3000 [==============================] - 3s 898us/step - loss: 0.2842 - accuracy: 0.8661\n",
            "3000/3000 [==============================] - 3s 943us/step - loss: 0.2978 - accuracy: 0.8541\n",
            "3000/3000 [==============================] - 3s 883us/step - loss: 0.2864 - accuracy: 0.8649\n",
            "3000/3000 [==============================] - 3s 890us/step - loss: 0.2924 - accuracy: 0.8587\n",
            "3000/3000 [==============================] - 3s 884us/step - loss: 0.2887 - accuracy: 0.8632\n",
            "3000/3000 [==============================] - 3s 895us/step - loss: 0.2847 - accuracy: 0.8659\n",
            "3000/3000 [==============================] - 3s 896us/step - loss: 0.2898 - accuracy: 0.8635\n",
            "3000/3000 [==============================] - 3s 891us/step - loss: 0.2986 - accuracy: 0.8609\n",
            "3000/3000 [==============================] - 3s 894us/step - loss: 0.2845 - accuracy: 0.8659\n",
            "3000/3000 [==============================] - 3s 863us/step - loss: 0.3001 - accuracy: 0.8553\n",
            "3000/3000 [==============================] - 3s 860us/step - loss: 0.2882 - accuracy: 0.8651\n",
            "3000/3000 [==============================] - 3s 854us/step - loss: 0.2986 - accuracy: 0.8609\n",
            "3000/3000 [==============================] - 3s 869us/step - loss: 0.3030 - accuracy: 0.8609\n",
            "3000/3000 [==============================] - 3s 885us/step - loss: 0.2958 - accuracy: 0.8594\n",
            "3000/3000 [==============================] - 3s 898us/step - loss: 0.3057 - accuracy: 0.8571\n",
            "3000/3000 [==============================] - 3s 1ms/step - loss: 0.2986 - accuracy: 0.8648\n",
            "3000/3000 [==============================] - 4s 1ms/step - loss: 0.2889 - accuracy: 0.8639\n",
            "3000/3000 [==============================] - 4s 1ms/step - loss: 0.2867 - accuracy: 0.8642\n",
            "3000/3000 [==============================] - 3s 1ms/step - loss: 0.2922 - accuracy: 0.8617\n",
            "3000/3000 [==============================] - 3s 873us/step - loss: 0.2862 - accuracy: 0.8655\n",
            "3000/3000 [==============================] - 3s 885us/step - loss: 0.2904 - accuracy: 0.8616\n",
            "3000/3000 [==============================] - 3s 892us/step - loss: 0.3133 - accuracy: 0.8511\n",
            "3000/3000 [==============================] - 3s 895us/step - loss: 0.2847 - accuracy: 0.8659\n",
            "3000/3000 [==============================] - 3s 882us/step - loss: 0.2936 - accuracy: 0.8652\n",
            "3000/3000 [==============================] - 3s 883us/step - loss: 0.2866 - accuracy: 0.8659\n",
            "3000/3000 [==============================] - 3s 896us/step - loss: 0.3567 - accuracy: 0.8310\n",
            "3000/3000 [==============================] - 3s 888us/step - loss: 0.2964 - accuracy: 0.8634\n",
            "3000/3000 [==============================] - 3s 900us/step - loss: 0.2908 - accuracy: 0.8634\n",
            "3000/3000 [==============================] - 3s 895us/step - loss: 0.3089 - accuracy: 0.8489\n",
            "3000/3000 [==============================] - 3s 915us/step - loss: 0.2958 - accuracy: 0.8608\n",
            "3000/3000 [==============================] - 3s 903us/step - loss: 0.2917 - accuracy: 0.8643\n",
            "3000/3000 [==============================] - 3s 888us/step - loss: 0.2990 - accuracy: 0.8618\n",
            "3000/3000 [==============================] - 3s 905us/step - loss: 0.2935 - accuracy: 0.8625\n",
            "3000/3000 [==============================] - 3s 894us/step - loss: 0.2873 - accuracy: 0.8650\n",
            "3000/3000 [==============================] - 3s 896us/step - loss: 0.2872 - accuracy: 0.8645\n",
            "3000/3000 [==============================] - 3s 888us/step - loss: 0.2868 - accuracy: 0.8641\n",
            "3000/3000 [==============================] - 3s 880us/step - loss: 0.2911 - accuracy: 0.8632\n",
            "3000/3000 [==============================] - 3s 886us/step - loss: 0.2877 - accuracy: 0.8653\n",
            "3000/3000 [==============================] - 3s 967us/step - loss: 0.2913 - accuracy: 0.8599\n",
            "3000/3000 [==============================] - 3s 1ms/step - loss: 0.2896 - accuracy: 0.8627\n",
            "3000/3000 [==============================] - 3s 929us/step - loss: 0.2844 - accuracy: 0.8659\n",
            "3000/3000 [==============================] - 3s 887us/step - loss: 0.2854 - accuracy: 0.8659\n",
            "3000/3000 [==============================] - 3s 898us/step - loss: 0.2853 - accuracy: 0.8658\n",
            "3000/3000 [==============================] - 3s 910us/step - loss: 0.2857 - accuracy: 0.8657\n",
            "3000/3000 [==============================] - 3s 887us/step - loss: 0.2849 - accuracy: 0.8657\n",
            "3000/3000 [==============================] - 3s 898us/step - loss: 0.2883 - accuracy: 0.8654\n",
            "3000/3000 [==============================] - 3s 894us/step - loss: 0.2850 - accuracy: 0.8658\n",
            "3000/3000 [==============================] - 3s 902us/step - loss: 0.2875 - accuracy: 0.8657\n",
            "3000/3000 [==============================] - 3s 899us/step - loss: 0.2855 - accuracy: 0.8658\n",
            "3000/3000 [==============================] - 3s 911us/step - loss: 0.2843 - accuracy: 0.8661\n",
            "3000/3000 [==============================] - 3s 914us/step - loss: 0.2853 - accuracy: 0.8658\n",
            "3000/3000 [==============================] - 3s 887us/step - loss: 0.2853 - accuracy: 0.8659\n",
            "3000/3000 [==============================] - 3s 904us/step - loss: 0.2878 - accuracy: 0.8659\n",
            "3000/3000 [==============================] - 3s 911us/step - loss: 0.2844 - accuracy: 0.8659\n",
            "3000/3000 [==============================] - 3s 906us/step - loss: 0.2843 - accuracy: 0.8661\n",
            "3000/3000 [==============================] - 3s 898us/step - loss: 0.2846 - accuracy: 0.8661\n",
            "3000/3000 [==============================] - 3s 891us/step - loss: 0.2843 - accuracy: 0.8661\n",
            "3000/3000 [==============================] - 3s 899us/step - loss: 0.2844 - accuracy: 0.8660\n",
            "3000/3000 [==============================] - 3s 904us/step - loss: 0.2850 - accuracy: 0.8657\n",
            "3000/3000 [==============================] - 3s 906us/step - loss: 0.2850 - accuracy: 0.8659\n",
            "3000/3000 [==============================] - 3s 906us/step - loss: 0.2845 - accuracy: 0.8661\n",
            "3000/3000 [==============================] - 3s 904us/step - loss: 0.2853 - accuracy: 0.8656\n",
            "3000/3000 [==============================] - 3s 892us/step - loss: 0.2851 - accuracy: 0.8661\n",
            "3000/3000 [==============================] - 3s 897us/step - loss: 0.2845 - accuracy: 0.8658\n",
            "3000/3000 [==============================] - 3s 905us/step - loss: 0.2846 - accuracy: 0.8659\n",
            "3000/3000 [==============================] - 3s 888us/step - loss: 0.2897 - accuracy: 0.8641\n",
            "3000/3000 [==============================] - 3s 892us/step - loss: 0.2845 - accuracy: 0.8660\n",
            "3000/3000 [==============================] - 3s 903us/step - loss: 0.2847 - accuracy: 0.8661\n",
            "3000/3000 [==============================] - 3s 938us/step - loss: 0.2863 - accuracy: 0.8658\n",
            "3000/3000 [==============================] - 3s 961us/step - loss: 0.2850 - accuracy: 0.8657\n",
            "3000/3000 [==============================] - 3s 973us/step - loss: 0.2848 - accuracy: 0.8657\n",
            "3000/3000 [==============================] - 3s 974us/step - loss: 0.2869 - accuracy: 0.8658\n",
            "3000/3000 [==============================] - 3s 898us/step - loss: 0.2861 - accuracy: 0.8655\n",
            "3000/3000 [==============================] - 3s 904us/step - loss: 0.2847 - accuracy: 0.8660\n",
            "3000/3000 [==============================] - 3s 901us/step - loss: 0.2861 - accuracy: 0.8657\n",
            "3000/3000 [==============================] - 3s 902us/step - loss: 0.2848 - accuracy: 0.8657\n",
            "3000/3000 [==============================] - 3s 889us/step - loss: 0.2850 - accuracy: 0.8659\n",
            "3000/3000 [==============================] - 3s 905us/step - loss: 0.2845 - accuracy: 0.8660\n",
            "3000/3000 [==============================] - 3s 911us/step - loss: 0.2937 - accuracy: 0.8609\n",
            "3000/3000 [==============================] - 3s 891us/step - loss: 0.2868 - accuracy: 0.8656\n",
            "3000/3000 [==============================] - 3s 897us/step - loss: 0.2847 - accuracy: 0.8661\n",
            "3000/3000 [==============================] - 3s 898us/step - loss: 0.3176 - accuracy: 0.8481\n",
            "3000/3000 [==============================] - 3s 899us/step - loss: 0.2854 - accuracy: 0.8651\n",
            "3000/3000 [==============================] - 3s 898us/step - loss: 0.3310 - accuracy: 0.8333\n",
            "3000/3000 [==============================] - 3s 912us/step - loss: 0.2948 - accuracy: 0.8629\n",
            "3000/3000 [==============================] - 3s 912us/step - loss: 0.4244 - accuracy: 0.8353\n",
            "3000/3000 [==============================] - 3s 903us/step - loss: 0.2952 - accuracy: 0.8587\n",
            "3000/3000 [==============================] - 3s 903us/step - loss: 0.2994 - accuracy: 0.8597\n",
            "3000/3000 [==============================] - 3s 887us/step - loss: 0.2907 - accuracy: 0.8635\n",
            "3000/3000 [==============================] - 3s 912us/step - loss: 0.2861 - accuracy: 0.8651\n",
            "3000/3000 [==============================] - 3s 911us/step - loss: 0.2913 - accuracy: 0.8620\n",
            "3000/3000 [==============================] - 3s 907us/step - loss: 0.2845 - accuracy: 0.8659\n",
            "3000/3000 [==============================] - 3s 923us/step - loss: 0.2979 - accuracy: 0.8564\n",
            "3000/3000 [==============================] - 3s 908us/step - loss: 0.2869 - accuracy: 0.8644\n",
            "3000/3000 [==============================] - 3s 903us/step - loss: 0.2937 - accuracy: 0.8579\n",
            "3000/3000 [==============================] - 3s 912us/step - loss: 0.2888 - accuracy: 0.8628\n",
            "3000/3000 [==============================] - 3s 896us/step - loss: 0.2850 - accuracy: 0.8659\n",
            "3000/3000 [==============================] - 3s 907us/step - loss: 0.2903 - accuracy: 0.8627\n",
            "3000/3000 [==============================] - 3s 898us/step - loss: 0.2959 - accuracy: 0.8607\n",
            "3000/3000 [==============================] - 3s 922us/step - loss: 0.2855 - accuracy: 0.8661\n",
            "3000/3000 [==============================] - 3s 912us/step - loss: 0.2985 - accuracy: 0.8545\n",
            "3000/3000 [==============================] - 3s 904us/step - loss: 0.2880 - accuracy: 0.8655\n",
            "3000/3000 [==============================] - 3s 916us/step - loss: 0.3018 - accuracy: 0.8615\n",
            "3000/3000 [==============================] - 3s 911us/step - loss: 0.2978 - accuracy: 0.8624\n",
            "3000/3000 [==============================] - 3s 920us/step - loss: 0.2942 - accuracy: 0.8604\n",
            "3000/3000 [==============================] - 3s 878us/step - loss: 0.3052 - accuracy: 0.8574\n",
            "3000/3000 [==============================] - 3s 931us/step - loss: 0.2927 - accuracy: 0.8655\n",
            "3000/3000 [==============================] - 3s 888us/step - loss: 0.2893 - accuracy: 0.8636\n",
            "3000/3000 [==============================] - 3s 895us/step - loss: 0.2870 - accuracy: 0.8637\n",
            "3000/3000 [==============================] - 3s 905us/step - loss: 0.2915 - accuracy: 0.8608\n",
            "3000/3000 [==============================] - 3s 915us/step - loss: 0.2861 - accuracy: 0.8657\n",
            "3000/3000 [==============================] - 3s 921us/step - loss: 0.2894 - accuracy: 0.8629\n",
            "3000/3000 [==============================] - 3s 918us/step - loss: 0.3175 - accuracy: 0.8486\n",
            "3000/3000 [==============================] - 3s 930us/step - loss: 0.2848 - accuracy: 0.8659\n",
            "3000/3000 [==============================] - 3s 909us/step - loss: 0.2951 - accuracy: 0.8641\n",
            "3000/3000 [==============================] - 3s 934us/step - loss: 0.2873 - accuracy: 0.8656\n",
            "3000/3000 [==============================] - 3s 953us/step - loss: 0.3582 - accuracy: 0.8297\n",
            "3000/3000 [==============================] - 3s 935us/step - loss: 0.2968 - accuracy: 0.8622\n",
            "3000/3000 [==============================] - 3s 949us/step - loss: 0.2912 - accuracy: 0.8643\n",
            "3000/3000 [==============================] - 3s 935us/step - loss: 0.3093 - accuracy: 0.8473\n",
            "3000/3000 [==============================] - 3s 957us/step - loss: 0.2959 - accuracy: 0.8623\n",
            "3000/3000 [==============================] - 3s 919us/step - loss: 0.2898 - accuracy: 0.8643\n",
            "3000/3000 [==============================] - 3s 922us/step - loss: 0.2975 - accuracy: 0.8618\n",
            "3000/3000 [==============================] - 3s 918us/step - loss: 0.2934 - accuracy: 0.8629\n",
            "3000/3000 [==============================] - 3s 920us/step - loss: 0.2875 - accuracy: 0.8643\n",
            "3000/3000 [==============================] - 3s 909us/step - loss: 0.2868 - accuracy: 0.8644\n",
            "3000/3000 [==============================] - 3s 942us/step - loss: 0.2861 - accuracy: 0.8649\n",
            "3000/3000 [==============================] - 3s 934us/step - loss: 0.2902 - accuracy: 0.8625\n",
            "3000/3000 [==============================] - 3s 938us/step - loss: 0.2863 - accuracy: 0.8654\n",
            "3000/3000 [==============================] - 3s 915us/step - loss: 0.2899 - accuracy: 0.8627\n",
            "3000/3000 [==============================] - 3s 947us/step - loss: 0.2895 - accuracy: 0.8629\n",
            "3000/3000 [==============================] - 3s 935us/step - loss: 0.2846 - accuracy: 0.8659\n",
            "3000/3000 [==============================] - 3s 930us/step - loss: 0.2849 - accuracy: 0.8660\n",
            "3000/3000 [==============================] - 3s 925us/step - loss: 0.2851 - accuracy: 0.8655\n",
            "3000/3000 [==============================] - 3s 941us/step - loss: 0.2854 - accuracy: 0.8655\n",
            "3000/3000 [==============================] - 3s 930us/step - loss: 0.2847 - accuracy: 0.8659\n",
            "3000/3000 [==============================] - 3s 911us/step - loss: 0.2856 - accuracy: 0.8657\n",
            "3000/3000 [==============================] - 3s 917us/step - loss: 0.2843 - accuracy: 0.8659\n",
            "3000/3000 [==============================] - 3s 929us/step - loss: 0.2852 - accuracy: 0.8657\n",
            "3000/3000 [==============================] - 3s 907us/step - loss: 0.2854 - accuracy: 0.8659\n",
            "3000/3000 [==============================] - 3s 903us/step - loss: 0.2843 - accuracy: 0.8661\n",
            "3000/3000 [==============================] - 3s 901us/step - loss: 0.2850 - accuracy: 0.8658\n",
            "3000/3000 [==============================] - 3s 920us/step - loss: 0.2850 - accuracy: 0.8658\n",
            "3000/3000 [==============================] - 3s 924us/step - loss: 0.2879 - accuracy: 0.8655\n",
            "3000/3000 [==============================] - 3s 1ms/step - loss: 0.2849 - accuracy: 0.8659\n",
            "3000/3000 [==============================] - 3s 1ms/step - loss: 0.2843 - accuracy: 0.8661\n",
            "3000/3000 [==============================] - 3s 924us/step - loss: 0.2845 - accuracy: 0.8661\n",
            "3000/3000 [==============================] - 3s 927us/step - loss: 0.2844 - accuracy: 0.8659\n",
            "3000/3000 [==============================] - 3s 930us/step - loss: 0.2844 - accuracy: 0.8660\n",
            "3000/3000 [==============================] - 3s 901us/step - loss: 0.2849 - accuracy: 0.8659\n",
            "3000/3000 [==============================] - 3s 910us/step - loss: 0.2847 - accuracy: 0.8659\n",
            "3000/3000 [==============================] - 3s 927us/step - loss: 0.2845 - accuracy: 0.8660\n",
            "3000/3000 [==============================] - 3s 916us/step - loss: 0.2853 - accuracy: 0.8654\n",
            "3000/3000 [==============================] - 3s 911us/step - loss: 0.2848 - accuracy: 0.8659\n",
            "3000/3000 [==============================] - 3s 912us/step - loss: 0.2849 - accuracy: 0.8659\n",
            "3000/3000 [==============================] - 3s 907us/step - loss: 0.2846 - accuracy: 0.8660\n",
            "3000/3000 [==============================] - 3s 907us/step - loss: 0.2903 - accuracy: 0.8640\n",
            "3000/3000 [==============================] - 3s 906us/step - loss: 0.2846 - accuracy: 0.8659\n",
            "3000/3000 [==============================] - 3s 925us/step - loss: 0.2846 - accuracy: 0.8659\n",
            "3000/3000 [==============================] - 3s 915us/step - loss: 0.2864 - accuracy: 0.8658\n",
            "3000/3000 [==============================] - 3s 918us/step - loss: 0.2850 - accuracy: 0.8657\n",
            "3000/3000 [==============================] - 3s 917us/step - loss: 0.2846 - accuracy: 0.8660\n",
            "3000/3000 [==============================] - 3s 899us/step - loss: 0.2861 - accuracy: 0.8659\n",
            "3000/3000 [==============================] - 3s 895us/step - loss: 0.2855 - accuracy: 0.8656\n",
            "3000/3000 [==============================] - 3s 900us/step - loss: 0.2850 - accuracy: 0.8659\n",
            "3000/3000 [==============================] - 3s 908us/step - loss: 0.2856 - accuracy: 0.8657\n",
            "3000/3000 [==============================] - 3s 917us/step - loss: 0.2846 - accuracy: 0.8658\n",
            "3000/3000 [==============================] - 3s 919us/step - loss: 0.2845 - accuracy: 0.8659\n",
            "3000/3000 [==============================] - 3s 924us/step - loss: 0.2843 - accuracy: 0.8661\n",
            "3000/3000 [==============================] - 3s 904us/step - loss: 0.2965 - accuracy: 0.8602\n",
            "3000/3000 [==============================] - 3s 930us/step - loss: 0.2860 - accuracy: 0.8656\n",
            "3000/3000 [==============================] - 3s 925us/step - loss: 0.2846 - accuracy: 0.8659\n",
            "3000/3000 [==============================] - 3s 904us/step - loss: 0.3144 - accuracy: 0.8498\n",
            "3000/3000 [==============================] - 3s 884us/step - loss: 0.2849 - accuracy: 0.8652\n",
            "3000/3000 [==============================] - 3s 873us/step - loss: 0.3317 - accuracy: 0.8352\n",
            "3000/3000 [==============================] - 3s 919us/step - loss: 0.2945 - accuracy: 0.8620\n",
            "3000/3000 [==============================] - 3s 980us/step - loss: 0.4179 - accuracy: 0.8343\n",
            "3000/3000 [==============================] - 3s 990us/step - loss: 0.2959 - accuracy: 0.8579\n",
            "3000/3000 [==============================] - 3s 975us/step - loss: 0.3019 - accuracy: 0.8574\n",
            "3000/3000 [==============================] - 3s 914us/step - loss: 0.2896 - accuracy: 0.8629\n",
            "3000/3000 [==============================] - 3s 915us/step - loss: 0.2857 - accuracy: 0.8651\n",
            "3000/3000 [==============================] - 3s 931us/step - loss: 0.2913 - accuracy: 0.8623\n",
            "3000/3000 [==============================] - 3s 938us/step - loss: 0.2844 - accuracy: 0.8660\n",
            "3000/3000 [==============================] - 3s 912us/step - loss: 0.2980 - accuracy: 0.8557\n",
            "3000/3000 [==============================] - 3s 924us/step - loss: 0.2871 - accuracy: 0.8641\n",
            "3000/3000 [==============================] - 3s 919us/step - loss: 0.2932 - accuracy: 0.8584\n",
            "3000/3000 [==============================] - 3s 903us/step - loss: 0.2888 - accuracy: 0.8626\n",
            "3000/3000 [==============================] - 3s 910us/step - loss: 0.2857 - accuracy: 0.8659\n",
            "3000/3000 [==============================] - 3s 887us/step - loss: 0.2897 - accuracy: 0.8641\n",
            "3000/3000 [==============================] - 3s 894us/step - loss: 0.2966 - accuracy: 0.8603\n",
            "3000/3000 [==============================] - 3s 885us/step - loss: 0.2842 - accuracy: 0.8661\n",
            "3000/3000 [==============================] - 3s 895us/step - loss: 0.2988 - accuracy: 0.8539\n",
            "3000/3000 [==============================] - 3s 912us/step - loss: 0.2874 - accuracy: 0.8653\n",
            "3000/3000 [==============================] - 3s 904us/step - loss: 0.2996 - accuracy: 0.8617\n",
            "3000/3000 [==============================] - 3s 913us/step - loss: 0.3094 - accuracy: 0.8601\n",
            "3000/3000 [==============================] - 3s 922us/step - loss: 0.2948 - accuracy: 0.8589\n",
            "3000/3000 [==============================] - 3s 912us/step - loss: 0.3082 - accuracy: 0.8553\n",
            "3000/3000 [==============================] - 3s 918us/step - loss: 0.2952 - accuracy: 0.8653\n",
            "3000/3000 [==============================] - 3s 933us/step - loss: 0.2897 - accuracy: 0.8629\n",
            "3000/3000 [==============================] - 3s 937us/step - loss: 0.2866 - accuracy: 0.8635\n",
            "3000/3000 [==============================] - 3s 934us/step - loss: 0.2925 - accuracy: 0.8613\n",
            "3000/3000 [==============================] - 3s 951us/step - loss: 0.2861 - accuracy: 0.8659\n",
            "3000/3000 [==============================] - 3s 942us/step - loss: 0.2895 - accuracy: 0.8621\n",
            "3000/3000 [==============================] - 3s 949us/step - loss: 0.3154 - accuracy: 0.8505\n",
            "3000/3000 [==============================] - 3s 952us/step - loss: 0.2847 - accuracy: 0.8658\n",
            "3000/3000 [==============================] - 3s 932us/step - loss: 0.2936 - accuracy: 0.8639\n",
            "3000/3000 [==============================] - 3s 930us/step - loss: 0.2865 - accuracy: 0.8658\n",
            "3000/3000 [==============================] - 3s 942us/step - loss: 0.3551 - accuracy: 0.8315\n",
            "3000/3000 [==============================] - 3s 943us/step - loss: 0.2960 - accuracy: 0.8629\n",
            "3000/3000 [==============================] - 3s 907us/step - loss: 0.2918 - accuracy: 0.8631\n",
            "3000/3000 [==============================] - 3s 928us/step - loss: 0.3099 - accuracy: 0.8457\n",
            "3000/3000 [==============================] - 3s 922us/step - loss: 0.2954 - accuracy: 0.8611\n",
            "3000/3000 [==============================] - 3s 903us/step - loss: 0.2884 - accuracy: 0.8645\n",
            "3000/3000 [==============================] - 3s 933us/step - loss: 0.2991 - accuracy: 0.8617\n",
            "3000/3000 [==============================] - 3s 923us/step - loss: 0.2927 - accuracy: 0.8628\n",
            "3000/3000 [==============================] - 3s 925us/step - loss: 0.2875 - accuracy: 0.8644\n",
            "3000/3000 [==============================] - 3s 899us/step - loss: 0.2871 - accuracy: 0.8647\n",
            "3000/3000 [==============================] - 3s 930us/step - loss: 0.2868 - accuracy: 0.8651\n",
            "3000/3000 [==============================] - 3s 919us/step - loss: 0.2921 - accuracy: 0.8631\n",
            "3000/3000 [==============================] - 3s 908us/step - loss: 0.2864 - accuracy: 0.8657\n",
            "3000/3000 [==============================] - 3s 920us/step - loss: 0.2907 - accuracy: 0.8593\n",
            "3000/3000 [==============================] - 3s 921us/step - loss: 0.2885 - accuracy: 0.8636\n",
            "3000/3000 [==============================] - 3s 889us/step - loss: 0.2843 - accuracy: 0.8661\n",
            "3000/3000 [==============================] - 3s 904us/step - loss: 0.2847 - accuracy: 0.8659\n",
            "3000/3000 [==============================] - 3s 931us/step - loss: 0.2850 - accuracy: 0.8657\n",
            "3000/3000 [==============================] - 3s 917us/step - loss: 0.2870 - accuracy: 0.8650\n",
            "3000/3000 [==============================] - 3s 906us/step - loss: 0.2849 - accuracy: 0.8659\n",
            "3000/3000 [==============================] - 3s 934us/step - loss: 0.2856 - accuracy: 0.8657\n",
            "3000/3000 [==============================] - 3s 927us/step - loss: 0.2852 - accuracy: 0.8658\n",
            "3000/3000 [==============================] - 3s 925us/step - loss: 0.2858 - accuracy: 0.8661\n",
            "3000/3000 [==============================] - 3s 934us/step - loss: 0.2852 - accuracy: 0.8656\n",
            "3000/3000 [==============================] - 3s 937us/step - loss: 0.2843 - accuracy: 0.8661\n",
            "3000/3000 [==============================] - 3s 933us/step - loss: 0.2848 - accuracy: 0.8659\n",
            "3000/3000 [==============================] - 3s 917us/step - loss: 0.2851 - accuracy: 0.8655\n",
            "3000/3000 [==============================] - 3s 931us/step - loss: 0.2891 - accuracy: 0.8656\n",
            "3000/3000 [==============================] - 3s 929us/step - loss: 0.2846 - accuracy: 0.8659\n",
            "3000/3000 [==============================] - 3s 950us/step - loss: 0.2843 - accuracy: 0.8661\n",
            "3000/3000 [==============================] - 3s 948us/step - loss: 0.2845 - accuracy: 0.8661\n",
            "3000/3000 [==============================] - 3s 928us/step - loss: 0.2843 - accuracy: 0.8661\n",
            "3000/3000 [==============================] - 3s 946us/step - loss: 0.2846 - accuracy: 0.8661\n",
            "3000/3000 [==============================] - 3s 954us/step - loss: 0.2854 - accuracy: 0.8656\n",
            "3000/3000 [==============================] - 3s 953us/step - loss: 0.2847 - accuracy: 0.8659\n",
            "3000/3000 [==============================] - 3s 934us/step - loss: 0.2843 - accuracy: 0.8661\n",
            "3000/3000 [==============================] - 3s 923us/step - loss: 0.2854 - accuracy: 0.8655\n",
            "3000/3000 [==============================] - 3s 907us/step - loss: 0.2850 - accuracy: 0.8659\n",
            "3000/3000 [==============================] - 3s 914us/step - loss: 0.2850 - accuracy: 0.8657\n",
            "3000/3000 [==============================] - 3s 924us/step - loss: 0.2845 - accuracy: 0.8660\n",
            "3000/3000 [==============================] - 3s 916us/step - loss: 0.2894 - accuracy: 0.8644\n",
            "3000/3000 [==============================] - 3s 931us/step - loss: 0.2845 - accuracy: 0.8660\n",
            "3000/3000 [==============================] - 3s 1ms/step - loss: 0.2852 - accuracy: 0.8659\n",
            "3000/3000 [==============================] - 3s 1ms/step - loss: 0.2882 - accuracy: 0.8657\n",
            "3000/3000 [==============================] - 3s 917us/step - loss: 0.2847 - accuracy: 0.8657\n",
            "3000/3000 [==============================] - 3s 933us/step - loss: 0.2844 - accuracy: 0.8660\n",
            "3000/3000 [==============================] - 3s 932us/step - loss: 0.2869 - accuracy: 0.8659\n",
            "3000/3000 [==============================] - 3s 937us/step - loss: 0.2858 - accuracy: 0.8657\n",
            "3000/3000 [==============================] - 3s 952us/step - loss: 0.2843 - accuracy: 0.8660\n",
            "3000/3000 [==============================] - 3s 942us/step - loss: 0.2849 - accuracy: 0.8659\n",
            "3000/3000 [==============================] - 3s 933us/step - loss: 0.2847 - accuracy: 0.8657\n",
            "3000/3000 [==============================] - 3s 923us/step - loss: 0.2846 - accuracy: 0.8659\n",
            "3000/3000 [==============================] - 3s 924us/step - loss: 0.2849 - accuracy: 0.8660\n",
            "3000/3000 [==============================] - 3s 930us/step - loss: 0.2954 - accuracy: 0.8586\n",
            "3000/3000 [==============================] - 3s 939us/step - loss: 0.2870 - accuracy: 0.8655\n",
            "3000/3000 [==============================] - 3s 931us/step - loss: 0.2844 - accuracy: 0.8660\n",
            "3000/3000 [==============================] - 3s 936us/step - loss: 0.3185 - accuracy: 0.8524\n",
            "3000/3000 [==============================] - 3s 936us/step - loss: 0.2850 - accuracy: 0.8652\n",
            "3000/3000 [==============================] - 3s 928us/step - loss: 0.3365 - accuracy: 0.8349\n",
            "3000/3000 [==============================] - 3s 910us/step - loss: 0.2948 - accuracy: 0.8633\n",
            "3000/3000 [==============================] - 3s 886us/step - loss: 0.4173 - accuracy: 0.8339\n",
            "3000/3000 [==============================] - 3s 922us/step - loss: 0.2959 - accuracy: 0.8591\n",
            "3000/3000 [==============================] - 3s 939us/step - loss: 0.3005 - accuracy: 0.8577\n",
            "3000/3000 [==============================] - 3s 933us/step - loss: 0.2902 - accuracy: 0.8641\n",
            "3000/3000 [==============================] - 3s 909us/step - loss: 0.2853 - accuracy: 0.8649\n",
            "3000/3000 [==============================] - 3s 918us/step - loss: 0.2902 - accuracy: 0.8625\n",
            "3000/3000 [==============================] - 3s 917us/step - loss: 0.2844 - accuracy: 0.8660\n",
            "3000/3000 [==============================] - 3s 894us/step - loss: 0.2980 - accuracy: 0.8543\n",
            "3000/3000 [==============================] - 3s 912us/step - loss: 0.2870 - accuracy: 0.8648\n",
            "3000/3000 [==============================] - 3s 925us/step - loss: 0.2929 - accuracy: 0.8576\n",
            "3000/3000 [==============================] - 3s 946us/step - loss: 0.2886 - accuracy: 0.8633\n",
            "3000/3000 [==============================] - 3s 952us/step - loss: 0.2849 - accuracy: 0.8659\n",
            "3000/3000 [==============================] - 3s 939us/step - loss: 0.2896 - accuracy: 0.8637\n",
            "3000/3000 [==============================] - 3s 925us/step - loss: 0.2984 - accuracy: 0.8616\n",
            "3000/3000 [==============================] - 3s 978us/step - loss: 0.2848 - accuracy: 0.8659\n",
            "3000/3000 [==============================] - 3s 995us/step - loss: 0.2990 - accuracy: 0.8549\n",
            "3000/3000 [==============================] - 3s 1ms/step - loss: 0.2882 - accuracy: 0.8650\n",
            "3000/3000 [==============================] - 3s 935us/step - loss: 0.2967 - accuracy: 0.8611\n",
            "3000/3000 [==============================] - 3s 927us/step - loss: 0.3021 - accuracy: 0.8597\n",
            "3000/3000 [==============================] - 3s 936us/step - loss: 0.2963 - accuracy: 0.8597\n",
            "3000/3000 [==============================] - 3s 921us/step - loss: 0.3061 - accuracy: 0.8557\n",
            "3000/3000 [==============================] - 3s 928us/step - loss: 0.2976 - accuracy: 0.8649\n",
            "3000/3000 [==============================] - 3s 926us/step - loss: 0.2894 - accuracy: 0.8633\n",
            "3000/3000 [==============================] - 3s 924us/step - loss: 0.2867 - accuracy: 0.8633\n",
            "3000/3000 [==============================] - 3s 931us/step - loss: 0.2928 - accuracy: 0.8616\n",
            "3000/3000 [==============================] - 3s 912us/step - loss: 0.2859 - accuracy: 0.8659\n",
            "3000/3000 [==============================] - 3s 934us/step - loss: 0.2903 - accuracy: 0.8611\n",
            "3000/3000 [==============================] - 3s 932us/step - loss: 0.3144 - accuracy: 0.8508\n",
            "3000/3000 [==============================] - 3s 920us/step - loss: 0.2845 - accuracy: 0.8659\n",
            "3000/3000 [==============================] - 3s 925us/step - loss: 0.2936 - accuracy: 0.8641\n",
            "3000/3000 [==============================] - 3s 922us/step - loss: 0.2867 - accuracy: 0.8657\n",
            "3000/3000 [==============================] - 3s 929us/step - loss: 0.3538 - accuracy: 0.8356\n",
            "3000/3000 [==============================] - 3s 877us/step - loss: 0.2982 - accuracy: 0.8620\n",
            "3000/3000 [==============================] - 3s 907us/step - loss: 0.2905 - accuracy: 0.8634\n",
            "3000/3000 [==============================] - 3s 930us/step - loss: 0.3104 - accuracy: 0.8465\n",
            "3000/3000 [==============================] - 3s 933us/step - loss: 0.2957 - accuracy: 0.8611\n",
            "3000/3000 [==============================] - 3s 920us/step - loss: 0.2901 - accuracy: 0.8641\n",
            "3000/3000 [==============================] - 3s 905us/step - loss: 0.2970 - accuracy: 0.8623\n",
            "3000/3000 [==============================] - 3s 918us/step - loss: 0.2934 - accuracy: 0.8627\n",
            "3000/3000 [==============================] - 3s 950us/step - loss: 0.2870 - accuracy: 0.8641\n",
            "3000/3000 [==============================] - 3s 946us/step - loss: 0.2878 - accuracy: 0.8645\n",
            "3000/3000 [==============================] - 3s 927us/step - loss: 0.2864 - accuracy: 0.8647\n",
            "3000/3000 [==============================] - 3s 933us/step - loss: 0.2916 - accuracy: 0.8628\n",
            "3000/3000 [==============================] - 3s 917us/step - loss: 0.2868 - accuracy: 0.8651\n",
            "3000/3000 [==============================] - 3s 906us/step - loss: 0.2900 - accuracy: 0.8611\n",
            "3000/3000 [==============================] - 3s 943us/step - loss: 0.2889 - accuracy: 0.8642\n",
            "3000/3000 [==============================] - 3s 940us/step - loss: 0.2847 - accuracy: 0.8659\n",
            "3000/3000 [==============================] - 3s 964us/step - loss: 0.2852 - accuracy: 0.8659\n",
            "3000/3000 [==============================] - 3s 936us/step - loss: 0.2851 - accuracy: 0.8657\n",
            "3000/3000 [==============================] - 3s 949us/step - loss: 0.2877 - accuracy: 0.8653\n",
            "3000/3000 [==============================] - 3s 970us/step - loss: 0.2855 - accuracy: 0.8656\n",
            "3000/3000 [==============================] - 3s 936us/step - loss: 0.2877 - accuracy: 0.8655\n",
            "3000/3000 [==============================] - 3s 955us/step - loss: 0.2859 - accuracy: 0.8658\n",
            "3000/3000 [==============================] - 3s 955us/step - loss: 0.2867 - accuracy: 0.8659\n",
            "3000/3000 [==============================] - 3s 951us/step - loss: 0.2853 - accuracy: 0.8658\n",
            "3000/3000 [==============================] - 3s 945us/step - loss: 0.2844 - accuracy: 0.8660\n",
            "3000/3000 [==============================] - 3s 983us/step - loss: 0.2848 - accuracy: 0.8658\n",
            "3000/3000 [==============================] - 3s 942us/step - loss: 0.2849 - accuracy: 0.8658\n",
            "3000/3000 [==============================] - 3s 945us/step - loss: 0.2860 - accuracy: 0.8657\n",
            "3000/3000 [==============================] - 3s 976us/step - loss: 0.2846 - accuracy: 0.8660\n",
            "3000/3000 [==============================] - 3s 966us/step - loss: 0.2843 - accuracy: 0.8661\n",
            "3000/3000 [==============================] - 3s 939us/step - loss: 0.2846 - accuracy: 0.8660\n",
            "3000/3000 [==============================] - 3s 950us/step - loss: 0.2843 - accuracy: 0.8661\n",
            "3000/3000 [==============================] - 3s 905us/step - loss: 0.2848 - accuracy: 0.8659\n",
            "3000/3000 [==============================] - 3s 946us/step - loss: 0.2849 - accuracy: 0.8656\n",
            "3000/3000 [==============================] - 3s 969us/step - loss: 0.2844 - accuracy: 0.8659\n",
            "3000/3000 [==============================] - 3s 967us/step - loss: 0.2843 - accuracy: 0.8661\n",
            "3000/3000 [==============================] - 3s 957us/step - loss: 0.2849 - accuracy: 0.8656\n",
            "3000/3000 [==============================] - 3s 929us/step - loss: 0.2855 - accuracy: 0.8659\n",
            "3000/3000 [==============================] - 3s 938us/step - loss: 0.2847 - accuracy: 0.8659\n",
            "3000/3000 [==============================] - 3s 968us/step - loss: 0.2844 - accuracy: 0.8660\n",
            "3000/3000 [==============================] - 3s 999us/step - loss: 0.2885 - accuracy: 0.8653\n",
            "3000/3000 [==============================] - 3s 968us/step - loss: 0.2850 - accuracy: 0.8659\n",
            "3000/3000 [==============================] - 3s 964us/step - loss: 0.2846 - accuracy: 0.8660\n",
            "3000/3000 [==============================] - 3s 981us/step - loss: 0.2868 - accuracy: 0.8658\n",
            "3000/3000 [==============================] - 3s 992us/step - loss: 0.2847 - accuracy: 0.8659\n",
            "3000/3000 [==============================] - 3s 975us/step - loss: 0.2845 - accuracy: 0.8661\n",
            "3000/3000 [==============================] - 3s 983us/step - loss: 0.2885 - accuracy: 0.8657\n",
            "3000/3000 [==============================] - 3s 938us/step - loss: 0.2857 - accuracy: 0.8656\n",
            "3000/3000 [==============================] - 3s 966us/step - loss: 0.2848 - accuracy: 0.8659\n",
            "3000/3000 [==============================] - 3s 960us/step - loss: 0.2853 - accuracy: 0.8659\n",
            "3000/3000 [==============================] - 3s 955us/step - loss: 0.2847 - accuracy: 0.8659\n",
            "3000/3000 [==============================] - 3s 984us/step - loss: 0.2846 - accuracy: 0.8658\n",
            "3000/3000 [==============================] - 3s 948us/step - loss: 0.2851 - accuracy: 0.8658\n",
            "3000/3000 [==============================] - 3s 964us/step - loss: 0.2959 - accuracy: 0.8603\n",
            "3000/3000 [==============================] - 3s 1ms/step - loss: 0.2872 - accuracy: 0.8655\n",
            "3000/3000 [==============================] - 3s 1ms/step - loss: 0.2844 - accuracy: 0.8661\n",
            "3000/3000 [==============================] - 3s 949us/step - loss: 0.3208 - accuracy: 0.8483\n",
            "3000/3000 [==============================] - 3s 951us/step - loss: 0.2852 - accuracy: 0.8651\n",
            "3000/3000 [==============================] - 3s 977us/step - loss: 0.3352 - accuracy: 0.8336\n",
            "3000/3000 [==============================] - 3s 1ms/step - loss: 0.2943 - accuracy: 0.8647\n",
            "3000/3000 [==============================] - 3s 992us/step - loss: 0.4310 - accuracy: 0.8335\n",
            "3000/3000 [==============================] - 3s 992us/step - loss: 0.2968 - accuracy: 0.8596\n",
            "3000/3000 [==============================] - 3s 973us/step - loss: 0.2997 - accuracy: 0.8593\n",
            "3000/3000 [==============================] - 3s 953us/step - loss: 0.2893 - accuracy: 0.8638\n",
            "3000/3000 [==============================] - 3s 986us/step - loss: 0.2856 - accuracy: 0.8651\n",
            "3000/3000 [==============================] - 3s 998us/step - loss: 0.2906 - accuracy: 0.8631\n",
            "3000/3000 [==============================] - 3s 989us/step - loss: 0.2847 - accuracy: 0.8660\n",
            "3000/3000 [==============================] - 3s 972us/step - loss: 0.2994 - accuracy: 0.8555\n",
            "3000/3000 [==============================] - 3s 959us/step - loss: 0.2871 - accuracy: 0.8647\n",
            "3000/3000 [==============================] - 3s 988us/step - loss: 0.2927 - accuracy: 0.8588\n",
            "3000/3000 [==============================] - 3s 970us/step - loss: 0.2885 - accuracy: 0.8634\n",
            "3000/3000 [==============================] - 3s 974us/step - loss: 0.2847 - accuracy: 0.8661\n",
            "3000/3000 [==============================] - 3s 957us/step - loss: 0.2902 - accuracy: 0.8635\n",
            "3000/3000 [==============================] - 3s 950us/step - loss: 0.2959 - accuracy: 0.8617\n",
            "3000/3000 [==============================] - 3s 957us/step - loss: 0.2849 - accuracy: 0.8660\n",
            "3000/3000 [==============================] - 3s 931us/step - loss: 0.2983 - accuracy: 0.8555\n",
            "3000/3000 [==============================] - 3s 929us/step - loss: 0.2876 - accuracy: 0.8653\n",
            "3000/3000 [==============================] - 3s 951us/step - loss: 0.2980 - accuracy: 0.8616\n",
            "3000/3000 [==============================] - 3s 995us/step - loss: 0.3029 - accuracy: 0.8601\n",
            "3000/3000 [==============================] - 3s 975us/step - loss: 0.2949 - accuracy: 0.8601\n",
            "3000/3000 [==============================] - 3s 1ms/step - loss: 0.3080 - accuracy: 0.8553\n",
            "3000/3000 [==============================] - 3s 985us/step - loss: 0.2941 - accuracy: 0.8657\n",
            "3000/3000 [==============================] - 3s 955us/step - loss: 0.2892 - accuracy: 0.8637\n",
            "3000/3000 [==============================] - 3s 987us/step - loss: 0.2865 - accuracy: 0.8643\n",
            "3000/3000 [==============================] - 3s 974us/step - loss: 0.2917 - accuracy: 0.8625\n",
            "3000/3000 [==============================] - 3s 983us/step - loss: 0.2860 - accuracy: 0.8659\n",
            "3000/3000 [==============================] - 3s 1ms/step - loss: 0.2898 - accuracy: 0.8622\n",
            "3000/3000 [==============================] - 3s 1ms/step - loss: 0.3167 - accuracy: 0.8490\n",
            "3000/3000 [==============================] - 3s 1ms/step - loss: 0.2844 - accuracy: 0.8659\n",
            "3000/3000 [==============================] - 3s 1ms/step - loss: 0.2937 - accuracy: 0.8631\n",
            "3000/3000 [==============================] - 3s 1ms/step - loss: 0.2884 - accuracy: 0.8655\n",
            "3000/3000 [==============================] - 3s 1ms/step - loss: 0.3543 - accuracy: 0.8322\n",
            "3000/3000 [==============================] - 3s 1ms/step - loss: 0.2932 - accuracy: 0.8629\n",
            "3000/3000 [==============================] - 3s 979us/step - loss: 0.2902 - accuracy: 0.8641\n",
            "3000/3000 [==============================] - 3s 925us/step - loss: 0.3100 - accuracy: 0.8463\n",
            "3000/3000 [==============================] - 3s 938us/step - loss: 0.2951 - accuracy: 0.8609\n",
            "3000/3000 [==============================] - 3s 939us/step - loss: 0.2916 - accuracy: 0.8638\n",
            "3000/3000 [==============================] - 3s 984us/step - loss: 0.2983 - accuracy: 0.8615\n",
            "3000/3000 [==============================] - 3s 963us/step - loss: 0.2922 - accuracy: 0.8631\n",
            "3000/3000 [==============================] - 3s 957us/step - loss: 0.2877 - accuracy: 0.8638\n",
            "3000/3000 [==============================] - 3s 954us/step - loss: 0.2861 - accuracy: 0.8646\n",
            "3000/3000 [==============================] - 3s 949us/step - loss: 0.2868 - accuracy: 0.8645\n",
            "3000/3000 [==============================] - 3s 960us/step - loss: 0.2916 - accuracy: 0.8632\n",
            "3000/3000 [==============================] - 3s 957us/step - loss: 0.2871 - accuracy: 0.8651\n",
            "3000/3000 [==============================] - 3s 956us/step - loss: 0.2898 - accuracy: 0.8619\n",
            "3000/3000 [==============================] - 3s 930us/step - loss: 0.2888 - accuracy: 0.8630\n",
            "3000/3000 [==============================] - 3s 950us/step - loss: 0.2846 - accuracy: 0.8659\n",
            "3000/3000 [==============================] - 3s 969us/step - loss: 0.2852 - accuracy: 0.8660\n",
            "3000/3000 [==============================] - 3s 947us/step - loss: 0.2853 - accuracy: 0.8657\n",
            "3000/3000 [==============================] - 3s 946us/step - loss: 0.2872 - accuracy: 0.8653\n",
            "3000/3000 [==============================] - 3s 929us/step - loss: 0.2850 - accuracy: 0.8659\n",
            "3000/3000 [==============================] - 3s 949us/step - loss: 0.2896 - accuracy: 0.8654\n",
            "3000/3000 [==============================] - 3s 957us/step - loss: 0.2849 - accuracy: 0.8659\n",
            "3000/3000 [==============================] - 3s 963us/step - loss: 0.2859 - accuracy: 0.8655\n",
            "3000/3000 [==============================] - 3s 958us/step - loss: 0.2850 - accuracy: 0.8658\n",
            "3000/3000 [==============================] - 3s 938us/step - loss: 0.2844 - accuracy: 0.8660\n",
            "3000/3000 [==============================] - 3s 954us/step - loss: 0.2848 - accuracy: 0.8657\n",
            "3000/3000 [==============================] - 3s 952us/step - loss: 0.2849 - accuracy: 0.8657\n",
            "3000/3000 [==============================] - 3s 944us/step - loss: 0.2863 - accuracy: 0.8659\n",
            "3000/3000 [==============================] - 3s 1ms/step - loss: 0.2844 - accuracy: 0.8660\n",
            "3000/3000 [==============================] - 3s 970us/step - loss: 0.2843 - accuracy: 0.8661\n",
            "3000/3000 [==============================] - 3s 928us/step - loss: 0.2842 - accuracy: 0.8661\n",
            "3000/3000 [==============================] - 3s 989us/step - loss: 0.2844 - accuracy: 0.8660\n",
            "3000/3000 [==============================] - 3s 996us/step - loss: 0.2847 - accuracy: 0.8659\n",
            "3000/3000 [==============================] - 3s 987us/step - loss: 0.2847 - accuracy: 0.8658\n",
            "3000/3000 [==============================] - 3s 994us/step - loss: 0.2845 - accuracy: 0.8660\n",
            "3000/3000 [==============================] - 3s 1ms/step - loss: 0.2843 - accuracy: 0.8660\n",
            "3000/3000 [==============================] - 3s 988us/step - loss: 0.2850 - accuracy: 0.8657\n",
            "3000/3000 [==============================] - 3s 979us/step - loss: 0.2848 - accuracy: 0.8659\n",
            "3000/3000 [==============================] - 3s 1ms/step - loss: 0.2847 - accuracy: 0.8657\n",
            "3000/3000 [==============================] - 3s 999us/step - loss: 0.2850 - accuracy: 0.8660\n",
            "3000/3000 [==============================] - 3s 1000us/step - loss: 0.2895 - accuracy: 0.8644\n",
            "3000/3000 [==============================] - 3s 976us/step - loss: 0.2848 - accuracy: 0.8658\n",
            "3000/3000 [==============================] - 3s 1ms/step - loss: 0.2850 - accuracy: 0.8659\n",
            "3000/3000 [==============================] - 3s 1ms/step - loss: 0.2881 - accuracy: 0.8657\n",
            "3000/3000 [==============================] - 3s 997us/step - loss: 0.2851 - accuracy: 0.8658\n",
            "3000/3000 [==============================] - 3s 981us/step - loss: 0.2848 - accuracy: 0.8657\n",
            "3000/3000 [==============================] - 3s 965us/step - loss: 0.2855 - accuracy: 0.8660\n",
            "3000/3000 [==============================] - 3s 969us/step - loss: 0.2857 - accuracy: 0.8657\n",
            "3000/3000 [==============================] - 3s 1ms/step - loss: 0.2847 - accuracy: 0.8659\n",
            "3000/3000 [==============================] - 3s 991us/step - loss: 0.2851 - accuracy: 0.8656\n",
            "3000/3000 [==============================] - 3s 991us/step - loss: 0.2848 - accuracy: 0.8657\n",
            "3000/3000 [==============================] - 3s 963us/step - loss: 0.2843 - accuracy: 0.8659\n",
            "3000/3000 [==============================] - 3s 1ms/step - loss: 0.2845 - accuracy: 0.8659\n",
            "3000/3000 [==============================] - 3s 1ms/step - loss: 0.2957 - accuracy: 0.8598\n",
            "3000/3000 [==============================] - 3s 1ms/step - loss: 0.2846 - accuracy: 0.8659\n",
            "3000/3000 [==============================] - 3s 1ms/step - loss: 0.2846 - accuracy: 0.8659\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "    <style>\n",
              "    table.eli5-weights tr:hover {\n",
              "        filter: brightness(85%);\n",
              "    }\n",
              "</style>\n",
              "\n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "        <table class=\"eli5-weights eli5-feature-importances\" style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto;\">\n",
              "    <thead>\n",
              "    <tr style=\"border: none;\">\n",
              "        <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">Weight</th>\n",
              "        <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
              "    </tr>\n",
              "    </thead>\n",
              "    <tbody>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0341\n",
              "                \n",
              "                    &plusmn; 0.0039\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                m_Never-married\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 81.04%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0316\n",
              "                \n",
              "                    &plusmn; 0.0018\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                education-num\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 81.10%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0314\n",
              "                \n",
              "                    &plusmn; 0.0019\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                capital-gain\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 86.65%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0191\n",
              "                \n",
              "                    &plusmn; 0.0022\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                r_Husband\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 87.92%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0166\n",
              "                \n",
              "                    &plusmn; 0.0032\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                age\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 88.19%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0161\n",
              "                \n",
              "                    &plusmn; 0.0020\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                m_Divorced\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 90.80%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0112\n",
              "                \n",
              "                    &plusmn; 0.0012\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                o_Craft-repair\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 91.01%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0109\n",
              "                \n",
              "                    &plusmn; 0.0017\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                w_Private\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 91.58%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0099\n",
              "                \n",
              "                    &plusmn; 0.0018\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                o_Other-service\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 92.89%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0078\n",
              "                \n",
              "                    &plusmn; 0.0009\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                w_Self-emp-not-inc\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 93.03%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0076\n",
              "                \n",
              "                    &plusmn; 0.0018\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                hours-per-week\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 93.42%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0070\n",
              "                \n",
              "                    &plusmn; 0.0015\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                capital-loss\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 93.82%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0064\n",
              "                \n",
              "                    &plusmn; 0.0010\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                o_Machine-op-inspct\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 94.00%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0061\n",
              "                \n",
              "                    &plusmn; 0.0015\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                c_United-States\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 94.46%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0054\n",
              "                \n",
              "                    &plusmn; 0.0019\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                o_Handlers-cleaners\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 94.73%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0051\n",
              "                \n",
              "                    &plusmn; 0.0025\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                race_White\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 94.75%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0050\n",
              "                \n",
              "                    &plusmn; 0.0011\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                o_Adm-clerical\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 94.91%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0048\n",
              "                \n",
              "                    &plusmn; 0.0011\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                r_Not-in-family\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 95.00%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0047\n",
              "                \n",
              "                    &plusmn; 0.0006\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                o_Farming-fishing\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 95.16%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0045\n",
              "                \n",
              "                    &plusmn; 0.0011\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                o_Sales\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 95.34%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0043\n",
              "                \n",
              "                    &plusmn; 0.0005\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                r_Own-child\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 95.48%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0041\n",
              "                \n",
              "                    &plusmn; 0.0012\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                o_Transport-moving\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 95.81%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0037\n",
              "                \n",
              "                    &plusmn; 0.0007\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                w_Local-gov\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 96.03%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0034\n",
              "                \n",
              "                    &plusmn; 0.0010\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                m_Separated\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 96.14%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0033\n",
              "                \n",
              "                    &plusmn; 0.0004\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                r_Unmarried\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 96.27%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0031\n",
              "                \n",
              "                    &plusmn; 0.0005\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                race_Black\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 96.35%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0030\n",
              "                \n",
              "                    &plusmn; 0.0018\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                sex\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 96.35%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0030\n",
              "                \n",
              "                    &plusmn; 0.0006\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                w_State-gov\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 96.53%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0028\n",
              "                \n",
              "                    &plusmn; 0.0011\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                c_?\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 96.72%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0026\n",
              "                \n",
              "                    &plusmn; 0.0007\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                o_Prof-specialty\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 96.73%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0026\n",
              "                \n",
              "                    &plusmn; 0.0009\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                o_?\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 96.87%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0024\n",
              "                \n",
              "                    &plusmn; 0.0009\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                m_Widowed\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 96.95%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0023\n",
              "                \n",
              "                    &plusmn; 0.0011\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                w_?\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 96.99%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0023\n",
              "                \n",
              "                    &plusmn; 0.0008\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                o_Protective-serv\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 97.24%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0020\n",
              "                \n",
              "                    &plusmn; 0.0014\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                m_Married-civ-spouse\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 97.38%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0019\n",
              "                \n",
              "                    &plusmn; 0.0005\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                r_Other-relative\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 97.50%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0017\n",
              "                \n",
              "                    &plusmn; 0.0008\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                r_Wife\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 97.61%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0016\n",
              "                \n",
              "                    &plusmn; 0.0009\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                c_Mexico\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 97.70%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0015\n",
              "                \n",
              "                    &plusmn; 0.0002\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                race_Amer-Indian-Eskimo\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 97.75%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0015\n",
              "                \n",
              "                    &plusmn; 0.0006\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                w_Self-emp-inc\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 97.86%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0014\n",
              "                \n",
              "                    &plusmn; 0.0006\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                race_Asian-Pac-Islander\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 98.36%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0010\n",
              "                \n",
              "                    &plusmn; 0.0003\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                w_Federal-gov\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 98.44%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0009\n",
              "                \n",
              "                    &plusmn; 0.0001\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                demogweight\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 98.52%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0008\n",
              "                \n",
              "                    &plusmn; 0.0007\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                o_Priv-house-serv\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 98.52%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0008\n",
              "                \n",
              "                    &plusmn; 0.0003\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                o_Exec-managerial\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 98.66%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0007\n",
              "                \n",
              "                    &plusmn; 0.0004\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                race_Other\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 98.69%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0007\n",
              "                \n",
              "                    &plusmn; 0.0005\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                c_Columbia\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 98.93%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0005\n",
              "                \n",
              "                    &plusmn; 0.0003\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                c_Dominican-Republic\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 98.95%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0005\n",
              "                \n",
              "                    &plusmn; 0.0002\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                c_Italy\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.05%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0004\n",
              "                \n",
              "                    &plusmn; 0.0003\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                c_Vietnam\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.05%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0004\n",
              "                \n",
              "                    &plusmn; 0.0001\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                c_Puerto-Rico\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.13%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0004\n",
              "                \n",
              "                    &plusmn; 0.0003\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                m_Married-spouse-absent\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.13%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0004\n",
              "                \n",
              "                    &plusmn; 0.0002\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                c_China\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.17%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0004\n",
              "                \n",
              "                    &plusmn; 0.0003\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                c_Guatemala\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.19%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0003\n",
              "                \n",
              "                    &plusmn; 0.0002\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                c_India\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.24%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0003\n",
              "                \n",
              "                    &plusmn; 0.0003\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                c_South\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.24%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0003\n",
              "                \n",
              "                    &plusmn; 0.0002\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                c_Greece\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.24%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0003\n",
              "                \n",
              "                    &plusmn; 0.0002\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                c_Taiwan\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.26%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0003\n",
              "                \n",
              "                    &plusmn; 0.0003\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                o_Tech-support\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.26%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0003\n",
              "                \n",
              "                    &plusmn; 0.0004\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                c_El-Salvador\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.28%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0003\n",
              "                \n",
              "                    &plusmn; 0.0001\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                c_Philippines\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.28%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0003\n",
              "                \n",
              "                    &plusmn; 0.0002\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                c_England\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.28%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0003\n",
              "                \n",
              "                    &plusmn; 0.0001\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                c_Peru\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.31%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0003\n",
              "                \n",
              "                    &plusmn; 0.0002\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                c_Japan\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.33%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0003\n",
              "                \n",
              "                    &plusmn; 0.0002\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                c_Germany\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.35%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0003\n",
              "                \n",
              "                    &plusmn; 0.0003\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                c_Cuba\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.43%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0002\n",
              "                \n",
              "                    &plusmn; 0.0002\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                c_Portugal\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.43%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0002\n",
              "                \n",
              "                    &plusmn; 0.0001\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                c_Ecuador\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.50%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0002\n",
              "                \n",
              "                    &plusmn; 0.0003\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                c_Poland\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.50%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0002\n",
              "                \n",
              "                    &plusmn; 0.0001\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                c_Thailand\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.50%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0002\n",
              "                \n",
              "                    &plusmn; 0.0001\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                m_Married-AF-spouse\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.56%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0001\n",
              "                \n",
              "                    &plusmn; 0.0002\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                c_Nicaragua\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.59%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0001\n",
              "                \n",
              "                    &plusmn; 0.0001\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                c_Iran\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.62%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0001\n",
              "                \n",
              "                    &plusmn; 0.0002\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                c_Jamaica\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.62%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0001\n",
              "                \n",
              "                    &plusmn; 0.0001\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                c_Haiti\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.62%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0001\n",
              "                \n",
              "                    &plusmn; 0.0001\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                c_Cambodia\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.62%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0001\n",
              "                \n",
              "                    &plusmn; 0.0001\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                w_Without-pay\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.65%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0001\n",
              "                \n",
              "                    &plusmn; 0.0001\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                c_Canada\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.65%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0001\n",
              "                \n",
              "                    &plusmn; 0.0001\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                c_Scotland\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.65%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0001\n",
              "                \n",
              "                    &plusmn; 0.0002\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                c_Trinadad&amp;Tobago\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.68%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0001\n",
              "                \n",
              "                    &plusmn; 0.0001\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                c_Hungary\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.68%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0001\n",
              "                \n",
              "                    &plusmn; 0.0001\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                c_Outlying-US(Guam-USVI-etc)\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.71%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0001\n",
              "                \n",
              "                    &plusmn; 0.0001\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                c_Laos\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.71%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0001\n",
              "                \n",
              "                    &plusmn; 0.0002\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                o_Armed-Forces\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.75%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0001\n",
              "                \n",
              "                    &plusmn; 0.0001\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                c_Yugoslavia\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.78%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0001\n",
              "                \n",
              "                    &plusmn; 0.0001\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                w_Never-worked\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.82%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0000\n",
              "                \n",
              "                    &plusmn; 0.0001\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                c_Hong\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.87%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0000\n",
              "                \n",
              "                    &plusmn; 0.0001\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                c_Ireland\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.87%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0000\n",
              "                \n",
              "                    &plusmn; 0.0001\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                c_France\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(0, 100.00%, 100.00%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0\n",
              "                \n",
              "                    &plusmn; 0.0000\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                c_Holand-Netherlands\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(0, 100.00%, 99.92%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                -0.0000\n",
              "                \n",
              "                    &plusmn; 0.0001\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                c_Honduras\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "    \n",
              "    </tbody>\n",
              "</table>\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ubNLo2qSUCYh"
      },
      "source": [
        "#Added all the variables from sensitivity table, and used 0.005 as a cutoff point for variables in ELI5\r\n",
        "features=[\"education-num\",\"capital-gain\",'capital-loss','hours-per-week','m_Never-married',\"m_Divorced\",'w_Private','r_Not-in-family',\r\n",
        "          'o_Other-service', 'r_Own-child','r_Husband','race_Black','race_White','c_Germany','r_Own-child','m_Married-civ-spouse',\r\n",
        "          'o_Prof-specialty','o_Other-service','o_Farming-fishing','demogweight','o_Craft-repair','o_Adm-clerical','c_United-States','sex','age','w_Self-emp-not-inc','o_Machine-op-inspct',\r\n",
        "          'o_Handlers-cleaners'\r\n",
        "          ]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RQFY6hDefvCs",
        "outputId": "7ae45b80-a69d-4297-9eff-d720ed22e693"
      },
      "source": [
        "len(features)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "28"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NKpGC5_1TZh-"
      },
      "source": [
        "# create model\r\n",
        "def create_model():\r\n",
        "    model = Sequential()\r\n",
        "    \r\n",
        "    # hidden layers\r\n",
        "    model.add(Dense(100, input_dim=28, kernel_initializer='uniform', activation='relu'))\r\n",
        "    model.add(Dense(20, kernel_initializer='uniform', activation='relu'))\r\n",
        "    \r\n",
        "    # output layer\r\n",
        "    model.add(Dense(1, kernel_initializer='uniform', activation='sigmoid'))\r\n",
        "    \r\n",
        "    adam = keras.optimizers.Adam(lr = 0.001)\r\n",
        "    model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])\r\n",
        "    \r\n",
        "    return model\r\n",
        "\r\n",
        "model_2 = KerasClassifier(build_fn=create_model, epochs=100, batch_size=5, verbose=1, callbacks=[es,mc])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZAgUCWuvGvJF"
      },
      "source": [
        "# model with selected predictors\n",
        "df_features = df[features]\n",
        "X2 = df_features\n",
        "y2 = df['income']\n",
        "\n",
        "X2_train, X2_test, y2_train, y2_test = train_test_split(X2, y2, test_size=0.4, random_state=seed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mxv86S2mCJrD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89b861cf-44f9-4f97-cc70-e9f5965c0616"
      },
      "source": [
        "# fit model\r\n",
        "model_2.fit(x=X2_train, y=y2_train, validation_data=(X2_test, y2_test), callbacks=[es, mc], verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "3000/3000 [==============================] - 6s 2ms/step - loss: 0.4376 - accuracy: 0.7894 - val_loss: 0.3673 - val_accuracy: 0.8264\n",
            "Epoch 2/100\n",
            "3000/3000 [==============================] - 5s 2ms/step - loss: 0.3464 - accuracy: 0.8303 - val_loss: 0.3451 - val_accuracy: 0.8353\n",
            "Epoch 3/100\n",
            "3000/3000 [==============================] - 5s 2ms/step - loss: 0.3347 - accuracy: 0.8415 - val_loss: 0.3301 - val_accuracy: 0.8482\n",
            "Epoch 4/100\n",
            "3000/3000 [==============================] - 5s 2ms/step - loss: 0.3278 - accuracy: 0.8478 - val_loss: 0.3386 - val_accuracy: 0.8313\n",
            "Epoch 5/100\n",
            "3000/3000 [==============================] - 5s 2ms/step - loss: 0.3285 - accuracy: 0.8425 - val_loss: 0.3304 - val_accuracy: 0.8458\n",
            "Epoch 6/100\n",
            "3000/3000 [==============================] - 6s 2ms/step - loss: 0.3208 - accuracy: 0.8485 - val_loss: 0.3311 - val_accuracy: 0.8446\n",
            "Epoch 7/100\n",
            "3000/3000 [==============================] - 5s 2ms/step - loss: 0.3250 - accuracy: 0.8428 - val_loss: 0.3336 - val_accuracy: 0.8501\n",
            "Epoch 8/100\n",
            "3000/3000 [==============================] - 5s 2ms/step - loss: 0.3235 - accuracy: 0.8459 - val_loss: 0.3284 - val_accuracy: 0.8508\n",
            "Epoch 9/100\n",
            "3000/3000 [==============================] - 5s 2ms/step - loss: 0.3167 - accuracy: 0.8464 - val_loss: 0.3231 - val_accuracy: 0.8513\n",
            "Epoch 10/100\n",
            "3000/3000 [==============================] - 5s 2ms/step - loss: 0.3145 - accuracy: 0.8515 - val_loss: 0.3337 - val_accuracy: 0.8434\n",
            "Epoch 11/100\n",
            "3000/3000 [==============================] - 5s 2ms/step - loss: 0.3120 - accuracy: 0.8513 - val_loss: 0.3251 - val_accuracy: 0.8510\n",
            "Epoch 12/100\n",
            "3000/3000 [==============================] - 5s 2ms/step - loss: 0.3115 - accuracy: 0.8535 - val_loss: 0.3264 - val_accuracy: 0.8481\n",
            "Epoch 13/100\n",
            "3000/3000 [==============================] - 5s 2ms/step - loss: 0.3138 - accuracy: 0.8515 - val_loss: 0.3222 - val_accuracy: 0.8511\n",
            "Epoch 14/100\n",
            "3000/3000 [==============================] - 5s 2ms/step - loss: 0.3041 - accuracy: 0.8565 - val_loss: 0.3213 - val_accuracy: 0.8502\n",
            "Epoch 15/100\n",
            "3000/3000 [==============================] - 5s 2ms/step - loss: 0.3086 - accuracy: 0.8540 - val_loss: 0.3239 - val_accuracy: 0.8495\n",
            "Epoch 16/100\n",
            "3000/3000 [==============================] - 5s 2ms/step - loss: 0.2993 - accuracy: 0.8589 - val_loss: 0.3225 - val_accuracy: 0.8503\n",
            "Epoch 17/100\n",
            "3000/3000 [==============================] - 5s 2ms/step - loss: 0.3036 - accuracy: 0.8540 - val_loss: 0.3208 - val_accuracy: 0.8513\n",
            "Epoch 18/100\n",
            "3000/3000 [==============================] - 5s 2ms/step - loss: 0.3058 - accuracy: 0.8543 - val_loss: 0.3210 - val_accuracy: 0.8505\n",
            "Epoch 19/100\n",
            "3000/3000 [==============================] - 5s 2ms/step - loss: 0.2977 - accuracy: 0.8595 - val_loss: 0.3287 - val_accuracy: 0.8485\n",
            "Epoch 20/100\n",
            "3000/3000 [==============================] - 5s 2ms/step - loss: 0.3044 - accuracy: 0.8548 - val_loss: 0.3226 - val_accuracy: 0.8504\n",
            "Epoch 21/100\n",
            "3000/3000 [==============================] - 5s 2ms/step - loss: 0.3041 - accuracy: 0.8579 - val_loss: 0.3227 - val_accuracy: 0.8500\n",
            "Epoch 22/100\n",
            "3000/3000 [==============================] - 5s 2ms/step - loss: 0.2978 - accuracy: 0.8581 - val_loss: 0.3177 - val_accuracy: 0.8531\n",
            "Epoch 23/100\n",
            "3000/3000 [==============================] - 5s 2ms/step - loss: 0.3008 - accuracy: 0.8579 - val_loss: 0.3227 - val_accuracy: 0.8504\n",
            "Epoch 24/100\n",
            "3000/3000 [==============================] - 5s 2ms/step - loss: 0.2989 - accuracy: 0.8586 - val_loss: 0.3209 - val_accuracy: 0.8518\n",
            "Epoch 25/100\n",
            "3000/3000 [==============================] - 5s 2ms/step - loss: 0.3025 - accuracy: 0.8548 - val_loss: 0.3200 - val_accuracy: 0.8528\n",
            "Epoch 26/100\n",
            "3000/3000 [==============================] - 5s 2ms/step - loss: 0.2985 - accuracy: 0.8529 - val_loss: 0.3310 - val_accuracy: 0.8481\n",
            "Epoch 27/100\n",
            "3000/3000 [==============================] - 5s 2ms/step - loss: 0.3028 - accuracy: 0.8555 - val_loss: 0.3207 - val_accuracy: 0.8528\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7ffa9e14d748>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7xhHydkNGvJH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6f3c60f-48cd-44aa-adf9-d6a9d6b8bf8c"
      },
      "source": [
        "# predicted accuracy\n",
        "# compare the predicted income with actual income\n",
        "classificationSummary(y2_test, model_2.predict(X2_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  70/2000 [>.............................] - ETA: 1s  "
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2000/2000 [==============================] - 2s 795us/step\n",
            "Confusion Matrix (Accuracy 0.8528)\n",
            "\n",
            "       Prediction\n",
            "Actual    0    1\n",
            "     0 6914  687\n",
            "     1  785 1614\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JYJvYl_JGvJI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab23bf4d-ba99-46c2-9f28-f2bc726502e6"
      },
      "source": [
        "classificationSummary(y2_train, model_2.predict(X2_train))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " 127/3000 [>.............................] - ETA: 2s"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3000/3000 [==============================] - 2s 805us/step\n",
            "Confusion Matrix (Accuracy 0.8596)\n",
            "\n",
            "       Prediction\n",
            "Actual     0     1\n",
            "     0 10396  1019\n",
            "     1  1087  2498\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MAmpVjUjbocf"
      },
      "source": [
        "EDA With Categorical Variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YvGEw4VqGvJI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65f8e1db-40bc-4bd3-a02a-fede79f694c4"
      },
      "source": [
        "# df with predicted income\n",
        "X_feat= df[features]\n",
        "df_predict = pd.DataFrame(model_2.predict(X_feat))\n",
        "df_predict.columns=['predicted_income']\n",
        "df_full = df.join(df_predict)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " 145/5000 [..............................] - ETA: 3s"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "5000/5000 [==============================] - 4s 724us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gpfpfs43MeYx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2439
        },
        "outputId": "a8567468-1e89-4313-fa9a-4c0f65d1b91b"
      },
      "source": [
        "#Top 3 categorical variables\r\n",
        "plt.figure(figsize=(20, 8))\r\n",
        "sns.countplot(x = \"m_Never-married\", data = df_full, hue = \"predicted_income\")\r\n",
        "\r\n",
        "plt.figure(figsize=(20, 8))\r\n",
        "sns.countplot(x = \"r_Husband\", data = df_full, hue = \"predicted_income\")\r\n",
        "\r\n",
        "plt.figure(figsize=(20, 8))\r\n",
        "sns.countplot(x = \"m_Divorced\", data =df_full, hue = \"predicted_income\")\r\n",
        "\r\n",
        "plt.figure(figsize=(20, 8))\r\n",
        "sns.countplot(x = \"o_Other-service\", data = df_full, hue = \"predicted_income\")\r\n",
        "\r\n",
        "plt.figure(figsize=(20, 8))\r\n",
        "sns.countplot(x = \"c_United-States\", data = df_full, hue = \"predicted_income\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7ffa9865c2b0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 119
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABJ8AAAHhCAYAAADAnR9nAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dfbRfZXkn/O9lAkIrDm+RUgISFWwDxigh4tQqShVktUD7oMJCeVOjo2htp50Hy7OEh0pLX5xWRkcfqgi0jKD4AloqMvg2ukRJNPJaJKKWRIRMcFArKMT7+ePs4E84JxxC7vySk89nrb3O/l373ntfO39lfde+712ttQAAAABAD48bdwMAAAAAzFzCJwAAAAC6ET4BAAAA0I3wCQAAAIBuhE8AAAAAdCN8AgAAAKCb2eNuYFPbdddd29577z3uNgAAAABmjGXLlv3v1tqcyY5tdeHT3nvvnaVLl467DQAAAIAZo6q+O9Ux0+4AAAAA6Eb4BAAAAEA3wicAAAAAutnq1nwCAAAAZr77778/K1euzH333TfuVmaU7bbbLnPnzs0222wz7XOETwAAAMCMs3Llyuywww7Ze++9U1XjbmdGaK1lzZo1WblyZebNmzft80y7AwAAAGac++67L7vssovgaSOqquyyyy6P+m0y4RMAAAAwIwmeNr4N+TcVPgEAAADQjfAJAAAAYMSJJ56YSy+99JdqT3jCEx7xvNe85jW56aabkiR/8Rd/8ajve/755+eUU06Z9Nh5552XZzzjGVmwYEH233//XHbZZQ+e873vfW9a157OuB6ETwAAAAAbwfve977Mnz8/yYaFT1NZuXJlzjrrrHzxi1/Mddddl2uuuSYLFixIInwCAAAA2KxceOGFWbBgQZ75zGfmVa961aM+/3Of+1wOPvjgHH300fmN3/iNHHfccWmtJUkOPvjgLF26NKeeemruvffeLFy4MMcdd1yS5J/+6Z+yePHiLFy4MK973euydu3aJMkHPvCB7Lvvvlm8eHG+9KUvTXrPu+66KzvssMODb1894QlPyLx583LppZdm6dKlOe6447Jw4cLce++9OfPMM3PggQdm//33z5IlS9Jam3TcsmXL8oIXvCAHHHBADj300Nxxxx1JknPOOSfz58/PggULcswxxzzqf5/JCJ8AAACArcKNN96Yt7/97fnMZz6Tb3zjG3nnO9+5Qdf5+te/nr//+7/PTTfdlNtuu+1hodHZZ5+d7bffPsuXL89FF12Um2++OZdcckm+9KUvZfny5Zk1a1Yuuuii3HHHHTn99NPzpS99KV/84hcfnLL3UM985jOz2267Zd68eTnppJPyiU98Ikly9NFHZ9GiRbnooouyfPnybL/99jnllFNy7bXX5oYbbsi9996bT37ykw8bN3v27LzpTW/KpZdemmXLluXkk0/Oaaed9mDvX//613Pdddflve997wb9+zzU7I1yFQAAAIDN3Gc+85m87GUvy6677pok2XnnnScdN9kX3UZrixcvzty5c5MkCxcuzHe+850873nPm/K+V199dZYtW5YDDzwwSXLvvffmSU96Ur7yla/k4IMPzpw5c5Ikr3jFK/LNb37zYefPmjUrn/rUp3Lttdfm6quvzh/90R9l2bJlOeOMMx429rOf/Wz++q//Oj/5yU9y9913Z7/99svv/d7v/dKYW265JTfccENe/OIXJ0nWrl2b3XffPUmyYMGCHHfccTnqqKNy1FFHTflMj4bwCQAAAGDELrvskh/84AcP/r777rsfDKyS5PGPf/yD+7NmzcoDDzyw3uu11nLCCSfkL//yL3+p/vGPf3zS8WvXrs0BBxyQJDniiCNy5plnpqqyePHiLF68OC9+8Ytz0kknPSx8uu+++/KGN7whS5cuzZ577pkzzjgj991336T97Lfffvnyl7/8sGP//M//nC984Qv5xCc+kbPOOivXX399Zs9+bPGRaXcAAADAVuFFL3pRPvzhD2fNmjVJJkKlyRx88MG55JJL8rOf/SzJxGLdL3zhCx/VvbbZZpvcf//9SZJDDjkkl156ae66664H7/vd7343z3nOc/L5z38+a9asyf33358Pf/jDSSYCreXLl2f58uU588wz873vfS9f+9rXHrz28uXL8+QnPzlJssMOO+RHP/pRkjwYNO2666758Y9//Etf7Bsd9/SnPz2rV69+MHy6//77c+ONN+bnP/95br/99rzwhS/MX/3VX+Wee+7Jj3/840f13JPx5hMAAACwVdhvv/1y2mmn5QUveEFmzZqVZz3rWTn//PMfNu53f/d3s2zZshxwwAGZNWtWnvrUpz7q9Y+WLFmSBQsW5NnPfnYuuuiivP3tb89LXvKS/PznP88222yTd7/73TnooINyxhln5LnPfW523HHHLFy4cNJr3X///fmTP/mTfO9738t2222XOXPmPNjPiSeemNe//vXZfvvt8+Uvfzmvfe1rs//+++fXfu3XHpzmN9m4Sy+9NG9+85tzzz335IEHHshb3vKW7LvvvnnlK1+Ze+65J621vPnNb86OO+74qJ57MrVuRfatxaJFi9rSpUvH3QYAAADQ0c0335zf/M3fHHcbM9Jk/7ZVtay1tmiy8abdAQAAANCNaXcAAADAVumss856cJ2ldV72spfltNNOG1NHM5PwCWAj+LcznzHuFmCrtNfbrh93CwDAFuy0004TNG0C3abdVdWeVfXZqrqpqm6sqj8c6jtX1VVVdevwd6ehXlV1TlWtqKrrqurZI9c6YRh/a1WdMFI/oKquH845p6qq1/MAAAAA8Oj1XPPpgST/ubU2P8lBSd5YVfOTnJrk6tbaPkmuHn4nyUuT7DNsS5K8J5kIq5KcnuQ5SRYnOX1dYDWMee3IeYd1fB4AAAAAHqVu4VNr7Y7W2teG/R8luTnJHkmOTHLBMOyCJEcN+0cmubBNuCbJjlW1e5JDk1zVWru7tfaDJFclOWw49sTW2jVt4pN9F45cCwAAAIDNwCb52l1V7Z3kWUm+kmS31todw6HvJ9lt2N8jye0jp60cauurr5ykDgAAADCjfepTn8rTn/70PO1pT8vZZ5897nbWq/uC41X1hCQfSfKW1toPR5dlaq21qmqboIclmZjKl7322qv37QAAAICtxAF/euFGvd6yvzn+EcesXbs2b3zjG3PVVVdl7ty5OfDAA3PEEUdk/vz5G7WXjaXrm09VtU0mgqeLWmsfHcp3DlPmMvy9a6ivSrLnyOlzh9r66nMnqT9Ma+3c1tqi1tqiOXPmPLaHAgAAABijr371q3na056WpzzlKdl2221zzDHH5LLLLht3W1Pq+bW7SvL+JDe31v7ryKHLk6z7Yt0JSS4bqR8/fPXuoCT3DNPzrkzykqraaVho/CVJrhyO/bCqDhrudfzItQAAAABmpFWrVmXPPX/xns7cuXOzatWk7+NsFnpOu/utJK9Kcn1VLR9qf5bk7CQfqqpXJ/lukpcPx65IcniSFUl+kuSkJGmt3V1Vf57k2mHcma21u4f9NyQ5P8n2Sf5l2AAAAADYTHQLn1prX0xSUxw+ZJLxLckbp7jWeUnOm6S+NMn+j6FNAAAAgC3KHnvskdtv/8W32VauXJk99th8v8G2Sb52BwAAAMDGceCBB+bWW2/Nt7/97fzsZz/LxRdfnCOOOGLcbU2p+9fuAAAAANh4Zs+enXe961059NBDs3bt2px88snZb7/9xt3WlIRPAAAAABto2d8cP5b7Hn744Tn88MPHcu9Hy7Q7AAAAALoRPgEAAADQjfAJAAAAgG6ETwAAAAB0I3wCAAAAoBvhEwAAAADdCJ8AAAAAtiAnn3xynvSkJ2X//fcfdyvTMnvcDQAAAABsqf7tzGds1Ovt9bbrH3HMiSeemFNOOSXHH3/8Rr13L958AgAAANiCPP/5z8/OO+887jamTfgEAAAAQDfCJwAAAAC6ET4BAAAA0I3wCQAAAIBuhE8AAAAAW5Bjjz02z33uc3PLLbdk7ty5ef/73z/ultZr9rgbAAAAANhS7fW26zf5PT/4wQ9u8ns+Ft58AgAAAKAb4RMAAAAA3QifAAAAAOhG+AQAAADMSK21cbcw42zIv6nwCQAAAJhxtttuu6xZs0YAtRG11rJmzZpst912j+o8X7sDAAAAZpy5c+dm5cqVWb169bhbmVG22267zJ0791GdI3wCAAAAZpxtttkm8+bNG3cbxLQ7AAAAADoSPgEAAADQjfAJAAAAgG6ETwAAAAB0I3wCAAAAoBvhEwAAAADdCJ8AAAAA6Eb4BAAAAEA3wicAAAAAuhE+AQAAANCN8AkAAACAboRPAAAAAHQjfAIAAACgG+ETAAAAAN0InwAAAADoRvgEAAAAQDfCJwAAAAC66RY+VdV5VXVXVd0wUrukqpYP23eqavlQ37uq7h059t6Rcw6oquurakVVnVNVNdR3rqqrqurW4e9OvZ4FAAAAgA3T882n85McNlporb2itbawtbYwyUeSfHTk8LfWHWutvX6k/p4kr02yz7Ctu+apSa5ure2T5OrhNwAAAACbkW7hU2vtC0nunuzY8PbSy5N8cH3XqKrdkzyxtXZNa60luTDJUcPhI5NcMOxfMFIHAAAAYDMxrjWffjvJna21W0dq86rq61X1+ar67aG2R5KVI2NWDrUk2a21dsew//0ku3XtGAAAAIBHbfaY7ntsfvmtpzuS7NVaW1NVByT5eFXtN92LtdZaVbWpjlfVkiRLkmSvvfbawJYBAAAAeLQ2+ZtPVTU7yR8kuWRdrbX209bammF/WZJvJdk3yaokc0dOnzvUkuTOYVreuul5d011z9baua21Ra21RXPmzNmYjwMAAADAeoxj2t3vJPnX1tqD0+mqak5VzRr2n5KJhcVvG6bV/bCqDhrWiTo+yWXDaZcnOWHYP2GkDgAAAMBmolv4VFUfTPLlJE+vqpVV9erh0DF5+ELjz09yXVUtT3Jpkte31tYtVv6GJO9LsiITb0T9y1A/O8mLq+rWTARaZ/d6FgAAAAA2TLc1n1prx05RP3GS2keSfGSK8UuT7D9JfU2SQx5blwAAAAD0NK6v3QEAAACwFRA+AQAAANCN8AkAAACAboRPAAAAAHQjfAIAAACgG+ETAAAAAN0InwAAAADoRvgEAAAAQDfCJwAAAAC6ET4BAAAA0I3wCQAAAIBuhE8AAAAAdCN8AgAAAKAb4RMAAAAA3QifAAAAAOhG+AQAAABAN8InAAAAALoRPgEAAADQjfAJAAAAgG6ETwAAAAB0I3wCAAAAoBvhEwAAAADdCJ8AAAAA6Eb4BAAAAEA3wicAAAAAuhE+AQAAANCN8AkAAACAboRPAAAAAHQjfAIAAACgG+ETAAAAAN0InwAAAADoRvgEAAAAQDfCJwAAAAC6ET4BAAAA0I3wCQAAAIBuhE8AAAAAdCN8AgAAAKAb4RMAAAAA3QifAAAAAOhG+AQAAABAN8InAAAAALoRPgEAAADQTbfwqarOq6q7quqGkdoZVbWqqpYP2+Ejx95aVSuq6paqOnSkfthQW1FVp47U51XVV4b6JVW1ba9nAQAAAGDD9Hzz6fwkh01S/7vW2sJhuyJJqmp+kmOS7Dec89+ralZVzUry7iQvTTI/ybHD2CT5q+FaT0vygySv7vgsAAAAAGyAbuFTa+0LSe6e5vAjk1zcWvtpa+3bSVYkWTxsK1prt7XWfpbk4iRHVlUleVGSS4fzL0hy1EZ9AAAAAAAes3Gs+XRKVV03TMvbaajtkeT2kTErh9pU9V2S/J/W2gMPqQMAAACwGdnU4dN7kjw1ycIkdyR5x6a4aVUtqaqlVbV09erVm+KWAAAAAGQTh0+ttTtba2tbaz9P8g+ZmFaXJKuS7DkydO5Qm6q+JsmOVTX7IfWp7ntua21Ra23RnDlzNs7DAAAAAPCINmn4VFW7j/z8/STrvoR3eZJjqurxVTUvyT5Jvprk2iT7DF+22zYTi5Jf3lprST6b5Ojh/BOSXLYpngEAAACA6Zv9yEM2TFV9MMnBSXatqpVJTk9ycFUtTNKSfCfJ65KktXZjVX0oyU1JHkjyxtba2uE6pyS5MsmsJOe11m4cbvF/J7m4qt6e5OtJ3t/rWQAAAADYMN3Cp9basZOUpwyIWmtnJTlrkvoVSa6YpH5bfjFtDwAAAIDN0Di+dgcAAADAVkL4BAAAAEA3wicAAAAAuhE+AQAAANCN8AkAAACAboRPAAAAAHQjfAIAAACgG+ETAAAAAN0InwAAAADoRvgEAAAAQDfCJwAAAAC6ET4BAAAA0I3wCQAAAIBuhE8AAAAAdCN8AgAAAKAb4RMAAAAA3QifAAAAAOhG+AQAAABAN8InAAAAALoRPgEAAADQjfAJAAAAgG6ETwAAAAB0I3wCAAAAoBvhEwAAAADdCJ8AAAAA6Eb4BAAAAEA3wicAAAAAuhE+AQAAANCN8AkAAACAboRPAAAAAHQjfAIAAACgG+ETAAAAAN0InwAAAADoRvgEAAAAQDfCJwAAAAC6ET4BAAAA0I3wCQAAAIBuhE8AAAAAdCN8AgAAAKAb4RMAAAAA3QifAAAAAOhG+AQAAABAN8InAAAAALrpFj5V1XlVdVdV3TBS+5uq+tequq6qPlZVOw71vavq3qpaPmzvHTnngKq6vqpWVNU5VVVDfeequqqqbh3+7tTrWQAAAADYMD3ffDo/yWEPqV2VZP/W2oIk30zy1pFj32qtLRy214/U35PktUn2GbZ11zw1ydWttX2SXD38BgAAAGAz0i18aq19IcndD6l9urX2wPDzmiRz13eNqto9yRNba9e01lqSC5McNRw+MskFw/4FI3UAAAAANhPjXPPp5CT/MvJ7XlV9vao+X1W/PdT2SLJyZMzKoZYku7XW7hj2v59kt6luVFVLqmppVS1dvXr1RmofAAAAgEcylvCpqk5L8kCSi4bSHUn2aq09K8kfJ/kfVfXE6V5veCuqref4ua21Ra21RXPmzHkMnQMAAADwaMze1DesqhOT/G6SQ4bQKK21nyb56bC/rKq+lWTfJKvyy1Pz5g61JLmzqnZvrd0xTM+7axM9AgAAAADTtEnffKqqw5L8lyRHtNZ+MlKfU1Wzhv2nZGJh8duGaXU/rKqDhq/cHZ/ksuG0y5OcMOyfMFIHAAAAYDPR7c2nqvpgkoOT7FpVK5Ocnomv2z0+yVUTWVKuGb5s9/wkZ1bV/Ul+nuT1rbV1i5W/IRNfzts+E2tErVsn6uwkH6qqVyf5bpKX93oWAAAAADZMt/CptXbsJOX3TzH2I0k+MsWxpUn2n6S+Jskhj6VHAAAAAPoa59fuAAAAAJjhhE8AAAAAdCN8AgAAAKAb4RMAAAAA3QifAAAAAOhG+AQAAABAN8InAAAAALoRPgEAAADQjfAJAAAAgG6ETwAAAAB0I3wCAAAAoBvhEwAAAADdCJ8AAAAA6Eb4BAAAAEA3wicAAAAAuhE+AQAAANCN8AkAAACAboRPAAAAAHQjfAIAAACgG+ETAAAAAN0InwAAAADoZlrhU1VdPZ0aAAAAAIyavb6DVbVdkl9JsmtV7ZSkhkNPTLJH594AAAAA2MKtN3xK8rokb0ny60mW5Rfh0w+TvKtjXwAAAADMAOsNn1pr70zyzqp6U2vtv22ingAAAACYIR7pzackSWvtv1XVf0yy9+g5rbULO/UFAAAAwAwwrfCpqv4xyVOTLE+ydii3JMInAAAAAKY0rfApyaIk81trrWczAAAAAMwsj5vmuBuS/FrPRgAAAACYeab75tOuSW6qqq8m+em6YmvtiC5dAQAAADAjTDd8OqNnEwAAAADMTNP92t3nezcCAAAAwMwz3a/d/SgTX7dLkm2TbJPk31trT+zVGAAAAABbvum++bTDuv2qqiRHJjmoV1MAAAAAzAzT/drdg9qEjyc5tEM/AAAAAMwg05129wcjPx+XZFGS+7p0BAAAAMCMMd2v3f3eyP4DSb6Tial3AAAAADCl6a75dFLvRgAAAACYeaa15lNVza2qj1XVXcP2kaqa27s5AAAAALZs011w/ANJLk/y68P2iaEGAAAAAFOabvg0p7X2gdbaA8N2fpI5HfsCAAAAYAaYbvi0pqpeWVWzhu2VSdb0bAwAAACALd90w6eTk7w8yfeT3JHk6CQnPtJJVXXesEbUDSO1navqqqq6dfi701CvqjqnqlZU1XVV9eyRc04Yxt9aVSeM1A+oquuHc86pqprm8wAAAACwCUw3fDozyQmttTmttSdlIoz6f6dx3vlJDntI7dQkV7fW9kly9fA7SV6aZJ9hW5LkPclEWJXk9CTPSbI4yenrAqthzGtHznvovQAAAAAYo+mGTwtaaz9Y96O1dneSZz3SSa21LyS5+yHlI5NcMOxfkOSokfqFbcI1SXasqt2THJrkqtba3UMPVyU5bDj2xNbaNa21luTCkWsBAAAAsBmYbvj0uJG3jda9jTR7A++5W2vtjmH/+0l2G/b3SHL7yLiVQ2199ZWT1B+mqpZU1dKqWrp69eoNbBsAAACAR2u6AdI7kny5qj48/H5ZkrMe681ba62q2mO9zjTuc26Sc5Nk0aJF3e8HAAAAwIRpvfnUWrswyR8kuXPY/qC19o8beM87hylzGf7eNdRXJdlzZNzcoba++txJ6gAAAABsJqY77S6ttZtaa+8atpsewz0vT7Lui3UnJLlspH788NW7g5LcM0zPuzLJS6pqp2Hq30uSXDkc+2FVHTR85e74kWsBAAAAsBnY0HWbpqWqPpjk4CS7VtXKTHy17uwkH6qqVyf5bpKXD8OvSHJ4khVJfpLkpGRicfOq+vMk1w7jzhwWPE+SN2Tii3rbJ/mXYQMAAABgM9E1fGqtHTvFoUMmGduSvHGK65yX5LxJ6kuT7P9YegQAAACgn2lPuwMAAACAR0v4BAAAAEA3wicAAAAAuhE+AQAAANCN8AkAAACAboRPAAAAAHQjfAIAAACgG+ETAAAAAN0InwAAAADoRvgEAAAAQDfCJwAAAAC6ET4BAAAA0I3wCQAAAIBuhE8AAAAAdCN8AgAAAKAb4RMAAAAA3QifAAAAAOhG+AQAAABAN8InAAAAALoRPgEAAADQjfAJAAAAgG6ETwAAAAB0I3wCAAAAoBvhEwAAAADdCJ8AAAAA6Eb4BAAAAEA3wicAAAAAuhE+AQAAANCN8AkAAACAboRPAAAAAHQjfAIAAACgG+ETAAAAAN0InwAAAADoRvgEAAAAQDfCJwAAAAC6ET4BAAAA0I3wCQAAAIBuhE8AAAAAdCN8AgAAAKAb4RMAAAAA3QifAAAAAOhG+AQAAABAN5s8fKqqp1fV8pHth1X1lqo6o6pWjdQPHznnrVW1oqpuqapDR+qHDbUVVXXqpn4WAAAAANZv9qa+YWvtliQLk6SqZiVZleRjSU5K8nettb8dHV9V85Mck2S/JL+e5H9W1b7D4XcneXGSlUmurarLW2s3bZIHAQAAAOARbfLw6SEOSfKt1tp3q2qqMUcmubi19tMk366qFUkWD8dWtNZuS5KqungYK3wCAAAA2EyMe82nY5J8cOT3KVV1XVWdV1U7DbU9ktw+MmblUJuqDgAAAMBmYmzhU1Vtm+SIJB8eSu9J8tRMTMm7I8k7NuK9llTV0qpaunr16o11WQAAAAAewTjffHppkq+11u5Mktbana21ta21nyf5h/xiat2qJHuOnDd3qE1Vf5jW2rmttUWttUVz5szZyI8BAAAAwFTGGT4dm5Epd1W1+8ix309yw7B/eZJjqurxVTUvyT5Jvprk2iT7VNW84S2qY4axAAAAAGwmxrLgeFX9aia+Uve6kfJfV9XCJC3Jd9Yda63dWFUfysRC4g8keWNrbe1wnVOSXJlkVpLzWms3brKHAAAAAOARjSV8aq39e5JdHlJ71XrGn5XkrEnqVyS5YqM3CAAAAMBGMe6v3QEAAAAwgwmfAAAAAOhG+AQAAABAN8InAAAAALoRPgEAAADQjfAJAAAAgG6ETwAAAAB0I3wCAAAAoBvhEwAAAADdCJ8AAAAA6Eb4BAAAAEA3wicAAAAAuhE+AQAAANCN8AkAAACAboRPAAAAAHQjfAIAAACgG+ETAAAAAN0InwAAAADoRvgEAAAAQDfCJwAAAAC6ET4BAAAA0I3wCQAAAIBuhE8AAAAAdCN8AgAAAKAb4RMAAAAA3QifAAAAAOhG+AQAAABAN8InAAAAALoRPgEAAADQjfAJAAAAgG6ETwAAAAB0I3wCAAAAoBvhEwAAAADdCJ8AAAAA6Eb4BAAAAEA3wicAAAAAuhE+AQAAANCN8AkAAACAboRPAAAAAHQjfAIAAACgG+ETAAAAAN0InwAAAADoZmzhU1V9p6qur6rlVbV0qO1cVVdV1a3D352GelXVOVW1oqquq6pnj1znhGH8rVV1wrieBwAAAICHG/ebTy9srS1srS0afp+a5OrW2j5Jrh5+J8lLk+wzbEuSvCeZCKuSnJ7kOUkWJzl9XWAFAAAAwPiNO3x6qCOTXDDsX5DkqJH6hW3CNUl2rKrdkxya5KrW2t2ttR8kuSrJYZu6aQAAAAAmN87wqSX5dFUtq6olQ2231todw/73k+w27O+R5PaRc1cOtanqAAAAAGwGZo/x3s9rra2qqicluaqq/nX0YGutVVXbGDcawq0lSbLXXnttjEsCAAAAMA1je/OptbZq+HtXko9lYs2mO4fpdBn+3jUMX5Vkz5HT5w61qeoPvde5rbVFrbVFc+bM2diPAgAAAMAUxhI+VdWvVtUO6/aTvCTJDUkuT7Lui3UnJLls2L88yfHDV+8OSnLPMD3vyiQvqaqdhoXGXzLUAAAAANgMjGva3W5JPlZV63r4H621T1XVtUk+VFWvTvLdJC8fxl+R5PAkK5L8JMlJSdJau7uq/jzJtcO4M1trd2+6xwAAAABgfcYSPrXWbkvyzEnqa5IcMkm9JXnjFNc6L8l5G7tHAAAAAB67cX7tDgAAAIAZTvgEAAAAQDfCJwAAAAC6ET4BAAAA0I3wCQAAAIBuhE8AAAAAdCN8AgAAAKAb4RMAAAAA3QifAAAAAOhG+AQAAABAN8InAAAAALoRPgEAAADQjVGS3pYAAAo8SURBVPAJAAAAgG6ETwAAAAB0I3wCAAAAoBvhEwAAAADdCJ8AAAAA6Eb4BAAAAEA3wicAAAAAuhE+AQAAANCN8AkAAACAboRPAAAAAHQjfAIAAACgG+ETAAAAAN0InwAAAADoRvgEAAAAQDfCJwAAAAC6ET4BAAAA0I3wCQAAAIBuhE8AAAAAdCN8AgAAAKAb4RMAAAAA3QifAAAAAOhG+AQAAABAN8InAAAAALoRPgEAAADQjfAJAAAAgG6ETwAAAAB0I3wCAAAAoBvhEwAAAADdCJ8AAAAA6Eb4BAAAAEA3mzx8qqo9q+qzVXVTVd1YVX841M+oqlVVtXzYDh85561VtaKqbqmqQ0fqhw21FVV16qZ+FgAAAADWb/YY7vlAkv/cWvtaVe2QZFlVXTUc+7vW2t+ODq6q+UmOSbJfkl9P8j+rat/h8LuTvDjJyiTXVtXlrbWbNslTAAAAAPCINnn41Fq7I8kdw/6PqurmJHus55Qjk1zcWvtpkm9X1Yoki4djK1prtyVJVV08jBU+AQAAAGwmxrrmU1XtneRZSb4ylE6pquuq6ryq2mmo7ZHk9pHTVg61qeoAAAAAbCbGFj5V1ROSfCTJW1prP0zyniRPTbIwE29GvWMj3mtJVS2tqqWrV6/eWJcFAAAA4BGMJXyqqm0yETxd1Fr7aJK01u5sra1trf08yT/kF1PrViXZc+T0uUNtqvrDtNbOba0taq0tmjNnzsZ9GAAAAACmNI6v3VWS9ye5ubX2X0fqu48M+/0kNwz7lyc5pqoeX1XzkuyT5KtJrk2yT1XNq6ptM7Eo+eWb4hkAAAAAmJ5xfO3ut5K8Ksn1VbV8qP1ZkmOramGSluQ7SV6XJK21G6vqQ5lYSPyBJG9sra1Nkqo6JcmVSWYlOa+1duOmfBAAAAAA1m8cX7v7YpKa5NAV6znnrCRnTVK/Yn3nAQAAADBeY/3aHQAAAAAz2zim3dHRAX964bhbgK3Sx3YYdwcAAACbJ+ETAADAVuTfznzGuFuArdJeb7t+3C2MjWl3AAAAAHQjfAIAAACgG+ETAAAAAN0InwAAAADoRvgEAAAAQDfCJwAAAAC6ET4BAAAA0I3wCQAAAIBuhE8AAAAAdCN8AgAAAKAb4RMAAAAA3QifAAAAAOhG+AQAAABAN8InAAAAALoRPgEAAADQjfAJAAAAgG6ETwAAAAB0I3wCAAAAoBvhEwAAAADdCJ8AAAAA6Eb4BAAAAEA3wicAAAAAuhE+AQAAANCN8AkAAACAboRPAAAAAHQjfAIAAACgG+ETAAAAAN0InwAAAADoRvgEAAAAQDfCJwAAAAC6ET4BAAAA0I3wCQAAAIBuhE8AAAAAdCN8AgAAAKAb4RMAAAAA3cwedwMAAGydDvjTC8fdAmyVPrbDuDsAtjbefAIAAACgG+ETAAAAAN0InwAAAADoZosPn6rqsKq6papWVNWp4+4HAAAAgF/YosOnqpqV5N1JXppkfpJjq2r+eLsCAAAAYJ0tOnxKsjjJitbaba21nyW5OMmRY+4JAAAAgMGWHj7tkeT2kd8rhxoAAAAAm4HZ425gU6iqJUmWDD9/XFW3jLMfYOZ5crJrkv897j5gq3N6jbsDgC2O/7fAmMz8/7c8eaoDW3r4tCrJniO/5w61X9JaOzfJuZuqKWDrU1VLW2uLxt0HAMAj8f8WYFPb0qfdXZtkn6qaV1XbJjkmyeVj7gkAAACAwRb95lNr7YGqOiXJlUlmJTmvtXbjmNsCAAAAYLBFh09J0lq7IskV4+4D2OqZ2gsAbCn8vwXYpKq1Nu4eAAAAAJihtvQ1nwAAAADYjAmfAB6Dqjqsqm6pqhVVdeq4+wEAmEpVnVdVd1XVDePuBdi6CJ8ANlBVzUry7iQvTTI/ybFVNX+8XQEATOn8JIeNuwlg6yN8Athwi5OsaK3d1lr7WZKLkxw55p4AACbVWvtCkrvH3Qew9RE+AWy4PZLcPvJ75VADAABgIHwCAAAAoBvhE8CGW5Vkz5Hfc4caAAAAA+ETwIa7Nsk+VTWvqrZNckySy8fcEwAAwGZF+ASwgVprDyQ5JcmVSW5O8qHW2o3j7QoAYHJV9cEkX07y9KpaWVWvHndPwNahWmvj7gEAAACAGcqbTwAAAAB0I3wCAAAAoBvhEwAAAADdCJ8AAAAA6Eb4BAAAAEA3wicAAAAAuhE+AQBMU1XNrarLqurWqvpWVb2zqrYdji2sqsNHxp5RVX8yvm4fWVUdUVWnjrsPAGBmEz4BAExDVVWSjyb5eGttnyT7JnlCkrOGIQuTHD7F6Rtyv1kb6TqzpzrWWru8tXb2xrgPAMBUhE8AwFavqv64qm4YtrdMMexFSe5rrX0gSVpra5P8UZKTq+qJSc5M8oqqWl5VrxjOmV9Vn6uq26rqzSP3e2VVfXUY+/+tC5qq6sdV9Y6q+kaS5z6kx7Or6qaquq6q/naozamqj1TVtcP2W0P9jKr6x6r6UpJ/rKprqmq/kWt9rqoWVdWJVfWuobZbVX2sqr4xbP9xfb0CAEyX8AkA2KpV1QFJTkrynCQHJXltVT1rkqH7JVk2Wmit/TDJvyXZO8nbklzSWlvYWrtkGPIbSQ5NsjjJ6VW1TVX9ZpJXJPmt1trCJGuTHDeM/9UkX2mtPbO19sWRHndJ8vtJ9mutLUjy9uHQO5P8XWvtwCT/V5L3jbQ3P8nvtNaOTXJJkpcP19o9ye6ttaUPeb5zkny+tfbMJM9OcuMj9AoAMC1TvoYNALCVeF6Sj7XW/j1JquqjSX47ydc3wrX/ubX20yQ/raq7kuyW5JAkByS5dmImX7ZPctcwfm2Sj0xynXuS3Jfk/VX1ySSfHOq/k4m3q9aNe2JVPWHYv7y1du+w/6Ekn05yeiZCqEsnuceLkhyfPPhW1z1V9ar19AoAMC3CJwCA6bkpydGjhWG63V5JVmTibaGH+unI/tpM/N+rklzQWnvrJOPvG4KfVNWVmQirlrbWXlNVizMRXB2d5JRMhEWPS3JQa+2+h/SVJP++7ndrbVVVramqBZl4k+n103zm9fUKADAtpt0BAFu7/5XkqKr6lar61UxMb/tfk4y7OsmvVNXxyYMLgr8jyfmttZ8k+VGSHaZxv6uTHF1VTxqus3NVPfmhg1prhw5T+F4zvM30H1prV2RinalnDsM+neRN686pqoXrue8lSf7LcJ3rpujrP617tqr6D9PtFQBgfYRPAMBWrbX2tSTnJ/lqkq8keV9r7WFT7lprLRPB1Muq6tYk38zEVLg/G4Z8NhNT4EYXHJ/sfjcl+X+SfLqqrktyVZLdH6HNHZJ8chj/xSR/PNTfnGTRsAj5TVn/G02XJjkmE1PwJvOHSV5YVddnYm2r+RvYKwDAL6mJ/0cBAAAAwMbnzScAAAAAurHgOADAiKraJRNrHT3UIa21NZu6HwCALZ1pdwAAAAB0Y9odAAAAAN0InwAAAADoRvgEAAAAQDfCJwAAAAC6ET4BAAAA0M3/D4ajkE8nMAyKAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 1440x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ycxKY0DDdKJW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "outputId": "227aee2d-487d-43f8-88db-18c3841ff4c2"
      },
      "source": [
        "pd.crosstab(df_full['predicted_income'], df_full[\"m_Never-married\"])\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>m_Never-married</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>predicted_income</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>11202</td>\n",
              "      <td>7980</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5573</td>\n",
              "      <td>245</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "m_Never-married       0     1\n",
              "predicted_income             \n",
              "0                 11202  7980\n",
              "1                  5573   245"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "-aQelVZvjqaM",
        "outputId": "d9f6ab84-9b0b-400c-a6d7-da8ba414e7e4"
      },
      "source": [
        "pd.crosstab(df_full['predicted_income'], df_full[\"m_Divorced\"])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>m_Divorced</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>predicted_income</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>15977</td>\n",
              "      <td>3205</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5588</td>\n",
              "      <td>230</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "m_Divorced            0     1\n",
              "predicted_income             \n",
              "0                 15977  3205\n",
              "1                  5588   230"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "Z87aPYdsjqt8",
        "outputId": "03d3cd80-f2fa-4f86-91cd-7015a74b3609"
      },
      "source": [
        "pd.crosstab(df_full['predicted_income'], df_full[\"r_Husband\"])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>r_Husband</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>predicted_income</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>13683</td>\n",
              "      <td>5499</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1253</td>\n",
              "      <td>4565</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "r_Husband             0     1\n",
              "predicted_income             \n",
              "0                 13683  5499\n",
              "1                  1253  4565"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "UygjMGLkj4uY",
        "outputId": "40fb3319-2224-4af3-9c11-2f10c4dc40e8"
      },
      "source": [
        "pd.crosstab(df_full['predicted_income'], df_full[\"o_Other-service\"])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>o_Other-service</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>predicted_income</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>16650</td>\n",
              "      <td>2532</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5795</td>\n",
              "      <td>23</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "o_Other-service       0     1\n",
              "predicted_income             \n",
              "0                 16650  2532\n",
              "1                  5795    23"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "SFQuU3Wtj6Oj",
        "outputId": "ee6cc288-06ae-4780-9275-4e7d027bfed3"
      },
      "source": [
        "pd.crosstab(df_full['predicted_income'], df_full[\"c_United-States\"])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>c_United-States</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>predicted_income</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2158</td>\n",
              "      <td>17024</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>421</td>\n",
              "      <td>5397</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "c_United-States      0      1\n",
              "predicted_income             \n",
              "0                 2158  17024\n",
              "1                  421   5397"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QWtTJgYwKzN6"
      },
      "source": [
        "EDA Numerical Variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WsC2ESZTGvJJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "outputId": "49c26a30-190c-406b-f0e8-4e50c7f6c87f"
      },
      "source": [
        "# histogram for education-num overlay with income\r\n",
        "plt.figure(figsize=(10, 5))\r\n",
        "plt.hist(df[\"education-num\"], 10, color='r', alpha=0.5, label='education-num')\r\n",
        "plt.hist(df[\"income\"], 10, color='b', alpha=0.5, label='income')\r\n",
        "plt.legend(loc='upper right')\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Ush0C90dcUb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "outputId": "c3261a06-88a6-41fd-81cf-182003384ef5"
      },
      "source": [
        "# histogram for demogweight overlay with income\r\n",
        "plt.figure(figsize=(10, 5))\r\n",
        "plt.hist(df[\"demogweight\"], 10, color='r', alpha=0.5, label='demogweight')\r\n",
        "plt.hist(df[\"income\"], 10, color='b', alpha=0.5, label='income')\r\n",
        "plt.legend(loc='upper right')\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uv8ZBfp5MfOb"
      },
      "source": [
        "Part Two"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qpaTuuwJcGiG"
      },
      "source": [
        "df2 = pd.read_csv('USCensusTest.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qkOEaShCb6_Z"
      },
      "source": [
        "# data preprocessiong the test data\r\n",
        "\r\n",
        "# educatiion/education-num - drop educatiion\r\n",
        "df2 = df2.drop(columns=['education'])\r\n",
        "\r\n",
        "# standadize inputs\r\n",
        "# continuous variables - MinMax normalization\r\n",
        "scaler = preprocessing.MinMaxScaler()\r\n",
        "df2['age'] = scaler.fit_transform(df2[['age']])\r\n",
        "df2['demogweight'] = scaler.fit_transform(df2[['demogweight']])\r\n",
        "df2['education-num'] = scaler.fit_transform(df2[['education-num']])\r\n",
        "df2['capital-gain'] = scaler.fit_transform(df2[['capital-gain']])\r\n",
        "df2['capital-loss'] = scaler.fit_transform(df2[['capital-loss']])\r\n",
        "df2['hours-per-week'] = scaler.fit_transform(df2[['hours-per-week']])\r\n",
        "\r\n",
        "# categorical variables - Indicator\r\n",
        "df2['sex'].replace({'Male': 1, 'Female': 0}, inplace=True)\r\n",
        "df2 = pd.get_dummies(df2, \r\n",
        "                    prefix=['w', 'o', 'm', 'r', 'race', 'c'], \r\n",
        "                    columns=['workclass', 'occupation', 'marital-status', 'relationship', 'race', 'native-country'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yuCW_C0BcoQQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba62b71b-9960-4c76-9dcb-9423710f2fbd"
      },
      "source": [
        "# full model\r\n",
        "test_pred=model2.predict(df2[features])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  45/1513 [..............................] - ETA: 1s  "
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1513/1513 [==============================] - 2s 1ms/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jfU86gwKk4MJ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_f5Y_RPgnTe_"
      },
      "source": [
        "Created Text File for the Numbpy Array of Model Predictions\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ukViJGQsGvJI"
      },
      "source": [
        "with open('Team7Predictions.txt', 'wb') as f:\r\n",
        "    np.save(f, test_pred, allow_pickle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WbyUtpBQk5AK"
      },
      "source": [
        "with open('Team7Predictions.txt', 'rb') as f:\r\n",
        "    test_set_predictions = np.load(f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7yJA-eoDmaw9",
        "outputId": "6a44df6d-0ef4-4a5f-c683-35093a1a38c9"
      },
      "source": [
        "test_set_predictions"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0],\n",
              "       [0],\n",
              "       [0],\n",
              "       ...,\n",
              "       [0],\n",
              "       [0],\n",
              "       [0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 154
        }
      ]
    }
  ]
}